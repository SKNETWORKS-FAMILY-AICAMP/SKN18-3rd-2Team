import argparse
import os
from typing import List, TypedDict, Literal, Any, Dict

from dotenv import load_dotenv

from langchain_core.prompts import ChatPromptTemplate
from langchain_core.documents import Document
from langchain_core.output_parsers import StrOutputParser
from langgraph.graph import StateGraph, END
from langchain_community.chat_models import ChatOllama

from embedding_utils import get_embedding_model
from custom_pgvector import CustomPGVector
from db_utils import make_conn_str

class RAGState(TypedDict, total=False):
    """ê·¸ëž˜í”„ ìƒíƒœ ì •ì˜"""
    question: str
    k: int
    collection_name: str
    in_domain: bool
    retrieved_docs: List[Document]
    context: str
    answer: str
    citations: List[Dict[str, Any]]


def get_llm() -> ChatOllama:
    """ChatOllama LLMì„ ì´ˆê¸°í™”"""
    model = os.getenv("OLLAMA_MODEL")
    temperature = float(os.getenv("GEN_TEMPERATURE", "0.2"))
    return ChatOllama(model=model, temperature=temperature)


def get_vectorstore(collection_name: str) -> CustomPGVector:
    """pgvector ì»¬ë ‰ì…˜ì„ VectorStoreë¡œ ê°ì‹¼ ê°ì²´ë¥¼ ìƒì„±"""
    embedding_model = get_embedding_model()
    return CustomPGVector(
            conn_str=make_conn_str(),
            embedding_fn=embedding_model,
            table=collection_name,
        )

def build_prompt() -> ChatPromptTemplate:
    """ì˜ì•½í’ˆ ë„ë©”ì¸ì— ë§žì¶˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"""
    return ChatPromptTemplate.from_messages(
        [
            (
                "system",
                (
                    "ë„ˆëŠ” í•œêµ­ì–´ ì˜ì•½í’ˆ ì •ë³´ ì•ˆë‚´ ì±—ë´‡ì´ì•¼. "
                    "ì•„ëž˜ CONTEXT(ê·¼ê±°)ë¥¼ ë°”íƒ•ìœ¼ë¡œë§Œ ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µí•˜ê³ , "
                    "ëª¨ë¥´ëŠ” ê²ƒì€ ëª¨ë¥¸ë‹¤ê³  ë§í•´. "
                    "íš¨ëŠ¥/ìš©ë²•, ì‚¬ìš© ì „ ì£¼ì˜, ìƒí˜¸ìž‘ìš©, ì´ìƒë°˜ì‘, ë³´ê´€ë²• ë“±ì€ ë°˜ë“œì‹œ ì •í™•í•œ í‘œí˜„ì„ ì‚¬ìš©í•´.\n\n"
                    "FORMAT ì§€ì¹¨:\n"
                    "- í•µì‹¬ ìš”ì•½ 3~5ì¤„\n"
                    "- í•„ìš”í•œ ê²½ìš° ëª©ë¡ìœ¼ë¡œ ì •ë¦¬\n"
                    "- ì¶œì²˜ ì œí’ˆëª…ì„ 'ê·¼ê±°' ì„¹ì…˜ì— í•¨ê»˜ í‘œê¸°"
                ),
            ),
            ("human", "ì§ˆë¬¸: {question}\n\nCONTEXT:\n{context}\n\ní•œêµ­ì–´ë¡œ ë‹µë³€í•´ì¤˜."),
        ]
    )


def build_guard_prompt() -> ChatPromptTemplate:
    """
    ì£¼ì œ ì—°ê´€ì„±(ì˜ì•½í’ˆ ë„ë©”ì¸) íŒë³„ í”„ë¡¬í”„íŠ¸.
    - 'YES' ë˜ëŠ” 'NO'ë¡œë§Œ ë‹µí•˜ë„ë¡ ê°•ì œ.
    - YES: ì•½, ë³µì•½, íš¨ëŠ¥, ìš©ë²•/ìš©ëŸ‰, ì´ìƒë°˜ì‘, ìƒí˜¸ìž‘ìš©, ë³´ê´€, ê¸ˆê¸°, ì„±ë¶„, ì œí˜• ë“±ê³¼ ê´€ë ¨.
    """
    return ChatPromptTemplate.from_messages(
        [
            (
                "system",
                (
                    "ë„ˆëŠ” ìž…ë ¥ ë¬¸ìž¥ì´ 'ì˜ì•½í’ˆ/ë³µì•½/ì•½ë¬¼ì •ë³´' ë„ë©”ì¸ê³¼ ê´€ë ¨ ìžˆëŠ”ì§€ íŒë³„í•˜ëŠ” ë¶„ë¥˜ê¸°ì•¼. "
                    "ê´€ë ¨ ìžˆìœ¼ë©´ 'YES', ì—†ìœ¼ë©´ 'NO' ë¼ëŠ” í•œ ë‹¨ì–´ë§Œ ì¶œë ¥í•´."
                ),
            ),
            (
                "human",
                (
                    "íŒë³„ ê¸°ì¤€ ì˜ˆì‹œ:\n"
                    "- YES: ì•½ ì´ë¦„/ì œí’ˆëª…/ì„±ë¶„/íš¨ëŠ¥/ìš©ë²•/ìš©ëŸ‰/ìƒí˜¸ìž‘ìš©/ë³´ê´€/ê¸ˆê¸°/ì£¼ì˜/ë¶€ìž‘ìš©\n"
                    "- NO: ì¼ë°˜ ìƒì‹, ì‹œì‚¬, ì£¼ì‹, ìŠ¤í¬ì¸ , ë²•ë¥ (ì•½ê³¼ ë¬´ê´€), ë†ë‹´, ìŒì•…, ì¢…êµ ë“±\n\n"
                    "ìž…ë ¥: {question}\n"
                    "ì •ë‹µ(YES/NO)ë§Œ ì¶œë ¥:"
                ),
            ),
        ]
    )


def node_guard(state: RAGState) -> RAGState:
    """ì‚¬ìš©ìž ì§ˆë¬¸ì´ ì˜ì•½í’ˆ ë„ë©”ì¸ê³¼ ê´€ë ¨ ìžˆëŠ”ì§€ LLMìœ¼ë¡œ íŒë³„"""
    llm = get_llm()
    guard_chain = build_guard_prompt() | llm | StrOutputParser()
    result = guard_chain.invoke({"question": state["question"]}).strip().upper()
    state["in_domain"] = (result == "YES")
    return state


def node_retrieve(state: RAGState) -> RAGState:
    """ìœ ì‚¬ë„ ê²€ìƒ‰ìœ¼ë¡œ ë¬¸ì„œ ì²­í¬ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
    collection = state["collection_name"]
    k = state.get("k", 5)
    vectorstore = get_vectorstore(collection)
    docs_and_scores = vectorstore.similarity_search_with_score(state["question"], k=k)
    docs: List[Document] = [d for d, _ in docs_and_scores]

    context_lines: List[str] = []
    citations: List[Dict[str, Any]] = []
    for doc, score in docs_and_scores:
        meta = doc.metadata or {}
        product = meta.get("ì œí’ˆëª…") or meta.get("title") or meta.get("product") or "ì•Œ ìˆ˜ ì—†ëŠ” ì œí’ˆ"
        snippet = (doc.page_content or "")[:300].replace("\n", " ")
        context_lines.append(f"[ì œí’ˆëª…: {product}] {doc.page_content}")
        citations.append({"ì œí’ˆëª…": product, "score": float(score), "snippet": snippet})

    state["retrieved_docs"] = docs
    state["context"] = "\n\n".join(context_lines)
    state["citations"] = citations
    return state


def node_generate(state: RAGState) -> RAGState:
    """LLMìœ¼ë¡œ ìµœì¢… ë‹µë³€ì„ ìƒì„±"""
    llm = get_llm()
    prompt = build_prompt()
    chain = prompt | llm | StrOutputParser()

    answer = chain.invoke({"question": state["question"], "context": state.get("context", "")})
    state["answer"] = answer
    return state


def node_fallback(state: RAGState) -> RAGState:
    """ë„ë©”ì¸ê³¼ ê´€ë ¨ ì—†ì„ ë•Œì˜ ì•ˆë‚´ ë©”ì‹œì§€"""
    state["answer"] = (
        "ì´ ì±—ë´‡ì€ ì˜ì•½í’ˆ ì •ë³´ ì „ìš©ìž…ë‹ˆë‹¤. ì•½ ì´ë¦„, íš¨ëŠ¥Â·ìš©ë²•, ìƒí˜¸ìž‘ìš©, ì´ìƒë°˜ì‘, ë³´ê´€ë²• ë“± "
        "ì˜ì•½í’ˆ ê´€ë ¨ ì§ˆë¬¸ì„ í•´ì£¼ì‹œë©´ ê·¼ê±°ì— ê¸°ë°˜í•˜ì—¬ ì •í™•ížˆ ì•ˆë‚´í•´ë“œë¦´ê²Œìš”."
    )
    state["citations"] = []
    state["context"] = ""
    return state


def route_topic(state: RAGState) -> Literal["retrieve", "fallback"]:
    """in_domain stateê°’ì— ë”°ë¼ ë¶„ê¸°ë¥¼ ì •í•˜ëŠ” í•¨ìˆ˜"""
    return "retrieve" if state.get("in_domain") else "fallback"


def build_graph():
    """ê·¸ëž˜í”„ë¥¼ ì •ì˜ í•˜ëŠ” í•¨ìˆ˜"""
    graph = StateGraph(RAGState)

    graph.add_node("guard", node_guard)        # ì£¼ì œ ì—°ê´€ì„± íŒë³„
    graph.add_node("retrieve", node_retrieve)  # ì—°ê´€ ì‹œ ê²€ìƒ‰
    graph.add_node("generate", node_generate)  # ë‹µë³€ ìƒì„±
    graph.add_node("fallback", node_fallback)  # ë¹„ì—°ê´€ ì‹œ

    graph.set_entry_point("guard")
    # guard ë…¸ë“œë¥¼ ì§€ë‚˜ retrieve|fallback ë‘˜ ì¤‘ ì–´ë–¤ ë…¸ë“œë¡œ ê°ˆì§€ ê²°ì •í•˜ëŠ” ë¶„ê¸° ì—£ì§€
    graph.add_conditional_edges("guard", route_topic, {"retrieve": "retrieve", "fallback": "fallback"})
    graph.add_edge("retrieve", "generate")
    graph.add_edge("generate", END)
    graph.add_edge("fallback", END)

    return graph.compile()


def run_once(question: str, collection_name: str = "drug_info", k: int = 4) -> Dict[str, Any]:
    """ê·¸ëž˜í”„ë¥¼ í•œ ë²ˆ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ dictë¡œ ë°˜í™˜"""
    app = build_graph()
    initial: RAGState = {"question": question, "collection_name": collection_name, "k": k}
    final_state = app.invoke(initial)
    return {
        "question": final_state["question"],
        "answer": final_state.get("answer", ""),
        "citations": final_state.get("citations", []),
        "in_domain": final_state.get("in_domain", False),
    }


def run(collection_name: str = "drug_info", k: int = 4, exit_words: tuple[str, ...] = ("quit", "exit", "bye")) -> None:
    """ì‚¬ìš©ìžê°€ ì¢…ë£Œ ë‹¨ì–´ë¥¼ ìž…ë ¥í•  ë•Œê¹Œì§€ ë°˜ë³µ ì‹¤í–‰í•˜ëŠ” ì¸í„°ëž™í‹°ë¸Œ ë£¨í”„"""
    app = build_graph()
    exit_words_lower = {word.lower() for word in exit_words}
    print(
        "ðŸ’Š ì˜ì•½í’ˆ ì •ë³´ RAG ì±—ë´‡ìž…ë‹ˆë‹¤. ì¢…ë£Œí•˜ë ¤ë©´ "
        f"{', '.join(exit_words)} ì¤‘ í•˜ë‚˜ë¥¼ ìž…ë ¥í•˜ì„¸ìš”."
    )

    while True:
        try:
            question = input("\nì§ˆë¬¸> ").strip()
        except EOFError:
            print("\nìž…ë ¥ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        if not question:
            print("ì§ˆë¬¸ì„ ìž…ë ¥í•˜ê±°ë‚˜ ì¢…ë£Œ ëª…ë ¹ì„ ìž…ë ¥í•˜ì„¸ìš”.")
            continue

        if question.lower() in exit_words_lower:
            print("ì±„íŒ…ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        initial: RAGState = {
            "question": question,
            "collection_name": collection_name,
            "k": k,
        }
        final_state = app.invoke(initial)

        answer = final_state.get("answer", "")
        citations = final_state.get("citations", [])
        in_domain = final_state.get("in_domain", False)

        print("\n=== IN_DOMAIN ===\n", in_domain)
        print("\n=== ANSWER ===\n")
        print(answer or "â— ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        if citations:
            print("\n=== CITATIONS ===")
            for idx, citation in enumerate(citations, start=1):
                product = citation.get("ì œí’ˆëª…") or citation.get("product_name") or "N/A"
                score = citation.get("score")
                snippet = citation.get("snippet", "")
                if score is not None:
                    print(f"#{idx} ì œí’ˆëª…: {product} | score={score:.4f}")
                else:
                    print(f"#{idx} ì œí’ˆëª…: {product}")
                if snippet:
                    print(f"   snippet: {snippet}")
        else:
            print("\n=== CITATIONS ===\n(ì—†ìŒ)")


def parse_args():
    p = argparse.ArgumentParser()
    p.add_argument("--collection", default="drug_info", help="pgvector ì»¬ë ‰ì…˜ëª…")
    p.add_argument("--k", type=int, default=5, help="ê²€ìƒ‰ ìƒìœ„ k")
    return p.parse_args()


def main():
    load_dotenv()
    args = parse_args()
    run(args.collection, args.k)
    # print("ì§ˆë¬¸ì„ ìž…ë ¥í•˜ì„¸ìš” >> ")
    # question = input()
    # result = run_once(question, args.collection, args.k)

    # # ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥
    # from pprint import pprint
    # print("\n=== IN_DOMAIN ===\n", result["in_domain"])
    # print("\n=== ANSWER ===\n")
    # print(result["answer"])
    # print("\n=== CITATIONS ===")
    # pprint(result["citations"])


if __name__ == "__main__":
    main()
