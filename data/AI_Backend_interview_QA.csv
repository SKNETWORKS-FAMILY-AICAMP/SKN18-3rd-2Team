대분류,중분류,질문,답변
AI,통계,고유값(eigen value)와 고유벡터(eigen vector)이 무엇이고 왜 중요한지 설명해주세요.,"정방행렬 $(n times n)$인 $A$는 임의의 벡터 $(n times 1)$인 $x$의 방향과 크기를 변화시킬 수 있다. 수많은 벡터 $x$중 어떤 벡터들은 $A$에 의해 선형 변환되었을 때에도 원래 벡터와 평행한 경우가 있다. 이렇듯 $Ax$가 원래 $x$에 상수 $lambda$를 곱한 것과 같을 때의 $x$를 고유 벡터, 람다를 고유값이라 한다. $$ Ax = lambda x $$ 아래처럼 $x1$은 $A$에 의해 변환되었음에도 $x1$과 평행하다. 따라서 $x1$은 고유벡터이다. 고유값과 고유벡터를 통해 $A$를 고유값과 고유벡터들로 분해하는 고유값 분해(eigen decomposition), 정방행렬 뿐만 아닌 $m times n$행렬도 분해할 수 있는 특이값 분해(SVD), 데이터들을 차원 축소시킬 때 가장 원래 의미를 잘 보존시키는 주성분 분석(PCA) 등에 활용할 수 있으므로 중요하다."
AI,통계,샘플링(Sampling)과 리샘플링(Resampling)이 무엇이고 리샘플링의 장점을 말씀해주세요.,"샘플링이란 표본추출을 의미하는 것으로, 모집단 전체에 대한 추정치(estimate)를 얻기 위해 임의의 sample을 뽑아내는 것이다. 모집단 전체에 대한 조사는 불가능하기 때문에 sample을 이용하여 모집단에 대한 추론(inference)을 하게되는 것이다. 하지만 표본은 모집단을 닮은 모집단의 mirror image 같은 존재이지만, 모집단 그 자체일수는 없다. 따라서 표본에는 반드시 모집단의 원래 패턴에서 놓친 부분, 즉 noise가 존재할 수 밖에 없다. 리샘플링은 모집단의 분포 형태를 알 수 없을 때 주로 사용하는 방법이다. 즉, 모분포를 알 수 없으므로 일반적인 통계적 공식들을 사용하기 힘들 때, 현재 갖고 있는 데이터를 이용하여 모분포와 비슷할 것으로 추정되는 분포를 만들어 보자는 것이다. 리샘플링은 가지고 있는 샘플에서 다시 샘플 부분집합을 뽑아서 통계량의 변동성(variability of statistics)을 확인하는 것이라고 할 수 있다. 즉, 같은 샘플을 여러 번 사용해서 성능을 측정하는 방식이다. 가장 많이 사용되는 방법이며 종류로는 K-fold 교차 검증, 부트스트래핑이 있다. 리샘플링은 표본을 추출하면서 원래 데이터 셋을 복원하기 때문에 이를 통해서 모집단의 분포에 어떤 가정도 필요 없이 표본만으로 추론이 가능하다는 장점이 있다."
AI,통계,확률 모형과 확률 변수는 무엇인가요?,"확률변수(Random Variable) 란, 표본 공간의 각 단위 사건에 실수 값을 부여하는 변수이다. 확률변수는 어떠한 함수로 해석할 수 있으므로 라고 표기한다. 무작위(Random) 실험을 했을 때, 특정 확률로 발생하는 각각의 결과를 수치적 값으로 표현하는 변수라고 할 수 있다. 또한 확률 변수에는 , 두가지 경우가 있다. 는 확률변수 $X$가 취할 수 있는 값이 유한하기 떄문에 셀 수 있는 확률변수이다. 반면에 는 어떠한 두 수 사이에 반드시 다른 수가 존재하는, 셀 수 없는 범위의 확률변수를 가지는 경우에 사용된다. 주사위 굴리기 예제를 생각해보자. 확률모형(Probability Model) 이란 확률변수를 이용하여 데이터의 분포를 수학적으로 정의한 모형이다. 데이터 분포를 묘사하기 위해서 사용된다. 보통 확률 분포 함수(probability distribution function) 또는 확률 밀도 함수(probability density function)를 주로 사용하며, 이때 함수의 계수를 분포의 모수(parameter)라고 부른다. 확률분포(Probability Distribution) 란 표본공간에 정의된 확률을 이용하여 확률변수의 값 또는 영역에 대한 확률을 표현한 것이다. 예를 들어 가장 널리 쓰이는 확률 모형의 하나인 는 다음과 같은 수식으로 확률 밀도 함수를 정의한다. $$ N(x ; mu, sigma) = frac{1}{sigma sqrt{2 pi}} e^{-frac{(x- mu)^2}{2 sigma^2}} $$ 다음과 같은 함수들이 확률모형에 포함될 수 있다. (자세한 내용은 확률통계 기초용어 - EG 공간 참고) 확률질량함수(PMF, Probability Mass Function) - 이산형 확률밀도함수(PDF, Probability Density Function) - 연속형 누적분포함수(CDF, Cumulative Distribution Function) 추가적으로 확률 통계의 기초 용어를 정리하면 다음과 같다. (주사위 굴리기 예제 사용)"
AI,통계,누적 분포 함수와 확률 밀도 함수는 무엇인가요? 수식과 함께 표현해주세요.,"확률 변수 $X$가 임의의 실수 집합 $B$에 포함되는 사건의 확률이 다음과 같이 어떤 음이 아닌 함수 $f$의 적분으로 주어진다고 하자. $$ P(X in B) = int{B} f(x) dx $$ 이 때의 $X$를 연속확률변수라고 하며, 함수 $f(x)$를 확률 밀도 함수(Probability Density Function, PDF)라고 한다. 단, 실수 집합 $B$가 실수 전체일 경우 실수 전체에 대한 확률밀도함수의 적분은 1을 만족해야 한다. $$ P(X in R) = int{R} f(x) dx = 1 $$ 누적 분포 함수(Cumulative Distribution Function, CDF)는 확률변수가 특정 값보다 작거나 같을 확률을 나타내는 함수이다. 특정 값을 $a$라고 할 때, 누적 분포 함수는 다음과 같이 나타낼 수 있다. $$ F(a) = P(X ≤ a) = int^a{-infty} f(x) dx $$ 확률 밀도 함수와 누적 분포 함수는 미분과 적분의 관계를 갖는다. 확률 밀도 함수를 음의 무한대에서 특정값 $a$까지 적분을 하면, $a$에 대한 누적 분포 함수를 얻을 수 있다. 반대로 누적 분포 함수를 미분하면 확률 밀도 함수를 얻을 수 있다."
AI,통계,조건부 확률은 무엇인가요?,"조건부 확률은 사건 $A$가 일어났다는 전제 하에 사건 $B$가 일어날 확률이다. 이는 $P(B|A) = P(B cap A) / P(A)$로 표현 가능하다. 조건부 확률은 베이즈 정리와도 이어지며, 조건부 확률을 이용한 가장 유명한 문제는 몬티홀 문제가 있다. 베이즈 정리 베이즈 정리를 통해 가능도(Likelihood)와 증거(Evidence)를 바탕으로 사전확률을 사후확률로 업데이트한다. $D$: 새로 관찰되는 데이터 $theta$: 모델에서 계산하고 싶어하는 모수 (가설) 사후확률(Posterior): 데이터를 관찰했을 때, 이 가설이 성립할 확률 (데이터 관찰 이후 측정하기 때문에 사후확률) 사전확률(Prior): 가설에 대해 사전에 세운 확률 (데이터 관측 이후 사후확률이 사전확률이 된다.) 가능도(Likelihood): 현재 주어진 모수 (가정) 에서 이 데이터가 관찰될 가능성 증거(Evidence): 데이터 전체의 분포"
AI,통계,공분산과 상관계수는 무엇일까요? 수식과 함께 표현해주세요.,"공분산은 확률변수 X의 편차(평균으로부터 얼마나 떨어져 있는지)와 확률변수 Y의 편차를 곱한 것의 평균값이다. $$ Cov(X, Y) = E((X - muX)(Y-muY)) $$ 공분산은 두 변수 간에 양의 상관관계가 있는지, 음의 상관관계가 있는지 정도를 알려준다. 하지만 상관관계가 얼마나 큰지는 제대로 반영하지 못한다. 공분산의 문제는 확률변수의 단위 크기에 영향을 많이 받는다는 것이다. 이를 보완할 수 있는 것이 바로 상관계수이다. 상관계수는 확률변수의 절대적 크기에 영향을 받지 않도록 공분산을 단위화시킨 것이다. 즉, 공분산에 각 확률변수의 분산을 나눠주었다. $$ rho = frac{Cov(X, Y)}{sqrt{Var(X) cdot Var(Y)}}, quad -1 ≤ rho≤ 1 $$ 상관계수는 양의 상관관계가 있는지 음의 상관관계가 있는지 알려줄 뿐만 아니라, 그 상관성이 얼마나 큰지도 알려준다. 1 또는 -1에 가까울수록 상관성이 큰 것이고, 0에 가까울수록 상관성이 작은 것이다."
AI,통계,신뢰 구간의 정의는 무엇인가요?,"구간 추정에서 모수가 a 에서 b 사이에 있을 것으로 추정(신뢰구간)하고 그 확률(%, 신뢰수준)을 구한다. 신뢰구간(Confidence Interval) 은 모집단의 모수(parameter)가 위치해 있을 것으로 신뢰할 수 있는 구간이다. 모수가 어느 범위 안에 있는지를 확률적으로 보여주는 방법이라고 할 수 있다. 신뢰구간을 구하는 이유는 모수의 신뢰성을 가늠하기 위함이다. 추가적으로, 신뢰구간에 대한 정확한 해석은 모평균을 포함할 확률이 95%가 되는 구간이 아닌, 같은 방법으로 100번 표본을 추출했을 때, 함께 계산되는 100개의 신뢰구간 중 모평균을 포함한 신뢰구간들의 숫자가 95개정도 된다라고 해야한다. 왜냐면, 모평균은 이미 정해져 있는 값이므로 전자의 해석을 사용할 수 없기 때문이다. 신뢰수준은 방법의 정확도, 참값을 구하기 위한 작업을 많이 반복했을 때, 참값이 특정 범위에 있는 비율이다. 모수(Parameter) 는 모집단의 특성을 보여주는 값이다. 예를들어, 평균, 분산 등의 고정인 값이 있을 수 있다."
AI,통계,p-value를 모르는 사람에게 설명한다면 어떻게 설명하실 건가요?,"p-value를 알기 위해서는 먼저 1종 오류를 알아야 한다. 여기서 1종 오류란 귀무가설이 참인데 기각한 경우을 말한다. 귀무가설이란 기존의 주장을 말하며, 이와 반대로 새로운 주장을 대립가설이라고 한다. 예를 들어, 어느 제약회사에서 치료약 A를 개발했다. 기존에는 치료약 A가 없었으므로 귀무가설은 ""치료약 A가 효과가 없다""라고 설정한다. 반대로 대립가설은 ""치료약 A는 효과가 있다""로 설정한다. 회사에서는 검정을 한 결과, 귀무가설을 기각하고 대립가설을 채택했다. 치료약 A는 판매되었고 높은 매출을 기록했다. 그런데 알고보니 치료약 A가 효과가 없다는 것이 밝혀졌다. 참인 귀무가설을 기각했기에 이는 1종 오류가 일어났다고 볼 수 있다. 다시 돌아와서 p-value는 1종 오류를 범할 확률을 말한다. 예를 들어, p-value가 5%라면, 100번 중 5번 1종 오류가 발생한다는 말이다. 검정을 할 때는 유의 수준 $alpha$를 정하는데, 이것이 1종 오류의 상한선이 된다. 그래서 유의 수준보다 p-value가 작다면 실험의 오류가 상한선보다 작으므로 귀무가설을 기각하고 대립가설을 채택한다. 만약 크다면 상한선을 넘었으므로 귀무가설을 채택한다."
AI,통계,R square의 의미는 무엇인가요?,"결정계수(R square)는 선형 회귀 모델에서 데이터에 대해 회귀선이 얼마나 잘 설명하는지에 대한 설명력을 의미한다. 결정계수는 0~1 의 값을 가질 수 있고, 만약 값이 1 이라면 회귀선으로 모든 데이터를 다 설명할 수 있다고 이해할 수 있다. 참고로 결정계수는 다음의 식으로 구할 수 있다. $$ R^2 = SSE/SST = 1 - SSR/SST $$ SSE(Explained Sum of Squares) = $sum(text{추정값 - 관측값 평균})^2$ SST(Total Sum of Squares) = $sum(text{관측값 - 관측값 평균})^2$ SSR(Residual Sum of Squares) = $SSR = sum(text{관측값 - 추정값})^2$ 관측값은 실제 데이터의 값을 말하며, 추정값은 회귀 모델을 통해 나온 값을 말한다. 회귀 모델의 성능을 평가하는 방법은 결정계수 외에도 MAE, MSE, RMSE 가 있다."
AI,통계,평균(mean)과 중앙값(median)중에 어떤 케이스에서 뭐를 써야할까요?,": 모든 관측값의 합을 자료의 개수로 나눈 것 : 전체 관측값을 크기 순서로 배열했을 때 가운데 위치하는 값 평균은 전체 관측값이 골고루 반영되므로 대표값으로서 가치가 있다. 평균 근처에 표본이 몰려 있는 상황에서 대표값으로 유용하지만 극단적인 값에 영향을 많이 받는다. 중앙값에서는 관측값을 크기 순서로 배열할 때 관측값의 위치가 중요하고, 가운데 위치한 관측값 이외의 관측값들의 크기는 중요하지 않다. 따라서 평균과는 달리 중앙값은 관측값들의 변화에 민감하지 않고 특히 아주 큰 관측값이나 아주 작은 관측값(즉, outlier)에 영향을 받지 않는다. 중앙값이 유용한 경우는 표본의 편차, 혹은 왜곡이 심하게 나타나는 경우이다."
AI,통계,중심극한정리는 왜 유용한걸까요?,"중심극한정리란 크기가 n인 표본추출(30개 이상)이 무수히 많이 수행되면(최소 100회 이상을 의미), 표본 평균의 분포가 정규분포에 수렴한다는 것이다. 중심극한정리가 유용한 이유는 모집단의 형태가 어떻든지 간에 상관없이 표본 평균의 분포가 정규분포를 따르기 때문이다."
AI,통계,엔트로피(Entropy)에 대해 설명해주세요. 가능하면 정보이득(Information Gain)도요.,"엔트로피는 주어진 데이터의 혼잡도를 의미하며, 엔트로피는 다음과 같이 데이터가 어떤 클래스에 속할 확률에 대한 기댓값으로 표현할 수 있다. $$ E = - sum^k{i=1} pi log2 (pi) $$ 엔트로피는 데이터가 서로 다른 클래스에 속하면 높고, 같은 클래스에 속하면 낮다. 다시 말하면 각각의 데이터가 특정 클래스에 속할 확률이 높고 나머지 클래스에 속할 확률이 낮다면 엔트로피가 낮고, 모든 각각의 클래스에 속할 확률이 비슷하다면 엔트로피는 높다. 정보이득은 데이터가 어떤 클래스에 속할 확률이 커짐에 따라 정보를 잘 얻게되는 것을 말하며, 감소되는 엔트로피 양을 의미한다. 수식으로는 기존 시스템의 엔트로피에서 현재 엔트로피를 뺀 값으로 표현된다. 의사결정트리는 가지를 칠 때 이 값을 사용하여 가지를 친다. 이 때 어떤 데이터를 두 집합으로 나누었을 때 두 집합의 정보이득이 크도록, 엔트로피는 작아지도록 분할을 한다."
AI,통계,"어떨 때 모수적 방법론을 쓸 수 있고, 어떨 때 비모수적 방법론을 쓸 수 있나요?","표본의 통계량(평균, 표준편차 등)을 통해 모집단의 모수(모평균, 모표준편차 등)를 추정하는 방법을 통계적 추론이라고 한다. 모집단이 어떤 분포를 따른다는 가정 하에 통계적 추론을 하는 방법을 모수적 방법이라 하는데, 표본의 수가 30개 이상일 때 중심극한 정리에 의해 정규분포를 따르므로 모수적 방법론을 사용한다. 반대로, 모집단의 분포를 가정하지 않는 비모수적 방법은, 표본의 수가 30개 미만이거나 정규성 검정에서 정규 분포를 따르지 않는다고 증명되는 경우 비모수적 방법론을 사용한다."
AI,통계,"""likelihood""와 ""probability""의 차이는 무엇일까요?","확률(Probability)은 어떤 시행(trial)에서 특정 결과(sample)가 나올 가능성을 말한다. 즉, 시행 전 모든 경우의 수의 가능성은 정해져 있으며 그 총합은 1(100%)이다. 가능도(Likelihood)은 어떤 시행(trial)을 충분히 수행한 뒤 그 결과(sample)를 토대로 경우의 수의 가능성을 도출하는 것을 말한다. 아무리 충분히 수행해도 어디까지나 추론(inference)이기 때문에 가능성의 합이 1이 되지 않을수도 있다. PDF(probability density function)에서는 확률변수를 변수로 보기 때문에 총합이 1이지만, likelihood function에서는 분포의 모수를 변수로 보기 때문에 총합이 1이 되지 않을수도 있다."
AI,통계,통계에서 사용되는 bootstrap의 의미는 무엇인가요.,"부트스트랩(Bootstrap) 은 가설검증을 하거나 metric을 계산하기 전에 random sampling을 적용하는 방법이다. 모수의 분포를 추정하는 방법 중 하나는, 현재 가진 표본에서 추가적으로 표본을 복원추출하고 각 표본에 대한 통계량을 다시 계산하는 것이다. 부트스트랩이 여기에 해당하며, 여러번의 무작위 추출을 통해, 평균의 신뢰구간을 구할 수 있다. 200개로만 통계량을 구하는 것이 아니라 200개를 기준으로 복원 추출하여 새로운 통계량을 구하는 것을 예시로 들 수 있다. 머신러닝에서 부트스트램의 의미 머신러닝에서 부트스트랩은 아래와 같이 해석될 수 있다. 랜덤 샘플링을 통해 학습 데이터를 늘리는 방법 여러 모델을 학습시켜 추론 결과의 평균을 사용하는 방법(=앙상블) 복원추출이란? 복원추출(Sampling with replacement)이란 확률을 구할 때, 추출했던 것을 원래대로 돌려놓고 다시 추출하는 방법을 말한다."
AI,통계,모수가 매우 적은 (수십개 이하) 케이스의 경우 어떤 방식으로 예측 모델을 수립할 수 있을까요?,"모수는 모집단의 수가 아닌, 평균, 표준편차 등의 모집단의 특징을 말합니다. 여기서는 모집단의 수로 잘못 쓰인 것으로 보이며, 데이터가 적은 경우라 가정하고 답변을 작성하였습니다. 표본이 매우 작은 경우 표본평균의 분포가 정규분포를 따른다고 가정할 수 없으므로 비모수적 방법을 채택하여 예측 모델을 수립할 수 있다. 하지만 중심극한정리에 의해 표본의 크기가 30보다 클 경우 표본평균이 정규분포를 따른다고 가정할 수 있으므로, 이 경우에는 모수적 방법을 사용한다."
AI,통계,베이지안과 프리퀀티스트 간의 입장차이를 설명해주실 수 있나요?,"베이지안은 사건의 확률을 바라볼 때, 사전 확률을 미리 염두해두고 사건의 발생에 따라 베이즈 정리로 사후 확률을 구해 다시 사전 확률을 업데이트시킨다. 즉, 베이지안은 과거의 사건이 현재 사건에 영향을 끼친다는 입장을 가지고 있다. 반면, 프리퀀티스트는 확률을 무한번 실험한 결과, 객관적으로 발생하는 현상의 빈도수로 바라본다. 즉, 프리퀀티스트는 현재의 객관적인 확률에 의해서만 사건이 발생한다는 입장을 가지고 있다."
AI,통계,검정력(statistical power)은 무엇일까요?,"| | 귀무가설 H0 참 | 귀무가설 H0 거짓 | | :--------------: | :------------: | :--------------------: | | 귀무가설 H0 채택 | 옳은 결정(1-α) | 제 2종 오류(β) | | 귀무가설 H0 기각 | 제 1종 오류(α) | 옳은 결정(1-β), 검정력 | 검정력은 대립가설 H1이 참인 경우 귀무가설 H0를 기각(대립가설 H1을 채택)할 확률이다."
AI,통계,missing value가 있을 경우 채워야 할까요? 그 이유는 무엇인가요?,"missing value를 처리하는 방법에는 크게 4가지가 있다. : 누락된 데이터를 그대로 놔두는 방법이다. : 누락된 데이터를 제거하는 방법이다. 그러나 중요한 정보를 가진 데이터를 잃을 위험이 있다. : 0, 빈번한 값, 지정한 상수값으로 채우기 : K-means, 평균값, 중앙값으로 대체하는 것 1번 방법을 사용하여, 데이터가 누락된 채로 놔둔다고 가정하자. 일부 xgboost같은 알고리즘은 결측값을 고려하여 잘 학습한다. 그러나 결측치를 처리하는 로직이 없는 알고리즘(ex. sklearn의 LinearRegression)은 누락된 데이터 때문에 엉망이 될 수 있다. 따라서 결측치를 처리해주어야한다. 2번 방법을 사용하여, 누락된 데이터를 제거한다고 해보자. 제거하는 방법은 가장 쉬운 방법이다. 그러나 만약 100명 중 한명의 특징(feature)이 누락된 상태이므로, 해당 특징을 전부 삭제한다면 중요한 특성을 잃어버리는 결과를 초래하게 된다. 3번, 4번 방법을 사용하여 결측치를 채운다고 해보자. 결측치를 채움으로서, 중요한 정보를 잃지않고 특성을 유지할 수 있다. 그러나 만약 100명 중 99명의 특징이 누락된 상태라고 한다면, 해당 특징을 어떠한 값으로 채우는 행위가 무의미할 것이다. 따라서 결측치 상태나 비율, 어떤 모델을 사용할 것인지에 따라서 결측치 대응 방법이 달라질 수 있다."
AI,통계,아웃라이어의 판단하는 기준은 무엇인가요?,"이상치(outlier)는 전체 데이터의 패턴에서 벗어난 이상한 값을 가진 데이터를 말한다. 이상치는 모델의 성능에 영향을 미치므로 이를 탐지하는 것은 정말 중요하다. 이상치를 탐지하는 방법 중 하나로 IQR(Inter Quantile Range) 기법이 있다. IQR 기법을 사용하기 위해서는 우선 데이터를 오름차순으로 정렬하고 25%, 50%, 75%, 100%로 4등분을 한다. 이 75% 지점과 25% 지점의 값의 차이를 IQR이라고 한다. 이 IQR에 1.5를 곱한 값을 75% 지점의 값에 더하여 최대값을, 25% 지점의 값에서 빼서 최소값을 계산한다. 이 때 최소값보다 작거나 최대값보다 큰 값을 이상치라고 판단한다. 또 다른 탐지 방법으로는 Z-score를 계산하는 방식이 있다. Z-score는 데이터가 평균에서 얼마나 떨어져 있는지를 나타내는 지표로, 임계값을 설정하여 Z-score이 이 값보다 크다면 이상치로 판단한다. 하지만 Z-score 방식은 데이터가 가우시안 분포를 따른다고 가정하기 때문에 데이터가 가우시안 분포가 아닐 경우 별도의 변환이 필요하다."
AI,통계,필요한 표본의 크기를 어떻게 계산합니까?,"먼저 모집단의 크기 $N$ 을 구하고, 신뢰수준 $z$ 와 오차범위 $e$ 를 얼마로 할지 선정하여 표본의 크기를 구할 수 있다. $$ frac{frac{z^2 times p(1-p)}{e^2}}{1 + (frac{z^2 times p(1-p)}{e^2 N})} $$ 참고로 신뢰수준은 표본추출을 반복했을 때 얼마나 그 결과를 신뢰할 수 있는지에 대한 정도로 95% 를 주로 사용한다. 오차범위는 작을 수록 모집단의 특성에 대한 유용한 정보를 제공하지만 모집단에 대한 추론이 틀릴 가능성도 높아지므로 10% 를 넘지 않게 한다."
AI,통계,Bias를 통제하는 방법은 무엇입니까?,"편향(Bias)는 데이터 내에 있는 모든 정보를 고려하지 않음으로 인해, 지속적으로 잘못된 것들을 학습하는 경향을 의미한다. 이는 언더피팅(Underfitting)과 관계되어 있다. 반대로 분산(Variance)는 데이터 내에 있는 에러나 노이즈까지 잘 잡아내는 highly flexible models에 데이터를 피팅시킴으로써, 실제 현상과 관계 없는 랜덤한 것들까지 학습하는 알고리즘의 경향을 의미한다. 이는 오버피팅(Overfitting)과 관계되어 있다. 편향(Bias)과 분산(Variance)은 한 쪽이 증가하면 다른 한 쪽이 감소하고, 한쪽이 감소하면 다른 한쪽이 증가하는 tradeoff 관계를 가진다. Bias를 통제하기 위한 방법으로는 뉴런이나 계층의 개수가 같은 모델의 크기 증가, 오류평가시 얻은 지식을 기반으로 입력 특성 수정, 정규화, 모델 구조를 수정, 학습 데이터 추가 등의 방법이 있다."
AI,통계,로그 함수는 어떤 경우 유용합니까? 사례를 들어 설명해주세요.,"우선 단위 수가 너무 큰 값들을 바로 회귀분석 할 경우 결과를 왜곡할 우려가 있으므로 이를 방지하기 위해 사용된다. 예를들어, 나이와 재산보유액의 관계를 회귀분석으로 푼다고 했을 때, 재산보유액의 숫자가 굉장히 클 수 있다. 재산보유액에 로그를 취할 경우, 데이터의 왜도와 첨도를 줄일 수 있어 정규성이 높아지는 효과를 얻는다. 또한 비선형관계의 데이터를 선형으로 만들기 위해 사용된다. 예를들어, 기하급수적으로 늘어나는 제곱 형식의 그래프에 자연로그를 취하면 그 관계가 직선(선형)이 된다. 로그함수 주의사항 로그 함수는 0~1 사이에서는 음수값을 가지므로, $log(1+x)$와 같은 방법으로 처리해주어야한다. 왜도(skewness)와 첨도(Kurtosis) 왜도는 데이터가 한쪽으로 치우친 정도이다. 첨도는 분포가 얼마나 뾰족한지를 나타내는 정도이다."
AI,통계,"출장을 위해 비행기를 타려고 합니다. 당신은 우산을 가져가야 하는지 알고 싶어 출장지에 사는 친구 3명에게 무작위로 전화를 하고 비가 오는 경우를 독립적으로 질문했습니다. 각 친구는 2/3로 진실을 말하고 1/3으로 거짓을 말합니다. 3명의 친구가 모두 ""그렇습니다. 비가 내리고 있습니다""라고 말했습니다. 실제로 비가 내릴 확률은 얼마입니까?","출장지에 비가 내릴 때 $p$, 내리지 않을 때를 $1-p$라고 하자. 출장지에 비가 내리는데( $p$ ) 모든 친구가 비가 내린다라고 한다면 모든 친구가 진실을 말하는 것( $frac{8}{27}$ )이다. 이 경우 확률은 $frac{8p}{27}$이다. 출장지가 비가 내리지 않는데( $(1-p)$ ) 모든 친구가 비가 내린다라고 한다면 모든 친구가 거짓을 말하는 것( $frac{1}{27}$ )이다. 이 경우 확률은 $frac{(1-p)}{27}$이다. 위에서 계산한 확률을 위의 식에 대입하고 식을 정리하면 아래와 같다. $$ Pr(raining | Yes) = frac{frac{8p}{27}}{frac{8p}{27} + frac{(1-p)}{27}} = frac{8p}{8p + (1-p)} = frac{8p}{7p+1} $$ 만약 출장지에 비가 올 확률이 25%라면 실제로 출장지에 비가 내릴 확률은 약 72.7%이다."
AI,머신러닝,"알고 있는 metric에 대해 설명해주세요. (ex. RMSE, MAE, recall, precision ...)","평가지표(metric)을 크게 분류를 위한 평가지표와 회귀를 위한 평가지표로 나눌 수 있다. --- 우선 분류 작업(task)에 적용할 수 있는 평가지표를 살펴보자. 정확도(accuracy) 정확도는 모델의 예측이 얼마나 정확한지를 의미한다. 정확도는 (예측 결과가 동일한 데이터 개수)/(전체 예측 데이터 개수)로 계산할 수 있다. 하지만 라벨 불균형이 있는 데이터에서 정확도를 사용하면 안 된다. 예를 들면, 0과 1의 비율이 9:1인 데이터가 있다고 했을 때, 모두 0으로 예측하면 정확도가 90%가 나올 것이다. 이는 잘못된 판단이므로 정확한 판단을 위해서는 다른 지표를 사용해야 한다. 오차 행렬(confusion matrix) 오차 행렬은 모델이 예측을 하면서 얼마나 헷갈리고 있는지를 보여주는 지표이다. 주로 이진 분류에서 많이 사용하며 이진 분류에 대한 오차 행렬은 위의 그림처럼 같이 나타낼 수 있다. True Positive는 긍정으로 예측을 했는데 실제로 긍정인 경우를, False Positive는 긍정으로 예측했는데 실제로 부정인 경우를, False Negative는 부정으로 예측했는데 실제로 긍정인 경우를, True Negative는 부정으로 예측했는데 실제로 부정인 경우를 말한다. 위의 값을 바탕으로 모델이 어떤 오류를 발생시켰는지를 살펴볼 수 있다. 참고로 정확도는 (TN + TP) / (TN + FP + FN + TP)로 계산할 수 있다. 정밀도(precision), 재현율(recall) 정밀도와 재현율은 긍정 데이터 예측 성능에 초점을 맞춘 평가지표이다. 정밀도란 예측을 긍정으로 한 데이터 중 실제로 긍정인 비율을 말하며, 재현율은 실제로 긍정인 데이터 중 긍정으로 예측한 비율을 말한다. 오차 행렬을 기준으로 정밀도는 TP / (FP + TP)으로, 재현율은 TP / (FN + TP)으로 계산할 수 있다. 정밀도와 재현율은 트레이드오프 관계를 갖는다. 정밀도는 FP를, 재현율은 FN을 낮춤으로써 긍정 예측의 성능을 높인다. 이 같은 특성 때문에 정밀도가 높아지면 재현율은 낮아지고 재현율이 높아지면 정밀도는 낮아진다. 가장 좋은 경우는 두 지표 다 적절히 높은 경우이다. F1-Score 정밀도와 재현율 한 쪽에 치우치지 않고 둘 다 균형을 이루는 것을 나타낸 것이 이다. F1-Score는 정밀도와 재현율의 조화평균으로 계산할 수 있다. $$ F1 = frac{2}{frac{1}{recall} + frac{1}{precision}} = 2 frac{precision recall}{precision + recall} $$ ROC-AUC ROC는 FPR(False Positive Rate)가 변할 때 TPR(True Positive Rate)가 어떻게 변하는지를 나타내는 곡선을 말한다. 여기서 FPR이란 FP / (FP + TN)이고, TPR은 TP / (FN + TP)으로 재현율을 말한다. 그럼 어떻게 FPR을 움직일까? 바로 분류 결정 임계값을 변경함으로써 움직일 수 있다. FPR이 0이 되려면 임계값을 1로 설정하면 된다. 그럼 긍정의 기준이 높으니 모두 부정으로 예측될 것이다. 반대로 1이 되려면 임계값을 0으로 설정하여 모두 긍정으로 예측시키면 된다. 이렇게 임계값을 움직이면서 나오는 FPR과 TPR을 각각 x와 y 좌표로 두고 그린 곡선이 ROC이다. AUC는 ROC 곡선의 넓이를 말한다. AUC가 높을수록 즉, AUC가 왼쪽 위로 휘어질수록 좋은 성능이 나온다고 판단한다. 즉, TPR이 높고 FPR이 낮을수록 예측 오류는 낮아지기 때문에 성능이 잘 나온다 볼 수 있다. --- 마지막으로 회귀 작업에 적용할 수 있는 평가지표를 살펴보자. MAE(Mean Absolute Error)는 예측값과 정답값 사이의 차이의 절대값의 평균을 말한다. $$ MAE = frac{1}{N} sum^N{i=1} |yi - acute{yi}| $$ MSE(Mean Squared Error)는 예측값과 정답값 사이의 차이의 제곱의 평균을 말하며, MAE와 달리 제곱을 했기 때문에 이상치에 민감하다. $$ MSE = frac{1}{N} sum^N{i=1} (yi - acute{yi})^2 $$ RMSE(Root Mean Squared Error)는 MSE에 루트를 씌운 값을 말한다. $$ RMSE = sqrt{MSE} = sqrt{frac{1}{N} sum^N{i=1} (yi - acute{yi})^2} $$ RMSLE(Root Mean Squared Logarithmic Error)는 RMSE와 비슷하나 예측값과 정답값에 각각 로그를 씌워 계산을 한다. $$ RMSLE = sqrt{frac{1}{N} sum^N{i=1} (log(yi+1) - log(acute{yi}+1))^2} $$ R Squared는 분산을 기반으로 예측 성능을 평가하는 지표를 말한다. 정답값의 분산 대비 예측값의 분산 비율을 지표로 하며, 1에 가까울수록 정확도가 높다."
AI,머신러닝,정규화를 왜 해야할까요? 정규화의 방법은 무엇이 있나요?,"정규화는 개별 피처의 크기를 모두 똑같은 단위로 변경하는 것을 말한다. 정규화를 하는 이유는 피처의 스케일이 심하게 차이가 나는 경우 값이 큰 피처가 더 중요하게 여겨질 수 있기 때문이다. 이를 막기 위해 피처 모두 동일한 스케일로 반영되도록 하는 것이 정규화이다. 정규화하는 방법으로는 대표적으로 두 가지가 존재한다. 첫 번째 정규화 방법은 최소-최대 정규화(min-max normalization)으로 각 피처의 최소값을 0, 최대값을 1로 두고 변환하는 방법이다. 값을 $x$로, 최소값을 $min$, 최대값을 $max$로 둘 때, 정규화된 값은 $frac{x - min}{max - min}$으로 계산할 수 있다. 두 번째 정규화 방법으로 Z-점수 정규화(z-score normalization)이 있다. 이 방법은 각 피처의 표준편차와 평균으로 값을 정규화시킨다. 정규화된 값은 $frac{x - mean}{std}$로 계산할 수 있다."
AI,머신러닝,Local Minima와 Global Minimum에 대해 설명해주세요.,"비용 함수(cost function)에서의 Global Minimum은 에러가 최소화되는 즉, 우리가 찾고자 하는 지점을 말하며, Local Minima는 에러가 최소가 될 수 있는 후보가 되는 지점 중 Global Minimum을 뺀 지점을 말한다. Local Minima는 자칫 에러가 최소화되는 지점을 찾았다고 착각할 수 있기에 함정에 비유할 수 있다. 이를 해결하기 위해 Momentum과 같은 최적화 알고리즘을 사용하거나 학습률(learning rate)를 잘 조절하여 Local Minima에서 벗어날 수 있다."
AI,머신러닝,차원의 저주에 대해 설명해주세요.,"차원의 저주란 데이터 차원이 증가할수록 해당 공간의 크기가 기하급수적으로 증가하여 데이터 간 거리가 기하급수적으로 멀어지고 희소한 구조를 갖게 되는 현상을 말한다. 이를 해결하기 위해서는 차원을 증가시킨만큼 더 많은 데이터를 추가하거나 PCA, LDA, LLE, MDS와 같은 차원 축소 알고리즘으로 차원을 줄여 해결할 수 있다."
AI,머신러닝,dimension reduction 기법으로 보통 어떤 것들이 있나요?,"차원 축소는 피처 선택(feature selection)과 피처 추출(feature extraction)으로 나눌 수 있다. 우선 피처 선택은 특정 피처에 종속성이 강한 불필요한 피처는 제거하고 데이터의 특징을 잘 표현하는 주요 피처만 선택하는 것을 말한다. 반면 피처 추출은 기존 피처를 저차원의 피처로 압축하여, 피처를 함축적으로 잘 설명할 수 있도록 저차원으로 매핑하는 것을 말한다. 대표적인 피처 추출 알고리즘으로 PCA, SVD, NMF, LDA 등이 있다."
AI,머신러닝,"PCA는 차원 축소 기법이면서, 데이터 압축 기법이기도 하고, 노이즈 제거기법이기도 합니다. 왜 그런지 설명해주실 수 있나요?","PCA(Principle Component Analysis)는 입력 데이터의 공분산 행렬을 기반으로 고유벡터를 생성하고 이렇게 구한 고유 벡터에 입력 데이터를 선형 변환하여 차원을 축소하는 방법이다. 차원은 곧 입력 데이터의 피처를 뜻하므로 데이터 압축 기법으로 볼 수도 있다. 또한 PCA는 고유값이 가장 큰, 즉 데이터의 분산이 가장 큰 순으로 주성분 벡터를 추출하는데, 가장 나중에 뽑힌 벡터보다 가장 먼저 뽑힌 벡터가 데이터를 더 잘 설명할 수 있기 때문에 노이즈 제거 기법이라고도 불린다."
AI,머신러닝,"LSA, LDA, SVD 등의 약자들이 어떤 뜻이고 서로 어떤 관계를 가지는지 설명할 수 있나요?","는 Principle Component Analysis의 약자로 데이터의 공분산 행렬을 기반으로 고유벡터를 생성하고 이렇게 구한 고유 벡터에 입력 데이터를 선형 변환하여 차원을 축소하는 방법이다. 는 Singular Value Decomposition의 약자로 PCA와 유사한 행렬 분해 기법을 사용하나 정방 행렬(square matrix)를 분해하는 PCA와 달리 행과 열의 크기가 다른 행렬에도 적용할 수 있다. 는 Latent Semantic Analysis의 약자로 잠재 의미 분석을 말하며, 주로 토픽 모델링에 자주 사용되는 기법이다. LSA는 DTM(Document-Term Matrix)이나 TF-IDF(Term Frequency-Inverse Document Frequency) 행렬에 Truncated SVD를 적용하여 차원을 축소시키고, 단어들의 잠재적인 의미를 이끌어낸다. Truncated SVD는 SVD와 똑같으나 상위 n개의 특이값만 사용하는 축소 방법이다. 이 방법을 쓸 경우 원 행렬로 복원할 수 없다. 는 Latent Dirichlet Allocation 혹은 Linear Discriminant Analysis의 약자이다. 전자는 토픽모델링에 사용되는 기법 중 하나로 LSA와는 달리 단어가 특정 토픽에 존재할 확률과 문서에 특정 토픽이 존재할 확률을 결합확률로 추정하여 토픽을 추정하는 기법을 말한다. 후자는 차원축소기법 중 하나로 분류하기 쉽도록 클래스 간 분산을 최대화하고 클래스 내부의 분산은 최소화하는 방식을 말한다. Latent Dirichlet Allocation와 관련된 자세한 내용은 #9 텍스트 더미에서 주제를 추출해야 합니다. 어떤 방식으로 접근해 나가시겠나요?을 참고해주세요!"
AI,머신러닝,Markov Chain을 고등학생에게 설명하려면 어떤 방식이 제일 좋을까요?,"마코프 체인(Markov Chain) 마코프 체인이란 마코프 성질을 지닌 이산 확률 과정(Discrete-time Stochastic Process)을 말한다. 마코프 성질(Markov Property) $n+1$회의 상태(state)는 오직 $n$회에서의 상태, 혹은 그 이전 일정 기간의 상태에만 영향을 받는 것을 의미한다. 예를 들면 동전 던지기는 독립 시행이기 때문에 $n$번째의 상태가 앞이던지 뒤이던지 간에 $n+1$번째 상태에 영향을 주지 않는다. 하지만 1차 마코프 체인은 $n$번째 상태가 $n+1$번째 상태를 결정하는데에 영향을 미친다. (시간 $t$에서의 관측은 단지 최근 $r$개의 관측에만 의존한다는 가정을 하고 그 가정하에서 성립한다.) 정리하면 마코프 체인은 확률변수(random variable)가 어떤 상태(state)에 도달할 확률이 오직 바로 이전 시점의 상태(state)에 달려 있는 경우를 가리킨다. 예를 들어, 오늘의 날씨가 어제의 날씨에만 의존하면 1차 마코프 체인, 이틀 전까지의 날씨에만 의존하면 2차 마코프 체인이다. 마코프 모델(Markov Model) 마코프 모델은 위의 가정하에 확률적 모델을 만든 것으로써 가장 먼저 각 상태를 정의하게 된다. 상태(state)는 $V = v1, ... , vm$로 정의하고, m개의 상태가 존재하게 되는 것이다. 그 다음은 상태 전이 확률(State transition Probability)을 정의할 수 있다. 상태 전이 확률이란 각 상태에서 각 상태로 이동할 확률을 말한다. 상태 전이 확률 $a{ij}$는 상태 $vi$에서 상태 $vj$로 이동할 확률을 의미한다. 아래의 식은 상태 전이 확률을 식으로 나타낸 것과 그 아래는 확률의 기본 정의에 의한 상태 전이 확률의 조건이다. 그리고 상태와 상태 전이 확률을 정리하여 상태 전이도(state transition diagram)으로도 표현할 수 있다."
AI,머신러닝,텍스트 더미에서 주제를 추출해야 합니다. 어떤 방식으로 접근해 나가시겠나요?,"잠재 디리클레 할당(Latent Dirichlet Allocation, LDA) 잠재 디리클레 할당(LDA)이란 문서의 집합에서 토픽을 찾아내는 프로세스를 뜻하는 토픽 모델링의 대표적인 알고리즘을 말한다. LDA는 ""문서들은 토픽들의 혼합으로 구성되어져 있으며, 토픽들은 확률 분포에 기반하여 단어들을 생성한다""고 가정하며, 데이터가 주어지면 LDA는 토픽을 문서가 생성되던 과정을 역추적한다. 예를 들어, 다음과 같은 예시 문장 3개가 있다고 가정하자. LDA를 통해 각 문서의 토픽 분포와 각 토픽 내의 단어 분포를 추정할 수 있다. 각 문서의 토픽 분포 문서1 : 토픽 A 100% 문서2 : 토픽 B 100% 문서3 : 토픽 B 60%, 토픽 A 40% 각 토픽의 단어 분포 토픽A : 사과 20%, 바나나 40%, 먹어요 40%, 귀여운 0%, 강아지 0%, 깜찍하고 0%, 좋아요 0% 토픽B : 사과 0%, 바나나 0%, 먹어요 0%, 귀여운 33%, 강아지 33%, 깜찍하고 16%, 좋아요 16% LDA는 토픽의 제목을 정해주지 않지만, 이 시점에서 알고리즘의 사용자는 위 결과로부터 두 토픽이 각각 과일에 대한 토픽과 강아지에 대한 토픽이라고 판단해볼 수 있다."
AI,머신러닝,SVM은 왜 반대로 차원을 확장시키는 방식으로 동작할까요? SVM은 왜 좋을까요?,"SVM(Support Vector Machine)은 데이터가 사상된 공간에서 경계로 표현되며, 공간상에 존재하는 여러 경계 중 가장 큰 폭을 가진 경계를 찾는다. $B1$: 결정 경계 $b{11}$: plus-plane $b{12}$: minus-plane SVM의 장단점은 다음과 같다. | 장점 | 단점 | | ------------------------------------------------- | --------------------------------------------------------------------- | | 분류와 회귀에 모두 사용할 수 있다. | 데이터 전처리와 매개변수 설정에 따라 정확도가 달라질 수 있다. | | 신경망 기법에 비해 과적합 정도가 낮다. | 예측이 어떻게 이루어지는지에 대한 이해와 모델에 대한 해석이 어렵다. | | 예측의 정확도가 높다. | 대용량 데이터에 대한 모델 구축 시 속도가 느리며,메모리 할당량이 크다. | | 저차원과 고차원 데이터에 대해서 모두 잘 작동한다. | | 마진(Margin) 마진(Margin)은 plus-plane과 minus-plane 사이의 거리를 의미하며, 최적의 결정 경계는 마진을 최대화한다. SVM은 선형 분류뿐만 아니라 비선형 분류에도 사용되는데, 비선형 분류에서는 입력자료를 다차원 공간상으로 맵핑할 때 커널 트릭(kernel trick)을 사용하기도 한다. 원공간(Input Space)의 데이터를 선형분류가 가능한 고차원 공간(Feature Space)으로 매핑한 뒤 두 범주를 분류하는 초평면을 찾는다. (Kernel-SVM) 커널 트릭(Kernel Trick) 커널 함수를 이용하여 차원 공간(low dimensional space)을 고차원 공간(high dimensional space)으로 매핑해주는 작업을 커널트릭이라 한다. 커널 함수의 종류는 다음과 같다."
AI,머신러닝,"다른 좋은 머신 러닝 대비, 오래된 기법인 나이브 베이즈(naive bayes)의 장점을 옹호해보세요.","데이터에서 변수들에 대한 조건부 독립을 가정하는 알고리즘으로 클래스에 대한 사전 정보와 데이터로부터 추출된 정보를 결합하고, 베이즈 정리(Bayes Theorem)를 이용하여 어떤 데이터가 특정 클래스에 속하는지 분류하는 알고리즘이다. 나이브 베이즈의 장단점은 다음과 같다. | 장점 | 단점 | | -------------------------------------------------------------------------- | ---------------------------------------------------------------------- | | 단순하고 빠르며 매우 효과적이다 | 모든 속성은 동등하게 중요하고 독립적이라는 알려진 결함 가정에 의존한다 | | 노이즈와 결측 데이터가 있어도 잘 수행한다 | 수치 속성으로 구성된 많은 데이터셋에 대해 이상적이지 않다 | | 훈련에 대한 상대적으로 적은 예제가 필요하지만 매우 많은 예제도 잘 수행한다 | 추정된 확률은 예측된 범주보다 덜 신뢰적이다 | | 예측에 대한 추정된 확률을 얻기 쉽다 | |"
AI,머신러닝,회귀 / 분류시 알맞은 metric은 무엇일까?,"1 답변을 참고해주세요. 해당 답변에서 서술하지 않은 지표만 추가로 설명합니다. 회귀 $$ R^2 = frac{sum (hat{y}l - bar{y})}{sum (yi - bar{y})^2} $$ 결정계수(Coefficient of determination)는 (회귀선에 의해 설명되는 변동)/(전체 변동)을 말하며, 독립변수의 개수가 많아질수록 결정계수가 1에 가까워진다. 회귀모형이 높은 결정계수를 갖는다면 실제로 모형이 설명력이 높은 것인지 단순히 독립변수의 개수가 많은 것인지 알기 어려워 결정계수를 신뢰할 수 없게 되는 문제가 발생한다. $$ adj R^2 = 1 - frac{n - 1}{(n - p - 1)(1 - R^2)} $$ 수정된 결정계수는 결정계수의 문제를 해결하기 위해 표본의 크기(n)와 독립변수의 수(p)를 고려하여 수정된 결정계수를 계산한다. 분류 $$ - (y - log (p))) + (1 - y) log (1-p) $$ Log Loss 혹은 Binary Crossentropy는 이진 분류에서의 지표로 사용된다. $$ LogarithmicLoss = - frac{1}{N} sum^N{i=1} sum^M{j=1} y{ij} log (p{ij}) $$ Categorical Crossentropy는 분류해야할 클래스가 3개 이상인 멀티 클래스 분류에서의 지표로 사용된다."
AI,머신러닝,"Association Rule의 Support, Confidence, Lift에 대해 설명해주세요.","연관규칙분석(Association Analysis)은 흔히 장바구니 분석(Market Basket Analysis) 또는 서열분석(Sequence Analysis)이라고 불린다. 기업의 데이터베이스에서 상품의 구매, 서비스 등 일련의 거래 또는 사건들 간의 규칙을 발견하기 위해 적용하며, 연관성 분석의 평가 지표로는 Support, Confidence, Lift를 사용한다. Support(지지도) 전체 거래 중 항목 A와 항목 B를 동시에 포함하는 거래의 비율로 정의한다. $$ 지지도 = P(A cap B) = frac{A와 B가 동시에 포함된 거래수}{전체 거래수} = frac{A cap B}{전체} $$ Confidence(신뢰도) 항목 A를 포함한 거래 중에서 항목 A와 항목 B가 같이 포함될 확률이다. 연관성의 정도를 파악할 수 있다. $$ 신뢰도 = frac{P(A cap B)}{P(A)} = frac{A와 B가 동시에 포함된 거래수}{A를 포함하는 거래수} = frac{지지도}{P(A)} $$ Lift(향상도) A가 구매되지 않았을 때 품목 B의 구매확률에 비해 A가 구매됐을 때 품목 B의 구매확률의 증가 비이다. 연관규칙 A→B는 품목 A와 품목 B의 구매가 서로 관련이 없는 경우에 향상도가 1이 된다. $$ 향상도 = frac{P(B | A)}{P(B)} = frac{P(A cap B)}{P(A)P(B)} = frac{A와 B가 동시에 포함된 거래수}{A를 포함하는 거래수 times B를 포함하는 거래수} = frac{신뢰도}{P(B)} $$ --- 에를 들어 어떤 슈퍼마켓에서 5명의 고객에 의해 발생된 5($N = 5$)건의 거래를 가지고, 연관규칙 X:{계란, 맥주} → Y:{기저귀}에 대해 살펴보자. | CustomerID | TransactionID | Items | | :------------: | :---------------: | :------------------------------------: | | 1131 | no.1 | 계란, 우유 | | 2094 | no.2 | 계란, 기저귀, 맥주, 사과 | | 4122 | no.3 | 우유, 기저귀, 맥주, 콜라 | | 4811 | no.4 | 계란, 우유, 맥주, 기저귀 | | 8091 | no.5 | 계란, 우유, 맥주, 콜라 | $$ P(Y) = frac{n(Y)}{N} = frac{n \{ no.2, no.3, no.4 \} }{N} = frac{3}{5} = 0.6 $$ 지지도(Support) = $s(X→Y) = frac{n(Xcup Y)}{N} = frac{n \{ no.2, no.4 \} }{N} = frac{2}{5} = 0.4$ 신뢰도(Confidence) = $c(X→Y) = frac{n(Xcup Y)}{n(X)} = frac{n \{ no.2, no.4 \} }{n \{ no.2, no.4, no.5 \} } = frac{2}{3} = 0.6667$ 향상도(Lift) = $Lift(X→Y) = frac{c(X→Y)}{s(Y)} = frac{0.6667}{0.6} = 1.1111$"
AI,머신러닝,최적화 기법중 Newton's Method와 Gradient Descent 방법에 대해 알고 있나요?,"Newton's Method 함수 $f$의 2차 테일러 근사(quadratic approximation)은 다음과 같다. $$ f(y)approx f(x)+ abla f(x)^T(y-x)+frac{1}{2}(y-x)^T abla^2f(x)(y-x), \ f{approx}(y)=f(x)+ abla f(x)^T(y-x)+frac{1}{2}(y-x)^T abla^2f(x)(y-x) $$ 여기서 $y$는 다음 스텝의 $x$ 값인 $x^+$이다. 또한 quadratic approximation을 $f{approx}$로 정한다. 이 $f{approx}$ 즉, quadratic approximation을 최소로 만드는 입력 $y$를 찾으려 한다. 이때 $f{approx}$는 convex이므로 위 식의 gradient를 0으로 만드는 입력 $y$가 $f{approx}$를 최소로 만들 것이다. 이 결과가 Newton's method에서의 step update 식이 된다. 아래 식의 미분은 $y$에 대한 미분 임을 기억하자. $$ abla f{approx}(y)= abla f(x)+frac{1}{2}left(( abla^2f(x))^T(y-x)+(y-x)^T abla^2f(x)right) \ = abla f(x)+ abla^2f(x)(y-x)qquadqquadqquad \ = 0,qquadqquadqquadqquadqquadqquadqquadquad;, \ Leftrightarrow y=x-( abla^2f(x))^{-1} abla f(x)qquadqquad; $$ Gradient Descent Gradient descent에서는 함수 $f$의 2차 테일러 근사항을 사용하고, 2차 항의 경우 실제 2차 미분 결과가 아닌, 정방행렬(identity matrix)과 이를 $t$로 나눈 값으로 가정한다. $$ f(y)approx f(x)+ abla f(x)^T(y-x)+frac{1}{2t}parallel y-xparallel^22, \ f{approx}(y)=f(x)+ abla f(x)^T(y-x)+frac{1}{2t}parallel y-xparallel^22 $$ Newton's method와 동일하게 위 근사식의 gradient가 0인 $y$ 값, 즉 $x^+$를 정할 수 있다. $$ abla f(y)= abla f(x)+frac{1}{t}(y-x), \ =0,qquadqquad; \ Leftrightarrow y=x-t abla f(x) $$ Newton's method와 Gradient descent의 step에 따른 수렴 방향 비교 파랑: Newton's method 검정: Gradient descent Gradient descent는 2차 미분항을 정방행렬에 상수가 곱해진 값으로 가정하고 gradient를 계산하기 때문에, 등고선(contour)의 접선 방향에 수직하게(perpendicular) 수렴함을 확인할 수 있고, Newton's method에 비해 느린 수렴 속도를 보인다."
AI,머신러닝,머신러닝(machine)적 접근방법과 통계(statistics)적 접근방법의 둘간에 차이에 대한 견해가 있나요?,"머신러닝적 접근방법과 통계적 접근방법의 차이는 두 방법의 주 목적이 다르다는 것이다. 머신러닝적 접근방법은 모델의 예측 성공률을 높이는게 목적이다. 따라서 모델의 신뢰도나 정교한 가정보다는 다양한 피쳐를 사용하여 (오버피팅을 감안하더라도) 높은 예측률을 달성하고자 한다. 통계적 접근방법은 분포와 가정을 통해 신뢰 가능하고 정교한 모델을 만드는게 목적이다. 따라서 모형을 복잡하지 않고 단순하게 만들고, 어떤 피쳐가 어떤 원인을 주는지 알 수 있도록 한다."
AI,머신러닝,인공신경망(deep learning이전의 전통적인)이 가지는 일반적인 문제점은 무엇일까요?,"딥러닝 이전의 인공신경망은 선형적으로만 회귀, 분류를 수행하기 때문에 레이어를 깊게 쌓지 못했고, 때문에 XOR 문제 같은 복잡한 문제를 풀지 못하는 문제점이 있었다. 하지만 시그모이드와 같은 비선형 함수를 선형 모델에 추가하여 XOR 문제를 해결하고, 편미분 체인룰을 사용한 오차역전파 방법으로 모델을 업데이트할 수 있게 되면서 레이어를 깊게 쌓은 딥러닝 인공신경망이 발전하였다."
AI,머신러닝,지금 나오고 있는 deep learning 계열의 혁신의 근간은 무엇이라고 생각하시나요?,"ImageNet 과 같은 거대하고 높은 품질의 데이터셋이 모두에게 공개되면서 딥러닝의 혁신적인 발전이 시작될 수 있었다. 현재는 더 다양한 태스크에 적합한 좋은 GLUE 같은 데이터들도 공개되어 더욱 딥러닝의 발전에 이바지하고 있다. 현재 좋은 성능을 내는 딥러닝 모델들은 모두 큰 규모의 모델들인데 하드웨어의 발전이 이를 가능하게 하였다. 또한 end-to-end 모델이 나타나면서 데이터 레이블링, 하이퍼파라미터 찾기, 최적 모델 찾기 등 모든 작업을 기계에게 맡기면서 딥러닝이 크게 발전하였다."
AI,머신러닝,ROC 커브에 대해 설명해주실 수 있으신가요?,"ROC 커브는 이진분류 모델의 성능을 나타내는 지표이다. 모델이 참이라고 예측하는 경우는 FPR (False Positive Rate, 실제 값이 거짓일 때) 과 TPR (True Positive Rate, 실제 값이 참일 때) 두 경우로 나뉜다. FPR 과 TPR 을 그래프에서 x 축, y 축으로 동시에 표현한 ROC 커브를 통해 모델이 얼마나 옳은 값을 잘 예측하는지 알 수 있게 된다. ROC 커브가 좌상단과 가까운 경우 좋은 모델이라고 판단할 수 있다. 모델이 FPR 은 낮게, TPR 은 높게 예측하기 때문이다."
AI,머신러닝,여러분이 서버를 100대 가지고 있습니다. 이때 인공신경망보다 Random Forest를 써야하는 이유는 뭘까요?,"랜덤 포레스트는 여러 결정 트리를 앙상블하여 하나의 모델로 구성하는 방법이다. 랜덤 포레스트에서는 각 서버를 모델의 특성을 이해하는 단일 결정 트리 (Decision tree) 로 병렬적이게 구성할 수 있다. 반면, 인공신경망은 하나의 서버 자체가 모델의 특성을 모두 이해하는 end-to-end 구조로 직렬적이게 구성된다. 따라서 서버가 100대 있을 때는, 이를 병렬적으로 활용할 수 있는 랜덤 포레스트를 사용한다."
AI,머신러닝,K-means의 대표적 의미론적 단점은 무엇인가요? (계산량 많다는것 말고),"K-means 는 특성이 비슷한 데이터를 같은 그룹으로 묶어주는 클러스터링 알고리즘으로, k 개의 군집 개수를 정하고 군집의 중심점을 예측하여 각 데이터와 거리를 비교한 후 군집을 결정한다. K-means 알고리즘의 단점은 다음과 같다. K 를 몇 개로 설정하냐에 따라 성능이 달라진다. K 개 군집의 중심점을 예측하여야 하는데, 어디를 중심점으로 두냐에 따라 성능이 달라진다. 데이터가 잘 모여있는 경우에 효과적이지, 노이즈가 많은 경우 효과적이지 않다."
AI,머신러닝,"L1, L2 정규화에 대해 설명해주세요.","정규화(일반화)의 목적은 모델이 학습 데이터에 오버피팅되지 않고 처음 보는 테스트 데이터에도 좋은 성능을 내도록 만드는 것이다. 모델의 학습은 loss 함수를 최소화하는 방향으로 진행된다. 이 때, loss 함수에 L1, L2 정규화 항 (norm) 을 더함으로써 모델은 기존의 loss 도 줄이면서 정규화 항 (모델의 피쳐값과 관련) 도 줄이는 방향으로 학습된다. 모델의 피쳐값이 줄어듦에 따라 특정 피쳐가 너무 큰 값을 갖지 않게 되면서 오버피팅을 방지할 수 있게 된다. L1 정규화 (라쏘 회귀) L1 정규화는 특정 피쳐의 값이 매우 낮은 경우 (아웃라이어) 0에 수렴되는 특징이 있다. 특정 피쳐가 0이 되어 사라지는 것은 feature selection 과 동일하다고 볼 수 있다. $$ Cost = sum^N{i=0} (yi - sum^M{j=0} x{ij}Wj)^2 + lambda sum^M{j=0} |Wj| $$ L2 정규화 (릿지 회귀) L2 정규화는 특정 웨이트의 값이 매우 낮아도 0에 수렴되지는 않고 가까워지는 특징이 있다. 이는 L1 정규화에 비해 강하지 않게 정규화를 실행하여 항상 선형 모델에 일반화 효과를 줄 수 있다. $$ Cost = sum^N{i=0} (yi - sum^M{j=0} x{ij}Wj)^2 + lambda sum^M{j=0} Wj^2 $$ loss 식에 람다 모델의 웨이트에 대한 L1 or L2 norm 을 더해줌으로써 모델의 일반화가 가능해진다. loss 는 데이터 값과 추정 값의 차이로 모델은 loss 를 최소화하는 방향으로 학습하는데, L1 or L2 정규화를 사용하면 loss 가 웨이트의 크기만큼 커지기 때문에 데이터 값에 예측 값이 fit 해지지 않기 때문이다. Norm Norm은 벡터의 크기를 나타내는 것으로 L1 Norm은 벡터의 절댓값 크기를 나타내고, L2 Norm은 직선 거리 (제곱의 루트) 를 나타낸다. 위 그림에서 초록선은 L2 norm 을 의미하고, 나머지 선은 L1 norm 을 의미한다. L1 loss $$ L1LossFunction = sum^n{i=1} |y{true} - y{predicted}| $$ L2 loss $$ L2LossFunction = sum^n{i=1} (y{true} - y{predicted})^2 $$"
AI,머신러닝,Cross Validation은 무엇이고 어떻게 해야하나요?,"cross validation(교차검증)이란 train(학습) 데이터로 학습한 모델이, 학습에 사용되지 않은 validation(검증) 데이터를 기준으로 얼마나 잘 동작하는지 확인하는 것이다. 여기서 주의할 점은 train 데이터셋과 validation 데이터셋에는 test 데이터셋이 포함되면 안된다는 것이다. 교차검증을 통해 얻을 수 있는 장단점은 아래와 같다. 적은 데이터에 대한 validation 신뢰성을 높일 수 있다. 모든 데이터셋을 훈련에 활용할 수 있으므로 데이터 편중을 막을 수 있다. (k-fold 경우) 검증 결과에 따라 더 일반화된 모델을 만들 수 있다. 모델 학습에 오랜 시간이 소요된다. 교차검증 기법의 종류는 아래와 같다. (validation 데이터셋을 어떻게 지정하느냐에 따라 달라진다.) 홀드 아웃 교차검증(Holdout Cross Validation) K-겹 교차검증(K-fold Cross Validation) 계층별 k-겹 교차검증(Stratified K-Fold Cross Validation) 홀드 아웃 교차검증 홀드아웃 교차검증방법은 일정한 비율의 validation 데이터셋 하나를 지정하여 검증 데이터셋으로 사용하는 것이다. 홀드아웃 교차검증을 사용하는 경우, 두가지 문제점이 존재한다. validation 데이터셋으로 지정된 부분의 데이터가 학습셋으로 사용되지 않는다는 문제 validation 데이터셋에 편향되도록 모델을 조정하게 된다는 문제 이를 해결하기 위해 k-겹 교차검증이 등장했다. k-겹 교차검증 k-겹 교차검증 방법은 train 데이터를 k개의 fold로 나누어, 그 중 하나의 fold를 validation 데이터셋으로 삼아 검증하는 방법을 k번 반복하여, 그 평균을 결과로서 사용하는 방법이다. 세부적인 동작방법은 다음과 같다. train 데이터셋을 k개의 fold로 나누고, 그 중 하나를 validation 데이터셋으로 지정한다. validation 데이터셋을 제외한 나머지 폴드들을 train 데이터셋으로 사용하여 모델을 학습한다. 학습한 모델을 1번에서 지정해둔 validation 데이터셋으로 검증하고, 그 검증 결과를 저장해둔다. 모델을 초기화한 후, 기존 validation 데이터셋이 아닌 다른 fold를 validation 데이터셋으로 지정하고, 2번 과정부터 다시 수행한다. 모든 fold들이 한번씩 validation 데이터셋으로 사용된 후에는, 저장해둔 검증결과의 평균을 내어, 그것을 최종 validation 결과로 사용한다. 그러나 k-겹 교차검증 방법은 랜덤하게 validation 데이터셋을 지정하게 되므로, 편향된 데이터로 이뤄진 폴드가 생성될 수 있다는 단점이 있다. 이를 해결하기 위해서 계층별 k-겹 교차검증 방법이 등장했다. 계층별 k-겹 교차검증 계층별 k-겹 교차검증 방법은 k-겹 교차검증 방법에서 fold를 나눌때, 랜덤하게 fold를 지정하는 것이 아닌, 각 클래스별 비율을 고려하여 fold를 구성하는 방법이다. 왜 test 데이터셋 만으로 검증하면 안될까? 모든 train 데이터셋을 학습하고, test 데이터셋으로 검증한 결과를 확인한다고 하자. 개발자는 test 데이터셋 점수를 높이기 위해, test 데이터셋에 편향되도록 모델을 튜닝하게 될 것이다. 그러나 중요한 것은 test 데이터셋에 대한 정확도를 높이는 것 뿐만아니라, 모델의 일반적인 정확도를 높이는 것이다. 어떤 데이터가 들어와도 일정하게 높은 정확도를 보여주는 모델이 좋은 모델이라 할 수 있으므로, validation 데이터셋과 test 데이터셋을 분리하여 검증하는 과정을 통해, 모델을 일반화시켜야 한다."
AI,머신러닝,XGBoost을 아시나요? 왜 이 모델이 캐글에서 유명할까요?,"XGBoost(eXtreme Gradient Boosting) 이란, 트리 기반의 앙상블 학습에서 가장 각광받고 있는 알고리즘 중 하나이다. Kaggle 경연대회에서 상위를 차지한 많은 과학자들이 XGBoost를 이용하면서 널리 알려졌다. GBM에 기반하고 있지만, GBM의 단점인 느린 수행시간 및 과적합 규제(Regularization) 부재 등의 문제를 해결해서 각광받고 있다. XGBoost의 장점은 다음과 같다. 분류와 회귀영역에서 뛰어난 예측 성능을 발휘한다. XGBoost는 병렬처리를 사용하여, GBM 대비 빠른 수행시간을 보인다. Regularization, Early Stopping 기능을 통해 오버피팅을 방지할 수 있다. Tree Pruning(가지치기) 제공한다. 미리 정해둔 maxdepth까지만 split하고 pruning을 하고, 거꾸로 올라가면서 positive gain이 없는 노드를 삭제한다. 자체적으로 결측치를 처리해준다. 매 iteration마다 교차검증을 수행한다. GBM(Gradient Boosting Algorithm) 이란 회귀분석 또는 분류 분석을 수행할 수 있는 예측모형이며 예측모형의 앙상블 방법론 중 부스팅 계열에 속하는 알고리즘이다. LightGBM, CatBoost, XGBoost는 모두 GBM을 기반으로 만들어졌다. (자세한 내용은 Gradient Boosting Algorithm의 직관적인 이해 - DeepPlay 참고) boosting 이라는 테크닉 자체가 sequential 한데 어떻게 병렬처리를 할까? 세가지 가능성이 제기된다. 나뉜 분기마다 각각 병렬처리하거나, 분기가 나뉘는 지점 계산을 병렬처리 하거나, 처음부터 feature별 정렬을 통해 병렬처리를 할 수 있다. (자세한 내용은 XGBoost의 병렬처리가 어떻게 가능할까? - GoLab 참고)"
AI,머신러닝,앙상블 방법엔 어떤 것들이 있나요?,"앙상블(Ensemble) 은 여러개의 모델을 조합해서 그 결과를 뽑아 내는 방법이다. ""정확도가 높은 강한 모델을 하나 사용하는 것보다, 정확도가 낮은 약한 모델을 여러개 조합 하는 방식의 정확도가 높다""는 개념에서 비롯한 방법이다. , , 등의 방법이 있다. 배깅(Bagging, Bootstrap Aggregation) 이란 샘플을 여러번 뽑아(Bootstrap = 복원 랜덤 샘플링) 각 모델을 학습시켜 결과물을 집계(Aggregation)하는 방법이다. 카테고리 데이터는 투표 방식(Voting)으로 결과를 집계하며, 연속형 데이터는 평균으로 집계한다. Bagging을 사용한 대표적인 기법에는 방법이 있다. 학습 데이터가 충분하지 않더라도 충분한 학습효과를 주어 높은 bias의 underfitting 문제나, 높은 variance로 인한 overfitting 문제를 해결하는데 도움을 준다. 부스팅(Boosting) 이란 이전 모델의 오답에 가중치를 높게 부여하여 다음 모델을 학습하는 방법이다. 오답을 정답으로 맞추기 위해 오답에 더 집중하여 학습시키기 떄문에 일반적으로 배깅에 비해 정확도가 높다. 그러나 틀렸던 부분에 대해 반복적으로 학습하므로 오버피팅의 문제가 있으며, outlier에 취약하고, 속도가 느리다는 단점도 가지고 있다. 방법이 대표적이고, 등의 알고리즘이 존재한다. 스태킹(Stacking) 이란 여러 개별 모델이 예측한 결과값을 다시 학습 데이터셋으로 사용해서 모델을 만드는 방법이다. 그러나 위의 그림과 같은 기본적인 스태킹 방법은 하므로 문제점이 있다. 따라서 스태킹에 Cross Validation 방식을 도입하여 이 문제를 해결할 수 있다. 데이터를 쪼개고 이들 중 일부만을 가지고 학습한 모델을 여러개 만들어, 그 결과들을 으로 사용하여 다시 학습하는 것이다. 이 방법은 많은 개별 모델의 결과를 결합하여 예측 성능을 높일 수 있다는 장점이 있다. 배깅 vs 부스팅 배깅은 랜덤 복원추출(부트스트랩)을 여러번 반복하여 모델을 병렬적으로 여러개 학습을 시킨 다음, 평균을 내는 방식이다. 반면, 부스팅은 모든 데이터를 학습에 사용하되, 오답에 더 큰 가중치를 두어 다음 회차를 학습시키는 순차적인 방법이다."
AI,머신러닝,feature vector란 무엇일까요?,"특징(feature) 이란, 샘플(데이터)을 잘 설명하는 측정가능한 속성이다. 특징을 통해 특정 샘플을 수치화하여 나타낼 수 있다. 특징벡터(feature vector) 란 피쳐(feature)들의 집합이다. 굳이 벡터로 표시하는 이유는 수학적으로 다루기 편하기 때문이다. 데이터별로 어떤 특징을 가지고 있는지 찾아내고, 그것을 토대로 데이터를 벡터로 변환하는 작업을 특징추출(feature extraction) 이라고 한다. 특징 공간(feature space) 이란 관측값들이 있는 공간을 의미한다. 이 특징 공간은 여러 차원으로 구성될 수 있다. 어떤 데이터를 특징공간의 하나의 벡터로 표현하는 경우, 여러 특징 변수가 특징벡터에 영향을 줄 수 있다. 예를들어, 특징 변수가 하나인 데이터는 1차원 특징 공간에 나타나고, 특징 변수가 N개라면 N차원의 특징 공간에 나타낼 수 있다. d-차원 데이터의 특징 벡터는 다음과 같이 표시된다. $$ x = (x1, x2, ..., xd)^T $$ 분야에 따른 피처벡터의 의미 컴퓨터비전(이미지)에서의 특징은 edge, corner 등을 의미한다. 픽셀 값이 급격히 변화하는 곳, 밝기의 변화, 색상의 변화, 그래디언트의 방향 등의 매칭 정보등을 특징으로 삼는다. SIFT, SURF 등의 방법이 존재한다. 자연어처리(텍스트) 에서의 특징은 단어, 형태소, 서브워드, 토큰 등으로 표현될 수 있으며, BOW(Bag-of-Words)는 문서에서 단어의 발생을 설명하는 텍스트의 벡터 표현이다. 만약 8개의 단어로 이루어진 문장을 BoW로 만들면, 8차원(dimension)의 vector로서 하나의 단어를 표현할 수 있다. 정형데이터에서의 특징은 각 attribute(열)를 의미한다. 키, 나이, 국적 등이 특징으로 사용될 수 있다."
AI,머신러닝,좋은 모델의 정의는 무엇일까요?,"한 줄로 요약하자면, 좋은 모델은 데이터의 패턴을 잘 학습한 모델로서, 한번도 본적 없는 데이터에 대해 옳은 판단을 내리는 모델이 좋은 모델이라고 할 수 있다. 머신러닝, 딥러닝 등을 사용하여 모델을 생성하는 이유는 이다. 따라서 모델은 라고 볼 수 있다. 이 관점에서, 좋은 결정(옳은 결정)을 내리는 모델이 좋은 모델이다. 주어진 학습 데이터에 과적합된 모델의 경우, 주어진 데이터와 조금만 다른 데이터가 들어오면 제대로 분류하지 못하는 상황이 발생된다. 그러므로 모델의 일반화가 이루어져, 새로운 데이터에 대해서도 적정한 수준의 성능을 보이는 모델이 좋은 모델이라고 할 수 있다. 예를들어, 예측이 목적이라면, 실제 정답과 예측 값의 차이(loss, cost, error)를 최소화 하는 모델이 가장 좋은 모델이다. 또한 확률을 추정하는 경우에는 가능성(likelihood)을 최대화하는 모델이 좋은 모델이라고 할 수 있다."
AI,머신러닝,50개의 작은 의사결정 나무는 큰 의사결정 나무보다 괜찮을까요? 왜 그렇게 생각하나요?,"50개의 작은 의사결정 나무는 앙상블에서 기법을 사용한 모델로 볼 수 있다. 따라서 Bagging의 대표적인 방법인 방법이 왜 좋은지 설명하는 것으로, 왜 50개의 작은 의사결정 나무가 더 나은지 설명하고자 한다. 큰 트리는 작은 편향(bias)와 큰 분산(variance)를 갖기 때문에, 매우 깊이 성장한 트리는 훈련데이터에 대해 과적합(overfitting)하게 된다. Random Forest 방식으로 학습하면, 트리들의 편향은 그대로 유지하면서, 여러 데이터셋/여러 경우에 대해 학습하기 떄문에 분산을 감소시킬 수 있다. 또한 한 개의 결정트리의 경우, train 데이터에 있는 노이즈에 대해 매우 민감하지만, 여러 트리들을 만들면서 평균을 내면, 노이즈에 대해 강인해질 수 있다. 따라서 하나의 깊은/큰 의사결정 나무보다 50개의 작은 의사결정 나무가 더 좋은 모델을 완성시킨다고 할 수 있다. Bagging(Bootstrap Aggregating) Bagging은 Bootstrap(반복, 복원추출)하고, 이를 Aggregation(집계)하는 방법이다. 원래 데이터셋에 대해서 여러개의 작은 데이터셋 N개를 샘플링해서 만든다음, 각각의 데이터를 작은 모델 N개로 학습을 시킨다. 그 다음 학습된 N개의 모델을 모두 하나로 합쳐서 최종적인 모델로 사용하는 방법론을 의미한다. 결국, 병렬적으로 데이터를 나누어 여러 개의 모델을 동시에 학습시키는 방법이다. Random Forest Random Forest는 여러 의사 결정 나무를 생성한 후에 다수결(hard voting) 또는 평균(soft voting)에 따라 출력을 예측하는 알고리즘이다. 즉 의사 결정 나무와 bagging을 혼합한 형태라고 볼 수 있다. Random Forest의 특징은 bootstrap을 이용하여 학습 데이터셋에서 다양한 샘플을 추출하여 일부만 한번의 학습에 사용한다는 것이다. 데이터 샘플링 및 변수 선택을 통해 의사 결정 나무의 다양성을 확보할 수 있다. 이를 통해 예측의 변동성이 줄어들고, 과적합을 방지할 수 있어 결측치에 대해 강건하다는 장점을 가진다. 그러나 데이터의 수가 많아지면 의사결정나무에 비해 속도가 크게 떨어지고, 결과에 대한 해석이 어렵다는 단점이 있다."
AI,머신러닝,스팸 필터에 Logistic Regression을 많이 사용하는 이유는 무엇일까요?,"스팸 필터는 메일이 스팸 메일인지 아닌지에 대한 확률을 계산하여, 메일을 분류(Classification) 하는 문제이다. 로지스틱 회귀는 회귀를 바탕으로 데이터가 어떤 범주에 속할 확률을 0과 1 사이의 값으로 예측하고 그 확률에 따라 가능성이 더 높은 범주에 속하는 것으로 분류(Classification)해주는 지도 학습 알고리즘이다. 특히 입력값이 아무리 크거나 작아도 0에서 1 사이의 값으로 맵핑시킨다는 점에서 분류문제에 적합하다. 따라서 로지스틱 회귀가 스팸필터에 많이 사용된다. 분류문제에서 로지스틱 회귀가 적절한 이유 로지스틱 회귀는 시그모이드 함수(sigmoid function) 를 통해 선형함수를 0과 1 사이의 함수로 바꾼 것이며, S자 형태를 보인다. 시그모이드 함수의 정의는 아래와 같다. $$ S(x) = frac{1}{1 + e^{-x}} = frac{e^x}{e^x+1} $$ 로지스틱 회귀의 가설함수는 다음과 같다. $$ H(X) = frac{1}{1 + e^{-(Wx+b)}} = sigmoid(Wx+b) = sigma (Wx+b) $$ x값이 아무리 +, -로 작아지거나 커져도 항상 0과 1 사이의 값을 반환한다. 확률은 0에서 1사이의 범위 내에 들어와야하므로 이러한 형태가 적합하다. 이렇게 H(x)의 값이 0과 1사이로 나오면, 위의 Hypothesis 함수로 regression을 한 결과값이 threshold(ex.0.5) 이상인 경우엔 1로 분류하고, threshold 보다 작으면 0으로 분류하면 되기 떄문이다. 분류문제에서 선형회귀가 적합하지 않은 이유 과 같이 주어진 데이터를 표현하는 그래프를 그려, 적절한 지점을 기준으로 두 그룹으로 분류할 수 있다. 이때 의 데이터가 새로 들어왔다고 해보자. 그래프는 새로운 데이터 의 영향을 받아, 아래로 기울어진 형태로 업데이트되어, 의 붉은색 그래프 형태가 된다. 이렇게 되면, 원래는 1로 잘 분류되던 것들의 예측값이 기존 threshold 아래로 내려가게되어, 0으로 분류되어버리는 문제가 발생한다. 선형회귀 함수는 어떤 입력값이 들어오느냐에 따라 0과 1 사이의 범위를 벗어나기도 한다. 또한, 라는 가설함수(Hypothesis function)이 있다고 하자. x가 0.01 이상인 경우는 모두 1로 x가 0 이하인 경우는 모두 0으로 분류하게 된다. 이처럼 x값에 너무 민감하게 반응하는 모델이 만들어질 수 있다. 연산상으로는 매우 작은 값만 바뀌어도 아예 분류자체가 바뀌어버린다. 더 나아가, 선형모델은 확률이 아닌, 점들의 보간(interpolate)만으로 이루어지므로 확률로 해석할 수 없다. 예측값이 확률이 아니기 때문에 한 클래스와 다른 클래스를 구분할 수 있는 의미 있는 임계값이 없다. 또한 다중 클래스를 가지는 분류문제로 확장할 수 없다는 문제점도 있다. 이러한 문제점들 때문에, 분류문제에서 선형 회귀 모델은 적합하지 못하다."
AI,머신러닝,OLS(ordinary least square) Regression의 공식은 무엇인가요?,"최소자승법(OLS, Ordinary Least Squares) 이란, 산점도를 통해 데이터의 분포 그래프를 그릴때, 이 데이터들의 경향을 알기 위한 최적의 추세선을 그리기 위한 방법 중 하나이다. OLS는 근사적으로 구하려는 해와 실제 해의 오차의 제곱의 합이 최소가 되는 해를 구하는 방법이다. OLS Regression은 회귀를 통해서 방정식의 상수 값들을 추정하는 데에 사용된다. n개의 입력값과 그에 대응하는 출력값 $(xi, yi)(1leq ileq n)$이 있고, 이 계의 방정식이 변수 $x$와 $beta=(beta0, beta1, cdots , betak )$인 상수 $beta$에 대한 식 $f(x, beta)$으로 주어질 때, $sumi(yi - f(xi, beta))^{2}$ 의 값을 최소로 만드는 $beta$를 구하는 것이 문제의 목표이다. 추정하고자 하는 파라미터 β에 대한 표현식을 다음과 같이 구할 수 있다. $$ {hat {beta}}=(mathbf {X}^{rm {T}}mathbf {X})^{-1}mathbf {X}^{rm {T}}mathbf {y} = {big (} ~ {textstyle sum }mathbf xi mathbf xi^{rm {T}},{big )}^{-1}{big (} ~ {textstyle sum }mathbf xi yi ~ {big)} $$ 예를들어, 7개 데이터의 경향을 나타내는 추세선을 와 같이 그렸다고 하자. 이때 실제 데이터의 y값(실제값)과 추세선의 y값(예측값)의 차를 잔차(Residual) 라고 한다. (아래 그래프에서 잔차는 점선으로 표시) 최소자승법은 이 잔차의 제곱의 합(RSS, Residual Sum of Squares)을 최소로 하는 (가중치 벡터를 구하는) 방법이다. 잔차 제곱의 합은 의 에 해당하는 넓이와 같다. 잔차 제곱의 합을 구하는 식은 아래와 같다. 파란색 추세선보다 보라색 추세선의 잔차제곱의 합이 더 작다. 따라서 파란색 추세선보다 보라색 추세선이 위 7개의 데이터를 더 잘 표현해주는 추세선임을 알 수 있다. 이렇게 잔차 제곱의 합을 최소로 하는 방법이 최소자승법이며, 최소자승법을 활용하여 데이터를 가장 잘 표현하는 선형 회귀선을 그릴 수 있다. OLS vs. MSE OLS(Ordinary Least Square): 선형 회귀 모델을 만들기 위한 선횡 최소 제곱법, 모델을 만들때 사용한다. MSE(Mean Square Error): 모델 성능 평가 지표, 모델을 평가할 때 사용한다."
AI,딥러닝,딥러닝은 무엇인가요? 딥러닝과 머신러닝의 차이는?,"딥러닝이란 여러 층을 가진 인공신경망(Artificial Neural Network, ANN)을 사용하여 머신러닝 학습을 수행하는 것으로, 심층학습이라고도 부른다. 딥러닝은 엄밀히 말하자면 머신러닝에 포함되는 개념이다. 따라서 전통적인 머신러닝 기법과 딥러닝 기법의 차이를 설명하고자 한다. (인공신경망, 퍼셉트론에 대한 내용은 reference를 참고) 머신러닝과 딥러닝의 가장 큰 차이점은 다음과 같다. 기존 머신러닝에서는 학습하려는 데이터의 여러 특징 중에서 어떤 특징을 추출할지 사람이 직접 분석하고 판단해야하는 반면, 딥러닝에서는 기계가 자동으로 학습하려는 데이터에서 특징을 추출하여 학습하게 된다. 따라서 특징 추출에 사람이 개입(feature engineering)하면 머신러닝, 개입하지 않으면 딥러닝이다. 또한, 딥러닝은 머신러닝보다 큰 데이터셋과 긴 학습시간이 필요하다. 정형데이터는 주로 머신러닝, 비정형데이터는 주로 딥러닝 방식을 사용한다. AI, ML, DL 인공지능이란 인간이 가지고 있는 인식, 판단 등의 지적 능력을 모델링하여 컴퓨터에서 구현하는 것이다. 머신러닝, 딥러닝 외에도 다양한 분야가 인공지능 내에 포함된다. 머신러닝이란 데이터를 기반으로 패턴을 학습하고 결과를 예측하는 알고리즘 기법이다. 머신러닝은 조건이 복잡하고 규칙이 다양한 경우에, 데이터를 기반으로 일정한/숨겨진 패턴을 찾아내서 문제를 해결한다. 머신러닝의 단점은 데이터에 매우 의존적이라는 것이다. 즉, 좋은 품질의 데이터를 갖추지 못하면 머신러닝 수행결과도 좋지 않다는 것이다. 머신러닝은 아래와 같이 분류된다. | 지도 학습 | 비지도 학습 | | :---------------------------------------------------------------: | :----------------------------: | | 분류, 회귀, 추천시스템시각/음성 인지(DL), 텍스트분석/NLP(DL) | 클러스터링, 차원축소, 강화학습 |"
AI,딥러닝,Cost Function과 Activation Function은 무엇인가요?,"cost function 모델은 데이터에 대해 현재 예측을 얼마나 잘하고 있는지 알아야 학습 방향을 어느 방향으로, 얼마나 개선할지 판단할 수 있다. 이 때, 예측 값과 데이터 값의 차이에 대한 함수를 cost function(MSE, CrossEntropy 등) 이라고 한다. cost function 을 최소화함으로써 모델을 적절한 표현력을 갖추도록 학습시킬 수 있다. activation function 데이터를 예측하기 위해 선형 모델을 사용할 수 있다. 하지만 선형 모델의 경우 복잡한 데이터에 대해서는 적절한 예측을 못한다. 따라서 이를 처리하기 위해 비선형 모델이 필요하다. 선형 모델을 비선형 모델로 만들어주는 역할을 하는 함수가 바로 활성화 함수 activation function(Sigmoid, ReLU 등) 이다. 비선형 함수인 활성화 함수가 선형 함수와 결합됨으로써 선형 모델은 비선형 모델이 된다. 선형 모델은 깊게 쌓을 수 없다. 깊게 쌓아도 하나의 층을 잘 튜닝한 것과 다르지 않기 때문이다. 비선형 모델은 깊게 쌓을 수 있다. 선형으로 만들었다가 비선형으로 만드는 작업을 계속 반복할 수 있기 때문이다. 이로 인해 모델은 복잡한 데이터에 대해 더 표현력이 좋아질 수 있다. 활성화 함수는 입력 값에 대해 더 높게 혹은 더 낮게 만들 수 있기 때문에 활성화 함수라고 불린다."
AI,딥러닝,"Tensorflow, PyTorch 특징과 차이가 뭘까요?","| 구분 | Tensorflow | PyTorch | | :---------: | :----------------: | :-----------------: | | 패러다임 | Define and Run | Define by Run | | 그래프 형태 | Static graph(정적) | Dynamic graph(동적) | Tensorflow와 Pytorch의 가장 큰 차이점은 딥러닝을 구현하는 패러다임이 다르다는 것이다. Tensorflow는 Define-and-Run인 반면에, Pytorch는 Define-by-Run이다. Define and Run (Tensorflow)은 코드를 직접 돌리는 환경인 세션을 만들고, placeholder를 선언하고 이것으로 계산 그래프를 만들고(Define), 코드를 실행하는 시점에 데이터를 넣어 실행하는(Run) 방식이다. 이는 계산 그래프를 명확히 보여주면서 실행시점에 데이터만 바꿔줘도 되는 유연함을 장점으로 갖지만, 그 자체로 비직관적이다. Define by Run (PyTorch)은 선언과 동시에 데이터를 집어넣고 세션도 필요없이 돌리면 되기때문에 코드가 간결하고 난이도가 낮은 편이다. 두 프레임워크 모두 계산 그래프를 정의하고 자동으로 그래디언트를 계산하는 기능이 있다. 하지만 Tensorflow의 계산 그래프는 정적이고 Pytorch는 동적이다. 즉 Tensorflow에서는 계산 그래프를 한 번 정의하고 나면 그래프에 들어가는 입력 데이터만 다르게 할 수 있을 뿐 같은 그래프만을 실행할 수 있다. 하지만 PyTorch는 각 순전파마다 새로운 계산 그래프를 정의하여 이용한다."
AI,딥러닝,Data Normalization은 무엇이고 왜 필요한가요?,"Data Normalization(데이터 정규화)이란 feature들의 분포(scale)을 조절하여 균일하게 만드는 방법이다. 데이터 정규화가 필요한 이유는 데이터 feature 간 scale 차이가 심하게 날 때, 큰 범위를 가지는 feature(ex. 가격)가 작은 범위를 가지는 feature(ex. 나이)보다 더 강하게 모델에 반영될 수 있기 때문이다. 즉, 데이터 정규화는 모든 데이터 포인트가 동일한 정도의 스케일(중요도)로 반영되도록 하는 역할을 수행하며, 아래와 같은 장점을 얻을 수 있다. 학습속도가 개선된다. 노이즈가 작아지므로 오버피팅을 억제시킨다. 데이터를 덜 치우치게 만드므로, 좋은 성능을 보인다. Regularization, Normalization, Standardization Regularization(정규화, 규제) 란 모델에 제약(penalty)를 주어 모델의 복잡성을 낮추고, 이를 통해 오버피팅을 방지하는 방법이다. 제약을 사용하면 학습 정확도(train accuracy)는 조금 낮아질 수 있지만, 테스트 정확도(test accuracy)를 높일 수 있다. 정규화에는 와 같은 방법이 존재한다. (자세한 Regularization 방법은 reference 참고) Normalization, Standardization은 모두 데이터의 범위(scale)을 축소하는 방법이다.(re-scaling) 데이터의 범위 재조정이 필요한 이유는 하여 오버피팅이 될 가능성이 높기 때문이다. 두 방법은 scale 조절 방식에 차이가 존재한다. Normalization(정규화) 방법에는 Batch Normalization, Min-Max Normalization 등이 있다. : 적용시키려는 레이어의 통계량, 분포를 정규화시키는 방법이다. : 모든 데이터 중에서 가장 작은 값을 0, 가장 큰 값을 1로 두고, 나머지 값들은 비율을 맞춰서 모두 0과 1 사이의 값으로 스케일링하는 방법이다. 모든 feature들의 스케일이 동일하지만, 이상치(outlier)를 잘 처리하지 못한다. 식은 아래와 같다. $$ x= {{x - x{min}} over {x{max} - x{min}}} $$ Standardization(표준화) 란 표준화 확률변수를 구하는 방법이다. 이는 을 의미한다. z-score normalization이라 불리기도 한다. : 관측값이 평균 기준으로 얼마나 떨어져있는지 나타낼 때 사용한다. 각 데이터에서 데이터 전체의 평균을 빼고, 이를 표준편차로 나누는 방식이다. 이상치(outlier)를 잘 처리하지만, 정확히 동일한 척도로 정규화 된 데이터를 생성하지는 않는다. 식은 아래와 같다. $$ z-score = {{x-{mu}} over {sigma}} $$"
AI,딥러닝,"알고있는 Activation Function에 대해 알려주세요. (Sigmoid, ReLU, LeakyReLU, Tanh 등)","Sigmoid sigmoid 함수는 $s(z) = frac{1}{1 + e^{-z}}$로, 입력을 0~1 사이의 값으로 바꿔준다. 입력 값이 크거나 작을 때 기울기가 0에 가까워지는 문제가 있다. 이는 문제를 야기하므로 요즘에는 활성화 함수로서 잘 사용되지 않는다. 또한 값이 가 아니기 때문에 입력값의 부호에 그대로 영향을 받으므로 경사하강법 과정에서 정확한 방향으로 가지 못하고 지그재그로 움직이는 문제가 있다. (12-3 참고) Tanh tanh 함수는 입력을 -1~1 사이의 값으로 바꿔준다. sigmoid 함수와 마찬가지로 문제가 있다. ReLU ReLU 함수는 $f(x) = max(0, x)$으로, 입력이 양수면 그대로, 음수면 0을 출력한다. 계산 효율과 성능에서 뛰어난 성능을 보여 가장 많이 사용되는 활성화 함수이다. 양의 입력에 대해서는 문제가 발생하지 않는다. 음의 입력 값에 대해서는 어떤 업데이트도 되지 않는 문제가 발생한다. Leaky ReLU Leaky ReLU는 $f(x) = max(0.01x, x)$으로, ReLU 와 마찬가지로 좋은 성능을 유지하면서 음수 입력이 0이 아니게 됨에 따라 문제를 해결하였다."
AI,딥러닝,오버피팅일 경우 어떻게 대처해야 할까요?,"Early Stopping training loss는 계속 낮아지더라도 validation loss는 올라가는 시점을 overfitting으로 간주하여 학습을 종료하는 방법이다. Parameter Norm Penalty / Weight Decay 비용함수에 제곱을 더하거나($L2 Regularization$) 절댓값을 더해서($L1 Regularization$) weight의 크기에 페널티를 부과하는 방법을 말한다. $$ total cost = loss(D ; W) + frac{alpha}{2} lVert W rVert^22 $$ Data augmentation 훈련 데이터의 개수가 적을 때, 데이터에 인위적으로 변화를 주어 훈련 데이터의 수를 늘리는 방법이다. Noise robustness 노이즈나 이상치같은 엉뚱한 데이터가 들어와도 흔들리지 않는(robust 한) 모델을 만들기 위해 input data나 weight에 일부러 노이즈를 주는 방법을 말한다. Label smoothing 모델이 Ground Truth를 정확하게 예측하지 않아도 되게 만들어 주어 정확하지 않은 학습 데이터셋에 치중되는 경향(overconfident)을 막아주는 방법이다. Dropout 각 계층 마다 일정 비율의 뉴런을 임의로 정해 drop 시키고 나머지 뉴런만 학습하도록 하는 방법을 말한다. 매 학습마다 drop 되는 뉴런이 달라지기 때문에 서로 다른 모델들을 앙상블 하는 것과 같은 효과가 있다. dropout은 학습 시에만 적용하고, 추론 시에는 적용하지 않는다. Batch normalization 활성화함수의 활성화값 또는 출력값을 정규화하는 방법이다. 각 hidden layer에서 정규화를 하면서 입력분포가 일정하게 되고, 이에 따라 Learning rate을 크게 설정해도 괜찮아진다. 결과적으로 학습속도가 빨라지는 효과가 있다."
AI,딥러닝,하이퍼 파라미터는 무엇인가요?,"하이퍼 파라미터(Hyper-parameter)는 모델링할 때, 사용자가 직접 세팅해주는 값을 뜻한다. 하이퍼 파라미터는 정해진 최적의 값이 없으며, 사용자의 선험적 지식을 기반으로 설정(휴리스틱)한다. 예를들어 딥러닝의 하이퍼 파라미터에는 학습률, 배치 사이즈 등이 있고, 가중치는 학습 과정에서 바뀌는 값이며 이는 파라미터에 속한다. 하이퍼 파라미터 튜닝 기법에는 Manual Search, Grid Search, Random Search, Bayesian Optimization 등이 있다. 딥러닝에서의 하이퍼 파라미터는 아래의 그림을 참고한다. 파라미터 vs 하이퍼 파라미터 파라미터와 하이퍼 파라미터를 구분하는 기준은 사용자가 직접 설정하느냐 아니냐이다. 사용자가 직접 설정하면 하이퍼 파라미터, 모델 혹은 데이터에 의해 결정되면 파라미터이다. 딥러닝에서 하이퍼 파라미터는 등이 있고, 파라미터는 등이 있다. 용어 정리 선험적 지식: 경험하지 않아도 알 수 있는 것을 말한다. 휴리스틱: 체계적이면서 합리적인 판단이 굳이 필요하지 않은 상황에서 사람들이 빠르게 사용할 수 있도록, 보다 용이하게 구성된 간편추론의 방법이다. '대충 어림짐작하기', '눈대중으로 맞추기' 등의 방법을 일컫는다."
AI,딥러닝,Weight Initialization 방법에 대해 말해주세요. 그리고 무엇을 많이 사용하나요?,"딥러닝에서 가중치를 잘 초기화하는 것은 기울기 소실이나 local minima 등의 문제를 야기할 수 있기 때문에 중요하다. LeCun Initialization 딥러닝의 대가 LeCun 교수님이 제시한 초기화 방법으로 들어오는 노드 수에 대해 정규 분포와 균등 분포를 따르는 방법이 있다. 정규 분포를 따르는 방법 $$ W sim N(0, Var(W)), quad Var(W) = sqrt{frac{1}{n{in}}} $$ 균등 분포를 따르는 방법 $$ W sim U(- sqrt{frac{1}{n{in}}}, + sqrt{frac{1}{n{in}}}) $$ Xavier Initialization LeCun 방법과 비슷하지만 들어오는 노드 수와 나가는 노드 수에 의존하고, 적절한 상수값도 발견하여 사용한 방법이다. 정규 분포를 따르는 방법 $$ W sim N(0, Var(W)), quad Var(W) = sqrt{frac{2}{n{in} + n{out}}} $$ 균등 분포를 따르는 방법 $$ W sim U(- sqrt{frac{6}{n{in} + n{out}}}, + sqrt{frac{6}{n{in} + n{out}}}) $$ sigmoid 나 tanh 함수와는 좋은 결과를 보여주지만 ReLU 함수와 사용할 경우 0에 수렴하는 문제가 발생한다. 따라서 나 함수와 주로 많이 사용한다. He Initialization 와 함께 많이 사용되는 방법으로, LeCun 방법과 같지만 상수를 다르게 하였다. 들어오는 노드만 고려한다. 정규 분포를 따르는 방법 $$ W sim N(0, Var(W)), quad Var(W) = sqrt{frac{2}{n{in}}} $$ 균등 분포를 따르는 방법 $$ W sim U(- sqrt{frac{6}{n{in}}}, + sqrt{frac{6}{n{in}}}) $$"
AI,딥러닝,볼츠만 머신은 무엇인가요?,"볼츠만 머신은 가시층(Visible Layer)와 은닉층(Hidden Layer), 총 두 개의 층으로 신경망을 구성하는 방법이다. 볼츠만 머신은 모든 뉴런이 연결되어 있는 완전 그래프 형태이며, 제한된 볼츠만 머신(RBM)에서는 같은 층의 뉴런들은 연결되어 있지 않은 모양이다. 기본적으로 단층구조이며, 확률 모델이다. 분류나 선형 회귀 분석 등에 사용될 수 있다. 특히 DBN(Deep Belief Network)에서는 RBM들을 쌓아올려, 각 볼츠만 머신을 순차적으로 학습시킨다. 색깔 별 cell의 역할은 아래와 같다."
AI,딥러닝,"TF, PyTorch 등을 사용할 때 디버깅 노하우는?","오류가 발생하는 곳, 중요한 데이터가 바뀌는 지점을 디버깅 포인트로 두고, 확인하는 방법이 있다. 또, IDE에서 다양한 디버깅 extension을 지원하기 때문에 이를 잘 활용하면 좋은 인사이트를 얻을 수 있다. 예를들어, vs code의 jupyter extension을 사용하면 데이터 프레임, 변수값등을 보기 쉽게 정렬하여 확인할 수 있다. 디버깅 노하우도 중요하지만, 오류에 대한 대처방식을 익히면 좋다. 디버깅 하지 않고 오류에 대처할 수 있으므로, 디버깅 시간을 아껴준다. 예를들어, 딥러닝 학습을 위한 코드를 작성할 때, 가장 많이 발생하는 오류는 CUDA out of memory와 shape 오류이다.(개인적인 의견) out of memory와 같은 오류는 배치 사이즈를 줄인다거나, 입력 데이터의 사이즈를 줄이는 방식으로 해결할 수 있다. shape 오류는 디버깅을 통해서 현재 입력 데이터의 shape, type등을 확인하고, 함수의 파라미터가 요구하는 shape, type에 맞게 변형하는 과정이 필요하다. 추가적으로 딥러닝 디버깅 툴은 아니지만, logging tool로서 tensorboard, wandb 등이 매우 유용하게 사용될 수 있다. ---"
AI,딥러닝,뉴럴넷의 가장 큰 단점은 무엇인가? 이를 위해 나온 One-Shot Learning은 무엇인가?,사람은 처음 보는 물건 (새 레이블) 에 대해 조금만 봐도 다른 것과 이 물건을 구분해낼 수 있다. 하지만 뉴럴넷은 이 물건을 구분해내기 위해서는 이 물건에 대한 많은 데이터를 학습해야한다. One-shot Learning 은 뉴럴넷도 새로운 레이블을 지닌 데이터가 적을 때 (one-shot 에서는 한 개) 에도 모델이 좋은 성능을 내도록 사용되는 방법이다. 이를 위해서는 기존에 다른 레이블의 많은 데이터를 학습하여 데이터의 특성을 잘 이해하는 pretrained 모델이 필요하다. 학습된 모델에 새로운 레이블의 데이터 하나 던져 주면 모델은 데이터의 특성에 대한 이해를 바탕으로 이 레이블에 대해서도 이해를 하게 된다.
AI,딥러닝,요즘 sigmoid 보다 ReLU를 많이 쓰는데 그 이유는?,"우선 sigmoid와 ReLU 함수의 모양을 보자. sigmoid는 값이 큰 양수일수록 1에, 큰 음수일수록 0에 가까워진다. 반면 ReLU는 값이 양수이면 원래 값을 그대로 가져가고, 음수이면 0이다. 요즘 sigmoid보다 ReLU를 많이 쓰는 가장 큰 이유는 기울기 소실 문제(Gradient Vanishing) 때문이다. 기울기는 연쇄 법칙(Chain Rule)에 의해 국소적 미분값을 누적 곱을 시키는데, sigmoid의 경우 기울기가 항상 0과 1사이의 값이므로 이 값을 연쇄적으로 곱하게 되면 0에 수렴할 수 밖에 없다. 반면 ReLU는 값이 양수일 때, 기울기가 1이므로 연쇄 곱이 1보다 작아지는 것을 어느 정도 막아줄 수 있다. 다만, ReLU는 값이 음수이면, 기울기가 0이기 때문에 일부 뉴런이 죽을 수 있다는 단점이 존재한다. 이를 보완한 활성화 함수로 Leaky ReLU가 있다."
AI,딥러닝,Gradient Descent에 대해서 쉽게 설명한다면?,"Gradient Descent는 어떤 함수의 극소점을 찾기 위해 gradient 반대 방향으로 이동해 가는 방법이다. 딥러닝에서는 Loss function을 최소화시키기 위해 파라미터에 대해 Loss function을 미분하여 그 기울기값(gradient)을 구하고, 경사가 하강하는 방향으로 파라미터 값을 점진적으로 찾기위해 사용된다. Gradient Descent를 수식으로 표현하면 아래와 같다. $$ W{t+1} leftarrow Wt - eta gt $$ Gradient Descent의 문제점으로는 크게 두 가지가 있다. 첫 번째로 적절한 step size(learning rate)가 필요하다. step size가 큰 경우 한 번 이동하는 거리가 커지므로 빠르게 수렴할 수 있다는 장점이 있다. 하지만, step size를 너무 크게 설정해버리면 최소값을 계산하도록 수렴하지 못하고 함수 값이 계속 커지는 방향으로 최적화가 진행될 수 있다. 한편 step size가 너무 작은 경우 발산하지는 않을 수 있지만 최적의 x를 구하는데 소요되는 시간이 오래 걸린다는 단점이 있다. 두 번째로 local minima 문제이다. gradient descent 알고리즘을 시작하는 위치는 매번 랜덤하기 때문에 어떤 경우에는 local minima에 빠져 계속 헤어나오지 못하는 경우도 생긴다. (자세한 내용은 #14-1. GD가 Local Minima 문제를 피하는 방법은? 참고)"
AI,딥러닝,Local Minima 문제에도 불구하고 딥러닝이 잘 되는 이유는?,"local minima 문제가 사실은 고차원(High Dimensional)의 공간에서는 발생하기 힘든, 매우 희귀한 경우이기 때문이다. 실제 딥러닝 모델에서는 weight가 수도없이 많으며, 그 수많은 weight가 모두 local minima에 빠져야 weight update가 정지되기 때문에 local minima는 큰 문제가 되지 않는다. Local Minima 문제에도 불구하고 딥러닝이 잘 되는, 더 구체적인 이유 고차원의 공간에서 모든 축의 방향으로 오목한 형태가 형성될 확률은 거의 0에 가깝다. 따라서, 고차원의 공간에서 대부분의 critical point는 local minima가 아니라 saddle point다. 그리고, 고차원의 공간에서 설령 local minima가 발생한다 하더라도 이는 global minimum이거나 또는 global minimum과 거의 유사한 수준의 에러 값을 갖는다. 왜냐하면, critical point에 포함된 위로 볼록인 방향 축의 비율이 크면 클수록 높은 에러를 가지기 때문이다.(실험적 결과) local minima는 위로 볼록인 경우가 하나도 없는 경우이기 때문에 결과적으로 매우 낮은 에러를 갖게 될 것이다. Critical point, Saddle point, Local minimum : 일차 미분이 0인 지점이다. (local/global)minima, (local/global)maxima, saddle point를 가리킴 : 모든 방향에서 극소값을 만족하는 점 : 모든 방향에서 극소값을 만족하는 점 중에 가장 값이 작은 점(정답) : 어느 방향에서 보면 극대값이지만 다른 방향에서 보면 극소값이 되는 점"
AI,딥러닝,Training 세트와 Test 세트를 분리하는 이유는?,모델은 데이터에 대해 예측값을 만들고 정답과 비교하며 업데이트되면서 학습이 된다. 그런데 학습 데이터에 대해서는 좋은 성능을 낸다 하더라도 본 적 없는 데이터에 대해서는 잘 대응하지 못하는 오버피팅 문제가 생긴다면 좋은 모델이 아니다. 이를 막기 위해 학습된 모델이 처음 보는 데이터에도 강건하게 성능을 내는지 판단하기 위한 수단으로 test 세트를 따로 만든다.
AI,딥러닝,Batch Normalization의 효과는?,"배치 정규화(Batch Normalization)은 학습 시 미니배치 단위로 입력의 분포가 평균이 0, 분산이 1이 되도록 정규화한다. 더불어 $gamma$로 스케일과 $beta$로 이동 변환을 수행한다. 이렇게 배치 정규화를 사용하면 다음과 같은 효과를 얻을 수 있다. 기울기 소실/폭발 문제가 해결되어 큰 학습률을 설정할 수 있어 학습속도가 빨라진다. 항상 입력을 정규화시키기 때문에 가중치 초깃값에 크게 의존하지 않아도 된다. 자체적인 규제(Regularization) 효과가 있어 Dropout이나 Weight Decay와 같은 규제 방법을 사용하지 않아도 된다."
AI,딥러닝,"SGD, RMSprop, Adam에 대해서 아는대로 설명한다면?","SGD Loss Function을 계산할 때 전체 train set을 사용하는 것을 Batch Gradient Descent 라고 한다. 그러나 이렇게 계산을 할 경우 한번 step을 내딛을 때 전체 데이터에 대해 Loss Function을 계산해야 하므로 너무 많은 계산량이 필요하다. 이를 방지하기 위해 보통은 Stochastic Gradient Descent(SGD)라는 방법을 사용한다. 이 방법에서는 loss function을 계산할 때 전체 데이터(batch) 대신 데이터 한 개 또는 일부 조그마한 데이터의 모음(mini-batch)에 대해서만 loss function을 계산한다. 데이터 한 개를 사용하는 경우를 Stochastic Gradient Descent(SGD), 데이터의 일부(mini-batch)를 사용하는 경우를 mini-batch Stochastic Gradient Descent(mini-batch SGD)라고 하지만 오늘날의 딥러닝에서 일반적으로 통용되는 SGD는 mini-batch SGD이다. 이 방법은 batch gradient descent 보다 다소 부정확할 수는 있지만, 훨씬 계산 속도가 빠르기 때문에 같은 시간에 더 많은 step을 갈 수 있으며 여러 번 반복할 경우 보통 batch의 결과와 유사한 결과로 수렴한다. 또한, SGD를 사용할 경우 Batch Gradient Descent에서 빠질 local minima에 빠지지 않고 더 좋은 방향으로 수렴할 가능성도 있다. RMSprop RMSProp은 딥러닝의 대가 제프리 힌톤이 제안한 방법으로서, Adagrad의 단점을 해결하기 위한 방법이다. Adagrad의 식에서 gradient의 제곱값을 더해나가면서 구한 $Gt$부분을 합이 아니라 지수평균으로 바꾸어서 대체한 방법이다. 이렇게 대체를 할 경우 Adagrad처럼 $Gt$가 무한정 커지지는 않으면서 최근 변화량의 변수간 상대적인 크기 차이는 유지할 수 있다. 식으로 나타내면 다음과 같다. Adam Adam(Adaptive Moment Estimation)은 RMSProp과 Momentum 방식을 합친 것 같은 알고리즘이다. 이 방식에서는 Momentum 방식과 유사하게 지금까지 계산해온 기울기의 지수평균을 저장하며, RMSProp과 유사하게 기울기의 제곱값의 지수평균을 저장한다. 다만, Adam에서는 m과 v가 처음에 0으로 초기화되어 있기 때문에 학습의 초반부에서는 $mt, vt$가 0에 가깝게 bias 되어있을 것이라고 판단하여 이를 unbiased 하게 만들어주는 작업을 거친다. $mt, vt$의 식을 ∑ 형태로 펼친 후 양변에 expectation을 씌워서 정리해보면, 다음과 같은 보정을 통해 unbiased 된 expectation을 얻을 수 있다. 이 보정된 expectation들을 가지고 gradient가 들어갈 자리에 $widehat{mt}, Gt$가 들어갈 자리에 $widehat{vt}$를 넣어 계산을 진행한다."
AI,딥러닝,간단한 MNIST 분류기를 MLP+CPU 버전으로 numpy로 만든다면 몇줄일까?,"2-layer 신경망을 구현한다고 했을 때, 100줄 이내로 만들 수 있다."
AI,딥러닝,"간단한 MNIST 분류기를 TF, PyTorch 등으로 작성하는데 몇시간이 필요한가?","TF 나 Pytorch 를 몇 번 사용해본 사람이라면 도큐먼트 참고도 하고 적당히 구글링도 하면, MNIST 분류기의 를 구현하는데 2시간이 걸리지 않을 것이라 생각한다. 강력한 성능을 내는 모델도 이러한 프레임워크를 사용하면 빠른 시간 내에 구현해낼 수 있음에 감사하고, 추상화가 잘 된 함수들일지라도 안에서는 어떤 동작을 하는지 알고 사용해야한다. --- 19-1 CNN이 아닌 MLP로 해도 잘 될까? Convolution 레이어는 receptive field 를 통해 이미지의 위치 정보까지 고려할 수 있다는 장점이 있다. 반면 MLP 는 모두 Fully connected 구조이므로 이미지의 특징을 이해하는데 픽셀마다 위치를 고려할 수 없게된다. 따라서 MNIST 분류기에서 MLP 를 사용하면 CNN 을 사용했을 때보다 성능이 낮다. --- 19-2 마지막 레이어 부분에 대해서 설명 한다면? MNIST 분류기는 Convolution 레이어를 깊게 쌓으며 숫자 이미지의 작은 특징부터 큰 특징까지 파악한다. 마지막 레이어, 는 이미지 데이터의 특징을 취합하여 10개의 숫자 중 적절한 숫자로 분류하는 역할을 한다. 만약 더 많은 레이블에 대해 분류해야 한다면 마지막 레이어의 out dimension 을 그에 맞게 설정하면 된다. --- 19-3 학습은 BCE loss로 하되 상황을 MSE loss로 보고 싶다면? train 과정에서 criterion 은 BinaryCrossEntropy 를 사용하고, valid 데이터를 이용한 valid loss 를 구하는 과정에서는 MeanSquaredLoss 를 사용한다. ---"
AI,딥러닝,딥러닝할 때 GPU를 쓰면 좋은 이유는?,GPU(Graphics Processing Unit)은 부동 소수점 연산을 수행하는 많은 코어가 있어 수 많은 연산을 병렬처리할 수 있다. 또한 CPU보다 더 큰 메모리 대역폭을 가지고 있기 때문에 큰 데이터를 더 효율적으로 빠르게 처리할 수 있다. 메모리 대역폭(Memory Bandwidth)란 메모리가 처리할 수 있는 초당 데이터양을 뜻한다.
공통,Python,파이썬에서 리스트(list)와 튜플(tuple)의 차이는 무엇인가요?,"리스트는 mutable(변경 가능), 튜플은 immutable(변경 불가능)이라는 특징을 가지고 있다. 따라서 리스트는 선언 후에도 값에 대한 변경, 삭제가 가능하지만, 튜플은 선언 후에 값을 변경하거나 삭제하는 것이 불가능하다. 또한 리스트는 튜플보다 느리다는 단점을 가지고 있으며, 하나의 튜플/리스트에 다른 타입의 값을 함께 저장할 수 있다는 공통점이 있다. 리스트는 대괄호 를, 튜플은 소괄호 를 사용해서 나타낸다."
공통,Python,파이썬의 핵심 특징은 무엇인가요?,"파이썬이 주요 특징은 아래와 같다. 인터프리터 언어(Interpreter Language) 파이썬은 인터프리터 언어이므로, 실행하기 전에 컴파일을 할 필요가 없다. 자세한 내용은 Python an interpreted language. Explain. 참고 동적타이핑(Dynamic Typing) 파이썬은 실행시간에 자료형을 검사하므로, 선언할 때 변수 유형(ex.int, double, ...)을 명시할 필요가 없다. 이란 프로그램 내에서 변수의 데이터 타입을 정하는 것을 말한다. 데이터 타입 지정(assign)은 정적 또는 동적 타이핑으로 분류되는데, 프로그램 컴파일 시에 변수의 타입을 체크하는 C, C++과 같은 언어는 정적 타입(static typed) 언어라고 하고, 프로그램 실행 시에 타입을 체크하는 python은 동적 타입(dynamic typed) 언어이다. 객체 지향 프로그래밍(OOP) 파이썬은 클래스와 구성 및 상속을 함께 정의할 수 있다는 점에서 객체 지향 프로그래밍에 매우 적합하다. 일급객체(First-class citizen) 파이썬에서 함수와 클래스는 일급 객체이다. 일급객체는 변수나 데이터 구조 안에 담을 수 있고, 매개변수로 전달이 가능하며, 리턴값으로 사용될 수 있다는 특징을 가지고 있다. 이 외 특징 파이썬은 들여쓰기(indentation) 와 간결하고 쉬운 문법을 통해 빠르게 코드를 작성할 수 있다는 장점을 가지고있다. 변수, 인수(argument)를 미리 선언하지 않아도 자동으로 메모리 공간 할당되어 편리하다. 함수(function) 또는 모듈(module) 추가가 용이하여 확장성과 이식성이 좋다. 파이썬은 인터프리터로 동작하는 스크립트 언어이므로 다른 컴파일 언어에 비해 다소 느리다. 컴파일러가 코드를 기계어로 번역해서 실행가능 파일을 만드는 것에 비해, 인터프리터는 코드를 한줄씩 실행시간마다 번역해서 실행하기 때문이다."
공통,Python,파이썬이 인터프리터 언어라는 것은 무엇을 의미하나요? 설명해주세요.,"인터프리터는 고급 언어로 작성된 원시코드 명령어들을 한번에 한 줄씩 읽어들여서 실행하는 프로그램이다. 인터프리터 언어는 실행시간(runtime) 전에 기계 레벨 코드(machine-level code)를 만드는 컴파일 언어와 다르게 소스코드를 바로 실행하는 언어이며, 파이썬은 인터프리터 언어에 해당한다. 인터프리터 언어는 스크립트 언어와 동일한 의미이다. 스크립팅/스크립트 언어에 대한 질문과 답변은 What type of language is python? Programming or scripting?을 참고한다."
공통,Python,PEP 8이란 무엇인가요?,"PEP(Python Enhancement Proposal)는 Python 코드를 포맷하는 방법을 지정하는 규칙 집합이다. 다른 사람과 원활하게 협업하려면 공통된 스타일 공유가 필요하며, 일관성 있는 스타일은 나중에 수정하기도 쉽다. PEP8은 파이썬 코드를 어떻게 구성할 지 알려주는 스타일 가이드로서의 역할을 한다. Python formatting tool에는 , , , 등이 있다. PEP8 스타일 가이드 예시 whitespace 한 줄의 문자 길이가 79자 이하여야 한다. 함수와 클래스는 빈 줄 두개로 구분한다. naming 함수, 변수, 속성 : 보호(protected) 인스턴스 속성 : 비공개(private) 인스턴스 속성 :"
공통,Python,파이썬에서 메모리는 어떻게 관리되나요?,"Python은 모든 것을 객체로 관리한다. 객체가 더이상 필요하지 않으면 파이썬 메모리 관리자가 자동으로 객체에서 메모리를 회수하는 방식을 사용하므로, 파이썬은 동적 메모리 할당 방식을 사용한다고 말할 수 있다. 힙(heap)은 동적할당을 구현하는데 사용된다. 힙을 사용하여 동적으로 메모리를 관리하면, 필요하지 않은 메모리를 비우고 재사용할 수 있다는 장점이 있다. 모든 파이썬 객체 또는 자료구조는 python private heap 공간에서 관리되며, 프로그래머는 이 공간에 접근할 수 없고, 대신 파이썬 인터프리터가 대신해서 관리한다. 더 자세히보기 파이썬 객체에 대한 힙 공간 할당을 담당하는 것을 파이썬 메모리 관리자(Python Memory Manager) 라고 부른다. Python 메모리 관리자에는 객체별 할당자가있기 때문에 int, string 등과 같은 특정 객체에 대해 메모리를 명확하게 할당 할 수 있다. 또한, 사용되지 않는 모든 메모리를 재활용하고 힙 공간에서 사용할 수 있도록 하는 내장 Garbage Collector(GC) 를 가지고 있다."
공통,Python,파이썬에서 네임스페이스(namespace)란 무엇인가요?,"namespace는 이름 지정 충돌(naming conflicts)을 피하기 위해 이름이 고유한지 확인하는 데 사용되는 이름 지정 시스템(naming system)이다. 네임스페이스(namespace, 이름공간)란 프로그래밍 언어에서 특정한 객체(Object)를 이름(Name)에 따라 구분할 수 있는 범위를 의미한다. 파이썬 내부의 모든것은 객체로 구성되며 이들 각각은 특정 이름과의 매핑 관계를 갖게 되는데 이 매핑을 포함하고 있는 공간을 네임스페이스라고 한다. 네임스페이스가 필요한 이유는 다음과 같다. 프로그래밍을 수행하다보면 모든 변수 이름과 함수 이름을 정하는 것이 중요한데 이들 모두를 겹치지 않게 정하는 것은 사실상 불가능하다. 따라서 프로그래밍언어에서는 네임스페이스라는 개념을 도입하여, 특정한 하나의 이름이 통용될 수 있는 범위를 제한한다. 즉, 소속된 네임스페이스가 다르다면 같은 이름이 다른 개체를 가리키도록 하는 것이 가능하다. 파이썬 네임스페이스의 특징 네임스페이스는 딕셔너리 형태로 구현된다. 모든 이름 자체는 문자열로 되어있고 각각은 해당 네임스페이스의 범위에서 실제 객체를 가리킨다. 이름과 실제 객체 사이의 매핑은 가변적(Mutable)이므로 런타임동안 새로운 이름이 추가될 수 있다. 빌트인 네임스페이스는 함부로 추가하거나 삭제할 수 없다. 파이썬 네임스페이스의 3가지 분류 : 기본 내장 함수 및 기본 예외들의 이름들이 소속된다. 파이썬으로 작성된 모든 코드 범위가 포함된다. : 모듈별로 존재하며, 모듈 전체에서 통용될 수 있는 이름들이 소속된다. : 함수 및 메서드 별로 존재하며, 함수 내의 지역 변수들의 이름들이 소속된다."
공통,Python,PYTHONPATH란 무엇인가요?,"모듈을 import할 때 사용되는 환경변수이다. 모듈을 import할 때마다 PYTONPATH를 조회하여 가져온 모듈이 디렉토리에 있는지 확인한다. 인터프리터는 이를 사용하여 로드할 모듈을 결정한다. PYTHONPATH 환경 변수에 경로를 추가하면, 파이썬은 이 경로들을 에 추가한다. 이를 통해 파이썬 코드 내부에서 뿐만 아니라 파이썬 코드 밖에서도 를 조작할 수 있다. PYTHONPATH에는 에 추가할 여러 경로들이 들어간다. 리눅스에서는 처럼 로 두 경로를 구분하고, 윈도우에서는 처럼 로 두 경로를 구분한다. 이외에도 sys.path에는 파이썬에 포함된 여러 내장 모듈 등을 탐색하기 위한 기본 경로가 들어간다. 의 순서 import는 리스트에 들어있는 경로들을 탐색하며 불러올 파이썬 파일을 찾는다. 리스트에 들어있는 맨 처음 경로부터 탐색을 시작하여, 특정 경로에서 불러올 파일을 찾았다면 남은 경로를 더 찾아보지 않고 탐색을 중지한다. 의 기본값은 아래의 순서대로 추가된다. 파일이 속한 디렉터리의 절대 경로 PYTHONPATH 환경 변수 기타 기본 경로 아래의 코드를 통해서 를 직접 확인할 수 있다."
공통,Python,파이썬 모듈이란 무엇인가요? 자주 사용하는 내장 모듈 몇 가지를 말해보세요.,"모듈이란 Python 코드를 포함하는 파일로써, 함수나 변수 또는 클래스를 모아 놓은 파일이다. 모듈은 다른 파이썬 프로그램에서 불러와 사용할 수 있게끔 만든 파이썬 파일이라고도 할 수 있다. 실행 가능한 코드를 포함하는, 파이썬 확장자 로 만든 파이썬 파일은 모두 모듈이다. 모듈을 사용하면, 다른 코드에 적용하기가 쉬워지므로 이식성이 좋아진다. 자주 사용되는 빌트인 모듈(built-in module)의 예시는 다음과 같다."
공통,Python,파이썬에서 로컬 변수와 전역 변수는 무엇인가요?,"전역 변수(Global Variable)는 함수 외부 또는 전역 공간에 선언된 변수이다. 프로그램의 모든 함수에서 전역변수에 접근할 수 있다. (Whenever Python exits, why isn't all the memory de-allocated? 참고) 로컬 변수(Local Variable)는 함수 내부에 선언된 변수를 말한다. 로컬 변수는 전역 공간이 아닌 로컬 공간에 있다. 함수의 외부에서 함수의 로컬 변수에 액세스하려고 하면 오류가 발생한다. ---"
공통,Python,파이썬은 대소문자를 구분하나요?,"파이썬은 대소문자를 구분하는 언어이다. 예를들어, 와 는 다른 변수이다. ---"
공통,Python,파이썬에서 형 변환(type conversion)이란 무엇인가요?,"type conversion은 타입 캐스팅(type casting)과 동일한 의미를 가지며, 이는 어떤 데이터 타입을 다른 데이터 타입으로 변환하는 것을 말한다. 타입 캐스팅 함수의 종류 : 정수형으로 변환한다. : 실수형으로 변환한다. : 문자형을 정수형으로 변환한다. : 정수형을 10진수로 변환한다. : 정수형을 8진수로 변환한다. : 튜플형으로 변환한다. : set으로 변환한다. : list로 변환한다. : (key,value) 순서로 이뤄진 튜플을 딕셔너리형으로 변환한다. : 정수형을 문자형으로 변환한다. : 실수를 복소수로 변환한다. ---"
공통,Python,Windows에 파이썬을 어떻게 설치하고 환경 변수(PATH)는 어떻게 설정하나요?,"Windows에 Python을 설치하려면 다음 단계를 거쳐야한다. 링크에서 python을 설치한다. PC에 다운로드 받은 python을 설치하면서, 에 체크하고, 안내에 따라 설치하며 python을 설치한 위치를 저장해둔다. 으로 이동하여 시스템 변수를 편집하여 2번에서 저장해둔 python.exe 실행파일이 있는 경로를 추가해주면 된다."
공통,Python,파이썬에서 들여쓰기는 필수인가요?,"Python은 Indentation(들여쓰기)이 필요하다. 파이썬은 을 사용하여 영역을 지정하지 않고, 들여쓰기를 사용하여 코드블록을 지정하기 때문에 파이썬에서 들여쓰기는 문법적인 강제사항이다. 등의 모든 코드는 들여쓰기 블록 내에서 지정된다. 들여쓰기의 방법은 1칸, 2칸, 4칸, 탭 등 여러가지 방식이 있다. 일반적으로 파이썬은 네 개의 공백 문자를 사용하여 들여쓰기를 수행한다. 코드가 정확하게 들여쓰여지지 않으면 실행되지 않고 오류도 발생한다. 중요한 것은 같은 블록 내에서는 들여쓰기 칸 수가 같아야한다는 것이다. 들여쓰기 규칙 위반시에는 에러를 출력한다."
공통,Python,파이썬의 배열(array)과 리스트(list)의 차이는 무엇인가요?,"Python에서는 array과 list가 동일한 방식으로 데이터를 저장한다. 차이점은, 배열은 단일 데이터 타입 요소만 포함할 수 있는 반면, 리스트에는 다양한 타입의 요소들이 들어갈 수 있다는 것이다. array의 선언 방법은 처럼 자료형을 정하고, 지정한/동일한 자료형만을 넣을 수 있도록 되어있다. list은 변수에 로 여러 타입의 변수를 묶어서 선언할 수 있다. array에서 사용할 수 있는 타입은 아래와 같다."
공통,Python,파이썬에서 함수(function)란 무엇인가요?,"함수는 호출될 때만 실행되는 코드 블록이다. Python 함수를 정의하기 위해 def 키워드가 사용된다. 반복되는 부분을 함수로 만들어서 사용하면, 똑같은 코드를 여러번 반복하여 쓰지 않아도 되고, 프로그램의 흐름을 쉽게 파악할 수 있다는 장점이 있다."
공통,Python,__init__은 무엇인가요?,"는 파이썬에서 특별하게 약속된 메서드 가운데 하나로, 초기화 메서드 혹은 생성자라고도 한다. 이 메서드는 클래스의 새 개체/인스턴스가 생성될 때 메모리를 할당하기 위해 자동으로 호출되며, 그 객체가 갖게 될 여러 가지 성질을 정해준다. 모든 클래스에는 메서드가 있다. 💡 은 무엇인가? python 3.3 이하 버전에서, package import하기 위해서 사용되는 규칙이다. 3.3 이후의 버전에서는 이 제약사항이 해제되었다. 는 python 프로그램이 디렉토리를 처음 가져올 때 자동으로 실행되는 패키지 초기화 파일 역할을 하고, 모듈의 네임스페이스 초기화 역할을 한다."
공통,Python,람다 함수(lambda function)란 무엇인가요?,"익명 함수(이름이 없는 함수)를 람다 함수라고 한다. 람다 함수는 키워드를 통해서 함수를 생성하는 리터럴 표기법을 딱 한 줄의 코드로 표현할 수 있게 해주며, 의 형식으로 표현한다. 람다함수는 결과 부분을 return 키워드 없이 자동으로 return한다. 람다함수를 사용하면 코드가 간결해지고 메모리가 절약된다는 장점이 있다. 그러나 함수에 이름이 없고, 저장된 변수가 없기 때문에 다시 사용하기 위해서는 다시 코드를 적어주거나, 람다함수를 변수에 담아주어야한다. 따라서, 재사용할 이유가 없다면 lambda 함수를 생성하여 넘겨주는 편이 좋다. 람다함수의 표현법을 그림으로 표현하면 아래와 같다."
공통,Python,파이썬에서 self는 무엇인가요?,"우선 가 어디에서 쓰이는지 알아야 한다. 는 인스턴스 메서드(instance method)의 첫 번째 인자이다. 메서드가 호출될 때, 파이썬은 에 인스턴스를 넣고 이 인스턴스를 참조하여 인스턴스 메서드를 실행할 수 있게 된다."
공통,Python,"break, continue, pass는 어떻게 동작하나요?","는 가장 가까운 for문이나 while문의 루프에서 빠져나가도록 한다. 는 이번 이터레이션(iteration)을 건너뛰고 다음 이터레이션을 이어나가도록 한다. 는 문법적으로 필요하지만, 아무 것도 하지 않게 하고 싶을 때 사용한다. 주로 함수나 클래스의 구조부터 세우고 나중에 구현을 하고 싶을 때 사용한다."
공통,Python,[::-1] 은 무엇을 하나요?,"파이썬 시퀀스 자료형은 값이 연속적으로 이어진 자료형으로, 리스트, 튜플, range, 문자열이 있다. 시퀀스 자료형은 시퀀스 객체의 일부를 잘라낼 수 있는 슬라이싱(slicing)이라는 기능을 쓸 수 있다. 슬라이싱은 처럼 쓸 수 있으며, 는 시작 인덱스, 는 끝 인덱스(범위에 포함하지는 않음), 은 인덱스 증감폭을 말한다. 이 양수이면 증가하고, 음수이면 감소한다. 다시 돌아와 은 와 는 시작 인덱스와 끝 인덱스를 생략하였는데, 이럴 경우 전체 시퀀스를 가져오며, 증감폭이 -1이므로 부터 시작해 순으로 요소를 가져온다. 즉, 은 시퀀스를 역전(reverse)시킨다."
공통,Python,파이썬에서 리스트의 항목을 제자리에서 무작위로 섞으려면 어떻게 하나요?,random 모듈의 메서드를 사용하면 구현할 수 있다. 은 시퀀스 객체의 요소를 임의로 섞어서 해당 시퀀스를 반환한다.
공통,Python,이터레이터(iterator)와 이터러블(iterable)의 차이는 무엇인가요?,"iterable 객체는 함수에 인자로 전달 가능한, 반복 가능한 객체를 말한다. 예를 들면, 리스트(list), 딕셔너리(dictionary), 집합(set), 문자열(string) 등이 있다. iterable 객체를 함수의 인자로 넣으면 iterable 객체를 순회할 수 있는 객체를 반환하는데, 이것이 iterator 객체이다. iterator 객체를 함수의 인자로 주면 iterable 객체의 요소의 값을 차례대로 반환한다. 만약 iterable 객체를 모두 순회했다면, StopIteration 예외를 발생시킨다. 만약 다시 순회를 하고 싶다면 함수로 새로운 iterator 객체를 생성해주면 된다."
공통,Python,파이썬에서 난수를 생성하는 방법은 무엇인가요?,random 모듈로 간단히 생성할 수 있다. 편의를 위해 다음과 같이 random 모듈을 import하고 시드값을 2021로 고정하자. 0과 1사이의 임의의 수를 생성하고 싶은 경우 특정 범위 내의 임의의 정수를 생성하고 싶은 경우 특정 범위 내의 n개의 정수를 생성하고 싶은 경우
공통,Python,range와 xrange의 차이는 무엇인가요?,"파이썬2에서는 와 모두 존재하지만, 파이썬3부터는 가 내부적으로 로 동작하도록 바뀌어서 만 존재한다. 그러므로 파이썬2를 기준으로 와 를 설명한다. 객체는 입력으로 받은 정수 범위의 값을 요소로 같는 리스트를 말한다. 그러므로 과 는 완전히 동일하다. 는 제너레이터 객체로, 오직 루프를 돌때만 해당 범위의 정수를 하나씩 반환한다. 제너레이터에 관한 설명은 여기에서!"
공통,Python,파이썬에서 주석은 어떻게 작성하나요?,을 사용하여 주석을 달 수 있다. 따옴표를 이용한 주석은 Docstring 형식으로 자세한 내용은 #32를 참고!
공통,Python,피클링(pickling)과 언피클링(unpickling)은 무엇인가요?,"우선 와 의 개념을 알아야 한다. 란 객체를 바이트 스트림(byte stream)으로 변환하여 디스크에 저장하거나 네트워크로 보낼 수 있도록 만들어주는 것을 말한다. 반대로 바이트 스트림을 파이썬 객체로 변환하는 것을 라고 한다. pickle 모듈은 파이썬 객체의 직렬화와 역 직렬화를 수행하는 모듈이다. 이 때 파이썬 객체를 직렬화할 때를 이라고 하며, 바이트 스트림을 역 직렬화할 때를 이라고 한다."
공통,Python,파이썬의 제너레이터(generator)란 무엇인가요?,"제너레이터(Generator)란 Iterator 객체를 간단히 만들 수 있는 함수를 말한다. 제너레이터는 다음과 같이 1) yield문과 함수, 2) 표현식 형태로 만들 수 있다. 방법 1. yield문과 함수 제너레이터 함수 정의 제너레이터 객체 생성 및 next 함수로 호출 방법 2. 표현문 그럼 왜 리스트 대신 제너레이터를 사용할까? 리스트를 사용하면 리스트의 크기만큼 메모리에 공간이 할당된다. 반면 제너레이터는 말그대로 next 함수로 호출될 때 값을 생성하고 해당 값만 메모리에 올린다! 즉, 메모리를 절약할 수 있다. 작은 데이터라면 상관없지만 큰 데이터에서는 제너레이터 사용이 필수이다."
공통,Python,문자열의 첫 글자를 대문자로 만드는 방법은 무엇인가요?,문자열 메서드 를 사용하면 된다. 자세한 문자열 메서드는 여기를 참고!
공통,Python,문자열을 모두 소문자로 변환하는 방법은 무엇인가요?,문자열 메서드 을 사용하면 된다.
공통,Python,파이썬에서 여러 줄 주석을 다는 방법은 무엇인가요?,을 여러 줄 사용하여 여러 줄의 주석을 달 수 있다. 따옴표를 이용한 주석은 Docstring 형식으로 자세한 내용은 #32를 참고!
공통,Python,파이썬에서 독스트링(docstring)이란 무엇인가요?,"docstrings은 주석은 아니지만, 사용자에게 코드에 대한 설명을 적어놓은 문서(documentation)이다. docstrings는 속성이나 내장 함수로 접근할 수 있다. docstrings는 작은 따옴표() 혹은 큰 따옴표() 3개로 작성할 수 있다. 💡 Comments(주석) vs Dosctrings comments와 docstrings은 각각 , 을 쓴다는 점에서 다르지만 가장 큰 차이는 읽는 대상이다. comments는 개발을 위해 동료 혹은 나중에 코드를 읽을 나에게 남겨놓는 것이고 docstrings는 이 코드를 사용할 사용자들이 이해하기 쉽도록 남겨놓는 것이다."
공통,Python,"is, not, in 연산자의 목적은 무엇인가요?","는 객체 비교 연산자(identity operator)로 두 변수가 참조하는 객체의 id가 같을 경우 True를 반환한다. 보통 두 변수가 참조하는 객체가 동일한 객체인지 확인할 때 사용한다. 은 단항 논리 연산자(logical operator)로 뒤에 오는 boolean 값을 뒤집는다. 뒤에 오는 값이 True이면 False를, False이면 True를 반환한다. 은 멤버 연산자(membership operator)로, 요소 a와 시퀀스 b가 있는 지를 확인하고 싶을 때 로 표현하며 만약 a가 b 안에 있다면 True를, 없으면 False를 반환한다."
공통,Python,파이썬의 help()와 dir() 함수는 어떻게 사용하나요?,"는 docstrings를 작성하였다면 해당 docstrings를 출력한다. docstrings에는 클래스, 메서드의 사용법에 관한 내용이 담겨있으므로 해당 클래스와 메서드를 사용자에게 매우 유용하다. docstrings에 대한 내용은 #31 참고! 은 인자로 넣은 객체의 속성과 메서드를 문자열로 변환하고 그것을 요소로 갖는 정렬된 리스트를 반환한다. 은 사용할 객체의 메서드와 속성에 대한 정보를 얻고 싶을 때 유용하다. 다만 인자가 없다면 현재 지역 스코프에서 정의된 함수와 변수들의 리스트를 반환한다."
공통,Python,파이썬이 종료될 때 왜 모든 메모리가 해제되지 않나요?,"다른 객체나 전역 네임스페이스에서 참조되는 객체를 순환 참조하는 파이썬 모듈은 항상 해제되지는 않는다. 또한 C 라이브러리가 예약한 메모리의 해당 부분을 해제하는 것은 불가능하다. 그러므로 파이썬 종료 시, 모든 메모리가 해제되지는 않는다. 💡 순환 참조(Circular Reference) 두 객체가 서로 참조하는 경우를 말한다. 💡 전역 네임스페이스(Global Namespace) 네임스페이스(namespace)란 프로그래밍 언어에서 특정 객체를 이름에 따라 구분할 수 있는 범위를 의미한다. 전역 네임스페이스는 import한 모듈들의 이름을 포함하며, 스크립트가 끝날 때까지 지속된다."
공통,Python,파이썬에서 딕셔너리(dictionary)란 무엇인가요?,"딕셔너리는 key값과 그에 대응하는 value값을 얻을 수 있는 컬렉션을 말한다. 딕셔너리는 데이터가 들어온 순서가 상관이 없고, 인덱싱이 되어 있어 key값으로 요소에 접근하여 데이터(= value) 수정이 가능하다. 하지만, key값은 고유 값이므로 key값 중복은 불가능하다. 주로 자체적으로 만든 key값으로 데이터에 접근하고 싶을 때 딕셔너리 컬렉션을 사용한다. 딕셔너리의 뜻은 사전이다. 영한 사전에서 각 영단어(ex. beautiful)에 대응하는 단어(ex. 아름다운)가 나오는 것처럼, 영단어가 key값이고 그에 대응하는 단어를 value값으로 볼 수 있다. 특징1 : 딕셔너리는 {, }를 사용하여 선언하며 { key1 : value1, key2 : value2, ... } 로 요소를 나타낸다. key값으로 변하지 않는 값을 사용하고, value값으로 변하는 값과 변하지 않는 값 둘 다 사용할 수 있다. key값으로 리스트를 사용하면, 값이 변할 가능성이 있기 때문에 인터프리터에서 type error를 발생시킨다. 특징2 : 딕셔너리는 딕셔너리 쌍(key : value)을 추가하거나 제거할 수 있다. 추가 : dictex[ 새로운 key값 ] = 그에 대응하는 value값으로 추가할 수 있다. 제거 : del 키워드를 이용해 특정 쌍을 제거할 수 있다. 딕셔너리 앞에 del 키워드를 쓰면 딕셔너리가 완전히 제거된다. 특징3 : 딕셔너리의 key값은 중복될 수 없다. key값은 고유값이므로 2개 이상의 key값이 존재할 수 없다. key값에 해당하는 value값을 어떤 걸 불러야할지 모르기 때문. key값이 중복될 경우 하나를 제외한 나머지 것들이 모두 무시된다. key값에 대입한 최근의 value값을 불러온다."
공통,Python,파이썬에서 삼항 연산자는 어떻게 사용할 수 있나요?,ternary operators(삼항 연산자)는 조건문을 표시하는 데 사용되는 연산자이며 의 형태로 표현된다.
공통,Python,"*args, **kwargs는 무엇을 의미하나요? 왜 사용하나요?? And why would we use it?","는 함수에 전달되는 argument의 수를 알 수 없거나, list나 tuple의 argument들을 함수에 전달하고자 할 때 사용한다. 파이썬에서는 어디서부터 어디까지 에 담아야 할지 알 수 없기 때문에, 일반 변수를 앞에 두고 그 뒤에 를 지정해 주어야 한다. 는 함수에 전달되는 keyword argument의 수를 모르거나, dictionary의 keyword argument들을 함수에 전달하고자 할 때 사용한다. 와 를 함께 사용하는 경우 를 보다 앞에 두어야 한다. 일반 변수, , 를 모두 사용하는 경우 다음과 같은 순서를 따른다."
공통,Python,len()은 무엇을 하나요?,"함수는 object의 길이(item의 수)를 return 한다. argument로는 sequence(string, bytes, tuple, list, range, ...), collection(dictionary, set, frozenset, ...)을 받는다."
공통,Python,"파이썬 re 모듈의 split(), sub(), subn() 메서드를 설명하세요.","파이썬에서 정규표현식을 사용하기 위해 ""re"" 모듈을 사용한다. 문자열 수정을 위해 Python의 ""re"" 모듈은 3 가지 메서드를 제공한다. : pattern을 구분자로 string을 분리하여 list로 반환한다. : string에서 pattern과 일치하는 부분에 대하여 repl로 교체하여 결과 문자열을 반환한다. : sub와 동일하나, 결과로 (결과문자열, 매칭횟수)를 튜플로 반환한다."
공통,Python,음수 인덱스(negative index)란 무엇이며 왜 사용하나요?,"인덱스 시퀀스 객체에 (대괄호)를 붙여 사용 시퀀스 객체의 인덱스는 항상 0부터 시작 시퀀스 객체(list, tuple, range, 문자열)에 사용가능 시퀀스객체[인덱스] 음수 인덱스 인덱스를 음수로 지정하면 뒤에서부터 요소에 접근하게 된다. -1은 뒤에서 첫 번째, -5는 뒤에서 다섯 번째 요소를 뜻한다. 시퀀스 객체(list, tuple, range, 문자열)에 사용가능"
공통,Python,파이썬 패키지(packages)란 무엇인가요?,"모듈 모듈은 파이썬 코드를 논리적으로 묶어서 관리하고 사용할 수 있도록 하는 것으로, 보통 하나의 파이썬 파일이 하나의 모듈이 된다. 모듈 안에는 함수, 클래스, 혹은 변수들이 정의될 수 있으며, 실행 코드를 포함할 수도 있다. 모듈에 관한 자세한 내용은 #9. 모듈 참고! 패키지 패키지는 특정 기능과 관련된 여러 모듈을 묶은 것으로 패키지는 모듈에 namespace를 제공한다. 패키지는 하나의 디렉토리에 놓여진 모듈들의 집합을 가리키는데, 그 디렉토리에는 일반적으로 라는 패키지 초기화 파일이 존재한다. 패키지는 모듈들의 컨테이너로서 패키지 안에는 또다른 서브 패키지를 포함할 수도 있다. 파일시스템으로 비유하면 패키지는 일반적으로 디렉토리에 해당하고, 모듈은 디렉토리 안의 파일에 해당한다. 패키지들의 모음인 라이브러리에 대한 내용은 #52. 라이브러리 참고!"
공통,Python,파이썬에서 파일을 삭제하는 방법은 무엇인가요?,os 모듈을 import 한 후 함수를 사용하여 파일을 삭제할수있다. 자세한 내용은 os.remove - Python documentation 참고! ---
공통,Python,파이썬의 내장(built-in) 자료형에는 무엇이 있나요?,Python의 Built-in type은 아래와 같다. Integer Floating-point Complex number String Boolean Built-in function 자세한 내용은 Built-in Types - Python documentation 참고! 💡 빌트인built-in이란? 어떤 기능이나 함수 등이 내장 또는 빌트인되어 있다는 뜻은 그것이 프로그램에서 바로 사용가능하도록 준비되어 있다는 뜻이다. 자세한 내용은 basic-terminology-in-programming - shoark7 참고할 것. ---
공통,Python,넘파이(NumPy) 배열이 (중첩된) 파이썬 리스트보다 제공하는 이점은 무엇인가요?,"numpy array는 하나의 데이터 타입만 정의가 가능하다. Python list와 달리 다이나믹 타이핑을 지원하지 않으며, C의 Array를 사용하여 배열을 생성하기 때문에 속도가 빠르다. Python list는 데이터 주소값을 저장하고 데이터를 가져올 때는 해당 주소에 가서 데이터를 가져온다. 반면 Numpy array는 C의 배열과 유사하여 연속된 주소를 가지고 있어 데이터를 가져올 때는 순서대로 가져오면 되기 때문에 메모리를 효율적으로 사용한다. Numpy에 대한 내용은 #66. Numpy 참고!"
공통,Python,파이썬 리스트에 값을 추가하는 방법은 무엇인가요?,", , 함수를 사용하여 list에 value를 추가할 수 있다. append() 형태로 사용하며, $O(1)$의 시간복잡도를 갖는다. 괄호 안에 값을 입력하면 새로운 요소를 list 맨 끝에 추가한다. 요소를 추가할 때는 객체로 추가하게 되는데, 입력한 값이 리스트와 같은 반복 가능한 iterable 자료형이더라도 객체로 저장한다. extend() 형태로 사용하며, $O(N)$ 시간복잡도를 갖는다. 입력한 iterable 자료형의 항목 각각을 list의 끝에 하나씩 추가한다. iterable 자료형으로 추가되는 것이 아니라 iterable 자료형 안에 있는 항목이 하나씩 떼어져서 추가된다. append와 동일하게 요소를 list의 끝에 추가하지만 append와 다른 점은 괄호 안에는 iterable 자료형만 올 수 있다는 것이다. iterable 자료형이 아닌 경우 TypeError가 발생한다. insert() 시간복잡도: 형태로 사용하며, $O(N)$ 시간복잡도를 갖는다. list의 원하는 위치 i 앞에 추가할 값 x를 삽입할 수 있다. i는 위치를 나타내는 인덱스를 숫자를 입력한다. 음수를 입력하면 배열의 끝을 기준으로 처리된다. 추가할 값 x는 객체로 추가되며 iterable 자료형이더라도 객체로 저장된다. 연산자 형태로 사용하며, $O(1)$ 시간복잡도를 갖는다."
공통,Python,파이썬 리스트에서 값을 제거하는 방법은 무엇인가요?,", 함수를 사용하여 list에 value를 삭제할 수 있다. remove() 는 지우고자 하는 인덱스가 아닌, 값을 입력하는 방식이다. 만약 지우고자 하는 값이 리스트 내에 2개 이상이 있다면 순서상 가장 앞에 있는 값을 지우게 된다. 값을 삭제할 때 삭제된 값을 반환하지 않는다. 는 시간복잡도 $O(N)$를 갖는다. pop() 은 리스트에서 지우고자 하는 값의 인덱스를 받아서 지우는 방식이다. 값을 삭제할 때 삭제된 값을 반환한다. 인덱스를 지정하지 않으면 리스트의 마지막 요소가 삭제되며 반환된다. 은 시간복잡도 $O(N)$를 갖는다. del 형태로 사용하며, 시간복잡도 $O(N)$을 갖는다. 값을 삭제할 때 삭제된 값을 반환하지 않는다."
공통,Python,파이썬에 객체지향(OOP) 개념이 있나요?,"Python은 객체 지향 프로그래밍 언어이다. Python의 주요 OOP 개념에는 Class, Object, Method, Inheritance(상속), Polymorphism(다형성), Data Abstraction(데이터 추상화), Encapsulation(캡슐화)을 포함한다. 더 자세한 내용은 #55. Inheritance, #59. Polymorphism, #60. Encapsulation, #61. Data Abstraction 참고!"
공통,Python,얕은 복사(shallow copy)와 깊은 복사(deep copy)의 차이는 무엇인가요?,Shallow copy는 새로운 객체(변수)를 만든 후에 원본에 접근할 수 있는 참조(reference)를 입력한다. 이런 경우 서로 다른 변수명이지만 본질적으로 서로 같은 대상을 의미하므로 하나의 변수 역시 수정이 된다. 가변형(mutable) 자료형에 대해서 적용이 가능하다. 가변형(mutable) 자료형은 같은 주소에서 값(value)이 변경 가능하기 때문에 얕은 복사가 가능하다. 반면 불변형(immutable) 자료형은 본질적으로 변경이 불가능하므로 재배정을 통해 변수를 바꾼다. 따라서 재배정이 이루어지므로 객체가 서로 달라진다. Deep copy는 새로운 객체(변수)를 만든 뒤에 원본의 복사본을 변수에 입력한다. 서로 값만 같을 뿐 본질적으로 서로 다르기 때문에 한 변수가 수정될 시 다른 변수가 수정되지 않는다.
공통,Python,파이썬에서 멀티스레딩은 어떻게 구현되나요?,"파이썬에서 멀티 쓰레드를 구현하는 방법은 을 사용하거나 을 사용하는 방법이 있다. 현재 thread 모듈은 deprecated 되어 threading 모듈을 사용하는 것을 권장한다. 멀티스레딩을 사용하면 당연히 속도가 빨라질 것이라 생각할 수 있지만, 파이썬의 GIL(Global Interpreter Lock) 정책으로 인해, 멀티스레딩을 사용한다 하더라도, 속도는 싱글스레드와 별반 다르지 않다. 하나의 자원에 여러 프로세스가 아무런 규칙없이 접근하면, 자원 동기화 문제가 발생할 수 있다. 이를 방지하기 위해서 자원에 lock을 두는데, Python은 모든 자원의 lock을 global하게 관리하고 있다. 한번에 하나의 스레드만 자원에 접근할 수 있다는 것이다. 이로인해, 자원을 공유하는 여러 스레드를 동시에 실행시킨다고 해도, 결국 GIL 때문에 한번에 하나의 스레드만 실행되는 것이다. 💡 멀티스레딩이 유용한 경우 GIL은 cpu 동작에 대해서만 적용된다. 쓰레드가 cpu 동작을 마치고 I/O 작업을 실행하는 동안에는 다른 쓰레드가 cpu 동작을 동시에 실행할 수 있다. 따라서 cpu 동작이 많지 않고 I/O동작이 더 많은 프로그램에서는 멀티 쓰레드만으로 성능적으로 큰 효과를 얻을 수 있다."
공통,Python,파이썬에서 컴파일과 링크 과정은 무엇인가요?,"파이썬 파일()를 실행하면, 소스 코드는 바이트 코드(byte code)로 변환되며, , 파일 형식으로 저장된다. 이 때 소스 코드를 바이트 코드로 변환하는 과정을 컴파일(compilation) 단계라고 한다. 파이썬 가상머신(Python Virtual Machine)이 바이트 코드를 기계어(machine code)로 변환하여 어떤 운영체제든 실행할 수 있도록 한다. 이 때 우리의 코드와 인터프리터가 필요한 라이브러리를 연결시키는 과정이 있는데, 이를 링크(linking) 단계라고 한다. 참고로 dis 모듈을 사용하여 소스 코드가 어떤 바이트 코드로 변환되는지 확인할 수 있다."
공통,Python,파이썬 라이브러리(libraries)란 무엇인가요? 몇 가지 예를 들어보세요.,"파이썬 라이브러리는 패키지의 모음이다. 주로 사용되는 파이썬 라이브러리로는 , , , 등이 있다. 패키지에 대한 더 자세한 내용은 #42. 패키지 참고! ---"
공통,Python,split은 어떤 용도로 쓰이나요?,"은 특정 문자를 기준으로 문자열을 분리할 때 사용한다. sep을 구분자로 사용하여 문자열에 있는 단어 list를 반환한다. sep이 지정되면 구분자를 기준으로 문자열을 분리하고, sep이 지정되지 않았거나 None인 경우에는 whitespace를 기준으로 문자열을 분리한다. maxsplit이 지정되면 그 수만큼의 분할이 수행되고, maxsplit이 지정되지 않았거나 -1인 경우에는 가능한 모든 분할이 수행된다."
공통,Python,파이썬에서 모듈을 임포트하는 방법은 무엇인가요?,키워드를 사용하여 모듈을 가져올 수 있다. 세 가지 방법으로 모듈을 가져올 수 있다.
공통,Python,파이썬에서 상속(Inheritance)을 예시와 함께 설명하세요.,"상속을 통해 상위 (부모) 클래스의 멤버 함수, 멤버 변수들을 모두 하위 (자식) 클래스가 가질 수 있다. 상위 클래스를 상속함으로써 코드 재사용성이 더 좋아지고, 관리가 용이해진다. 파이썬은 부모 클래스 A 를 자식 클래스 B 가 상속하는 Single Inheritance, 부모 클래스 A 를 자식 클래스 B 가 다시 B 를 자식 클래스 C 가 상속하는 Multi-level Inheritance, 부모 클래스 A 가 여러 자식 클래스에 상속되는 Hierarchical Inheritance, 하나의 자식 클래스가 여러 부모 클래스를 상속하는 Multiple Inheritance 가 있다. ---"
공통,Python,파이썬에서 클래스는 어떻게 생성하나요?,"class 키워드를 사용하여 클래스를 만들 수 있다. 이 때, 클래스명 옆 괄호에 상속받을 부모 클래스를 설정할 수도 있다. 기본적으로 이라는 매직 메소드를 통해 멤버 변수들을 세팅할 수 있다. 자세히는 클래스가 객체로 선언될 때, 멤버 변수의 값을 초기화하는 역할을 담당한다. 클래스 내에서는 멤버 함수를 만들 수 있고, 클래스 객체에서 멤버 함수를 사용할 수 있다. ---"
공통,Python,파이썬에서 몽키 패칭(monkey patching)이란 무엇인가요?,"주로 테스트를 위해 많이 사용되는 방법으로, 어떤 클래스나 모듈의 일부 (함수나 변수 등) 를 로컬에서 런타임으로만 instance 를 통해 수정하는 방법을 말한다. 예시로 heath.py 파일의 A 클래스에 a 라는 함수가 있는데, 다른 파일에서 A 를 import 하여 a 함수 대신 newa 를 할당하여 사용하는 방법이 있다."
공통,Python,파이썬은 다중 상속(multiple inheritance)을 지원하나요?,파이썬은 자바와 다르게 multiple inheritance 을 지원한다. multiple inheritance 의 개념은 #55 에서 참고할 수 있다. 예시는 아래와 같다. ---
공통,Python,파이썬에서 다형성(Polymorphism)이란 무엇인가요?,"다형성은 객체지향의 주요 개념으로 여러가지 형태를 가질 수 있는 능력을 말한다. 다형성은 코드의 유지보수에 도움을 준다. 파이썬은 다형성을 지원하는데, + 연산이나 len 연산에 대해 생각해볼 수 있다. 이들은 여러 타입의 변수에 대해서도 동일한 기능을 제공하는데 overriding 과 overloading 을 통해 각기 다른 타입의 변수에도 반응하도록 다형성을 주었기 때문에 가능하다."
공통,Python,파이썬에서 캡슐화(encapsulation)를 정의해보세요.,캡슐화는 주요 변수나 함수를 외부로부터 보호하는 방법을 말한다. 캡슐화를 통해 코드의 안전성을 높일 수 있다. 파이썬에서는 클래스를 생각해볼 수 있다. 클래스의 멤버 변수나 멤버 함수에 접근하기 위해서는 클래스에 대한 객체를 만들어야 한다. 객체를 통해 멤버에 접근하기 때문에 직접 변수를 손대는 것보다 데이터를 더 안전하게 지킬 수 있다. ---
공통,Python,파이썬에서 데이터 추상화(data abstraction)는 어떻게 하나요?,데이터 추상화는 객체지향의 주요 개념으로 사용자에게 데이터의 주요 정보만 제공하여 구체적인 구현은 몰라도 사용할 수 있게 만드는 방법이다. 파이썬에서는 abstract class 를 통해 데이터 추상화를 할 수 있다. abstract class 를 사용하기 위해서는 모듈을 import 하고 와 를 사용해야 한다. ---
공통,Python,파이썬은 접근 지정자(access specifiers)를 사용하나요?,"파이썬은 다른 언어와 달리 private, protected 등의 접근 제한자를 직접 명시하지 않고 변수명을 통해 접근 제어를 한다. 접두사 가 한 개 있는 경우에는 protected, 접두사 가 두 개 있는 경우에는 private, 접두사 가 없거나 접미사 가 두 개 이상 있는 경우에는 public 이다."
공통,Python,파이썬에서 빈 클래스(empty class)는 어떻게 만들까요?,"파이썬에서 클래스 내부에 아무 내용 없이 선언만 하기 위해서는 나 을 사용할 수 있다. 추가적으로 empty class 를 선언한 후, 외부에서 객체를 통해 클래스의 변수나 함수를 만들 수도 있다. ---"
공통,Python,object()는 무엇을 하나요?,파이썬은 모든 것이 객체이다. 따라서 기본적으로 object 클래스를 상속받고 있다. 함수를 사용하면 새로운 기본 object 객체를 반환받을 수 있다. ---
공통,Python,파이썬의 map 함수는 무엇인가요?,"map 함수는 iterable 한 객체의 모든 원소에 동일한 함수를 적용하는 기능을 한다. 첫 인자로 적용할 함수를, 두번째 인자로 iterable 한 객체를 넣으면, iterable 한 map 객체 형태로 각 원소에 대해 함수가 적용된 묶음들이 담겨 나온다. ---"
공통,Python,파이썬의 넘파이(NumPy)는 리스트보다 더 좋은가요?,"파이썬의 리스트는 각 원소들의 값을 직접 사용하지 않고 원소들의 주소를 참조하는 방식을 사용하기 때문에 원소들의 타입이 정해지지 않아 편리하지만 메모리를 많이 사용하고 느리다는 단점이 있다. 반면, 넘파이는 C 기반으로 구현되어 원소들의 타입을 미리 설정하여 메모리를 적게 사용하고 빠르다. 또한 행렬과 선형대수에 편리한 함수들을 제공한다는 장점도 있다. ---"
공통,Python,파이썬의 GIL(Global Interpreter Lock)은 무엇인가요?,"멀티쓰레딩을 할 때, 공유 자원에 대해 여러 쓰레드가 동시에 접근한다면 갱신된 내용이 유실되는 등의 문제가 발생할 수 있다. 이를 막기 위해 파이썬은 GIL (Global Interpreter Lock) 을 통해 python interpreter 에 한 쓰레드만 접근하여 모든 자원을 사용할 수 있게 한다. 정확히는 멀티 쓰레드가 bytecode(=instruction) 한 라인씩을 들고 있기 때문에, 한 쓰레드의 bytecode 한 줄에 대해서만 GIL 은 허용한다."
공통,Python,CPython이란 무엇인가요?,"파이썬은 일반적으로 C 로 구현된 인터프리터 언어이다. 일반적인 C 언어와 구분하기 위해 파이썬 구현체 C 를 CPython 이라고 부른다. CPython 은 인터프리터이면서 컴파일러로 Python 코드를 C 가 아닌 bytecode 로 컴파일해주고, 이를 interpreter(virtual machine) 가 실행하게 만든다. 이러한 CPython 의 interpreter 적인 특징이 파이썬을 차별되게 만들었다."
공통,Python,파이썬에서 데코레이터(Decorator)란 무엇인가요?,"함수를 인자로 받고 내부 함수에서 인자로 받은 함수를 사용하는 클래스나 함수가 있을 때, 인자로 사용할 함수를 간편하게 지정해주는 역할을 하는 것이 Decorator 이다. Decorator 의 사용 문법은 인자가 될 함수 위에 을 붙여주면 된다. 아래 예시를 보면, Decorator 를 통해 bignumber 와 bignumber2 라는 서로 다른 함수를 maketimechecker 가 인자로 받아 내부 함수에서 사용하고 있다."
공통,Python,오브젝트 인터닝(object interning)이란 무엇인가요?,"파이썬에서는 모든 것이 객체이므로 변수들은 값을 바로 가지지 않고 값을 가진 주소를 참조하게 된다. object interning 은 자주 사용될, 즉 재활용될 object 에 대해 매번 새로운 주소를 할당하는 것은 비효율적이므로, 하나의 주소에 값을 주고 그 주소를 재활용하는 작업을 말한다. 기본적으로 파이썬에서는 에 대해 고정된 주소를 할당하여 interning 을 하고 있다."
공통,Python,"@classmethod, @staticmethod, @property는 무엇인가요?","@classmethod 클래스 내부의 함수 중에 @classmethod 로 선언된 함수에 대해서는 클래스의 객체를 만들지 않고도 바로 접근이 가능하다. 하지만 함수의 첫 인자로 클래스를 받아서, 상속되었을 때 자식 클래스의 데이터를 따르는 특징이 있다. @staticmethod @staticmethod 는 @classmethod 와 마찬가지로 클래스의 객체를 만들지 않고도 바로 접근할 수 있다. 하지만 클래스를 인자로 받지 않기 때문에, 상속되었을 때에도 자식 클래스의 데이터를 따르지 않고 처음에 클래스에서 선언한 데이터대로 함수가 사용된다. @property 객체지향 언어에서는 캡슐화를 위해 변수를 직접 지정하지 않고 객체의 함수를 통해 지정하고 받아오는 setter, getter 함수를 사용한다. 파이썬에서는 이를 편하게 사용할 수 있도록 @property 를 제공한다. getter 가 될 함수에 @property 를, setter 가 될 함수에 @변수.setter 를 붙이면 된다."
BACKEND,네트워크,TCP/IP의 각 계층을 설명해주세요.,"TCP/IP는 인터넷에서 표준으로 사용되고 있는 네트워크 프로토콜(규칙)을 의미한다. TCP/IP는 IP(Internet Protocol)을 중심으로 한 여러 프로토콜의 집합체로, TCP/IP 5계층 혹은 TCP/IP 4계층(링크계층과 물리계층을 하나의 계층으로 보는 경우)으로 불린다. TCP/IP는 크게 5개의 계층으로 구성된다. 애플리케이션 계층(Application Layer, L5) 네트워크 애플리케이션과 애플리케이션 계층 프로토콜이 있는 곳이다. HTTP, SMTP, FTP와 같은 많은 프로토콜을 포함한다. 도메인 주소를 32비트 네트워크 주소로 변환하는 기능을 위한 DNS(Domain Name Server)를 지원한다. 애플리케이션 계층 패킷을 메시지(message)라고 한다. 트랜스포트 계층(Transport Layer, L4) 네트워크 계층에서 보내온 데이터 정렬, 오류 정정 등을 수행하고 신뢰할 수 있는 통신을 확보한다. TCP/UDP 같은 프로토콜이 이 계층에 위치한다. TCP, UDP에 대한 내용은 [[#4] TCP와 UDP의 차이를 설명해주세요.](#4) 을 참고한다. 트랜스포트 계층 패킷을 세그먼트(segment)라고 한다. 네트워크 계층(Network Layer/IP Layer, L3) 다른 네트워크에 있는 목적지에 데이터를 전송하는 역할을 수행한다. 즉, 네트워크 간의 통신을 가능하게 해주는 역할을 수행한다. 이를 위해, 라우터(router) 장비와 IP 프로토콜(오직 하나만 존재), 라우팅 프로토콜이 사용된다. 라우터는 다른 네트워크와 통신하기 위해 경로를 설정하고 논리주소를 결정하는 역할을 수행한다.(경로설정) 네트워크 계층의 패킷을 데이터그램(datagram)이라 한다. 링크 계층(Data Link Layer, L2) 네트워크 기기 간 데이터 전송 및 물리 주소를 결정하는 역할을 수행한다. 주로 건물이나 특정 지역을 범위로 하는 네트워크인 랜(LAN)에서 데이터를 정상적으로 주고받기 위해 필요한 계층이다. 데이터 링크 계층에서는 일반적으로 이더넷(Ethernet) 프로토콜이 사용되며, 스위치(switch) 같은 장치가 사용된다. 링크 계층 패킷을 프레임(frame)이라 한다. 물리 계층(Physical Layer, L1) 물리적인 연결과 전기 신호 변환/제어를 담당하여, 이진 데이터를 전기 신호로 변환한다. 또한 컴퓨터와 네트워크 장비를 물리적으로 연결하여, 하나의 노드에서 다른 노드로 비트를 이동시키는 역할을 수행한다. 물리 계층의 프로토콜들은 링크(실제 전송매체 ex.광케이블)에 의존한다."
BACKEND,네트워크,OSI 7계층와 TCP/IP 계층의 차이를 설명해주세요.,"(: TCP/IP 5계층에서 물리계층과 링크계층을 하나로 묶은 것) OSI 7계층은 TCP/IP 계층의 애플리케이션 계층을 더 세분화한 것이다. TCP/IP 계층과 다른, 응용계층, 표현계층과 세션계층에 대해서 설명하고 나머지는 [[#1] CP/IP의 각 계층을 설명해주세요.](#1)을 참고한다. 응용 계층(Application Layer) 사용자 또는 애플리케이션이 네트워크에 접근할 수 있도록 해주는 계층이다. 사용자를 위한 인터페이스를 지원하며, 사용자에게 보이는 유일한 계층이다. 메일 전송, 인터넷 접속 등의 작업을 수행할 수 있다. 표현 계층(Presentation Layer) 응용계층으로부터 전달받거나 전송하는 데이터의 인코딩 및 디코딩이 이루어지는 계층이다. 응용 계층에서 데이터를 이해할 수 있도록, 응용프로그램에 맞춰 변환하게 된다. 예를들어, JPEG, TIFF, GIF, MPEG 등의 다양한 포맷을 구분하게 된다. 세션 계층(Session Layer) 응용프로세스가 통신을 관리하기 위한 방법을 정의한다. 네트워크상 양쪽의 연결을 관리/지속시키는 역할과 세션을 만들거나 없애는 역할을 담당하는 계층이다. 통신하는 사용자들을 동기화하고 오류복구를 진행한다. 통신연결은 포트를 기반으로 구성하여 연결되며, OS가 세션계층에 속한다."
BACKEND,네트워크,"Frame, Packet, Segment, Datagram을 비교해주세요. (TCP/IP 5계층 기준)","Packet: 컴퓨터 간에 데이터를 주고받을 때, 네트워크를 통해 전송되는 데이터 조각을 패킷이라고 부른다. 송신 측(애플리케이션)은 많은 양의 데이터를 한번에 보내는 것이 아니라, 일정 단위로 잘라서 보낸다. 각 계층에서 필요한 정보는 캡슐화/역캡슐화되어 전달되고, 수신 측은 받은 패킷을 다시 조립해서 사용한다. Segment: Transport 계층(L4)에서 신뢰할 수 있는 통신을 구현하기 위한 헤더를 데이터(L5 계층 데이터)에 붙이는데, 이렇게 만들어진 패킷을 세그먼트라고 부른다. Datagram: Network 계층(L3)에서 다른 네트워크와 통신하기 위한 헤더를 세그먼트(L4 계층 데이터)에 붙인것을 데이터그램, 데이터 세그먼트라고 부른다. Frame: 데이터 링크 계층(L2)에서 물리적인 통신 채널을 열기 위해 패킷에 헤더와 트레일러를 붙인다. 트레일러는 데이터를 전달할 때 데이터 끝 부분에 붙이는 정보로, 주로 에러 검출에 사용된다. 왜 패킷을 잘라서 보낼까? 많은 데이터를 한번에 보내게 되면, 데이터 손실의 가능성이 있으며, 대역폭(신호를 전송할 수 있는 주파수 범위)을 너무 많이 차지하게 되므로, 패킷의 흐름을 원활히 조절하기 위함이다. 소켓(Socket), 포트(Port), 패킷(Packet) Port는 프로세스를 식별하기 위해, 호스트 내부적으로 프로세스가 할당받는 고유한 값이다. 같은 호스트 내에서 서로 다른 프로세스가 같은 포트 넘버를 가질 수 있음, 대신 같은 소켓을 사용하지는 못한다. 를 통해 만들어지는 소켓에는 새로운 포트 번호가 할당되는 것이 아니라, 서버가 가지는 포트(웹서버 기준, 80)와 동일한 포트 번호를 가진다. 만약 지정된 포트 번호를 다른 소켓이 사용하고 있다면, API는 에러를 리턴한다. 포트는 논리적인 접속장소이다. Socket은 프로세스로부터 네트워크로 데이터를 전달하는 출입구(인터페이스) 역할을 한다. 고 표현하며, 수신 측 호스트의 트랜스포트 계층은 실제로 데이터(세그먼트)를 직접 프로세스로 전달하지 않고, 중간 매개자인 소켓에게 전달한다. 호스트에서는 하나 이상의 소켓이 존재할 수 있으므로 소켓은 고유의 식별자를 가지고 있어야한다. 같은 프로세스가 같은 포트를 가지고도 여러 개의 소켓을 열 수 있기 때문에, 소켓과 포트는 다른 개념이다. 요약하자면, 소켓은 프로세스가 네트워크를 통해서 데이터를 주고받으려면 반드시 열어야 하는 창구 같은 것이고, 포트는 프로세스 식별을 위해 하나의 호스트에서 프로세스에 할당하는 고유값이고, 패킷은 네트워크 상의 데이터 조각을 말하는 것이다. 캡슐화/역캡슐화 캡슐화(Encapsulation): (데이터 송신 시)하위 계층으로 패킷을 보낼때, 하위계층에서 필요로하는 추가정보(메타데이터)를 헤더/트레일러에 추가하여 보내게된다. 역캡슐화(Decapsulation): 데이터 수신 시, 상위 계층으로 패킷을 전달하고, 전달된 패킷의 헤더를 차례대로 제거하면서 데이터를 얻게 된다."
BACKEND,네트워크,TCP와 UDP의 차이를 설명해주세요.,"TCP와 UDP는 모두 트랜스포트 계층(4계층)의 프로토콜이다. TCP와 UDP가 공통적으로 가지고 있는 기능은 아래와 같다. 트랜스포트 다중화/역다중화 기능(Transport Multiplexing/Demultiplexing): 을 로 확장 무결성 검사(오류검출): 헤더에 오류 검출 필드를 포함 이제 TCP와 UDP 각각에 대해 알아보자. UDP는 위의 가장 기본적인 두가지 기능만을 제공한다. UDP는 비신뢰적인 서비스로서, 프로세스에 의해서 전송된 데이터가 손상되지 않은채로 목적지에 도착하는 것을 보장하지 않는다. 또한 비연결형 서비스이며, 오류검출은 선택사항이다. UDP는 비연결형 서비스이므로 연결설정이 불필요하고 연결상태가 없다. 따라서 연결을 설정하기위한 어떠한 지연이 없고, 유지해야하는 정보가 없기 때문에 더 많은 클라이언트를 수용할 수 있다. 또한 UDP의 패킷 오버헤드(8 byte per segment)가 TCP(20 byte per segment)에 비해 더 작다는 장점이 있다. 그러나 혼잡제어를 사용하지 않아, 네트워크가 폭주상태에 빠지는 것을 막을 수 없다는 단점과 신뢰적이지 않으므로, 몇몇의 정보를 잃어버릴 수 있다는 단점이 존재한다. TCP는 가장 기본적인 두가지 기능도 제공하면서, 신뢰적인 데이터 전달(Reliable Data Transfer) 기능, 연결지향형 서비스, 혼잡제어(Congestion control) 등의 기능을 제공한다. 신뢰적인 데이터 전달은 흐름제어, 순서번호, 확인응답, 타이머 등의 기술을 사용하여 프로세스에게 데이터가 순서대로 정확히 전달되도록 하는 역할을 한다. 종단 시스템 간에 IP의 비신뢰적인 서비스를 프로세스 사이의 신뢰적인 데이터 전송 서비스로 만들수 있으며, TCP에서의 오류검출은 필수사항이다. 혼잡제어는 보내는 쪽(송신측)의 트래픽을 조절하여 스위치/링크의 혼잡을 방지하는 역할을 한다. 이는 특정 애플리케이션을 위해 제공하는 특정 서비스가 아니라, 전체를 위한 서비스로서, 혼잡한 네트워크 링크에서 각 TCP 연결이 링크의 대역폭을 공평하게 공유하여 통과하도록 해준다. 따라서, UDP는 속도증가와 지연 감소를 위해서 많이 사용되고, TCP는 신뢰성이 중요한 경우에 사용된다. 예를들어, UDP는 동영상 전송과 같이, 몇 프레임 정도 손실되어도 괜찮은 데이터 전송에 사용되고, TCP는 몇몇의 정보도 손실되어서는 안되는 애플리케이션에 이용된다."
BACKEND,네트워크,TCP와 UDP의 헤더를 비교해주세요.,"UDP segment의 간략한 구조는 아래와 같다. 애플리케이션 데이터는 UDP 데이터그램의 데이터 필드에 위치한다. UDP 헤더는 2바이트(16비트)씩 구성된 4개의 필드를 가진다. UDP 헤더는 , , , 로 이루어져있다. 포트번호는 (목적지) 호스트가 (역다중화 기능을 수행하는) 정확한 프로세스에게 애플리케이션 데이터를 넘기게 하기 위해 사용된다. 체크섬(checksum)은 세그먼트에 오류가 발생했는지를 검사하기 위해 사용되며, 체크섬은 UDP 세그먼트 이외에 IP 헤더의 일부 필드도 계산한다.(가상헤더) UDP 헤더와 데이터를 모두 포함하여 체크하게 된다. 길이는 헤더를 포함하는 UDP 세그먼트의 길이(바이트 단위)를 나타낸다. UDP헤더와 데이터를 합친 길이를 나타낸다. --- TCP segment의 간략한 구조는 아래와 같다. TCP 소켓은 4개의 다른 요소들의 집합에 의해 식별된다.(, , , ) 따라서 IP를 제외한 (각 16 bit)와 (32 bit), (32 bit)를 합쳐, 기본적으로 20 byte의 헤더를 가지게 되며, 옵션을 포함하면 최대 60 byte의 헤더를 가질 수 있다. 다른 출발지 주소를 가지는 세그먼트는, 다른 소켓을 통해서 프로세스에 전달된다. UDP와 다르게, TCP 세그먼트는 출발지 주소가 다르면, 다른 소켓으로 전달된다. 포트번호는 IP 정보와 결합하여 출발지, 도착지를 구분하기 위해 사용된다. Sequence Number는 SYN 패킷을 보낼때, 동기화를 위해 사용되는 번호이다. 초기 Sequence Number를 ISN이라 부르며, 여기에는 랜덤한 수가 담긴다. Ack Number는 ACK 패킷을 보낼 때 동기화를 위해 사용되는 번호이다."
BACKEND,네트워크,TCP의 3-way-handshake와 4-way-handshake를 비교 설명해주세요.,"핸드셰이크(Handshake)란, 호스트 간 데이터를 전송하기 전에 먼저 정확한 전송을 보장하기 위해 상대방 컴퓨터와 사전에 세션을 수립하는 과정을 의미한다. 3-way handshake는 TCP의 연결을 초기화 할 때 사용한다. 양쪽 모두 데이터를 전송할 준비가 되었다는 것을 보장하고, 실제로 데이터 전달이 시작하기전에 한쪽이 다른 쪽이 준비되었다는 것을 알수 있도록 한다. 양쪽 모두 상대편에 대한 초기 순차일련변호를 얻을 수 있도록 한다. 절차는 다음과 같다. 접속 요청 프로세스가 연결 요청 메시지 전송한다.(SYN) 접속 요청을 받은 프로세스가 요청을 수락한다는 확인 메시지를 보낸다. (ACK) 동시에 접속 요청을 받은 프로세스도 접속 요청을 한 프로세스에 연결 요청을 보낸다.(SYN) → (SYN + ACK) 마지막으로 접속 요청 프로세스가 수락 확인을 보내 연결을 맺는다.(ACK) 단순히 응답을 주고받는데 2-way Handshake면 충분해보이지 않는가? 왜 3-way 일까? TCP/IP 통신은 양방향성 connection이다. 위의 그림의 1번 과정에서 클라이언트가 연결 요청을 SYN으로 보내면, 서버는 클라이언트가 요청한 SYN에 대한 대답(ACK)과 함께, 자신도 연결하겠다는 요청의 의미로 SYN을 보내고, 클라이언트로부터 요청에 대한 대답(과정 3)을 받아야한다. 이 과정은 2-way handshaked에서는 성립될 수 없다. 4-way handshake는 세션을 종료하기 위해 수행되는 절차이다. 구체적인 과정은 다음과 같다. 클라이언트가 연결을 종료하겠다는 FIN 플래그를 전송한다. 서버는 일단 확인메시지를 보내고 자신의 통신이 끝날때까지 기다리는데, 이 상태가 상태이다. 서버가 통신이 끝났으면 연결이 종료되었다고 클라이언트에게 FIN 플래그를 전송한다. 클라이언트는 확인했다는 메시지를 보낸다. 💡 와 상태란 무엇일까? 상태로 대기하는 이유는, 세션 종료후, 혹시나 네트워크에 아직 라이브 패킷이 존재할수도 있기때문이다. 💡 용어 SYN(Synchronization): 연결요청, 세션을 설정하는데 사용되며 초기에 시퀀스 번호를 보낸다. ACK(Acknowledgement): 보낸 시퀀스 번호에 TCP 계층에서의 길이 또는 양을 더한 것과 같은 값을 ACK에 포함하여 전송한다. FIN(Finish) : 세션을 종료시키는데 사용되며 더 이상 보낸 데이터가 없음을 표시한다."
BACKEND,네트워크,TCP의 연결 설정 과정(3단계)과 연결 종료 과정(4단계)이 단계가 차이나는 이유가 무엇인가요?,"연결 설정 과정과 다르게, 연결 종료 과정에서 고려해야하는 경우가 존재하는데, 이는 전송중인 데이터에 대한 경우이다. 클라이언트는 아직 서버로부터 못 받은 데이터가 있을 것을 대비하여 일정시간동안 세션을 남긴다(). 모든 데이터를 다 보내서 더 이상 보낼 데이터가 없다는 의미의 을 받으면, 바로 연결을 종료한다."
BACKEND,네트워크,만약 Server에서 FIN 플래그를 전송하기 전에 전송한 패킷이 Routing 지연이나 패킷 유실로 인한 재전송 등으로 인해 FIN 패킷보다 늦게 도착하는 상황이 발생하면 어떻게 될까요?,"클라이언트에서 세션을 종료시킨 후 뒤늦게 도착하는 패킷이 있다면 이 패킷은 Drop되고 데이터는 유실될 것이다. A 클라이언트는 이러한 현상에 대비하여 Client는 Server로부터 을 수신하더라도 일정시간동안 세션을 남겨놓고 잉여 패킷을 기다리는 과정을 거치게 되는데 이 과정을 라고 한다. 일정시간이 지나면, 세션을 만료하고 연결을 종료시키며, 상태로 변화한다."
BACKEND,네트워크,초기 Sequence Number인 ISN을 0부터 시작하지 않고 난수를 생성해서 설정하는 이유가 무엇인가요?,Connection을 맺을 때 사용하는 포트는 유한 범위 내에서 사용하고 시간이 지남에 따라 재사용된다. 따라서 두 통신 호스트가 과거에 사용된 포트 번호 쌍을 사용하는 가능성이 존재한다. 서버 측에서는 패킷의 SYN을 보고 패킷을 구분하게 되는데 난수가 아닌 순차적인 number가 전송된다면 이전의 connection으로부터 오는 패킷으로 인식할 수 있다. 이러한 문제가 발생할 가능성을 줄이기 위해서 난수로 ISN을 설정하는 것이다.
BACKEND,네트워크,HTTP와 HTTPS에 대해서 설명하고 차이점에 대해 설명해주세요.,"HTTP란 서버/클라이언트 모델을 따라 데이터를 주고받기 위한 프로토콜이다. 즉, HTTP는 인터넷에서 하이퍼텍스트를 교환하기 위한 통신 규약으로, 80번 포트를 사용하고 있다. 따라서 HTTP 서버가 80번 포트에서 요청을 기다리고 있으며, 클라이언트는 80번 포트로 요청을 보내게 된다. HTTP는 1989년 팀 버너스 리(Tim Berners Lee)에 의해 처음 설계되었으며, WWW(World-Wide-Web) 기반에서 세계적인 정보를 공유하는데 큰 역할을 하였다. HTTPS는 HTTP에 데이터 암호화가 추가된 프로토콜이다. HTTPS는 HTTP와 다르게 443번 포트를 사용하며, 네트워크 상에서 중간에 제3자가 정보를 볼 수 없도록 공개키 암호화를 지원하고 있다. HTTP는 암호화가 추가되지 않았기 때문에 보안에 취약한 반면, HTTPS는 안전하게 데이터를 주고받을 수 있다. 하지만 HTTPS를 이용하면 암호화/복호화의 과정이 필요하기 때문에 HTTP보다 속도가 느리다. 또한 HTTPS는 인증서를 발급하고 유지하기 위한 추가 비용이 발생하다. 개인 정보와 같은 민감한 데이터를 주고받아야 한다면 HTTPS를 이용해야 하지만, 단순한 정보 조회 등 만을 처리하고 있다면 HTTP를 이용하면 된다."
BACKEND,네트워크,CORS가 무엇인가요?,"교차 출처 리소스 공유(Cross-Origin Resource Sharing, CORS)는 추가 HTTP 헤더를 사용하여, 한 출처에서 실행 중인 웹 애플리케이션이 다른 출처의 선택한 자원에 접근할 수 있는 권한을 부여하도록 브라우저에 알려주는 체제이다. CORS 체제는 브라우저와 서버 간의 안전한 교차 출처 요청 및 데이터 전송을 지원한다. 최신 브라우저는 XMLHttpRequest 또는 Fetch와 같은 API에서 CORS를 사용하여 교차 출처 HTTP 요청의 위험을 완화한다. CORS의 동작 원리 기본적으로 웹은 다른 출처의 리소스를 요청할 때는 HTTP 프로토콜을 사용하여 요청을 하는데, 이때 브라우저는 요청 헤더 (request header)에 필드에 요청을 보내는 출처를 담아 전송한다. 서버는 요청에 대한 응답을 하는데, 응답 헤더(response header)에 이라는 값에 '이 리소스를 접근하는 것이 허용된 출처'를 내려준다. 이후 응답을 받은 브라우저는 자신이 보냈던 요청의 Origin과 서버가 보내준 응답의 을 비교해 본 후 이 응답이 유효한 응답인지 아닌지를 결정한다."
BACKEND,네트워크,HTTP GET과 POST 메서드를 비교 설명해주세요.,"GET GET은 클라이언트에서 서버로 어떠한 리소스로부터 정보를 요청하기 위해 사용되는 메서드이다. GET을 통한 요청은 URL 주소 끝에 파라미터로 포함되어 전송되며, 이 부분을 쿼리 스트링(query string)이라고 부른다. 방식은 URL 끝에 를 붙이고 그다음 형식으로 이어 붙이면 된다. 예를 들면 이다. 서버에서는 과 라는 파라미터 명으로 각각 과 의 파라미터 값을 전달받을 수 있다. POST POST는 클라이언트에서 서버로 리소스를 생성하거나 업데이트하기 위해 데이터를 보낼 때 사용되는 메서드이다. POST는 전송할 데이터를 HTTP 메시지 body 부분에 담아서 서버로 보낸다.(body의 타입은 Content-Type 헤더에 따라 결정된다.) GET에서 URL의 파라미터로 보냈던 가 body에 담겨 보내진다 생각하면 된다. POST로 데이터를 전송할 때 길이 제한이 따로 없어 용량이 큰 데이터를 보낼 때 사용하거나 GET처럼 데이터가 외부적으로 드러나는 건 아니라서 보안이 필요한 부분에 많이 사용된다. POST를 통한 데이터 전송은 보통 HTML form을 통해 서버로 전송된다. GET과 POST의 차이점 사용목적: GET은 서버의 리소스에서 데이터를 요청할 때, POST는 서버의 리소스를 새로 생성하거나 업데이트할 때 사용한다. 요청에 body 유무: GET은 URL 파라미터에 요청하는 데이터를 담아 보내기 때문에 HTTP 메시지에 body가 없다. POST는 body에 데이터를 담아 보내기 때문에 당연히 HTTP 메시지에 body가 존재한다. 멱등성(idempotent): GET 요청은 멱등이며, POST는 멱등이 아니다. 💡멱등이란? 멱등의 사전적 정의는 연산을 여러 번 적용하더라도 결과가 달라지지 않는 성질을 의미한다. GET은 리소스를 조회한다는 점에서 여러 번 요청하더라도 응답이 똑같을 것이다. 반대로 POST는 리소스를 새로 생성하거나 업데이트할 때 사용되기 때문에 멱등이 아니라고 볼 수 있다.(POST 요청이 발생하면 서버가 변경될 수 있다.)"
BACKEND,네트워크,쿠키(Cookie)와 세션(Session)을 설명해주세요.,"쿠키(Cookie) 쿠키는 클라이언트(브라우저) 로컬에 저장되는 키와 값이 들어있는 작은 데이터 파일이다. 사용자 인증이 유효한 시간을 명시할 수 있으며, 유효 시간이 정해지면 브라우저가 종료되어도 인증이 유지된다는 특징이 있다. 쿠키는 클라이언트의 상태 정보를 로컬에 저장했다가 참조하며, Response Header에 Set-Cookie 속성을 사용하면 클라이언트에 쿠키를 만들 수 있다. 쿠키는 사용자가 따로 요청하지 않아도 브라우저가 Request 시에 Request Header를 넣어서 자동으로 서버에 전송한다. 쿠키는 다음과 같이 동작한다. 클라이언트가 페이지를 요청 서버에서 쿠키를 생성 HTTP 헤더에 쿠키를 포함 시켜 응답 브라우저가 종료되어도 쿠키 만료 기간이 있다면 클라이언트에서 보관 같은 요청을 할 경우 HTTP 헤더에 쿠키를 함께 보냄 서버에서 쿠키를 읽어 이전 상태 정보를 변경할 필요가 있을 때 쿠키를 업데이트하여 변경된 쿠키를 HTTP 헤더에 포함시켜 응답 세션(Session) 세션은 쿠키를 기반하고 있지만, 사용자 정보 파일을 브라우저에 저장하는 쿠키와 달리 세션은 서버 측에서 관리한다. 서버에서는 클라이언트를 구분하기 위해 세션 ID를 부여하며 웹 브라우저가 서버에 접속해서 브라우저를 종료할 때까지 인증 상태를 유지한다. 접속 시간에 제한을 두어 일정 시간 응답이 없다면 정보가 유지되지 않게 설정이 가능하다. 사용자에 대한 정보를 서버에 두기 때문에 쿠키보다 보안에 좋지만, 사용자가 많아질수록 서버 메모리를 많이 차지하게 된다. 즉 동접자 수가 많은 웹 사이트인 경우 서버에 과부하를 주게 되므로 성능 저하의 요인이 된다. 클라이언트가 Request를 보내면, 해당 서버의 엔진이 클라이언트에게 유일한 ID를 부여하는 데 이것이 세션 ID다. 세션의 동작 방식은 다음과 같다. 클라이언트가 서버에 접속 시 세션 ID를 발급 클라이언트는 세션 ID에 대해 쿠키를 사용해서 저장하고 가지고 있음 클라이언트는 서버에 요청할 때, 이 쿠키의 세션 ID를 서버에 전달해서 사용 서버는 세션 ID를 전달받아서 별다른 작업 없이 세션 ID로 세션에 있는 클라언트 정보를 가져옴 클라이언트 정보를 가지고 서버 요청을 처리하여 클라이언트에게 응답 쿠키와 세션의 차이점 사용자의 정보가 저장되는 위치: 쿠키는 서버의 자원을 전혀 사용하지 않으며, 세션은 서버의 자원을 사용한다. 보안: 쿠키는 클라이언트 로컬에 저장되기 때문에 변질되거나 request에서 스니핑 당할 우려가 있어서 보안에 취약하다. 반면 세션은 쿠키를 이용해서 세션 ID만 저장하고 그것으로 구분해서 서버에서 처리하기 때문에 비교적 보안성이 좋다. 라이프 사이클: 쿠키는 만료시간이 있지만 파일로 저장되기 때문에 브라우저를 종료해도 계속해서 정보가 남아 있을 수 있다. 또한 만료 기간을 넉넉하게 잡아두면 쿠키 삭제를 할 때까지 유지될 수도 있다. 반면에 세션도 만료시간을 정할 수 있지만 브라우저가 종료되면 만료시간에 상관없이 삭제된다. 속도: 쿠키에 정보가 있기 때문에 서버에 요청 시 속도가 빠르다. 반면 세션은 정보가 서버에 있기 때문에 처리가 요구되어 비교적 느린 속도를 낸다. 세션은 서버의 자원을 사용하기 때문에 무분별하게 만들다 보면 서버의 메모리가 감당할 수 없어질 수가 있고 속도가 느려질 수 있기 때문에 쿠키를 함께 사용한다."
BACKEND,네트워크,DNS가 무엇인가요?,"모든 네트워크 통신에는 고유의 주소, 즉 IP 주소가 필요하다. 이때 통신을 주고받는 주체가 되는 네트워크에 연결되어 있는 모든 장치들을 host라고 한다. IP는 사람이 이해하고 기억하기 어렵기 때문에 이를 위해서 각 ip에 부여한 이름이 도메인(Domain)이다. 예를 들어 210.89.164.90의 도메인은 naver.com이다. DNS(Domain Name Server 또는 Domain Name Service 모두를 의미)는 숫자로 이루어진 IP 주소와 일정한 형식을 가진 도메인을 서로 매핑 시키고 정보를 가지고 있다. 예를 들어 네이버에 접속하기 위해 주소창에 도메인(naver.com)을 입력하면, 컴퓨터는 해당 도메인이 연결된 DNS로 가서 서버 IP를 요청한다. 요청받은 네임 서버는 해당 도메인과 연결되어 있는 서버 IP(210.89.164.90)를 찾은 후, 컴퓨터에게 알려준다. 이처럼 도메인에 연결된 서버의 주소를 찾아주는 역할이 DNS이다. 브라우저가 도메인에 해당하는 IP를 찾는 순서 local cache 안에 검색한 해당 도메인의 IP가 있는지 확인한다. 이미 해당 도메인을 방문한 적이 있다면 컴퓨터가 해당 도메인의 IP를 기억하고 있으므로 그것을 사용한다. 만약 캐시에 없다면 컴퓨터 내부에 파일 형태로 존재하는 hosts 파일을 검색해서 찾는다. 해당 hosts 파일에 특정 도메인과 IP를 매핑 시켜놓으면 해당 도메인은 지정한 IP로 이동한다. 만약 위의 경우에서 도메인에 대한 IP를 찾지 못하면 최종적으로 DNS를 검색한다."
BACKEND,네트워크,REST와 RESTful의 개념을 설명하고 차이를 말해주세요.,"란 Representational State Transfer의 약자로, URI로 자원(Resource)을 명시하고 HTTP 메서드를 통해 해당 자원에 대한 CRUD(Create, Read, Update, Delete) 연산을 적용하는 것을 의미한다. 여기서의 자원은 데이터베이스의 정보를 말한다. 하지만 클라이언트가 직접 데이터베이스에 접속해 변경하는 것은 매우 위험한 방식 이다. 그래서 이를 막기 위해 REST API를 사용하는 것이다. 클라이언트가 서버에 데이터를 조회·생성·삭제·업데이트를 하겠다고 HTTP 메서드로 요청을 하면 서버는 로직에 따라 데이터베이스에 접근하여 요청을 처리한다. 은 REST 아키텍처로 구현된 웹 서비스를 나타내기 위한 용어로, ""REST API를 제공하는 웹 서비스는 RESTful하다""처럼 사용된다. HTTP 메서드 종류 요청의 종류에 다라 다른 HTTP 메서드를 사용하는데 주로 사용하는 대표적인 메서드는 다음과 같다. | 메서드 | 역할 | | :----: | :------------------------------------------------------ | | GET | 데이터를 조회한다. | | POST | 데이터를 등록한다. 인증 작업을 거칠 때 사용하기도 한다. | | DELETE | 데이터를 삭제한다. | | PUT | 데이터를 새 정보로 통째로 업데이트할 때 사용한다. | | PATCH | 데이터의 특정 필드를 수정할 때 사용한다. | URI란? URI는 Uniform Resource Identifier의 약자로, 자원을 식별자로 취급하여 나타내는 주소를 말한다. URI의 종류로 URL과 URN이 있다. URI는 일반적으로 다음과 같은 형식을 갖고 있다."
BACKEND,네트워크,소켓(Socket)이 무엇인가요? 자신 있는 언어로 간단히 소켓 생성 예시를 보여주세요.,"이란 Application 프로세스와 end-to-end 통신을 제공하는 Transport 프로토콜 사이의 인터페이스을 말한다. 즉, Application에서 Transport 프로토콜을 쓰기 위한 API를 말한다. 소켓은 크게 UDP와 TCP 두 종류로 분류할 수 있다. 자세한 내용은 #4. TCP와 UDP의 차이를 설명해주세요.을 참고! 파이썬으로 TCP에서의 소켓과 UDP에서의 소켓 생성 코드를 구현하면 다음과 같다. 소켓을 생성한다고 바로 통신을 할 수 없으며 실제 통신을 하기 위해는 바인딩, 연결 등 추가 작업이 필요하다. TCP TCP Client TCP Server UDP UDP Client UDP Server"
BACKEND,네트워크,Socket.io와 WebSocket의 차이를 설명해주세요.,"WebSocket 은 서버와 브라우저 간 연결을 유지한 상태로 데이터를 교환할 수 있도록 하는 프로토콜을 말한다. 전형적인 브라우저 렌더링 방식은 HTTP 요청에 대한 응답을 받아 브라우저 화면을 깨끗히 지우고 받은 내용을 새로 표시하는 방식인데, 내용을 지우고 다시 그리면 브라우저의 깜박임이 생기게 된다. 이러한 깜박임 없이 필요한 부분만 다시 그리는 상호작용 방식의 수요가 생겼다. 이러한 상호작용을 구현하기 위해 Pooling, Long Pooling, Streaming 등 다양한 방식을 사용했지만 요청을 보내고 응답을 보내는 단방향 메시지 교환 규칙을 준수하였기 때문에 상호작용하는 웹페이지를 구현하는 것은 매우 어려웠다. 이보다 쉽게 구현하기 위해 브라우저와 서버 간 양방향 메시지 송수신 규칙이 필요했고 이것이 WebSocket이다. Socket.io 는 서버와 브라우저의 양방향 통신을 가능하게 하는 모듈을 말한다. WebSocket의 경우 정말 좋은 기술이지만 오래된 브라우저의 경우 지원을 하지 않는 경우가 있다. 이런 경우 socket.io는 서버와 브라우저의 종류와 버전을 파악하여 가장 적합한 기술을 선택해 양방향 통신이 가능하도록 한다."
BACKEND,네트워크,IPv4와 IPv6 차이를 설명해주세요.,"IPv4와 IPv6는 인터넷 프로토콜(IP)의 버전을 말하며, IPv4는 IP의 4번째 버전, IPv6는 IP의 6번째 버전을 말한다. 이 때 인터넷 프로토콜은 호스트 간 패킷 교환 네트워크에서 패킷(Packet) 혹은 데이터그램(Datagram)으로 불리는 정보를 주고받는데 사용하는 프로토콜을 말한다. 는 헤더에 options이 존재하고, fragmentation/reassembly 기능을 제공해 MTU(Maximum Transport Unit)을 넘는 큰 데이터그램을 쪼개 전송을 하고 도착지에서 재조합을 한다. 또한 checksum 비트도 존재하여 매 라우터마다 checksum 비트를 갱신한다. 반면 는 빠른 속도를 위해 fragmentation/reassembly 기능을 제공하지 않으며, 데이터그램의 우선순위를 설정할 수 있는 priority 비트가 존재한다."
BACKEND,네트워크,MAC Address가 무엇인가요?,"는 Data Link Layer에서 통신을 위해 네트워크 인터페이스에 할당한 식별자를 말한다. 즉, 모든 네트워크 장비는 자신의 MAC 주소가 있으며 주소는 장비 제조업체가 할당한다. MAC 주소는 물리적 주소(Physical Address)라고 불리기도 한다. 💡 MAC 주소와 IP 주소의 차이 MAC 주소와 IP 주소 모두 통신기기의 식별자라는 것은 동일하다. 다만 MAC 주소는 제조업체가 통신기기에 부여하는 식별자이며 같은 식별자를 같는 통신기기는 없다. IP 주소는 Network Layer에서 통신을 하기 위한 주소로 보통 통신사에서 부여하며 바뀔 수 있다."
BACKEND,네트워크,"라우터와 스위치, 허브의 차이를 설명해주세요.",(여기서의 네트워크는 LAN(Local Area Network)를 말합니다.) 는 Network Layer 3계층 장비로 네트워크 사이를 연결하는 장치이다. 최종 도착지의 네트워크에 도착할 수 있도록 적절한 경로를 설정하여 패킷을 전송한다. 는 Data Link Layer 2계층 장비로 네트워크 내에서 패킷을 전송하는 장치를 말한다. 스위치로 요청이 들어오면 IP 주소에 대응되는 MAC 주소를 찾아 해당 MAC 주소로 패킷을 전송한다. 만약 IP 주소에 대응되는 MAC 주소가 없다면 허브처럼 브로드캐스트 방식으로 패킷을 전송하고 IP 주소와 MAC 주소를 대응시킨 테이블을 갱신시킨다. 는 Physical Layer 1계층 장비로 여러 기기를 연결하여 네트워크를 만들어주는 장치이다. 패킷을 받으면 연결된 모든 기기에 패킷을 전송한다. 💡 브로드캐스트(Broadcast)란? 브로드캐스트란 LAN에 있는 모든 네트워크 장비들에게 보내는 통신이다.
BACKEND,네트워크,SMTP가 무엇인가요?,은 인터넷에서 이메일을 보내기 위해 사용하는 TCP/IP 프로토콜을 말한다. 사용하는 TCP Port 번호는 25번이다. SMTP는 다음의 명령어를 사용하여 메일을 주고 받는다. MAIL 명령: 주소 반환 확립 RCPT 명령: 메시지 수신자 확립 DATA 명령: 메시지 텍스트의 첫 신호를 제공
BACKEND,네트워크,노트북으로 `www.google.com`에 접속을 했습니다. 요청을 보내고 받기까지의 과정을 자세히 설명해주세요.,"1단계 웹 사이트에 접속하기 위해서는 노트북의 IP주소, 1-hop 라우터의 IP 주소, DNS 서버 주소가 필요하다. 이를 알아 내기 위해 DHCP query가 담긴 IP 데이터그램을 1-hop 라우터에게 전송한다. DHCP 서버가 내장된 라우터가 노트북의 IP주소, 자신의 IP주소, DNS 서버의 IP주소를 담은 DHCP ACK를 다시 노트북에게 전송한다. DNS란 Domain Name System의 약자로 과 같은 도메인 주소를 IP 주소로 바꿔주는 시스템을 말한다. DHCP 서버는 보통은 라우터에 DHCP 서버가 내장되어 있으며 DHCP 서버에 연결된 클라이언트에게 자동적으로 IP주소를 할당한다. 자세한 내용은 #28을 참고! 2단계 DNS 서버에 DNS query를 보내기 전에 1-hop 라우터의 MAC 주소가 필요하므로 ARP query를 브로드캐스트 방식으로 전송하여 router의 MAC주소를 알아낸다. ARP란 Address Resolution Protocol의 약자로, MAC 주소와 IP 주소를 1:1 매핑하기 위해 사용된다. 3단계 에 요청을 보내기 위해서는 의 IP주소가 필요하므로, DNS query가 담긴 IP 데이터그램을 DNS 서버에 전송하고 의 IP 주소를 클라이언트인 노트북에게 전송한다. 4단계 TCP 소켓을 생성하고 3-way handshake로 연결을 생성한다. HTTP 요청을 보내고 응답을 받아 브라우저에 렌더링을 하면 Google 웹페이지를 브라우저에서 확인할 수 있다."
BACKEND,네트워크,여러 네트워크 topology에 대해 간단히 소개해주세요.,"컴퓨터끼리 정보를 교환하고 교류하는 형태를 의미하는 네트워크에서 토폴로지는 컴퓨터들의 특정한 망구성 방식을 의미한다. 하나의 네트워크 구성 방식을 보더라도, 노드와 링크와 같은 물리적 배치로 구분하는 물리적 토폴로지와 노드 간의 데이터 흐름으로 구분하는 논리적 토폴로지로 네트워크 구성을 각각 판단할 수 있다. Star 중앙에 위치한 메인 노드를 통해 다른 노드와 소통할 수 있는 구조이다. : 장애 발견이 쉽고 관리가 용이함 : 메인 노드에 장애가 발생하면 전체 네트워크 사용 불가능 Bus 버스라는 공통 배선을 통해 노드들이 연결되어 있어서, 한 노드의 신호가 모든 노드에 전달된다. (타겟 노드만 신호에 반응을 하고 다른 노드는 무시한다.) : 노드 추가 및 삭제가 용이하며, 한 노드에 장애가 발생해도 다른 노드에 영향을 주지 않음 : 공통 배선의 크기(대역폭)가 제한되어 있으므로 배선에 과부하가 걸릴 경우 네트워크 성능 저하 Ring 각 노드가 양 옆으로 연결된 원형 구조, 단방향으로 신호가 전달된다. : 단방향 구조로 단순하고, 중간에 있는 노드들이 증폭기의 역할을 해준다. (거리 제약 적어진다.) : 노드 추가 및 삭제가 어렵다. Mesh 다수의 노드가 서로 연결된 형태이다. (모두 연결되면 완전 연결형, 일부만 연결되면 부분 연결형) : 노드의 장애에 영향받지 않으며 유연한 대처가 가능하고 안정적이다. : 구축 비용이 크고, 노드 추가에도 비용이 많이 든다."
BACKEND,네트워크,subnet mask에 대해서 설명해주세요.,"IP 주소와 서브네팅 (subnetting) IPv4 의 경우 $2^{32}$의 숫자로 주소를 표현하고, 이를 국가, 회사 등 잘게 나눠 어느 영역을 쓰게할 것인지 결정한다. 한정된 자원이기 때문에 효율적으로 노드에 주소를 할당하는게 중요하다. 이를 위해 IP 를 쪼개는, 네트워크 파트 + 호스트 파트로 구성하는 서브네팅을 활용한다. 기본적으로 IP 주소에 따라 5 개의 클래스로 구분된다. 각 클래스에 따라 네트워크 파트와 호스트 파트가 정해진다. 위와 같은 클래스 구조와 더불어 더욱 효율적인 서브네팅을 위해서 사용하는 방법이 서브넷 마스크이다. 서브넷 마스크 (subnet mask) 할당된 IP 주소는 기본적으로 네트워크 파트와 호스트 파트가 정해져있다. 효율적인 주소 관리를 위해 내부적으로 호스트 파트를 새로운 네트워크 파트와 호스트 파트로 나눌 수 있다. 이 때 서브넷 마스크를 활용할 수 있다. 만약 C 클래스인 192.12.16.1 IP, 255.255.255.0 서브넷 마스크(호스트 파트)가 할당되었을 때 기존의 서브넷 마스크인 마지막 8 비트를 1111 0000 으로 바꾼다면, 4 비트만큼의 네트워크 파트 (그룹), 4 비트만큼의 호스트 (멤버) 를 할당할 수 있다. 이렇게 된다면 동일 네트워크 간에는 커뮤니케이션이 자유롭지만, 다른 네트워크 간에는 라우터를 거쳐야 커뮤니케이션을 할 수 있다. 어떤 기업을 생각해보자. 서브넷 마스크로 추가적인 서브네팅을 안한다면 인사팀, 재무팀 등등 여러 팀들이 모두 같은 네트워크 파트를 지니므로 서로에게 접근할 수 있다. 이럴 때 서브넷 마스크를 활용한 서브네팅으로 효율적으로 IP 를 관리할 수 있다."
BACKEND,네트워크,data encapsulation이 무엇인가요?,"data encapsulation 은 데이터를 보내는 송신측에서 데이터를 생성하는 방법으로, 네트워크 계층에서 상위 계층에서부터 하위 계층으로 내려올 때마다 각 계층의 헤더를 붙여 보내는 데이터로 만들어낸다. 반대로 데이터를 받는 수신측에서는 데이터를 받은 후에 계층을 거슬러 올라가면서 헤더를 떼내며 데이터를 파악한다."
BACKEND,네트워크,DHCP를 설명해주세요.,"DHCP (Dynamic Host Configuration Protocol) 는 동적으로 IP 주소나 기타 정보들을 관리해주는 프로토콜을 말한다. 관리해야하는 컴퓨터가 많고 이들의 IP 를 모두 직접 할당하고 관리하려면 상당히 복잡하고 시간이 많이들지만, DHCP 를 사용하면 이러한 문제점을 해결할 수 있다. DHCP 는 UDP 를 사용하여 클라이언트/서버 구조로 통신한다. 그 과정은 아래와 같다. : 컴퓨터가 동일 서브넷으로 브로드캐스팅(255.255.255.255)으로 DHCP 서버를 찾는다. : DHCP 가 사용가능한 IP 주소의 리스트를 컴퓨터에게 전달한다. : 컴퓨터가 리스트 중 하나의 IP 주소를 선택하여 서버에 전달한다. : DHCP 가 컴퓨터에게 해당 IP 주소를 허락/거절하는 메세지를 전달한다. 장점 DHCP 서버에서 자동으로 IP 를 관리해주므로 편리하다. IP 에 변동이 있을 때, DHCP 에만 정보를 입력하면 된다. 사용중인 컴퓨터에 대해서만 할당하므로 효율적이다. 단점 DHCP 서버에 의존하기 때문에 서버가 다운되는 경우 모든 컴퓨터에서 인터넷을 할 수 없다. 초기 DHCP 세팅 시간 및 트래픽이 크다. 단말 컴퓨터를 끌 경우, 완전히 주소가 release 될 때 까지 해당 IP 를 사용할 수 없다."
BACKEND,네트워크,"routing protocol을 몇 가지 설명해주세요. (ex. link state, distance vector)","패킷을 전달할 때 어느 경로로 갈지 정하는 것을 라우팅이라고 한다. 라우팅 경로 고정 여부 어떤 경로로 라우팅할지를 미리 정해두냐 동적으로 정하냐에 따라 , 으로 구분한다. 내/외부 라우팅 동적 라우팅에서 AS (Auotonomous System, 하나의 네트워크 관리자에 의해 관리되는 네트워크 집단) 를 기준으로 내부적으로 동작하냐, 외부적으로 동작하냐에 따라 (RIP, IGRP, OSPF, EIGRP) 과 (BGP, EGP) 으로 나눈다. 라우팅 테이블 관리 동적 라우팅에서 어떤 방식으로 라우팅 테이블을 관리하느냐에 따라서도 방법이 다르다. 크게 link state, distance vector 방법이 있다. 방법은 현재 위치 (단말 또는 라우터) 까지의 방향과 거리를 기록한 라우팅 테이블을 인접한 라우터들에게 전달하고 갱신한다. 메모리가 적게 들고 구성이 쉽지만, 전체 테이블 구성 시간이 길어질 수 있고 같은 경로를 반복해서 도는 루핑 문제가 발생할 수 있다. (EIGRP 는 루핑이 발생하지 않음) distance vector 를 사용하는 프로토콜로는 RIP, EIGRP, BGP 등이 있으며, distance vector 는 에 기반한다. 방법은 인접 테이블에 정보를 전달했으면 또 그 인접 테이블들은 이 정보를 바로 인접 테이블로 넘겨, 직접 연결되지 않은 모든 라우터들도 현재 정보를 파악할 수 있다. 정확하고 루핑 문제가 없다는 장점이 있어 대형 네트워크에서 많이 사용되지만 메모리의 소모와 cpu 로드가 많다는 단점이 있다. link state 를 사용하는 프로토콜로는 OSPF, IS-IS 등이 있으며, link state 는 에 기반한다."
BACKEND,네트워크,이더넷(ethernet)이 무엇인가요?,이더넷은 근거리 유선 통신을 위해 사용되는 네트워킹 방법으로 CSMA/CD프로토콜을 사용한다. IEEE 802.3 에 표준으로 정의되었다. 장점 적은 용량의 데이터를 보낼 때 성능이 좋다. 비용이 적고 관리가 쉽다. 구조가 단순하다. 단점 캐리어 충돌이 발생할 수 있다. 충돌이 발생하면 지연이 생긴다. CSMA/CD 방법을 간략히 말하자면 버스 구조로 통신을 하는데 캐리어라는 네트워킹 상의 신호를 감지하여 캐리어가 없으면 정보를 보내는 방식이다.
BACKEND,네트워크,client와 server의 차이점을 설명해주세요.,"네트워크 상에서 요청을 보내는 대상을 , 요청에 응답하는 대상을 라고 한다. client 와 server 는 고정되지 않고 요청에 따라 바뀐다. 전에는 요청을 보내는 client 였어도 다음 번에는 다른 노드로부터 요청을 받으면 server 가 된다."
BACKEND,네트워크,"delay, timing(jitter), throughput 차이를 설명해주세요.","위 세가지 개념은 모두 네트워크의 성능과 관련되어 있다. delay 하나의 데이터 패킷이 출발 지점에서 도착 지점에 도착한 시간을 의미한다. 딜레이는 : 라우터가 들어온 패킷의 헤더를 확인하고 처리하는데 걸리는 시간 : 라우터가 다른 패킷을 처리하느라 패킷이 라우터의 큐에서 대기하는 시간 : 라우터의 성능 (전송 속도) 에 따라 패킷이 논리회로를 통과할 때까지 걸리는 시간 : 라우터간 거리에 의해 발생하는 지연 시간 의 합으로 계산된다. timing(jitter) delay 의 변동을 (변화량 수준) 의미한다. 같은 스위치가 아닌 경우 패킷마다 대기 시간이 달라지므로 지터가 생긴다. throughput 지정된 시간동안 실제로 전송된 정보량을 의미한다. 데이터가 지나갈 수 있는 통로의 크기인 bandwidth 와 헷갈릴 수 있는데, bandwidth 가 크더라도 실제로 전송된 정보량이 적으면 throughput 이 적은 것이다."
BACKEND,운영체제,프로세스와 스레드의 차이(Process vs Thread)를 알려주세요.,"프로그램(Program)이란 파일이 저장 장치에 저장되어 있지만 메모리에 올라가 있지 않은 정적인 상태를 말한다. 프로세스(Process)란 운영체제로부터 시스템 자원을 할당받는 작업의 단위로 메모리에 올라와 실행되고 있는 프로그램의 인스턴스(독립적인 개체)를 의미한다. 할당받는 시스템 자원의 예 CPU 시간 운영되기 위해 필요한 주소 공간 Code, Data, Stack, Heap의 구조로 되어 있는 독립된 메모리 영역 프로세스의 특징 프로세스는 각각 독립된 메모리 영역(Code, Data, Stack, Heap의 구조)을 할당받는다. 프로세스당 최소 1개의 스레드(메인 스레드)를 가지고 있다. 각 프로세스는 별도의 주소 공간에서 실행되며, 한 프로세스는 다른 프로세스의 변수나 자료구조에 접근할 수 없다. 한 프로세스가 다른 프로세스의 자원에 접근하려면 프로세스 간의 통신(IPC, Inter-Process Communication)을 사용해야 한다. 스레드(Thread)란 프로세스가 할당받은 자원을 이용하는 실행의 단위로 프로세스와는 다른 더 작은 실행 단위 개념이다. 스레드는 프로세스의 코드에 정의된 절차에 따라 실행되는 특정한 수행 경로이다. 스레드의 특징 스레드는 프로세스 내에서 각각 Stack 영역만 따로 할당받고 Code, Data, Heap 영역은 공유한다. 스레드는 한 프로세스 내에서 동작되는 여러 실행의 흐름으로, 프로세스 내의 주소 공간이나 자원들(힙 공간 등)을 같은 프로세스 내에 스레드끼리 공유하면서 실행된다. 같은 프로세스 안에 있는 여러 스레드들은 같은 힙 공간을 공유한다. 반면에 프로세스는 다른 프로세스의 메모리에 직접 접근할 수 없다. 각각의 스레드는 별도의 레지스터와 스택을 갖고 있지만, 힙 메모리는 서로 읽고 쓸 수 있다. 한 스레드가 프로세스 자원을 변경하면, 다른 이웃 스레드(sibling thread)도 그 변경 결과를 즉시 볼 수 있다."
BACKEND,운영체제,멀티 프로세스 대신 멀티 스레드를 사용하는 이유를 설명해주세요.,"멀티 프로세스란 하나의 응용프로그램을 여러 개의 프로세스로 구성하여 각 프로세스가 하나의 작업을 처리하도록 하는 것이다. : 여러 개의 자식 프로세스 중 하나에 문제가 발생하면 그 자식 프로세스만 죽는 것 이상으로 다른 영향이 확산되지 않는다. - Context Switching 과정에서 캐시 메모리 초기화 등 무거운 작업이 진행되고 많은 시간이 소모되는 등의 오버헤드가 발생하게 된다. 프로세스는 각각의 독립된 메모리 영역을 할당받았기 때문에 하나의 프로그램에 속하는 프로세스들 사이의 변수를 공유할 수 없다. 멀티 스레드란 하나의 응용프로그램을 여러 개의 스레드로 구성하고 각 스레드로 하여금 하나의 작업을 처리하도록 하는 것이다. 윈도우, 리눅스 등 많은 운영체제들이 멀티 프로세싱을 지원하고 있지만 멀티 스레드를 기본으로 하고 있다. 웹 서버는 대표적인 멀티 스레드 응용 프로그램이다. - 프로세스를 생성하여 자원을 할당하는 시스템 콜이 줄어들어 자원을 효율적으로 관리할 수 있다. 스레드 간 데이터를 주고받는 것이 간단해지고 시스템 자원 소모가 줄어들게 된다. 스레드 사이의 작업량이 작아 Context Switching이 빠르다. 스레드는 프로세스 내의 Stack 영역을 제외한 모든 메모리를 공유하기 때문에 통신의 부담이 적다. - 주의 깊은 설계가 필요하며, 디버깅이 까다롭다. 단일 프로세스 시스템의 경우 효과를 기대하기 어렵다. 프로세스 밖에서 스레드 각각을 제어할 수 없다. 멀티 스레드의 경우 자원 공유의 문제가 발생한다.(동기화 문제) 하나의 스레드에 문제가 발생하면 전체 프로세스가 영향을 받는다. 멀티 프로세스 대신 멀티 스레드를 사용하는 이유 자원의 효율성 증대 프로세스 간의 Context Switching 시 단순히 CPU 레지스터 교체뿐만 아니라 RAM과 CPU 사이의 캐시 메모리에 대한 데이터까지 초기화되므로 오버헤드가 발생한다. 멀티 프로세스로 실행되는 작업을 멀티 스레드로 실행할 경우, 프로세스를 생성하여 자원을 할당하는 시스템 콜이 줄어들어 자원을 효율적으로 관리할 수 있다. 스레드는 프로세스 내의 메모리를 공유하기 때문에 독립적인 프로세스와 달리 스레드 간 데이터를 주고받는 것이 간단해지고 시스템 자원 소모가 줄어들게 된다. 처리 비용 감소 및 응답 시간 단축 스레드는 Stack 영역을 제외한 모든 메모리를 공유하기 때문에 프로세스 간의 통신(IPC)보다 스레드 간의 통신의 비용이 적으므로 작업들 간의 통신의 부담이 줄어든다. Context Switching 시 스레드는 Stack 영역만 처리하기 때문에 프로세스 간의 전환 속도보다 스레드 간의 전환 속도가 빠르다. Context Switching CPU에서 여러 프로세스를 돌아가면서 작업을 처리하는 데 이 과정을 Context Switching라 한다. 동작 중인 프로세스가 대기를 하면서 해당 프로세스의 상태(Context)를 보관하고, 대기하고 있던 다음 순서의 프로세스가 동작하면서 이전에 보관했던 프로세스의 상태를 복구하는 작업을 말한다. 동기화 문제(Synchronization Issue) 멀티 스레드를 사용하면 각각의 스레드 중 어떤 것이 어떤 순서로 실행될지 그 순서를 알 수 없다. 만약 A 스레드가 어떤 자원을 사용하다가 B 스레드로 제어권이 넘어간 후 B 스레드가 해당 자원을 수정했을 때, 다시 제어권을 받은 A 스레드가 해당 자원에 접근하지 못하거나 바뀐 자원에 접근하게 되는 오류가 발생할 수 있다. 이처럼 여러 스레드가 함께 전역 변수를 사용할 경우 발생할 수 있는 충돌을 동기화 문제라고 한다. Context Switching에 대한 자세한 내용은 #14. Context Switching이 무엇인지 설명하고 과정을 나열해주세요. 참고!"
BACKEND,운영체제,캐시의 지역성에 대해 설명해주세요.,"캐시 메모리는 CPU의 처리 속도와 메모리의 속도 차이로 인한 병목현상을 완화하기 위해 사용하는 고속 버퍼 메모리이다. 주기억장치에 있는 데이터를 액세스하려면 비교적 오랜 시간이 걸리게 되는데 이를 줄이기 위해 데이터를 빠르게 액세스할 수 있도록 중간에 캐시 메모리를 두는 것이다. 주기억장치 내에서 자주 읽고 쓰는 데이터의 일부를 캐시 메모리에 불러와 속도 차이를 줄이고, 주기억장치와 CPU 간 신호 교환에 이용되는 Memory Bandwidth를 I/O 사용에 집중할 수 있게 만든다. 캐시 메모리는 을 극대화하기 위해 데이터 를 사용한다. 지역성의 전제조건으로는 프로그램은 모든 코드나 데이터를 균등하게 액세스하지 않는다는 특성을 기본으로 한다. 즉, 이란 기억 장치 내의 정보를 균일하게 액세스하는 것이 아닌 어느 한순간에 특정 부분을 집중적으로 참조하는 특성이다. 데이터 지역성은 대표적으로 , , 으로 나뉜다. 시간적 지역성(temporal locality): CPU가 한 번 참조한 데이터는 다시 참조할 가능성이 높다. 공간적 지역성(spatial locality): CPU가 참조한 데이터와 인접한 데이터 역시 참조될 가능성이 높다. 순차적 지역성(sequential locality): 분기가 발생하지 않는 한 명령어는 메모리에 저장된 순서대로 인출/실행된다. 지역성은 어디까지나 경향에 대한 것이므로 항상 캐시의 높은 적중률을 보장해 주지는 않는다. 적중률(Hit rate) 캐시 메모리가 있는 컴퓨터 시스템은 CPU가 메모리에 접근하기 전 먼저 캐시 메모리에서 원하는 데이터의 존재 여부를 확인한다. 이때 필요한 데이터가 있는 경우를 적중(hit), 없는 경우를 실패(miss)라고 한다. 요청한 데이터를 캐시 메모리에서 찾을 확률을 적중률(hit rate)이라고 한다. 캐시 메모리의 성능은 적중률에 의해 결정된다."
BACKEND,운영체제,Thread-safe에 대해 설명해주세요. (hint: critical section),"이란 멀티 스레드 프로그래밍에서 일반적으로 어떤 함수나 변수, 객체를 여러 스레드가 동시에 접근해도 프로그램 실행에 문제가 없음을 뜻한다. 즉, 멀티 스레드 환경에서 여러 쓰레드가 동시에 동일한 코드를 실행시켰을 때 올바른 결과를 얻는 것을 말한다. 다음은 스레드 안전하지 않은 경우의 코드이다. 사용자가 원하는 결과는 스레드가 함수를 실행한 수에 1000000을 곱한 값이 count의 값이 되는 것이다. 하지만 다음 코드를 실행하면, count는 2000000가 아닌 1448523이 나온다. (실행할 때마다 값이 달라진다) 왜 그럴까? 바로 두 스레드가 count 변수를 공유하고 있기 때문이다. 이 때 공유 자원에 접근하는 코드 영역을 이라고 하며, 둘 이상의 프로세스가 동시에 임계 영역에 접근하는 것을 막는 것을 라고 한다. 파이썬에서는 threading 모듈에 있는 Lock 객체로 상호 배제를 시킬 수 있다. 다음 코드를 실행하면 최종 count는 우리가 원했던 2000000이 나온다."
BACKEND,운영체제,뮤텍스와 세마포어의 차이를 설명해주세요.,"는 한 스레드/프로세스가 임계 영역에 있으면 다른 스레드/프로세스가 못 들어오도록 막는 것을 말한다. 상호배제는 다음과 같이 수행된다. 임계 영역 진입 전 다른 스레드 /프로세스가 임계 영역에 안에 있는지 검사한다. 없다면 임계 영역에 진입하여 공유 자원에 접근한다. 있다면 기다린다. 끝나면 임계 영역을 벗어나 다른 프로세스에게 임계 영역에 벗어났음을 알린다. 는 현재 공유 자원에 접근할 수 있는 스레드 /프로세스의 수를 나타내는 값을 두어 상호배제를 하는 방법을 말한다. 세마포어는 변수로 음이 아닌 정수 S(여러 개가 존재 가능)와, 함수로 초기화 연산, P(검사), V(증가) 연산이 있으며, 다음과 같이 수행된다. 변수 S를 초기화 연산을 통해 초기화 시킨다. P 함수를 실행하여 S가 0보다 큰지 검사한다. 만약 0보다 크다면, S를 1 감소시키고 임계 영역에 진입하여 공유 자원에 접근한다. 크지 않다면, 스레드 /프로세스를 Ready Queue에 넣어 대기시킨다. 임계 영역에서 나온 스레드 /프로세스는 V 함수를 실행하여 Ready Queue에 스레드 /프로세스가 있는지 체크한다. 만약 있다면, 그 중 1개를 임계 영역에 진입시킨다. 없다면, S를 1 증가시킨다."
BACKEND,운영체제,"스케줄러가 무엇이고, 단기 /중기/장기로 나누는 기준에 대해 설명해주세요.","시스템 내에는 여러 개의 프로세스가 존재한다. 이 때 시간(time)과 공간(space) 즉, 자원을 할당할 프로세스를 선택해야 하는데, 이 역할을 맡은 것을 라고 한다. 스케줄러의 목적은 시스템 성능 향상이며 대표적인 시스템 성능 지표로 응답시간(response time), 작업 처리량(throughput), 자원 활용도(resource utilization)이 있다. 목적에 따라 다양한 성능 지표를 고려하여 스케줄러를 선택한다. 스케줄러는 발생하는 빈도와 할당하는 자원에 따라 장기/중기/단기 스케줄러로 나눌 수 있다. 는 시스템에 제출할 작업을 결정하는 Job Scheduling(Job → created)에서 사용하며, 시스템 내에 프로세스 수를 조절한다. 이 때 중요한 것은 CPU든 I/O든 모두 써서 효율성을 높이기 위해서 I/O bounded와 compute-bounded 프로세스들을 잘 섞어서 선택해야 한다. 는 메모리 할당을 결정하는 Memory Allocation(suspended ready → ready)에서 사용한다. 는 프로세서를 할당 받을 프로세스를 결정하는 Process Scheduling(ready → running)에서 사용하며, 가장 빈번하게 발생하므로 매우 빨라야 한다. 응답시간 vs 작업 처리량 vs 자원 활용도 : 작업 요청으로부터 응답을 받을 때까지의 시간 : 단위 시간 동안 완료된 작업의 수 : 주어진 시간동안 자원이 활용된 시간 I/O Bounded 프로세스 vs Compute-bounded 프로세스 : I/O 대기시간이 긴 프로세스 : CPU 사용시간이 긴 프로세스 스케줄링의 단계"
BACKEND,운영체제,"CPU 스케줄러인 FCFS, SJF, SRTF, RR, Priority Scheduling에 대해 간략히 설명해주세요.","스케줄링 정책 스케줄링 정책(scheduling policy)에 따라 스케줄러를 선점/비선점과 정적/동적 우선순위로 나눌 수 있다. : 할당 받을 자원을 스스로 반납할 때까지 사용한다. 이는 Context Switching 부하가 적다는 장점이 있지만, 우선순위가 높은 프로세스가 들어올 경우 우선순위가 역전되어 우선순위가 낮은 프로세스의 처리 시간이 늘어나 평균 응답시간이 증가한다는 단점이 있다. : 타의에 의해 자원을 빼앗길 수 있다. 비선점 스케줄링과 다르게 Context Switching 부하가 크지만, 응답성이 높으므로 real-time system, time-sharing system에 적합하다. : 프로세스 생성 시 결정된 우선순위가 유지된다. 이는 구현을 쉽게 하고, Context Switching이 덜 일어나기 때문에 부하가 적다. 하지만 시스템 환경 변화에 대한 대응이 어렵다. : 프로세스의 상태 변화에 따라 우선순위를 변경한다. 구현이 복잡하지만 시스템 환경 변화에 유연하게 대응이 가능하다. 대표적인 스케줄러 는 비선점 스케줄러로, Ready Queue에 먼저 도착한 프로세스를 먼저 처리한다. 자원을 효율적으로 사용할 수 있어 일괄 처리 시스템에 적합하다. 하지만 만약 수행시간이 긴 프로세스가 먼저 도착하면 다른 프로세스의 대기시간이 길어지는 Convoy Effect로 인해 평균 응답시간이 길다는 단점이 있다. 은 선점 스케줄러로, Ready Queue에 먼저 도착한 프로세스를 처리한다는 점에서 FCFS와 같지만 자원 사용 시간(time quantum)이 있다는 점에서 차이가 있다. 프로세스가 할당된 시간이 지나면 자원을 반납하게 하여 특정 프로세스의 자원 독점을 방지한다. 는 비선점 스케줄러로, CPU burst time이 가장 작은 프로세스를 먼저 처리한다. 가장 실행시간이 적은 프로세스를 먼저 처리하기 때문에 대기 시간을 줄일 수 있지만, 실행시간을 예측한다는 점에서 비현실적이며 계속해서 짧은 프로세스만 처리하므로 긴 프로세스는 뒤로 밀린다는 단점이 있다. 는 선점 스케줄러로, 잔여 실행 시간이 더 적은 프로세스를 먼저 처리한다. SJF의 장점을 극대화 했으나, 프로세스 생성 시 총 실행 시간 예측이 필요하고 잔여 시간을 계속 추적해야 해서 overhead가 크고 구현 및 사용이 비현실적이다. 은 각 프로세스에 지정된 우선순위를 기준으로 높은 우선순위를 가진 프로세스를 먼저 처리한다. 이 방식의 단점은 계속해서 우선순위가 높은 프로세스가 들어오면 그 프로세스를 먼저 처리하므로 낮은 프로세스는 뒤로 밀리는 starvation 문제가 발생한다. 이는 일정 시간 이상 기다리면 프로세스의 우선순위를 높여주는 aging 방식으로 해결할 수 있다."
BACKEND,운영체제,동기와 비동기의 차이를 설명해주세요.,"동기는 요청에 대한 결과를 받은 후에야 다음 요청을 진행하는 방식으로 결과를 받을 때까지 대기해야한다. 동기는 직관적인 구조이지만 비효율적이다. 비동기는 요청 결과에 관계 없이 바로 다음 요청을 수행하고, 결과는 함수를 통해 받는다. 비동기는 설계가 복잡하지만 효율적이다. Blocking, Non-Blocking Blocking 과 Non-Blocking은 결과에 대한 관점보다는 의 관점으로 이해할 수 있다. Blocking은 System Call 이 완료될 때까지 Waiting Queue에서 대기한다. Non-Blocking은 System Call이 완료와 상관없이 자신의 작업을 진행한다."
BACKEND,운영체제,메모리 관리 전략에는 무엇이 있는지 간략히 설명해주세요.,"제한된 메모리 크기를 효율적으로 사용하기 위해 메모리 관리 전략이 필요하다. 스왑 프로세스가 실행되기 위해서는 메모리에 올라가야한다. 실행되어야 하는 여러 프로세스 중, 기존에 메모리에 올라간 프로세스를 보조 기억장치 (HDD, SSD) 로 보내는 것을 swap-out, 보조 기억장치에 있던 프로세스를 메모리에 올리는 것을 swap-in 이라고 한다. 어떤 프로세스를 swap-out 시킬지에 대한 대표적인 방법으로는 round-robin 이 있다. 더 자세한 설명은 15. Swapping에 대해 설명해주세요을 참고! 압축 메모리에 프로세스들을 올리다보면 아래 사진과 같이 빈 공간(free) 이 생긴다. 이 공간을 fragmentation(단편화) 이라고 한다. 현재 메모리에서 프로세스와 단편화를 파악하고 프로세스가 연속적으로 메모리 주소에 할당되게 단편화를 없애는 방법을 압축이라 한다. 압축은 효율적이지 못하기 때문에 좋은 메모리 관리 방법이 아니다. 페이징 메모리에 연속적으로 프로세스를 할당하지 않고, 메모리를 페이지라는 단위로 물리적으로 나눠서 페이지에 프로세스를 올리는 방법이다. 프로세스가 페이지 크기보다 크다면 여러 페이지를 사용한다. 페이지 크기보다 작은 프로세스가 할당되면 내부적으로 공간이 남는 내부 단편화가 발생할 수 있다. 세그멘테이션 페이징은 물리적 단위로 메모리를 나눴다면, 세그멘테이션은 논리적 단위로 메모리를 나눈다. 이를 위해 세그멘테이션 테이블을 사용하고, 테이블에는 시작주소인 base 와 최대 크기인 limit 가 포함되어 있다. 세그멘테이션은 세그멘트 간에 할당되지 않은 공간이 남는 외부 단편화가 발생할 수 있다."
BACKEND,운영체제,가상 메모리에 대해 설명해주세요.,"메모리의 크기보다 큰 프로세스는 어떻게 해야 실행이될까? 이 문제를 해결하기 위한 방법으로, 프로세스에서 필요한 부분만 메모리에 올려 실행이 가능하게 동작하는 방법을 가상 메모리라고 한다. 페이지와 세그멘테이션 중 주로 페이지를 이용하는 Demand Paging 방법을 사용한다. Demand Paging 는 프로세스에서 현재 필요한 페이지만 메모리에 올리는 방법이다. 이를 위한 페이지 테이블은 기존의 테이블에서 valid 와 modified 가 추가적으로 필요하다. valid 는 해당 페이지가 메모리에서 사용되고 있는지를 나타낸다. 페이지가 메모리에 없는 경우 (valid == 0) 를 page fault 라고 한다. 아래의 과정으로 페이지를 메모리에 할당한다. 해당 페이지 valid bit 확인 valid 가 0 이면 CPU 인터럽트, 해당 ISR 로 이동 ISR 에서 backing store 를 탐색하여 해당 프로세스의 페이지 찾음 해당 페이지를 빈 프레임에 할당 페이지 테이블 갱신 (valid 1 로 변경) 다시 프로세스 실행 여러 프로세스의 필요한 페이지를 메모리에 올리는 것은 효율적이다. 하지만 결국 한정된 자원을 쓰다보면 메모리가 꽉차는 시점이 생긴다. 이 때 어떤 페이지를 내릴지 Page Replacement 를 판단해야 한다. 메모리에 올라갔던 페이지가 다시 내려가면 victim page 라고 하는데, modified bit 를 확인하여 페이지가 수정되지 않은 (modified == 0) 페이지 중 랜덤하게 혹은 가장 먼저 올라온 페이지를 내릴 수 있다."
BACKEND,운영체제,"교착상태(데드락, Deadlock)의 개념과 조건을 설명해주세요.","교착상태란, 두 개 이상의 작업이 서로 상대방의 작업이 끝나기 만을 기다리고 있기 때문에 결과적으로 아무것도 완료되지 못하는 상태를 가리킨다. 교착상태의 조건은 아래와 같다. 상호배제(Mutual exclusion) : 프로세스들이 필요로 하는 자원에 대해 배타적인 통제권을 요구한다. 점유대기(Hold and wait) : 프로세스가 할당된 자원을 가진 상태에서 다른 자원을 기다린다. 비선점(No preemption) : 프로세스가 어떤 자원의 사용을 끝낼 때까지 그 자원을 뺏을 수 없다. 순환대기(Circular wait) : 각 프로세스는 순환적으로 다음 프로세스가 요구하는 자원을 가지고 있다. 현재 대부분의 운영체제들은 교착상태를 막는 것이 불가능하여, 운영체제마다 각기 다른 방법으로 교착상태에 대응한다. 주요 접근 방식은 , , , , 등이 있다. 이 중에서 예방은 위의 중 하나를 제거하는 방식으로 진행되며, 회피는 부가적인 교착상태 회피 알고리즘을 사용한다. 또한 회복을 위해서는 ""교착상태에 있는 프로세스들을 하나씩 종료해가는 방법""과 ""사용되는 자원이 적은 프로세스 등을 위주로 자원을 선점할 수 있도록 하는 방법""이 쓰인다. Dining Philosophers 문제를 떠올리면, 쉽게 이해할 수 있다."
BACKEND,운영체제,사용자 수준 스레드와 커널 수준 스레드의 차이를 설명해주세요.,"사용자 수준 스레드란, 유저 레벨에서 생성되고 동작하는 스레드이다. 커널이 제공하는 pthread와 같은 스레드 라이브러리를 사용하여 스레드를 만들고, 사용자 단에서 스레드를 관리한다는 특징을 가진다. 사용자 수준 스레드는 스케줄링 결정이나 동기화를 위해 커널을 호출하지 않고 사용자 수준의 스레드 스케줄러를 이용한다. 따라서 (사용자/커널)모드 전환과 Context Switch가 없어, 인터럽트 발생 시에도 오버헤드가 적다. 그러나 사용자 수준 스레드는 시스템 전반에 걸친 스케줄링 우선순위를 지원하지 않기 때문에, 무슨 스레드가 먼저 동작할 지 모른다는 단점과 프로세스에 속한 스레드 중 I/O 작업등에 의해 하나라도 블락(block)이 걸린다면 전체 스레드가 블락된다는 단점도 존재한다. 커널 수준 스레드란, 커널 레벨에서 생성되는 스레드로, 커널이 직접 관리한다는 특징이 있다. 하나의 프로세스는 적어도 하나의 커널 스레드를 가지게 되며, 프로그래머 요청에 따라 스레드를 생성하더라도, 스케줄링하는 주체가 커널이면 커널 레벨(Kernel Level) 스레드라고 한다. 커널 수준 스레드는 다음과 같은 장점을 가지고 있다. 프로세스의 스레드들을 몇몇 프로세서에 한꺼번에 디스패치(dispatch) 할 수 있기 때문에 멀티프로세서 환경에서 매우 빠르게 동작한다. 또한 다른 스레드가 입출력 작업이 다 끝날 때까지 다른 스레드를 사용해 다른 작업을 진행할 수 있다. 커널이 각 스레드를 개별적으로 관리할 수 있으며, 커널이 직접 스레드를 제공해 주기 때문에 안정성과 다양한 기능이 제공된다. 반면에 스케줄링과 동기화를 위해 커널을 호출하는데 무겁고 오래걸린다는 단점이 있다. 또한, 커널 수준 스레드는 스케줄링 과정에서, 저장한 내용을 다시 불러오는 과정이 필요하다. 이는, 사용자 모드에서 커널 모드로의 전환이 빈번하게 이뤄져 성능 저하를 유발한다. 또한 사용자가 프로그래밍할 때 구현하기 어렵고 자원을 더 많이 소비하는 경향이 있다는 단점이 있다. 멀티 스레드 모델 사용자 수준 스레드와 커널 수준 스레드에 얘기하기 전에, 멀티 스레드 모델을 먼저 이해하는 것이 좋다. 멀티 스레드 모형이 위와 같이 존재하고, 어떤 멀티 스레드 모델을 사용하느냐에 따라서, 다르게 동작하기 때문에 사용자/커널 수준 스레드 차이가 발생하는 것이다. 추가적으로, 다대다 모델과 일대일 모델과 다대일 모델을 모두 채택하여 사용하는 경우가 있는데, 이를 이라고 한다. 사용자/커널 수준 스레드 구조 차이 스레드를 생성하는 방법 kernel의 지원없이 완전히 user space에서만 library를 제공하는 방법: 라이브러리의 함수를 호출하는 것은 시스템 호출이 아니라 사용자 공간의 지역함수를 호출한다. 운영체제에 의해 kernel space에서 구현하는 방법: 라이브러리 API를 호출하는 것은 kernel system call을 사용한다."
BACKEND,운영체제,외부 단편화와 내부 단편화에 대해 설명해주세요.,"메모리 단편화(Memory Fragmentation) 는 RAM에서 메모리의 공간이 작은 조각으로 나뉘어져 사용가능한 메모리가 존재하지만, 할당이 불가능한 상태를 말한다. 자세히 설명하자면, 어떤 태스크가 메모리를 할당받기 위해서는, 연속된 메모리 공간이 필요하다. 그러나 메모리 단편화가 일어나면, 할당되지 않은 메모리의 총량이 충분해도, 이들이 작은 메모리 파편(Memory Fragment)으로 존재하고 있기 때문에 메모리 할당이 불가능한 상황이 발생한다. 내부 단편화(Internal Fragmentation) 란, 메모리를 할당할 때 프로세스가 필요한 양보다 더 큰 메모리가 할당되어서 프로세스에서 사용하는 메모리 공간이 낭비 되는 상황을 말한다. 예를 들어, 메모장을 켰는데 OS가 4kb를 할당해주었다고 해보자. 그런데 실제로는 1kb만큼만 사용했다고 한다면, 필요 이상으로 프로세스가 메모리를 할당받았으므로 내부 단편화가 3kb만큼 생겼다고 할 수 있다. 외부 단편화(External Fragmentation) 란, 작은 메모리가 중간중간에 존재해서 메모리 공간은 충분하지만 실제로 할당할 수 없는 상황을 말한다. 메모리가 할당되고 해제되는 작업이 반복될 때 작은 메모리가 중간에 생기게 된다. 이를 hole이라고 부른다. 이렇게 중간에 끼인 hole들이 많아지면, 메모리 낭비로 인해, 총 가용공간이 충분하더라도 새로운 태스크가 메모리를 할당받지 못하는 상황이 올 수 있다. 예를 들어, 위의 그림처럼 메모리의 할당과 해제의 반복으로 인해 메모리 중간에 빈 hole들이 만들어졌다고 해보자. 현재 모든 hole의 총합은 16MB 이고, 9MB짜리 프로세스를 할당하고자 한다. 빈 메모리의 공간중에 제일 큰 빈 메모리(hole)의 크기가 9MB 보다 작을 때, 외부 단편화가 일어났다고 할 수 있다. 메모리 할당 방법 메모리 할당 방법은 크게 연속할당 방식과 불연속 할당 방식으로 나뉠 수 있다. 연속할당 방식에는 , 이 있고, 불연속 할당 방식에는 과 , (Paged Segmentations) 기법 등이 있다. 압축(Compaction)기법 주기적으로 삭제 공간을 회수하여, 메모리 공간을 정리하는 방식이다. 그러나 비용이 많이 든다는 단점이 있다. 페이징(Paging)기법: 가상메모리사용, 외부 단편화 해결, 내부 단편화 존재 쉽게말해, 프로세스를 일정한 단위로 잘라서 사용하자는 방식이다. 프로세스의 주소 공간을 동일한 크기의 페이지 단위로 나누어 물리적 메모리의 서로 다른 위치에 페이지들을 저장하는 방식을 말한다. 이때, 논리(가상) 메모리의 단위는 페이지(page), 물리 메모리의 단위는 프레임(frame)이라고 부른다. 페이징 기법을 사용하면 연속적이지 않은 공간도 활용할 수 있기 때문에 외부 단편화 문제를 해결할 수 있다. 대신 페이지 단위에 알맞게 꽉채워 쓰는게 아니므로 내부 단편화 문제는 여전히 존재한다. 페이지 단위를 작게하면 내부 단편화 문제도 해결할 수 있겠지만 대신 page mapping 과정이 많아지므로 오히려 효율이 떨어질 수 있다. 세그멘테이션(Segmentation)기법: 가상메모리사용, 내부 단편화 해결, 외부 단편화 존재 하나의 프로세스를 구성하는 주소 공간은 일반적으로 코드, 데이터, 스택 등의 의미 있는 단위들로 구성되며, 이렇게 기능적인 구조를 하나의 세그먼트 단위로 삼아, 분할하여 저장된다. 즉, 페이징기법에서 가상메모리를 같은 크기의 단위로 분할했지만 세그멘테이션 기법에서는 가상메모리를 서로 크기가 다른 논리적 단위인 세그먼트로 분할해서 메모리를 할당하여 실제 메모리 주소로 변환을 하게 된다. 각 세그먼트는 연속적인 공간에 저장되어 있다. 세그먼트들의 크기가 다르기 때문에 미리 분할해 둘 수 없고 메모리에 적재될 때 빈 공간을 찾아 할당해야한다. 마찬가지로 mapping을 위해 세그먼트 테이블이 필요하다. 프로세스가 필요한 메모리 만큼 할당해주기 때문에 내부단편화는 일어나지 않으나 여전히 중간에 프로세스가 메모리를 해제하면 생기는 hole, 즉 외부 단편화 문제는 여전히 존재한다."
BACKEND,운영체제,Context Switching이 무엇인지 설명하고 과정을 나열해주세요.,"Context Switching이란, 현재 실행중인 프로세스의 정보를 저장하고 다른 프로세스를 실행시킬 때 발생한다. CPU는 하나의 프로세스 정보만 기억할 수 있기 때문에, 다른 프로세스를 실행하기 위해서는, 기존에 실행중이던 프로세스의 상태 또는 레지스터 값(Context)을 PCB에 저장해야 한다. 기존의 값을 저장한 후, 다음 실행시킬 프로세스의 상태와 레지스터값을 PCB에서 읽어와서 레지스터에 적재하는 작업을 Context Switching 이라 한다. Context Switching 과정은 다음과 같다. Interrupt나 시스템 호출에 의해 context switching 요구 User Mode에서 Kernel Mode로 변경 기존 프로세스의 현재 context를 PCB에 저장 다음에 실행할 프로세스의 상태정보를 PCB에서 복구한 후 다음 프로세스를 실행 Kernel Mode에서 User Mode로 변경 Context Switching이 발생하는 상황 Context Switching은 인터럽트 발생 시에 발생하고, 인터럽트는 실행 중인 CPU 사용 할당 시간을 모두 소모하거나, 입출력을 위해 대기하는 경우에 발생하며, 프로세스의 CPU 제어권이 다른 프로세스에게 이양되는 상황으로 볼 수 있다. 따라서, 프로세스 상태와도 관련이 있으며, 3가지 상태 변화에 따라 인터럽트가 발생한다. Context Switch를 하는 주체는 OS 스케줄러이다. → → → PCB(Process Control Block) 프로세스를 관리하는데 있어 필요한 정보(메타 데이터)를 담고있는 운영체제 커널의 자료구조이다. 프로세스가 생성될 때마다 고유의 PCB가 생성되며, 프로세스가 완료되면 PCB는 제거된다. PCB에는 , (ex. ready, running), (다음 instruction), , , 등의 정보가 포함된다. Thread 단위의 Context Switching Process는 Thread보다 Context Switching 오버헤드가 크다. Thread는 Stack 영역을 제외한 모든 메모리를 공유하기 때문이다."
BACKEND,운영체제,Swapping에 대해 설명해주세요.,"스와핑(Swapping)이란, 주기억장치(메인메모리)에 적재한 하나의 프로세스와 보조기억장치(하드디스크)에 적재한 다른 프로세스의 메모리를 교체하는 기법이다. 프로세스가 실행되기 위해서는, 프로세스의 명령어와 명령어가 접근하는 데이터가 메모리에 적재되어있어야 한다. 메모리가 부족하면, 메모리 내에 존재하던 기존 프로세스를 backing store(하드디스크, 보조기억장치)라는 공간으로 내릴 수 있다.(=쫒아낸다) 그리고 다시 필요할 때 메모리에 불러와서 사용할 수도 있다. 필요없는 데이터를 backing store에 저장하는 것을 swap out, 필요한 데이터를 메모리에 올리는 것을 swap in이라고 한다. (메모리 기준으로 in, out) 프로세스 단위로 swap in, swap out하는 것을 swapping이라고 한다. 표준 스와핑과 페이지 단위 스와핑 스와핑을 사용하면, 실제 물리 메모리보다 더 많은 프로세스를 수용할 수 있다. 스와핑의 가장 중요한 역할은 프로세스의 수를 조절하여, 다중 프로그래밍의 정도(degree of muliprogramming)를 조절 할 수 있다는 것이다. 유휴 상태가 오래 지속되는 프로세스가 스와핑에 적합하며, swap out 될 대상 프로세스는 스와퍼(swapper)라고 불리는 중기 스케쥴러(medium-term scheduler)에 의해 선정된다. 주의할 점은, 스와핑이라는 개념이 프로세스가 종료되어 그 주소 공간을 디스크로 내쫓는 것이 아니라, 특정한 이유로 수행 중인 프로세스의 주소 공간을 일시적으로 메모리에서 디스크로 내려놓는 것을 의미한다는 것이다. 그러나 위와 같이 프로세스 단위로 스와핑하는 표준 스와핑 방법은 최근에 많이 사용되지 않는다. 메모리와 저장장치 사이에 프로세스 전체를 이동시키는 것이 힘들기 때문이다. 대신, 페이지 단위 스와핑을 이용한다. Backing Store 스왑 영역(swap area)라고도 부르며, 디스크 내에 파일 시스템과는 별도로 존재하는 일정 영역을 말한다. 프로세스가 수행중인 동안에만 디스크에 일시적으로 저장하는 공간이므로 저장 기간이 상대적으로 짧은 저장공간이다. 다수의 사용자 프로세스를 담을 수 있을 만큼 충분히 큰 저장공간이어야 하고 어느 정도의 접근 속도가 보장되어야 한다는 특징이 있다."
공통,자료구조,linked list,"linked list는 서로 떨어져 있는 데이터를 메모리 주소를 참조함으로써 이어진 것처럼 사용할 수 있다. linked list는 구조체가 이어진 형태로 존재하며, 이 구조체를 라고 부른다. 노드는 값을 담고 있는 와 다음 구조체를 가리키는 로 구성된다. 정확히는, 포인터가 다음 구조체의 주소를 담고 있다. 보통, linked list의 맨 첫 원소를 가리키는 head 포인터와 맨 마지막 원소를 가리키는 tail 포인터를 통해, 리스트의 요소에 접근하거나 수정한다. linked list는 구현 방법에 따라, single linked list와 double linked list, circular linked list 등으로 구분할 수 있다. Array vs. Linked list array에서 중간에 값을 삽입하고 싶다면, 삽입할 위치 뒤의 모든 데이터가 한 칸씩 이동해야 한다는 단점이 있다. 또한, array가 할당받은 공간이 부족한데, 메모리상 뒤쪽의 메모리가 비어있지 않으면, 모든 데이터가 더 큰 홀로 이사를 가야 한다는 단점도 존재한다. linked list는 연속된 공간을 사용하지 않아도 되기 때문에 앞서 언급했던 array의 단점을 모두 해소할 수 있다. 그러나 N번째 데이터를 참조하고 싶을 때, 계속해서 다음 주소를 참조하는 형식으로 따라가야 하므로 메모리 참조에 시간이 오래 걸린다. 따라서 삽입과 삭제가 빈번한 경우에는 linked list를 사용하고, 참조가 빈번하게 일어날 때는 array를 쓰는 것이 바람직하다. Time Complexity 비교 | 구분 | Array | Linked List | | :------: | :------: | :---------: | | | $O(n)$ | $O(1)$ | | | $O(n)$ | $O(1)$ | | | $O(1)$ | $O(n)$ | 삽입, 삭제, 접근 방법 접근: 원하는 원소가 나올때까지 링크 필드(포인터, 다음 노드)를 계속해서 탐색한다. 삽입: 삽입할 노드의 next에 현재 위치의 next를 연결한 후, 현재 위치의 next에 삽입할 노드의 주소를 넣어준다. 삭제: 삭제할 노드의 next를 앞선 노드의 next에 연결해준다. 기본적인 linked list 구조 (=Single linked list 구조) --- #1-1 single linked list 1 Linked list에서 언급한 내용은 모두 Single linked list에 해당한다. Single linked list는 linked list 중에서도 가장 기본적인 구조로 되어 있으며, head에서 tail까지 단방향으로 포인터가 이어져 있으므로 N 번째 노드에서 N-1 번째 노드에 접근할 수 없다. 대신, 다시 head로부터 N-1 번의 탐색을 통해 접근해야 한다."
공통,자료구조,hash table,"해시 테이블은 (Key, Value)로 데이터를 저장하는 자료구조 중 하나로 빠르게 데이터를 검색할 수 있는 자료구조이다. 해시 테이블이 빠른 검색속도를 제공하는 이유는 내부적으로 배열(버킷)을 사용하여 데이터를 저장하기 때문이다. 해시 테이블은 각각의 Key값에 해시함수를 적용해 배열의 고유한 index를 생성하고, 이 index를 활용해 값을 저장하거나 검색하게 된다. 여기서 실제 값이 저장되는 장소를 버킷 또는 슬롯이라고 한다. 예를 들어, 구조를 가지는 데이터 를 크기가 16인 해시 테이블에 저장한다고 하자. 그러면 먼저 연산을 통해 index 값을 계산한다. 그리고 로 value를 저장하게 된다. 이러한 구조로 데이터를 저장하면 Key값으로 데이터를 찾을 때 해시 함수를 1번만 수행하면 되므로 매우 빠르게 데이터를 저장/삭제/조회할 수 있다. 해시테이블의 평균 시간복잡도는 O(1)이다. 해시(Hash)값이 충돌하는 경우 만약 ""John Smith""를 해시 함수를 돌려 나온 값과 ""Sandra Dee""를 해시 함수를 돌려 나온 값이 동일하다면, 아래와 같이 해결할 수 있다. 해결방법 1: Separate Chaining(분리 연결법) 동일한 버킷의 데이터에 대해 자료구조를 활용해 추가 메모리를 사용하여 다음 데이터의 주소를 저장하는 방법이다. 동일한 해시 값을 가지면, 동일한 버킷 안에 엔트리를 할당해줘야한다. 이 때, 버킷 내부의 엔트리 값들은 linked list 형태로 이어준다. 이러한 Chaining 방식은 해시 테이블의 확장이 필요없고 간단하게 구현이 가능하며, 손쉽게 삭제할 수 있다는 장점이 있다. 하지만 데이터의 수가 많아지면 동일한 버킷에 chaining되는 데이터가 많아지며 그에 따라 캐시의 효율성이 감소한다는 단점이 있다. 해결방법 2: Open Addressing(개방주소법) Open Addressing이란 추가적인 메모리를 사용하는 Chaining 방식과 다르게 비어있는 해시 테이블의 공간을 활용하는 방법이다. Open Addressing을 구현하기 위한 대표적인 방법으로는 3가지 방식이 존재한다. Linear Probing: 현재의 버킷 index로부터 고정폭 만큼씩 이동하여 차례대로 검색해 비어 있는 버킷에 데이터를 저장한다. Quadratic Probing: 해시의 저장순서 폭을 제곱으로 저장하는 방식이다. 예를 들어 처음 충돌이 발생한 경우에는 1만큼 이동하고 그 다음 계속 충돌이 발생하면 2^2, 3^2 칸씩 옮기는 방식이다. Double Hashing Probing: 해시된 값을 한번 더 해싱하여 해시의 규칙성을 없애버리는 방식이다. 해시된 값을 한번 더 해싱하여 새로운 주소를 할당하기 때문에 다른 방법들보다 많은 연산을 하게 된다. 충돌을 방지하는 방법들은 데이터의 규칙성(클러스터링)을 방지하기 위한 방식이지만 공간을 많이 사용한다는 치명적인 단점이 있다. 만약 테이블이 꽉 차있는 경우라면 테이블을 확장해주어야 하는데, 이는 매우 심각한 성능의 저하를 불러오기 때문에 가급적이면 확정을 하지 않도록 테이블을 설계해주어야 한다. (통계적으로 해시 테이블의 공간 사용률이 70% ~ 80%정도가 되면 해시의 충돌이 빈번하게 발생하여 성능이 저하되기 시작한다고 한다.) 또한 해시 테이블에서 자주 사용하게 되는 데이터를 Cache에 적용하면 효율을 높일 수 있다. 자주 hit하게 되는 데이터를 캐시에서 바로 찾음으로써 해시 테이블의 성능을 향상시킬 수 있다. 시간 복잡도 삽입, 삭제, 탐색에 대해 해시 충돌이 일어나지 않는 경우에 $O(1)$, 충돌이 일어난다면 최악의 경우에 $O(N)$의 시간 복잡도를 가진다. 왜냐하면 해시 충돌로 인해서 하나의 버킷에 여러 엔트리가 연결되어있는 경우에 모든 엔트리를 탐색해야할 수 있기 때문이다."
공통,자료구조,stack,"LIFO (Last In First Out) 구조의 자료형으로 한 쪽으로만 데이터를 넣고 뺄 수 있다. 명령으로 데이터를 넣고, 명령으로 가장 마지막에 들어간 데이터를 빼낸다. stack 은 브라우저의 뒤로가기 기능, ctrl + z (되돌리기), 지역 변수와 매개변수를 저장하는 stack 메모리 등에 사용된다. 이외에도 DFS 알고리즘 등 다양한 곳에 사용되는 자료형이다. stack 에 데이터가 꽉 차서 더 넣을 공간이 없는데 데이터를 push 하는 경우 , 반대로 데이터가 없는데 pop 하는 경우를 라고 한다."
공통,자료구조,queue,"FIFO (First In First Out) 구조의 자료형으로 출구(front)와 입구(rear or back)가 따로 존재하여 먼저 입력된 데이터가 먼저 반환된다. 명령으로 rear 에 자료를 넣는다. rear += 1 되어 다음에 데이터를 받을 메모리를 가리켜야 한다. 명령으로 front 에서 데이터를 빼낸다. front += 1 되어 다음에 데이터를 반환할 메모리를 가리켜야 한다. queue 는 CPU 연산처리 작업대기, 프린터 인쇄, 프로세스 관리 등 들어온 순서를 보장해야하는 경우 사용된다. 이외에도 BFS 알고리즘 등에 사용된다. queue 의 rear 가 기리키는 공간에 데이터가 있는데 데이터를 push 하는 경우 , 반대로 front 가 가리키는 공간에 데이터가 없는데 pop 하는 경우를 라고 한다."
공통,자료구조,graph,"그래프는 정점과 간선으로 이루어진 자료구조이다. 정점 간의 연결관계는 간선으로 나타낸다. 그래프의 종류 간선이 담고있는 정보와 연결 상태에 따라 그래프의 종류가 나뉜다. 두 정점을 연결하는 간선에 방향이 없다면 , 두 정점을 연결하는 간선에 방향이 존재하면 라고 부른다. 방향 그래프는 간선의 방향으로만 이동할 수 있다. 두 정점을 이동할 때 비용이 발생하면 로 나타낼 수 있다. 모든 정점이 간선으로 연결된 경우, 라고 부른다. 그래프 구현 방식 첫 번째로 인접행렬 방식이 있다. 노드를 인덱스로 삼는 2차원 배열을 만들어 각 노드가 간선으로 연결되어있으면 배열에 1을 넣어주고, 연결되지 않았다면 0을 넣어주면 된다. 두 노드의 연결관계를 조회할 때, $O(1)$ 시간이 걸린다. 그러나 모든 정점에 대해, 간선 정보를 입력해야하므로 초기화에 $O(N^2)$ 시간이 소요된다. 노드의 수가 많고, 간선의 수가 적은 그래프의 경우에, 공간을 낭비하게 된다. 두 번째로 인접리스트 방식이 있다. 그래프의 노드들을 리스트로 표현한다. head 노드와 연결된 노드들을 링크에 달아주면 된다. 한 정점에 연결된 노드들의 정보를 얻기 위해서 $O(M)$ 시간이 걸린다.(M은 간선의 수) 간선 정보만 유지하므로, 공간 낭비가 적으나 두 정점이 연결되었는지 확인하기 위해서 $O(M)$ 시간이 걸리며, 구현이 비교적 어렵다. 그래프 용어 : 노드(node)라고도 하며 정점에는 데이터가 저장된다. : 링크(arcs)라고도 하며 노드간의 관계를 나타낸다. : 간선에 의해 직접 연결된 정점이다. : 경로 중 반복되는 정점이 없는것, 같은 간선을 자나가지 않는 경로이다. : 무방향 그래프에서 하나의 정점에 인접한 정점의 수이다. : 방향그래프에서 사용되는 용어로 한 노드에서 외부로 향하는 간선의 수를 뜻한다. : 방향그래프에서 사용되는 용어로 외부 노드에서 들어오는 간선의 수를 뜻한다."
공통,자료구조,tree,"tree는 그래프의 일종으로, 부모 노드 밑에 여러 자식 노드가 연결되고, 자식 노드 각각에 다시 자식 노드가 연결되는 재귀적 형태의 자료구조이다. 노드들은 서로 다른 자식 노드를 가지며 이때 각 노드는 재사용 되지 않는다. 트리는 다음과 같은 특징을 갖는다. 반드시 하나의 루트 노드만이 존재한다. 모든 자식 노드는 한 개의 부모 노드만을 가진다. 서로 다른 임의의 두 노드에 대해 두 노드를 연결하는 경로는 유일하다. 사이클을 가지는 노드 집합이 존재하지 않는다. 노드가 N개인 트리는 항상 N-1개의 간선을 가진다. 트리 용어 : 트리를 구성하는 기본 원소 : 트리에서 부모가 없는 최상위 노드, 트리의 시작점 : 루트 노드 방향으로 직접 연결된 노드 : 루트 노드 반대 방향으로 직접 연결된 노드 : 같은 부모 노드를 갖는 노드들 : 자식이 없는 노드 : 한 노드에서 다른 한 노드에 이르는 길 사이에 있는 노드들의 순서 : 출발 노드에서 도착 노드까지 거치는 노드의 개수 : 루트 경로의 길이 : 루트 노드(level=1)부터 노드까지 연결된 링크 수의 합 : 가장 긴 루트 경로의 길이 : 각 노드의 자식의 개수 : 트리의 최대 차수 = max[deg1, deg2, ..., degn] : 노드의 개수 : 가장 많은 노드를 갖고 있는 레벨의 크기"
공통,자료구조,heap(binary heap),"최대값 및 최소값을 찾아내는 연산을 빠르게 하기 위해 고안된 완전 이진 트리를 기본으로 한 자료구조로서 다음의 속성을 만족한다. A가 B의 부모 노드이면, A의 키값과 B의 키값 사이에는 대소관계가 성립한다. heap의 종류에는 min heap, max heap이 있다. 각 노드의 자식 노드의 최대 개수는 힙의 종류에 따라 다르지만, 대부분의 경우는 자식 노드의 개수가 최대 2개인 이진 힙(binary heap)을 사용한다. 힙에서는 가장 높은(혹은 가장 낮은) 우선순위를 가지는 노드가 항상 루트 노드에 오게 되는 특징이 있으며, 이를 응용하여 우선순위 큐와 같은 추상적 자료형을 구현할 수 있다. 이진 힙(binary heap) 이진 힙은 다음과 같은 두 가지 특징을 갖는다. 트리를 T, 임의 내부 노드를 v라고 하면 다음과 같다. 루트 노드를 제외한 각 내부 노드는 이다. (즉, 키 값은 오름차순이거나 내림차순이다.) 마지막 왼쪽 결합 노드들의 레벨을 제외한 다른 모든 레벨들은 완전 이진 트리를 형성한다. 힙 리스트(heap list)로 표현할 때 i번째 노드의 왼쪽 자식 노드의 위치는 2i가 되며, i번째 노드의 오른쪽 자식 노드의 위치는 2i+1이고, 또한 i번째 노드의 부모 노드의 위치는 i/2가 된다. 이진 힙의 시간복잡도는 $O(log n)$이다."
공통,자료구조,Red-black Tree,"레드-블랙트리의 정의 레드-블랙 트리(Red-Black Tree)는 이진탐색트리(Binary Search Tree)의 한 종류로, 삽입(insert), 삭제(delete), 검색(retrieval) 연산을 $O(log N)$에 수행하도록 보장하는 균형 잡힌 트리를 말한다. 즉, 트리의 높이가 $log N$이 되도록 한다. 레드-블랙 트리는 다음의 조건을 만족한다. 모든 노드는 빨간색 혹은 검은색이다. 루트 노드는 검은색이다. 혹은 로 표기된 리프노드는 검정색이다. 빨간색 노드의 자식 노드는 검정색이다. 즉, 빨간색 노드가 연속적으로 나올 수 없다. 리프노드에서 루트노드까지 가는 경로에서 만나는 검은색 노드의 개수는 같다. 레드-블랙트리가 균형 잡힌 트리인 이유 레드-블랙 트리의 5번째 조건 때문인데, 검은색 노드의 개수가 B이고 빨간색 노드가 최소가 되는 경우와 최대가 되는 경우를 생각해보자. 빨간색 노드가 최소가 되려면, 빨간색 노드 자체가 없어야 하고 총 노드의 개수는 B개이다. 빨간색 노드가 최대가 되려면, 으로 반복되어야 한다. 이 경우 총 노드의 개수는 2B이다. 그러므로 최소 경로와 최대 경로의 차이는 2배보다 크지 않으므로 레드-블랙 트리는 균형 잡힌 트리라고 말할 수 있다. 레드-블랙 트리의 연산 레드-블랙 트리의 연산으로 , , 가 있다. 자세한 내용은 레드-블랙 트리/동작 - 위키백과를 참고!"
공통,자료구조,B-Tree,"B-트리의 정의 B-트리는 이진 트리(Binary Tree)를 확장해 모든 리프 노드들이 같은 높이를 갖도록 하는 트리이다. 노드 내에 여러 개의 key가 있을 수 있으며, 최대 key의 개수에 따라 2개이면 2차 B-트리, N개면 N차 B-트리라고 부른다. B-트리는 다음의 조건을 만족한다. 노드의 key의 개수가 N이면, 자식 노드의 개수는 N+1이다. 노드 내의 key는 오름차순으로 정렬되어 있다. 루트 노드는 2개 이상의 자식을 가져야 한다. 루트 노드를 제외한 나머지 노드들은 적어도 최대 M/2개의 key를 가져야 한다. M은 B-트리의 차수를 말한다. 리프 노드는 모두 같은 레벨에 있어야 한다. B-트리의 연산 B-트리의 연산은 과 , 가 있다. 다음 연산은 B-트리 연산을 이해할 수 있는 자료로 이것을 참고! B-트리 연산 시뮬레이션: B-Tree Algorithm Visualizations B-트리 연산 개념 정리: [[자료구조] 그림으로 알아보는 B-Tree - emplam27.log]( B-트리 vs B+ 트리 B+ 트리는 B-트리와 비슷하지만 리프노드가 연결리스트의 형태를 띄어 선형 검색이 가능한 트리이다. 모든 노드에 key와 data가 있는 B 트리와는 달리 B+ 트리는 리프 노드에만 data가 존재한다. 또한 과 연산 모두 리프 노드에서만 이루어진다."
공통,알고리즘,"시간, 공간 복잡도","복잡도란 알고리즘의 성능을 평가하는 척도로 시간 복잡도(Time Complexity)와 공간 복잡도(Space Complexity)로 나뉜다. 시간 복잡도(Time Complexity): 알고리즘에 사용되는 연산 횟수의 총량 공간 복잡도(Space Complexity): 알고리즘에 사용되는 메모리 공간의 총량 즉, 시간 복잡도는 속도에 대한 분석 결과이고, 공간 복잡도는 메모리 사용량에 대한 분석 결과이다. 알고리즘의 복잡도는 점근적 표기법으로 나타내는데, 점근적 표기법에는 대표적으로 O(빅오), Ω(오메가), Θ(세타)가 있다. O Notation (빅오 표기법): 점근적 상한선 / 최악의 경우 Ω Notation (오메가 표기법): 점근적 하한선 / 최상의 경우 θ Notation (세타 표기법): 점근적 상한선과 점근적 하한선의 교집합 / 평균의 경우 일반적으로 최악의 경우의 성능을 측정하는 빅오 표기법을 많이 사용한다."
공통,알고리즘,Divide and Conquer,"분할 정복(Divide and Conquer)은 문제를 분할해서 분할한 문제를 해결한 다음 결과를 조합하는 알고리즘이다. 큰 문제를 작은 문제로 분할한다는 관점에서 하향식 접근 방법으로 문제를 푼다고 볼 수 있다. 분할: 문제를 동일한 유형의 여러 하위 문제로 나누는 것 해결: 가장 작은 단위의 하위 문제를 해결하는 것 조합: 하위 문제에 대한 결과를 원래 문제에 대한 결과로 조합하는 것 분할 정복 알고리즘은 보통 재귀를 사용하여 구현한다. 다음은 분할 정복의 대표적인 문제인 피보나치 수열 코드이다. python def fibb(n): table = [1] (n+1) for i in range(2, n+1): table[i] = table[i-1] + table[i-2] return table[n] python 전역 변수로 table과 n이 미리 선언됨 def fibb(n): if n BFS(Breadth-First Search, 너비우선탐색) BFS는 그래프 전체를 탐색하는 방법 중 하나로써, 현재 확인하는 노드의 인접한 노드들을 먼저 탐색하는 것이다. 시작 정점으로부터 가까운 정점을 먼저 방문하고 멀리 떨어져 있는 정점을 나중에 방문하는 순회하는 방식으로 노드를 탐색한다. 주로 구현은 Queue라는 자료구조에 이웃하는 정점을 다 담아놓고 차례대로 pop을 하는 방식으로 구현한다. 주로 두 노드 사이의 최단 경로 혹은 임의의 경로를 찾고 싶을 때 이 방법을 사용한다. - 노드의 수가 적고 깊이가 얕은 경우 빠르게 동작할 수 있다. 단순 검색 속도가 깊이 우선 탐색(DFS)보다 빠르다. 너비를 우선 탐색하기에 답이 되는 경로가 여러개인 경우에도 최단경로임을 보장한다. 최단경로가 존재한다면 어느 한 경로가 무한히 깊어진다해도 최단경로를 반드시 찾을 수 있다. - 재귀호출의 DFS와는 달리 큐에 다음에 탐색할 정점들을 저장해야 하므로 저장공간이 많이 필요하다. 노드의 수가 늘어나면 탐색해야하는 노드 또한 많아지기에 비현실적이다. DFS(Depth-First Search, 깊이우선탐색) DFS는 그래프 전체를 탐색하는 방법중 하나로써, 시작점 부터 다음 분기(branch)로 넘어가기 전에 해당 분기를 완벽하게 탐색하고 넘어가는 방법이다. 먼저 보이는 노드부터 계속해서 깊이를 늘려가며 탐색하고, 더 이상 탐색할 노드가 없다면 이전 노드로 돌아가서 다른 브랜치를 다시 깊이 파보는 형식을 말한다. Stack이나 재귀함수를 통해서 구현할 수 있는데, 재귀함수가 구현이 간편하다. - 현재 경로 상의 노드들만 기억하면 되므로, 저장 공간의 수요가 비교적 적다. 목표 노드가 깊은 단계에 있는 경우에도 해를 빨리 구할 수 있다. 구현이 너비 우선 탐색(BFS) 보다 간단하다. - 단순 검색 속도는 너비 우선 탐색(BFS) 보다 느리다. 깊이 우선 탐색은 해를 구하면 탐색이 종료되므로, 구한 해가 최단 경로가 된다는 보장이 없다. 목표에 이르는 경로가 다수인 경우, DFS를 통해 구한 해가 최적이 아닐 수 있다. DFS를 사용하여 최단 경로를 구하기 위해서는, 모든 경로를 전부 확인해보아야 한다. BFS와 DFS의 탐색 순서 주의해야할 것 노드를 Queue 혹은 Stack에 넣을 때, 방문 여부를 반드시 표시해주어야 한다. 그렇지 않으면, 자료구조에 노드가 중복되게 들어갈 수 있기 때문이다. 방문 표시를 하지 않으면, 심한 경우에는 무한루프에 빠질 수도 있다."
BACKEND,네트워크,TCP와 UDP의 차이점에 대해서 설명해보세요.,"TCP는 연결 지향형 프로토콜이고 UDP는 데이터를 데이터그램단위로 전송하는 프로토콜입니다. TCP는 가상 회선을 만들어 신뢰성을 보장하도록(흐름 제어, 혼잡 제어, 오류 제어) 하는 프로토콜로 따로 신뢰성을 보장하기 위한 절차가 없는 UDP에 비해 속도가 느린편입니다. TCP는 그래서 파일전송과 같은 신뢰성이 중요한 서비스에 사용되고, UDP는 스트리밍, RTP와 같이 연속성이 더 중요한 서비스에 사용됩니다. +) 하지만 UDP도 신뢰성을 UDP자체에서 보장하지 않는 것 뿐이지, 개발자가 직접 신뢰성을 보장하도록 할 수 있습니다. 그래서 HTTP/3은 QUIC이라는 프로토콜을 기반으로 하는데, QUIC은 UDP를 기반으로 합니다. 즉, UDP 자체는 신뢰성을 보장하지 않지만, 추가적인 정의를 통해 신뢰성을 보장받을 수 있습니다."
BACKEND,네트워크,"TCP 3, 4 way handshake에 대해서 설명해보세요.","TCP가 가상회선을 만들고 제거하는 과정에 대해서 묻는 질문입니다. TCP를 공부하셨다면 이 정도는 알겠지 하고 묻는 문제고, 실제 면접자리에서는 보통 네트워크에 대해서 설명할 때, 직접 설명하는 편입니다. TCP 3way handshake는 가상회선을 수립하는 단계입니다. 클라이언트는 서버에 요청을 전송할 수 있는지, 서버는 클라이언트에게 응답을 전송할 수 있는지 확인하는 과정입니다. SYN, ACK 패킷을 주고받으며, 임의의 난수로 SYN 플래그를 전송하고, ACK 플래그에는 1을 더한값을 전송합니다. 정확한 순서는 SYN(n) -> ACK(n + 1), SYN(m) -> ACK(m + 1) 순으로 일어납니다. 왜 임의의 난수를 지정하느냐는 꼬리질문이 나올 수 있습니다. 기존 요청과 구분하기 위해서 정도로 알고있고, 그 이상은 생각해본적이 없네요. TCP 4way handshake는 TCP연결을 해제하는 단계로, 클라이언트는 서버에게 연결해제를 통지하고 서버가 이를 확인하고 클라이언트에게 이를 받았음을 전송해주고 최종적으로 연결이 해제됩니다. 단, 서버에서 소켓이 닫혔다고 통지해도 클라이언트 측에서는 일정시간 대기하는데, 혹시나 패킷이 나중에 도착할 수 있기 때문입니다."
BACKEND,네트워크,HTTP와 HTTPS의 차이점에 대해서 설명해보세요.,"HTTP는 따로 암호화 과정을 거치지 않기 때문에 중간에 패킷을 가로챌 수 있고, 수정할 수 있습니다. 따라서 보안이 취약해짐을 알 수 있습니다. 이를 보완하기 위해 나온 것이 HTTPS입니다. 중간에 암호화 계층을 거쳐서 패킷을 암호화합니다."
BACKEND,네트워크,HTTPS에 대해서 설명하고 SSL Handshake에 대해서 설명해보세요.,"HTTPS는 HTTP에 보안 계층을 추가한 것입니다. HTTPS는 제3자 인증, 공개키 암호화, 비밀키 암호화를 사용합니다. 제3자 인증은 믿을 수 있는 인증기관에 등록된 인증서만 신뢰하는 것이고, 공개키 암호화는 비밀키를 공유하기 위해 사용합니다. 비밀키 암호화는 통신하는 데이터를 암호화하는데 사용합니다. 클라이언트는 TCP 3way handshake를 수행한 이후 Client Hello를 전송합니다. 서버는 인증서를 보냅니다.(다른 정보들도 전송하나 검색을 통해 알 수 있는 부분입니다. 대개 그 정도까지는 요구하지 않습니다.) 클라이언트는 받은 인증서를 신뢰하기 위해서 등록된 인증기관인지 확인합니다. 이 인증서는 인증기관의 개인키로 암호화되어있고, 공개키로 검증할 수 있습니다.(브라우저에 내장되어있음) 클라이언트는 사이트의 정보와, 서버의 공개키를 얻을 수 있습니다. 서버의 공개키로 통신에 사용할 비밀키를 암호화해서 서버에 보냅니다. 서버는 이를 개인키로 확인하고 이후 통신은 공유된 비밀키로 암호화되어 통신합니다. 제3자 인증: 인증서, 인증기관/공개키 암호화: 인증서, 비밀키 공유/비밀키 암호화: 통신과정 왜 공개키 암호화와 비밀키 암호화를 복합적으로 사용했는지도 질문을 받았습니다."
BACKEND,네트워크,GET과 POST의 차이점에 대해서 설명해보세요.,"대개의 경우 아래의 HTTP 메서드 질문을 더 많이합니다. 하지만 둘의 차이만을 물을 수도 있습니다. GET요청은 서버에 존재하는 정보를 요청합니다. 이 때 반환되는 정보는 정보 자체가 아니라 정보의 표현입니다.(뒤의 내용은 REST와 연관이 있고, 굳이 답변하지 않으셔도 됩니다.) 일반적으로 Request Body는 입력하지 않는 것이 일반적이며, 레거시 시스템의 경우 요청을 받아들이지 않을 수 있습니다. 캐싱을 수행하기 때문에 캐싱되지 않는 요청은 GET 요청이 맞지 않을 수 있습니다. POST요청은 서버에 정보를 생성하는 것을 요청합니다. 예전 HTTP 통신은 POST 요청으로 데이터 삭제, 수정도 form요청으로 같이 수행했습니다. POST 요청은 서버의 상태를 변경시키기 때문에 멱등성이 유지되지 않습니다. 보통 Request Body에 요청하는 데이터를 담아 전송합니다."
BACKEND,네트워크,HTTP 메서드와 이것이 하는 역할에 대해서 설명해보세요.,"보통 REST API를 설계했다면 이해할 수 있을정도로 설명하면 되는 것 같습니다. OPTIONS, HEAD, TRACE의 존재에 대해서는 알아만 둡시다. 특히 TRACE는 몰라도 되는 것 같습니다. OPTIONS는 해당 uri에 대해 서버가 허용하는 메서드를 확인할 때 사용합니다. HEAD는 GET과 비슷하나 header만 가져옵니다. GET 요청은 서버에 존재하는 데이터를 요청하는 것입니다. CRUD로 따지면 R입니다. POST 요청은 서버에 데이터를 생성하는 것을 요청합니다. CRUD로 따지면 C입니다. PUT 요청은 서버에 존재하는 데이터를 수정하거나 존재하지 않으면 생성합니다. CRUD로 따지면 C,U입니다. DELETE 요청은 서버에 데이터를 제거할 것을 요청합니다. 존재하지 않아도 동일하게 동작합니다. CRUD로 따지면 D입니다. PATCH 요청은 서버에 존재하는 데이터를 일부 수정합니다. CRUD로 따지면 U입니다. 더 나아가서 불필요한 메서드는 허용하지 않고 필요한 메서드만 허용하는 Whitelist 방식으로 관리합시다. 자세한 내용은 HTTP Method 취약점에 대해 검색합시다."
BACKEND,네트워크,"RESTful이란 무엇이며, 이것에 대해서 아는대로 설명해보세요.(보충필요)","REST는 굉장히 난해한 개념입니다. 하지만 REST가 무엇인지 대략의 감은 잡아둡시다. REST API를 설계했다면 충분히 물어볼만한 질문입니다. HTTP URI를 통해 자원을 표시하고 HTTP Method를 통해 자원에 대한 처리를 표현합니다. 사람이 읽을 수 있는 API라는 것이 특징입니다. HTTP를 사용하기 때문에 HTTP의 특성을 그대로 반영합니다. 또한 별도의 인프라 구축이 필요없습니다. 단점으로는 명확한 표준이 존재하지 않는다는 점, RESTful을 완전히 만족하는 API를 만들기는 매우 까다롭다는 점(그런 REST API로 괜찮은가 참고)이 있습니다. HATEOAS라는 개념이 있는데, 동적인 API를 제공할 수 있게됩니다.(모든 관련된 동작을 URI를 통해 알려줍니다.) 즉, 클라이언트가 API의 변화에 일일이 대응하지 않아도 된다는 장점을 가져옵니다."
BACKEND,네트워크,CORS란 무엇이며 이것에 대해서 설명해보세요.,"CORS는 웹개발을 하다가 흔히 만날 수 있는 이슈입니다. 대개는 프론트엔드 개발시에 로컬에서 API 서버에 요청을 보낼 때 흔하게 발생합니다. 서로 다른 도메인간에 자원을 공유하는 것을 뜻합니다. 대부분의 브라우저에서는 이를 기본적으로 차단하며, 서버측에서 헤더를 통해서 사용가능한 자원을 알려줍니다. preflight request는 실제 요청을 보내도 안전한지 판단하기 위해 사전에 보내는 요청입니다. OPTIONS 메서드로 요청하며 CORS를 허용하는지 확인합니다. CORS가 허용된 웹서버라면 사용 가능한 리소스를 헤더에 담아 응답합니다."
BACKEND,네트워크,"OSI7계층과 그 존재 이유, TCP/IP 4계층에 대해 설명해보세요.","OSI7계층은 네트워크 통신을 구성하는 요소들 7개의 계층으로 표준화 한 것입니다. 이렇게 표준화하는 것의 장점은 통신이 일어나는 과정을 단계별로 파악할 수 있어, 문제가 발생하면 해당 문제를 해결하기 용이해집니다. 실제로 우리가 대부분 사용하는 네트워크는 TCP/IP 4계층입니다. 통신에 실제로 사용되는 계층이고 1,2 계층이 1계층, 5, 6, 7계층이 4계층으로 운영됩니다."
BACKEND,네트워크,"웹 서버 소프트웨어(Apache, Nginx)는 OSI 7계층 중 어디서 작동하는지 설명해보세요.","Apache와 NGINX는 HTTP 웹 서버로, 이들이 동작하는 HTTP 프로토콜은 OSI 7 Layer 중 7계층인 애플리케이션 Layer 에 해당하는 프로토콜입니다. HTTP 프로토콜은 TCP/IP 프로토콜을 통해 동작합니다. TCP/IP 프로토콜은 OSI 7 Layer 중 4계층인 Transport Layer에서 동작합니다. 따라서 웹 서버 소프트웨어는 4계층의 TCP/IP 프로토콜과 7계층의 HTTP 프로토콜을 활용하여 동작합니다."
BACKEND,네트워크,"웹 서버 소프트웨어(Apache, Nginx)의 서버 간 라우팅 기능은 OSI 7계층 중 어디서 작동하는지 설명해보세요.","두 가지가 있습니다. Layer 4 (Transport Layer), 그리고 Layer 7 (Application Layer) 입니다. L4 에서는 TCP/UDP 포트 정보를 토대로 라우팅 기능이 제공됩니다. L7에서는 TCP/UDP 뿐만 아니라 HTTP의 URI 등을 토대로 라우팅 기능이 제공 됩니다. L4 에서 라우팅 기능을 사용 한 예시를 들자면, Nginx 의 경우 여러 포트들을 하나의 upstream 블록으로 묶어서 로드 밸런싱, 즉 특정 경로로 전달되는 요청을 각 포트 별로 분산해서 전달하도록 설정 해 줄 수 있습니다. L7 에서 라우팅 기능을 사용 한 예시를 들자면, Apache, Nginx 각각에서 서브 도메인에 대해 라우팅 설정을 해 둘 수 있습니다. 브라우저에서 /test 와 같은 서브 도메인으로 HTTP 프로토콜을 통한 요청을 보낸다면, 웹서버 내 Config 파일에 설정 된 경로 정보를 토대로 요청에 대한 라우팅을 제공하여 스태틱 파일을 전달하거나 API 서버에 대해 리버스 프록시 역할을 해 줄 수 있습니다."
BACKEND,운영체제,프로세스와 스레드의 차이를 설명해보세요.,"프로세스는 실행중인 프로그램을 의미합니다. 스레드는 실행 제어만 분리한 것을 의미합니다. 프로세스는 운영체제로부터 자원을 할당받지만, 스레드는 프로세스로부터 자원을 할당받고, 프로세스의 코드/데이터/힙영역을 공유하기 때문에 좀 더 효율적으로 통신할 수 있습니다. 또한 컨텍스트 스위칭도 캐시 메모리를 비우지 않아도 되는 스레드쪽이 빠릅니다. 그리고, 스레드는 자원 공유로 인해 문제가 발생할 수 있으니 이를 염두에 둔 프로그래밍을 해야합니다. 한 프로세스 안에 여러개의 스레드가 생성될 수 있습니다."
BACKEND,운영체제,컨텍스트 스위칭에 대해 설명해보세요.,"컨텍스트 스위칭은 한 Task가 끝날 때까지 기다리는 것이 아니라 여러 작업을 번갈아가며 실행해서 동시에 처리될 수 있도록 하는 방법입니다. 인터럽트가 발생하면 현재 프로세스의 상태를 PCB에 저장하고 새로운 프로세스의 상태를 레지스터에 저장하는 방식으로 동작합니다. 이 때, CPU는 아무런 일을 하지 않으므로 잦은 컨텍스트 스위칭은 성능저하를 일으킬 수 있습니다. 스레드와 프로세스의 동작방식이 약간 상이한데, 스레드는 캐시메모리나 PCB에 저장해야하는 내용이 적고, 비워야 하는 내용도 적기때문에 상대적으로 더 빠른 컨텍스트 스위칭이 일어날 수 있습니다."
BACKEND,운영체제,"동기와 비동기의 차이(블로킹, 넌블로킹) / 장단점에 대해 설명해보세요.","동기/비동기는 두 개 이상의 무엇인가가 시간을 맞춘다/안맞춘다로 구분할 수 있습니다. 동기 방식은 메서드 리턴과 결과를 전달받는 시간이 일치하는 명령 실행 방식입니다. 또, 동기 방식은 한 함수가 끝나는 시간과 바로 다음의 함수가 시작하는 시간이 같습니다. 비동기 방식은 여러 개의 처리가 함께 실행되는 방식으로, 동기 방식에 비해 단위시간 당 많은 작업을 처리할 수 있습니다. 단, CPU나 메모리를 많이 사용하는 작업을 비동기로 처리하게 되면 과부하가 걸릴 수 있습니다. 프로그램의 복잡도도 증가하게 됩니다. 블로킹/논블로킹은 동기/비동기와는 다른 관점으로, 내가 직접 제어할 수 없는 대상(IO/멀티스레드)을 상대하는 방법에 대한 분류입니다. 블로킹 방식은 대상의 작업이 끝날 때 까지 제어권을 대상이 가지고 있는 것을 의미합니다. 반면에 논블로킹은 대상의 작업 완료여부와 상관없이 새로운 작업을 수행합니다. 동기 논블로킹은 계속해서 polling을 수행하기 때문에 컨텍스트 스위칭이 지속적으로 발생해 지연이 발생합니다. 를 참고합시다."
BACKEND,운영체제,멀티스레드 프로그래밍에 대해 설명해보세요.,멀티스레드 프로그래밍은 하나의 프로세스에서 여러개의 스레드를 만들어 자원의 생성과 관리의 중복을 최소화하는 것을 멀티스레드 프로그래밍이라고 합니다. 장점 멀티 프로세스에 비해 메모리 자원소모가 줄어듭니다. 힙 영역을 통해서 스레드간 통신이 가능해서 프로세스간 통신보다 간단합니다. 스레드의 컨텍스트 스위칭은 프로세스의 컨텍스트 스위칭보다 빠릅니다. 단점 힙 영역에 있는 자원을 사용할 때는 동기화를 해야합니다. 동기화를 위해서 락을 과도하게 사용하면 성능이 저하될 수 있습니다. 하나의 스레드가 비정상적으로 동작하면 다른 스레드도 종료될 수 있습니다.
BACKEND,운영체제,Thread-safe 하다는 의미와 설계하는 법을 설명해보세요.,"두 개 이상의 스레드가 race condition에 들어가거나 같은 객체에 동시에 접근해도 연산결과의 정합성이 보장될 수 있게끔 메모리 가시성이 확보된 상태를 의미합니다. java.util.concurrent 패키지 하위의 클래스를 사용합니다. 인스턴스 변수를 두지 않습니다. Singleton 패턴을 사용합니다.(이 때, 일반적으로 구현하는 Singleton Pattern은 Thread-safe 하지 않습니다.) 동기화(syncronized) 블럭에서 연산을 수행합니다."
BACKEND,운영체제,프로세스 동기화에 대해 설명해보세요.,"알아야 하는 부분이 조금 많습니다. 면접때에는 적절히 짧게 끊어서 대답합시다. 너무 깊게 들어가면 말을 번복할 가능성도 있고, 잘 모른다는 인상을 주기 쉽습니다. 다중 프로세스 환경에서 자원등에 한 프로세스만이 접근가능하도록 하는 것입니다. 프로세스 동기화를 하지 않으면 데이터의 일관성이 깨지기 때문에 연산결과가 잘못 반환될 가능성이 존재하기 때문에 주의해야 합니다. Race Condition(경쟁 상태): 여러 프로세스나 스레드가 동기화 메커니즘 없이 자원에 접근하려는 상황을 가리킵니다. 공유된 자원에 대한 접근 순서에 따라 실행 결과가 달라질 수 있는 상황을 의미합니다. Critical Section(임계 구역): 여러 스레드가 동시에 접근해서는 안되는 공유자원에 접근하는 코드 블럭을 얘기합니다. 한 임계구역에 하나의 스레드 혹은 프로세스만 접근이 가능합니다. 임계 구역에 접근하는 것을 제어하기 위해 세마포어, 뮤텍스와 같은 매커니즘을 사용합니다. 임계 구역 문제를 해결하기 위한 조건(모두 충족해야함) 상호 배제(Mutual Exclusion): 한 프로세스가 임계구역에서 동작중이면 다른 프로세스는 접근할 수 없다. 진행(Progress): 임계구역에서 작업중인 프로세스가 없다면 입계구역으로 진입하려는 프로세스를 적절히 선택해서 진입할 수 있도록 합니다. 유한 대기(Bounded Waiting): 한 프로세스가 임계영역으로 진입을 요청한 후 다른 프로세스는 진입이 유한한 횟수로 제한되어야 합니다. (기아상태 방지)"
BACKEND,운영체제,교착상태와 기아상태의 해결방법에 대해 설명해보세요.,"교착상태(Deadlock)가 무엇인지 알고 있어야 합니다. 서로 다른 프로세스가 서로 점유하고 있는 자원의 반납을 대기하고 있는 상태를 의미합니다. 발생조건 상호 배제: 한 번에 한 프로세스만 해당 자원을 사용할 수 있어야 합니다. 점유 대기: 할당된 자원을 가진 상태에서 다른 자원을 기다립니다. 비선점: 다른 프로세스가 자원의 사용을 끝낼 때 까지 자원을 뺏을 수 없습니다. 순환대기: 각 프로세스가 순환적으로 다음 프로세스가 요구하는 자원을 가지고 있습니다. 해결방법 예방: 4가지 조건 중 하나라도 만족되지 않도록 합니다. 회피: 알고리즘을 데드락이 발생하지 않도록 합니다. 회복: 교착상태가 발생할 때, 해결합니다. 무시: 회복과정의 성능저하가 심하다면 그냥 무시합니다. 기아상태(Starvation): 여러 프로세스가 부족한 자원을 점유하기 위해 경쟁할 때, 특정 프로세스가 영원히 자원 할당이 되지 않는 경우입니다. 우선순위를 변경합니다.(우선순위를 수시로 변경하거나, 오래 기다린 프로세스의 우선순위를 높여주거나, Queue를 사용합니다.)"
BACKEND,운영체제,세마포어와 뮤텍스의 차이에 대해 설명해보세요.,"세마포어는 여러개의 프로세스가 접근 가능한 공유자원을 관리하는 방식이고, 뮤텍스가 될 수 있지만, 뮤텍스는 한 번에 한 개의 프로세스만 접근 가능하도록 관리하는 방식입니다. 따라서 뮤텍스는 세마포어가 될 수 없습니다. 또, 세마포어는 다른 프로세스가 세마포어를 해제할 수 있지만, 뮤텍스는 락을 획득한 프로세스만 락을 반환할 수 있습니다."
BACKEND,운영체제,가상 메모리에 대해 설명해보세요.,"가상 메모리는 프로세스가 실제 메모리의 크기와 상관없이 메모리를 이용할 수 있도록 지원하는 기술 입니다. 가상 메모리는 실제 메모리(RAM, main memory, first storage)와 보조 기억 장치(auxiliary storage, secondary storage)의 Swap 영역으로 구성됩니다. OS 는 메모리 관리자(Memory Management Unit)를 통해 메모리를 관리하며 프로세스는 사용하는 메모리가 실제 메모리인지, Swap 영역인지 모릅니다. Java 에서는 Swap 영역을 잡아주지 않은 경우 OOM 이 발생할 수 있습니다. Swap 영역은 실제 메모리가 아니기 때문에 지연시간이 많이 발생하며, 가급적이면 Swap 메모리를 사용하지 않도록 설계하는 것이 좋고, 만약 계속해서 사용하는 양이 증가한다면 메모리 누수를 의심해 볼 수 있습니다."
BACKEND,운영체제,캐시의 지역성에 대해 설명해보세요.,"캐시가 무엇인지, 왜 캐시를 사용하는지를 알고 있어야 합니다. 관련한 좋은 글을 링크해둡니다. 시간 지역성과 공간 지역성으로 나눌 수 있으며, 시간 지역성은 최근에 접근한 데이터에 다시 접근하는 경향을 의미하고, 공간 지역성은 최근 접근한 데이터의 주변 공간에 다시 접근하는 경향을 의미합니다."
BACKEND,운영체제,프로세스 관련 용어를 설명해보세요. (알아만 둡시다.),"PCB: 프로세스 제어 블록, 프로세스에 대한 중요한 정보를 저장합니다. PC: 프로그램 카운터, 프로세스 실행을 위한 다음 명령의 주소를 표시합니다. 캐시메모리: 자주 사용되는 데이터가 저장되는 공간으로 CPU의 레지스터와 메모리 사이에서 병목 현상을 완화하는 장치입니다."
BACKEND,데이터베이스,데이터베이스에서 인덱스를 사용하는 이유 및 장단점에 대해 설명해주세요.,"데이터베이스에서 인덱스를 사용하는 이유는 검색성능을 향상시키기 위함입니다. 하지만 검색성능을 실질적으로 향상시키기 위해서는 해당 쿼리가 index를 사용하는지, 카디널리티, Selectivity 같은 요소들이 고려된 인덱스가 생성되어야 합니다. 일반적인 경우의 장점으로는 빠른 검색 성능을 들 수 있습니다. 일반적인 경우의 단점으로는 인덱스를 구성하는 비용 즉, 추가, 수정, 삭제 연산시에 인덱스를 형성하기 위한 추가적인 연산이 수행됩니다. 따라서, 인덱스를 생성할 때에는 트레이드 오프 관계에 놓여있는 요소들을 종합적으로 고려하여 생성해야합니다. 그렇다고 모든 곳에서 인덱스를 사용하면 오히려 악효과를 낼 수 있다. 인덱스를 생성하면 추가적인 저장공간이 필요하고 인덱스 관리를 위한 오버헤드가 발생 할 수 있다. 인덱스가 존재하는 경우, 데이터 삽입,수정,삭제시에도 인덱스가 함께 업데이트 된다. 다라서 인덱스 수가 많이잘수록 쓰기 성능이 감소 할 수 있다. 쿼리에 사용되지 않는 인덱스가 존재하면, 해당 인덱스는 시스템 리소스 공간을 불필요하게 차지하기 때문에 시스템 전체 성능에 부정적인 영향이 있을 수 있다. 인덱스를 관리하는것도 비용이 드는 작업이기 때문에 인덱스가 많아지면 관리하기 어려울 수 있다. 등의 문제가 있기 때문에 인덱스를 생성전에 충분한 분석 및 검토가 필요하여 시스템을 균형있게 유지해야 한다."
BACKEND,데이터베이스,트랜잭션에 대해서 설명해주세요.,"트랜잭션이란 데이터베이스의 상태를 변화시키는 하나의 논리적인 작업 단위라고 할 수 있으며, 트랜잭션에는 여러개의 연산이 수행될 수 있습니다. 트랜잭션은 수행중에 한 작업이라도 실패하면 전부 실패하고, 모두 성공해야 성공이라고 할 수 있습니다."
BACKEND,데이터베이스,ACID에 대해서 설명해주세요.,"ACID는 트랜잭션이 안전하게 수행된다는 것을 보장하기 위한 성질입니다. Atomicity(원자성): 트랜잭션의 연산은 모든 연산이 완벽히 수행되어야 하며, 한 연산이라도 실패하면 트랜잭션 내의 모든 연산은 실패해야 합니다. Consistency(일관성): 트랜잭션은 유효한 상태로만 변경될 수 있습니다. Isolation(고립성): 트랜잭션은 동시에 실행될 경우 다른 트랜잭션에 의해 영향을 받지 않고 독립적으로 실행되어야 합니다. Durability(내구성): 트랜잭션이 커밋된 이후에는 시스템 오류가 발생하더라도 커밋된 상태로 유지되는 것을 보장해야 합니다. (일반적으로 비휘발성 메모리에 데이터가 저장되는 것을 의미)"
BACKEND,데이터베이스,트랜잭션 격리 수준(Transaction Isolation Levels)에 대해서 설명해주세요.,트랜잭션 격리수준은 고립도와 성능의 트레이드 오프를 조절합니다. READ UNCOMMITTED: 다른 트랜잭션에서 커밋되지 않은 내용도 참조할 수 있다. READ COMMITTED: 다른 트랜잭션에서 커밋된 내용만 참조할 수 있다. REPEATABLE READ: 트랜잭션에 진입하기 이전에 커밋된 내용만 참조할 수 있다. SERIALIZABLE: 트랜잭션에 진입하면 락을 걸어 다른 트랜잭션이 접근하지 못하게 한다.(성능 매우 떨어짐)
BACKEND,데이터베이스,정규화에 대해서 설명해주세요.,"정규화는 데이터의 중복방지, 무결성을 충족시키기 위해 데이터베이스를 설계하는 것을 의미합니다. 이 이상을 물어보는 경우가 있었는데, 학습이 좀 더 필요한 것 같습니다."
BACKEND,데이터베이스,JOIN에 대해서 설명해주세요.,단순히 SQL에서 JOIN 쿼리가 어떤식으로 동작하는지 알고 있어야 합니다. 다이어그램으로 이해하는 편이 좋습니다.
BACKEND,데이터베이스,RDBMS vs NOSQL에 대해서 설명해주세요.,"RDBMS는 데이터베이스를 이루는 객체들의 릴레이션을 통해서 데이터를 저장하는 데이터베이스입니다. SQL을 사용해 데이터의 저장, 질의, 수정, 삭제를 할 수 있으며 데이터를 효율적으로 보관하는 것을 목적으로 하고 구조화가 굉장히 중요합니다. 장점으로는 명확한 데이터 구조를 보장하고, 중복을 피할 수 있습니다. NOSQL은 RDBMS에 비해 자유로운 형태로 데이터를 저장합니다. 또한 수평확장을 할 수 있고 분산처리를 지원합니다. 다양한 형태의 NOSQL 데이터베이스가 있고, 대표적으로 key-value store, bigtable, dynamo, document db, graph db 등이 있습니다. 둘은 대체될 수 있는 것이 아니고, 각각 필요한 시점에 적절히 선택해서 사용해야 합니다. 둘 다 같이쓰는 상호보완적인 존재가 될 수도 있습니다."
BACKEND,데이터베이스,Redis에 대해서 간단히 설명해주세요.,"Redis는 key-value store NOSQL DB입니다. 싱글스레드로 동작하며 자료구조를 지원합니다. 그리고 다양한 용도로 사용될 수 있도록 다양한 기능을 지원합니다. 데이터의 스냅샷 혹은 AOF 로그를 통해 복구가 가능해서 어느정도 영속성도 보장됩니다. 스프링에서는 세션을 관리하거나, 캐싱을 하는데에 자주 사용되는 것으로 알고 있습니다."
BACKEND,데이터베이스,Redis와 Memcached의 차이에 대해서 설명해주세요.,"Redis는 싱글 스레드 기반으로 동작하고, Memcached는 멀티스레드를 지원해서 멀티 프로세싱이 가능합니다. Redis는 다양한 자료구조를 지원하고, Memcached는 문자열 형태로만 저장합니다. Redis는 여러 용도로 사용할 수 있도록 다양한 기능을 지원합니다. Redis는 스냅샷, AOF 로그를 통해서 데이터 복구가 가능합니다."
BACKEND,데이터베이스,Elastic Search에 대해서 간단히 설명해주세요.,"Elastic Search는 자바로 개발된 오픈소스 검색엔진 입니다. 보통 단독으로 사용하기보다는 ELK 스택이라고 부르는 Logstash, Kibana, Beats를 추가적으로 사용합니다. Inverted Index 구조로 데이터를 저장해서, 전문(Full-text) 검색시에 RDBMS에 비해 뛰어난 성능을 보장합니다. 다양한 용도로 사용할 수 있습니다. (데이터 저장, 문서 검색, 위치 검색, 머신 러닝 기반 검색, 로그 분석, 보안 감사 분석 등)"
BACKEND,데이터베이스,Elastic Search의 인덱스구조와 RDBMS의 인덱스 구조의 차이에 대해 설명해주세요.,"Elastic Search는 Inverted-Index 구조로 데이터를 저장합니다. 이는 책의 색인을 생각해보면 쉬운데, 특정 단어가 출현하는 doc을 저장하는 것입니다. 반면 RDBMS는 B-Tree와 그와 유사한 인덱스를 사용합니다. 데이터가 어디에 존재하는지 어떤 순서로 저장하는 지의 차이라고 생각합니다. RDBMS에도 다양한 인덱스 구조가 있으나 여기서 예로 든 것은 B-Tree 인덱스입니다."
BACKEND,데이터베이스,Elastic Search의 키워드 검색과 RDBMS의 LIKE 검색의 차이에 대해 설명해주세요.,Elastic Search의 키워드 검색은 document를 저장할 때 수행하는 알고리즘과 동일한 알고리즘으로 키워드를 분리합니다. 그 중에서 랭킹알고리즘을 통해서 가장 유사한 순서대로 결과를 나타냅니다. RDBMS에서의 LIKE 검색은 와일드카드로 시작하지 않는 경우에만 인덱스를 사용하고 나머지 경우는 전체를 탐색하기 때문에 상대적으로 느립니다.
BACKEND,데이터베이스,MongoDB에 대해서 간단히 설명해주세요.,"MongoDB는 문서 지향적인 NoSQL 데이터베이스로 대량의 비정형 데이터를 다루는 데에 강점을 보입니다. 문서(Document)란 데이터베이스의 종류이며, 그 도큐먼트들을 모은 것을 컬렉션이라고 설명할 수 있을 것 같습니다. 또한 MongoDB는 JSON 형식의 문서로 데이터를 저장합니다. 따라서 app의 요구사항에 맞춰 데이터를 조직화할 수 있다는 장점이 있습니다."
BACKEND,데이터베이스,"CAP 이론과, Eventual Consistency에 대해서 설명해주세요.","CAP 이론은 분산 환경에서 모두를 만족하는 시스템은 없다는 이론입니다. Consitenty(일관성): ACID의 일관성과는 약간 다릅니다. 모든 노드가 같은 시간에 같은 데이터를 보여줘야 한다는 것입니다. Availability(가용성): 모든 동작에 대한 응답이 리턴되어야 합니다. Partition Tolerance(분할 내성): 시스템 일부가 네트워크에서 연결이 끊기더라도 동작해야 합니다. CAP는 해당 시스템이 이거다 하고 말하기 곤란한게 어떻게 클러스터링 하느냐에 따라 달라질 수 있습니다. 그렇기 때문에 어떤 전략을 취할 때 어떤 것을 선택했는가를 잘 알아야 합니다. (단순히 MySQL이 CA입니다. 보다는 어떤 이유로 CA인지 근거를 생각해보기) 그리고 어느정도 한계가 있는 이론이고 PACELC 이론이라고 또 있습니다. Eventual Consistency는 이 Consistency를 보장해주지 못하기 때문에 나온 개념으로, Consistency를 완전히 보장하지는 않지만, 결과적으로 언젠가는 Conssistency가 보장됨을 의미합니다."
공통,자료구조,배열과 링크드 리스트의 차이를 설명해주세요.,"배열은 메모리상에 순서대로 데이터를 저장합니다. 반면 링크드 리스트는 다음 데이터의 위치에 대한 포인터를 가지고 있는 구조입니다. 배열은 데이터를 인덱스로 조회할 수 있기 때문에 인덱스 조회성능이 높고, 데이터가 메모리에 순서대로 저장되어 있기 때문에, 캐시의 지역성으로 인하여 비교적 빠르게 탐색을 수행할 수 있습니다. 링크드 리스트는 중간에 데이터를 삽입하거나 삭제하는 것이 용이하다는 장점이 있습니다."
공통,자료구조,List와 Set의 차이에 대해서 설명해주세요.,"List는 중복된 데이터를 저장하고 순서를 유지하는 선형 자료구조이고, Set은 중복되지 않은 데이터를 저장할 수 있고, 일반적으로 순서를 유지하지 않는 선형 자료구조입니다.(Set은 집합입니다., TreeSet과 같이 순서를 유지하는 Set도 존재합니다.)"
공통,자료구조,"Stack, Queue에 대해서 설명해주세요.","Stack 스택은 선형 자료구조의 일종으로 마지막에 저장한 데이터를 가장 먼저 꺼내게 되는 LIFO(Last In First Out)방식의 자료구조 입니다. 스택의 사용 예시로는 웹 브라우저의 방문기록(뒤로가기), 실행 취소(undo) 등이 있습니다. Queue 큐는 선형 자료구조의 일종으로 처음에 저장한 데이터를 가장 먼저 꺼내게 되는 FIFO(First In First Out)방식의 자료구조 입니다. 큐의 사용 예시로는 프린터의 인쇄 대기, 콜센터 고객 대기 시간 등이 있습니다."
공통,알고리즘,BST의 최악의 경우의 예와 시간복잡도에 대해서 설명해주세요.,"BST가 아닌 Self-Balanced Tree를 사용하는 이유에 대해서 생각해보았다면 쉽게 답할 수 있는 문제입니다. 예를들어 1부터 10까지 순차적으로 BST에 저장했다면, BST의 형태는 리스트와 같아집니다. 이 경우를 최악의 경우라고 하며 시간복잡도는 O(n)이 됩니다."
BACKEND,보안,"비대칭키 암호화, 대칭키 암호화에 대해 간단히 설명해주세요.","비대칭키 암호화란 공개키 암호화라고도 하며, 공개키는 외부에 공개되어있고, 비밀키는 내부적으로 가지고 있고 서로 각각의 키로 암호화하거나 해제할 수 있는 방식입니다. 이 방식은 대칭키를 공유하는 방식보다 비교적 안전하며, 대신 연산 성능이 떨어지는 편입니다. 대칭키 암호화란 양측이 동일한 키를 가지고 있으며, 암호화와 해제에 동일한 키를 사용하는 방식입니다. 이 방식은 비밀키가 노출되는 문제가 있을 수 있으며, 연산성능은 덜 필요해 상대적으로 빠릅니다."
BACKEND,보안,단방향 암호화에 대해서 간단히 설명해주세요.,"단방향 암호화는 복호화 불가능한 암호화라고 합니다. 대부분 해시 알고리즘을 이용해서 구현하며, 민감정보를 데이터베이스에 저장할 때, 해당 방식을 사용합니다. 보통의 단방향 암호화는 빠른 성능을 보여, 무차별 대입 공격에 취약합니다. 따라서 이런 정보를 저장하기 위해 bcrypt와 같은 방식을 사용합니다. 해시란 말에서 알 수 있듯이 충돌가능성이 있습니다. 이렇게 복호화 불가능한 암호화 방식이 위험하다는 것은 해시 충돌을 일으켰다는 말로 이해해도 됩니다."
BACKEND,보안,JWT에 대해서 간단히 설명해주세요.,"JWT란 토큰 인증 방식에서 쓰이는 것이라고 볼 수 있습니다. 다른 사용으론 데이터를 공유하는데도 사용할 수 있지만 일반적으론 토큰 인증 방식에서 사용됩니다. JWT는 헤더, 페이로드, 시그니쳐로 구분됩니다. 헤더는 토큰의 타입, 암호화 알고리즘을 담고 있고, 페이로드는 토큰의 정보를 담는 부분이며, 시그니처는 토큰의 정보가 신뢰할 수 있는것인지 판단할 수 있도록 합니다. JWT는 세션 기반 인증과 주로 대비됩니다. 세션기반 인증은 서버에서 세션 정보를 관리해야하는 비용이 들게됩니다. 또한 분산환경에서도 관리하기 어렵습니다. 하지만 JWT는 그 자체로 정보를 가지고 있기 때문에 세션의 단점을 보완할 수 있습니다. JWT와 다른 토큰 기반 인증 방식을 비교하는 질문이 나온적도 있습니다."
BACKEND,보안,OAuth에 대해서 간단히 설명해주세요.,"OAuth는 제3자 인증방식 입니다. 기본적으로 사용자는 서버를 신뢰할 수 없습니다. 그렇기 때문에, 민감정보를 작성하는 것을 꺼립니다. 서버측에서도 마찬가지 입니다. 사용자의 민감정보를 관리하는 것은 리소스가 필요합니다. 그래서 OAuth를 사용해서 신뢰할 수 있는 서버에게 정보를 맡겨놓고 접근할 수 있는 권한을 주는 것이라고 이해하면 됩니다. 그러면 사용자 측에서는 민감정보를 굳이 입력하지 않고도 서비스를 사용할 수 있고, 서버측에서도 민감정보를 굳이 관리하지 않아도 되기 때문에 이점이라고 볼 수 있습니다. OAuth 아키텍처에 대해서 설명해주세요."
공통,컴파일러,스크립트 언어와 컴파일 언어를 나열하고 차이점을 설명해주세요.,"스크립트 언어는 PHP, Javascript, Python이 대표적인 스크립트 언어입니다. 컴파일 언어는 C, C++, Swift, Go가 있습니다. Java는 조금 특수한 경우입니다. Java는 컴파일 시에 Java Byte Code로 컴파일 되며, 이는 JVM에서 인터프리터 방식으로 동작합니다. 하지만 JIT Compiler라는 기술과 Hotspot JVM이라는 기술의 합작으로 네이티브 언어와 유사한 수준의 퍼포먼스를 낼 수 있게 되었습니다. 스크립트 언어와 컴파일 언어의 차이점은 스크립트 언어는 인터프리터라는 방식으로 한 라인 한 라인 기계어로 번역하며 실행하고, 우리가 컴파일 에러라고 부르는 문법 오류를 사전에 방지하지 못하기 때문에 주의해야 합니다. 바로바로 실행하기에는 좋기 때문에 해당 방식이 필요한 분야에 많이 사용됩니다. 컴파일 언어는 컴파일 과정을 거쳐 기계어 코드로 번역이 되기 때문에 사전에 검증을 할 수 있고, 최적화를 해줄 수 있습니다. 이것이 컴파일러가 가지는 장점입니다."
공통,Java,JVM의 구조와 Java의 실행방식을 설명해주세요.,"자바 가상 머신의 약자를 따서 줄여 부르는 용어로 JVM의 역할은 자바 애플리케이션을 클래스 로더를 통해 읽어 자바 API와 함께 실행하는 것입니다. 메모리 관리(GC)을 수행하며 스택기반의 가상머신입니다. JVM의 구조는 Class Loader, Execution engine, Runtime Data Area, JNI, Native Method Library로 이루어져 있습니다. 클래스 로더: JVM내로 클래스를 로드하고, 링크를 통해 배치하는 작업을 수행하는 모듈 실행 엔진: 바이트 코드를 실행시키는 역할 인터프리터: 바이트 코드를 한줄 씩 실행합니다. JIT 컴파일러: 인터프리터 효율을 높이기 위한 컴파일러로 인터프리터가 반복되는 코드를 발견하면 JIT 컴파일러가 반복되는 코드를 네이티브 코드로 바꿔줍니다. 그 다음부터 인터프리터는 네이티브 코드로 컴파일된 코드를 바로 사용합니다. GC(Garbage Collector): 가비지 컬렉터로 힙 영역에서 사용되지 않는 객체들을 제거하는 작업을 의미합니다. Runtime Data Areas: 프로그램 실행 중에 사용되는 다양한 영역입니다. PC Register: Thread가 시작될 때 생성되며 현재 수행 중인 JVM 명령의 주소를 갖고 있습니다. Stack Area: 지역 변수, 파라미터 등이 생성되는 영역. 실제 객체는 Heap에 할당되고 해당 레퍼런스만 Stack에 저장됩니다. Heap Area: 동적으로 생성된 오브젝트와 배열이 저장되는 곳으로 GC의 대상 영역입니다. Method Area: 클래스 멤버 변수, 메소드 정보, Type 정보, Constant Pool, static, final 변수 등이 생성됩니다. 상수 풀(Constant Pool)은 모든 Symbolic Reference를 포함하고 있습니다. JNI(Java Native Interface): 자바 애플리케이션에서 C, C++, 어셈블리어로 작성된 함수를 사용할 수 있는 방법을 제공해줍니다. Native 키워드를 사용하여 메서드를 호출합니다. 대표적인 메서드는 Thread의 currentThread()입니다. Native Method Library: C, C++로 작성된 라이브러리 입니다. Java의 실행방식 자바 컴파일러(javac)가 자바 소스코드(.java)를 읽어 자바 바이트코드(.class)로 변환시킵니다. Class Loader를 통해 class 파일들을 JVM으로 로딩합니다. 로딩된 class파일들은 Execution engine을 통해 해석됩니다. 해석된 바이트코드는 Runtime Data Areas 에 배치되어 실질적인 수행이 이루어집니다."
공통,Java,"GC가 무엇인지, 필요한 이유는 무엇인지, 동작방식에 대해 설명해주세요.","GC는 힙 영역에서 사용하지 않는 객체들을 제거하는 작업을 총칭합니다. 이 객체를 제거하는 작업이 필요한 이유는 자바는 개발자가 메모리를 직접 해제해줄 수 없는 언어이기 때문입니다. 따라서 객체를 사용하고 제거하는 기능이 필요하게 됩니다. GC의 동작방식은 가장 간단한 Serial GC 방식으로 설명합니다. 좀 더 진보된 GC는 G1 GC, ZGC가 있으며 여기선 다루지 않습니다. GC는 Minor GC, Major GC로 구분할 수 있습니다. Minor GC는 young 영역에서, Major GC는 old 영역에서 일어난다고 정의합니다. (Major GC, Full GC는 명확히 정의된 문서가 없습니다.) GC를 수행할 때는 GC를 수행하는 스레드 이외의 스레드는 모두 정지합니다. 이를 Stop-the-world라고 합니다. Minor GC는 Eden 영역이 가득 참에서 부터 시작됩니다. Eden 영역에서 참조가 남아있는 객체를 mark하고 survivor 영역으로 복사합니다. 그리고 Eden 영역을 비웁니다. Survivor 영역도 가득차면 같은 방식으로 다른 Survivor 영역에 복사하고 비웁니다. 이를 반복하다 보면 계속 해서 살아남는 객체는 old 영역으로 이동하게 됩니다. Major GC는 old 영역에서 일어납니다. 위와 반대로 삭제되어야 하는 객체를 mark합니다. 그리고 지웁(sweep)니다. 메모리는 단편화 된 상태이므로 이를 한 군데에 모아주는 것을 Compaction이라 하며 compact라고 합니다. 그래서 Mark-Sweep-Compact 알고리즘이라고 합니다. 이것이 중요한 이유는 GC 수행시 시스템이 멈추기 때문에 의도치 않은 장애의 원인이 될 수 있습니다. 따라서 이를 위해 힙 영역을 조정하는 것을 GC 튜닝이라고 하고 JVM 메모리는 절대 마음대로 조정해선 안됩니다."
공통,Java,컬렉션 프레임워크에 대해서 설명해주세요.,"Java Collection은 널리 알려져 있는 자료구조를 바탕으로 객체, 데이터들을 효율적으로 관리 할 수 있는 자료구조들이 있는 라이브러리를 컬렉션 프레임워크라고 합니다. List, Set은 Collection 인터페이스을 상속받지만, Map 인터페이스는 구조상의 차이라 별도로 정의합니다."
공통,Java,제네릭에 대해서 설명해주세요.,제네릭은 자바의 타입 안정성을 맡고 있습니다. 컴파일 과정에서 타입체크를 해주는 기능으로 객체의 타입을 컴파일 시에 체크하기 때문에 객체의 타입 안정성을 높이고 형변환의 번거로움을 줄여줍니다.
공통,Java,애노테이션에 대해서 설명해주세요.,"애노테이션은 인터페이스를 기반으로 한 문법으로 주석처럼 코드에 달아 클래스에 특별한 의미를 부여하거나 기능을 주입할 수 있습니다. built-in annotation은 상속받아서 메소드를 오버라이드 할 때 나타나는 @Override 애노테이션이 그 대표적인 예입니다. 메타 애너테이션은 애노테이션을 선언할 때 사용하는 애노테이션입니다. @Retention: 애노테이션 유지 범위를 지정합니다. (소스, 클래스, 런타임) @Inherit: 애노테이션을 하위 클래스까지 전달여부를 지정합니다. 이 애노테이션이 있으면 하위 클래스까지 상속이 가능합니다. @Target: 해당 애노테이션을 어디에 사용할 지 결정합니다. (타입, 필드, 메서드, 파라미터, 생성자, 로컬변수, 애노테이션 타입)"
공통,Java,오버라이딩과 오버로딩이 무엇이며 어떤 차이가 있을까요?,"의외로 굉장히 많은 답을 들을 수 있는 질문입니다. 오버라이딩은 상위 클래스의 메소드를 재정의 하는 것을 의미합니다. 또, 런타임 다형성이기도 합니다. 오버로딩은 같은 클래스 내에서 동일한 메소드 이름을 가지지만, 매개변수의 타입, 개수가 다르게 구현할 수 있는 것을 의미하며 컴파일 타임 다형성이기도 합니다. 따라서 오버라이딩 될 수 있습니다. 추가로 를 써야하는 이유를 꼭 생각해보세요. 이 애노테이션은 컴파일 타임에 오버라이딩에 대한 안정성을 부여해주기 때문에 반드시 써주는 것이 좋습니다."
공통,Java,인터페이스와 추상클래스의 차이점에 대해 설명해주세요.,추상클래스는 객체의 추상적인 상위 개념으로 공통된 개념을 표현할 때 사용합니다. 단일 상속만 가능합니다. 추상클래스를 상속하는 집합간에는 연관관계가 있습니다. 인터페이스는 구현 객체가 같은 동작을 한다는 것을 보장하기 위해 사용합니다. 다중 상속이 가능합니다. 인터페이스를 구현하는 집합간에는 관계가 없을 수 있습니다.
공통,Java,클래스는 무엇이고 객체는 무엇인가요?,"클래스는 객체를 정의하는 틀 또는 설계도와 같은 의미로 사용됩니다. 객체는 식별 가능한 개체 또는 사물입니다. 객체는 구별 가능한 식별자, 특징적인 행동, 변경 가능한 상태를 가집니다. 인스턴스들을 통칭하는 용도로 사용합니다."
공통,Java,정적(static)이란 무엇인가요?,"static은 클래스 멤버라고 하며, 클래스 로더가 클래스를 로딩해서 메소드 메모리 영역에 적재할 때 클래스별로 관리됩니다. static 키워드를 통해 생성된 정적멤버들은 PermGen 또는 Metaspace에 저장되며 저장된 메모리는 모든 객체가 공유하며 하나의 멤버를 어디서든지 참조할 수 있는 장점이 있습니다. 그러나, GC의 관리 영역 밖에 존재하기 때문에 프로그램 종료시까지 메모리가 할당된 채로 존재합니다. 너무 남발하게 되면 시스템 성능에 악영향을 줄 수 있습니다."
공통,Java,자바의 원시타입들은 무엇이 있으며 각각 몇 바이트를 차지하나요?,"실제 면접에서 들었던 질문입니다. 들었을 때 굉장히 당황했던 기억이 나네요. boolean(1), char(unsigned 2), byte(1), short(2), int(4), long(8), float(4), double(8) 사실 JVM에 의존적이기 때문에 정확한 크기라기 보다는 대략적인 크기입니다."
공통,Java,접근 제어자의 종류와 이에 대해 설명해주세요.,"private, default, protected, public이 있습니다. private은 해당 클래스 내에서만 접근 가능하고, default는 해당 패키지, protected는 상속한 클래스, public은 전체 영역에서 접근 가능합니다. 접근 제어자를 사용하는 이유는 외부에 보여주고 싶은 정보들을 선택적으로 제공하기 위함이고, 캡슐화와 통하는 면이 있습니다."
공통,Java,객체지향에 대해서 설명해주세요.,"객체지향을 정의하면, 의존성 관리입니다. 객체지향으로 의존성을 관리함으로써 변경 영향을 최소화하고 독립적인 배포가 가능해지며 독립적인 개발이 가능해집니다. 따라서 객체지향에서 가장 중요한 것은 DIP(Dependency Inversion Principle)를 통한 고수준 정책(High Level Policy)와 저수준 구현 세부사항(Low Level Details)의 분리라고 할 수 있습니다."
공통,Java,SOLID(객체지향 5대원칙)에 대해서 설명해주세요.,"SRP(단일책임원칙)은 한 클래스의 하나의 책임만 가져야 합니다. OCP(개방-폐쇄 원칙)은 확장에는 열려 있으나 변경에는 닫혀 있어야 하며, 다형성을 활용해야 합니다. LSP(리스코프 치환 원칙)은 프로그램의 객체는 프로그램의 정확성을 깨뜨리지 않으면서 하위 타입의 인스턴스로 바꿀 수 있어야하는 원칙으로 상위 타입을 상속해서 재정의 했을 때 프로그램이 깨지지 않아야 합니다. ISP(인터페이스 분리 원칙)은 클라이언트는 자신이 사용하지 않는 메서드에 의존 관계를 맺으면 안되는 원칙입니다. 특정 클라이언트를 위한 인터페이스 여러 개가 범용 인터페이스 하나보다 더 낫습니다. 즉, 비대한 인터페이스보단 더 작고 구체적인 인터페이스로 분리해야합니다. DIP(의존관계 역전 원칙)은 추상적인 것은 자신보다 구체적인 것에 의존하지 않고, 변화하기 쉬운 것에 의존해서는 안된다는 원칙입니다. 구체적으론 구현 클래스에 의존하지 말고, 인터페이스에 의존해야 하는 원칙입니다."
공통,Java,"동일성(identity)와 동등성(equality)에 대해 설명해주세요. (equals(), ==)","동일성은 객체의 주소를 비교하는 것이고, 동등성은 객체의 같음을 비교하는 것입니다. 기본적으로 자바에서는 Object 클래스에 정의된 equals() 메소드가 동등성 비교를 합니다. 따라서, 개발자는 원한다면 equals() 메소드를 오버라이딩해서 동등성의 판단 기준을 정의해주면 됩니다."
공통,Java,원시타입과 참조타입의 차이에 대해 설명해주세요.,"원시타입은 Java에서 단 8개 밖에 존재하지 않는 타입입니다. 나머지는 모두 참조타입이라고 볼 수 있고, Object 클래스이거나 이를 상속하는 클래스들로 이루어져 있습니다. 원시타입은 항상 값이 존재해야 합니다. 반면, Object 타입은 null 포인터를 가질 수 있습니다. 그리고 멤버변수가 초기화될 때, 원시타입은 기본값을 가지지만, 참조타입은 null 포인터를 가지는 차이도 있습니다."
공통,Java,"String, StringBuilder, StringBuffer 각각의 차이에 대해 설명해주세요.",String은 불변입니다. StringBuilder와 StringBuffer는 이런 String의 특징때문에 사용하는 가변타입이라고 볼 수 있습니다. StringBuilder와 StringBuffer는 Thread-safe 여부의 차이가 있습니다. StringBuilder는 Thread-safe하지 않습니다. 따라서 Multi-Thread 환경에서 사용할 때는 StringBuffer를 사용합니다.
공통,Java,Checked Exception과 Unchecked Exception에 대해 설명해주세요. 스프링 트랜잭션 추상화에서 rollback 대상은 무엇일까요?,둘의 차이는 RuntimeException을 상속하는가의 여부에 따라 다릅니다. RuntimeException을 상속하면 UncheckedException이 됩니다. 스프링 트랜잭션 추상화에서 rollback 대상은 바로 UncheckedException입니다. 이 둘을 잘 알기 위해서는 토비의 스프링을 보시는 것을 추천합니다.
공통,Java,Java8에서 추가된 기능에 대해서 설명해주세요.,"자신이 사용한 경험을 말해주면 더 효과적일 것 같습니다. Java8에서는 Lambda식, Stream API, Optional, 날짜 시간 API, StringJoiner 등이 추가되었습니다. lambda는 함수형 프로그래밍을 지원하기 위한 기능이고, Stream API는 고차함수를 지원합니다. Optional은 Null-safety를 제공하며, Stream과 사용법이 유사합니다. 날짜 시간 API는 Joda-time등의 라이브러리에서 영향을 받아 괜찮은 API가 되었으며, StringJoiner는 문자열을 간단하게 구분자로 합칠 수 있는 기능을 제공합니다."
공통,Java,try-with-resource에 대해서 설명해주세요.,"try-with-resources는 자바 버전7에 도입된 문법입니다. 자바 7 버전 이전에서 하나 이상의 리소스(java.lang.AutoCloseable을 구현한 객체 혹은 java.io.Closeable를 구현한 객체)를 사용할 경우 개발자가 임의로 finally 문에서 .close()를 사용하여 자원 해제를 시켜줘야 했습니다. 만약 개발자가 사용한 자원을 finally 문에서 해제시켜주지 않고 누락시켰다면 자원이 해제되지 않은 채로 프로그램이 오작동하게 되고, finally 문에서 자원을 해제 시켜주더라도 자원 해제를 위한 중복 코드가 발생하기 때문에 소스 코드의 가독성을 해치는 단점이 있었습니다. 이를 해결하기 위해 try() 안에 사용할 리소스 객체를 명시적으로 선언하여 사용하면, try 블록 안에서 로직이 정상적으로 완료되었는지, 갑작스럽게 완료되었는지 여부와 관계 없이 JVM에서 자동으로 자원을 반납해주는 기능을 하도록 도입하였습니다. 추가로, 자바 9 버전에서는 try() 문 안에 명시적으로 객체 선언을 하기 보다는 try 문 바깥에서 객체 선언을 하고 생성된 인스턴스의 변수를 넣어줄 수 있도록 바뀌었습니다. Java 7 : try(BufferedReader br = new BufferedReader()) Java 9 : try(br)"
공통,Java,강한 결합과 느슨한 결합이 무엇인지 설명해주세요.,"결합도는 의존성의 정도를 나타내며 다른 모듈에 대해 얼마나 많은 정보를 알고 있는지에 대한 척도입니다. 어떤 모듈이 다른 모듈에 너무 자세한 부분(구현 세부사항)까지 알고 있을 경우에 강한 결합도를 가진다고 합니다. 어떤 모듈이 다른 모듈에 대해 필요한 정보(인터페이스로 추상화된 고수준 정책)만 알고 있다면 두 모듈은 낮은 결합도를 가진다고 합니다. 객체지향 관점에서 결합도는 객체 또는 클래스가 협력에 필요한 적절한 수준의 관계만을 유지하고 있는지를 나타냅니다. 이러한 관점에서 강한 결합도는 반드시 지양해야 하며, 개발자는 적절한 결합도를 유지할 수 있도록 고민하고 설계해야 합니다."
공통,Java,직렬화와 역직렬화에 대해서 설명해주세요.,직렬화란 자바 시스템 내부에서 사용되는 객체 또는 데이터를 외부의 자바 시스템에서도 사용할 수 있도록 바이트 형태로 데이터 변환하는 기술과 바이트로 변환된 데이터를 다시 변환하는 기술(역직렬화)을 아울러서 이야기 합니다. 자바 직렬화는 JVM의 메모리에서만 상주되어있는 객체 데이터를 영속화(Persistence)가 필요할 때 사용됩니다. 시스템이 종료되더라도 없어지지 않는 장점을 가지며 영속화된 데이터이기 때문에 네트워크로 전송이 가능합니다.
공통,Java,Mutable 객체와 Immutable 객체의 차이점에 대해 설명해주세요.,"Mutable 객체는 변경 가능 객체이고, Immutable 객체는 불변 객체라고 흔히들 말합니다. Mutable 객체는 도메인 개체(도메인 클래스 혹은 엔터티)로 사용됩니다. Mutable 객체의 변경 메서드는 Command method라고도 부르며, 리턴 타입을 void 로 정의합니다. 또한 void 리턴 타입의 어떠한 상태를 변경하는 메서드는 모두 Command method의 상징입니다. Immutable 객체는 불변객체이며 값 객체, 서비스 객체 등에 사용됩니다. Immutable 객체의 변경 메서드는 변경한 객체의 복사본을 반환해야 합니다."
공통,Java,자바에서 null을 안전하게 다루는 방법에 대해 설명해주세요.,공개 메서드가 아닌 곳에는 assert를 사용하여 null을 방어할 수 있습니다. 또한 메서드의 인자를 받을 때 Objects.requireNonNull()을 사용하여 방어할 수 있습니다. 그리고 Optional을 사용해 리턴 타입에서 null을 반환하지 않도록 방어할 수 있습니다. 마지막으로 사전 조건과 사후 조건을 명확히 하여 계약에 의한 설계를 실천해야 합니다.
공통,Java,JDK와 JRE의 차이점을 설명하세요.,"JDK는 Java Development KIT의 약자로 개발하는데 사용되는 도구이며 JRE를 포함하고 있으며 JRE는 Java Runtime Environment의 약자로 자바로 만들어진 프로그램을 실행시키는데 필요한 도구가 들어있는 차이가 있습니다. 운영서버와 같은 곳에서는 개발에 필요한 도구가 아닌 프로그램을 실행시키는 도구만 필요하기 때문에 개발도구가 들어있는 JDK아닌 JRE를 설치합니다. ----여기는 굳이 말씀 안하셔도 될듯합니다.---- 그러나 최근에 JDK가 많이 가벼워지고 하드웨어도 좋아지고 해서 운영서버에 설치하여도 큰 문제가 없고 JDK에 로깅, 디버깅, 로그분석등 유용한 도구들도 있고 해서 굳이 JRE설치하는것 보다 JDK를 설치 해서 개발및 실행환경을 통합적으로 관리하는 경우도 있다고 합니다."
BACKEND,Spring,Spring DI/IoC는 어떻게 동작하나요?,"IoC(제어의 역전)은 프로그램의 제어 흐름을 직접 제어하는 것이 아니라 외부에서 관리하는 것으로 코드의 최종호출은 개발자가 제어하는 것이 아닌 프레임워크의 내부에서 결정된 대로 이루어집니다. DI(의존관계 주입)은 Spring 프레임워크에서 지원하는 IoC의 형태로 클래스 사이의 의존관계를 빈 설정 정보를 바탕으로 컨테이너가 자동으로 연결해줍니다. 스프링에서는 스프링 컨테이너 ApplicationContext를 이용하여 설정 정보를 생성, 등록하고 필요한 객체를 생성자 혹은 setter를 통해 주입합니다."
BACKEND,Spring,Spring Bean이란 무엇인가요?,IoC 컨테이너 안에 들어있는 객체로 필요할 때 IoC컨테이너에서 가져와서 사용합니다. @Bean 을 사용하거나 xml설정을 통해 일반 객체를 Bean으로 등록할 수 있습니다.
BACKEND,Spring,스프링 Bean의 생성 과정을 설명해주세요.,객체 생성 → 의존 설정 → 초기화 → 사용 → 소멸 과정의 생명주기를 가지고 있습니다. Bean은 스프링 컨테이너에 의해 생명주기를 관리하며 빈 초기화방법은 @PostConstruct 를 빈 소멸에서는 @PreDestroy 를 사용합니다. 생성한 스프링 빈을 등록할 때는 ComponentScan을 이용하거나 @Configuration 의 @Bean 을 사용하여 빈 설정파일에 직접 빈을 등록할 수 있습니다.
BACKEND,Spring,스프링 Bean의 Scope에 대해서 설명해주세요.,"빈 스코프는 빈이 존재할 수 있는 범위를 뜻하며 싱글톤, 프로토타입, request, session, application 등이 있습니다. 싱글톤은 기본 스코프로 스프링 컨테이너의 시작과 종료까지 유지되는 가장 넓은 범위의 스코프입니다. 프로토타입은 빈의 생성과 의존관계 주입까지만 관여하고 더는 관리하지 않는 매우 짧은 범위의 스코프입니다. request는 웹 요청이 들어오고 나갈때까지 유지하는 스코프, session은 웹 세션이 생성, 종료할때까지, application은 웹 서블릿 컨텍스트와 같은 범위로 유지하는 스코프입니다."
BACKEND,Spring,IoC 컨테이너의 역할은 무엇이 있을까요?,애플리케이션 실행시점에 빈 오브젝트를 인스턴스화하고 DI 한 후에 최초로 애플리케이션을 기동할 빈 하나를 제공해준다
BACKEND,Spring,"DI 종류는 어떤것이 있고, 이들의 차이는 무엇인가요?","DI는 세가지 방법이 있습니다. 생성자 삽입, Setter를 이용한 메소드 매개 변수 삽입, 필드 주입이 있습니다. 생성자 주입은 생성자 호출시점에 딱 1번만 호출되는 것을 보장하며 불변, 필수 의존관계에 사용합니다. Setter주입은 선택, 변경 가능성이 있는 의존관계에 사용되며 스프링빈을 선택적으로 등록이 가능합니다. 필드 주입은 를 사용하는데 외부에서 변경이 불가능하여 테스트 하기 힘듭니다. DI 프레임워크 없이는 작동하기 힘들며, 주로 애플리케이션과 관계없는 테스트코드나 같은 스프링 설정 목적으로 사용합니다."
BACKEND,Spring,Autowiring 과정에 대해서 설명해주세요.,컨테이너에서 타입(인터페이스 또는 오브젝트)을 이용해 의존 대상 객체를 검색하고 할당할 수 있는 빈 객체를 찾아 주입한다
BACKEND,Spring,프론트 컨트롤러 패턴이란 무엇인가요?,"클라이언트의 다양한 요청마다 서블릿을 만들어서 사용한다고 하면 개발과 유지보수의 효율이 떨어질 수 밖에 없습니다. 프론트 컨트롤러 패턴을 사용함으로써 각 요청을 적절한 곳으로 위임해줌으로써 개발과 유지보수의 효율성이 증가하고 모든 요청에 대해 보안, 국제화, 라우팅 및 로그와 같은 일반적인 기능을 한 곳에서 캡슐화할 수 있습니다. Spring에서는 DispatcherServlet이 프론트 컨트롤러 패턴을 사용한 예이며, DispatcherServlet이 Bean으로 등록되어 package를 scan하고 @Controller, @RestController 애노테이션을 확인하여 어떠한 요청이 들어왔을 때 적절한 Handler Method에 위임해줍니다."
BACKEND,Spring,Servlet Filter와 Spring Interceptor의 차이는 무엇인가요?,"Filter는 Servlet Filter로써 javax.servlet 스펙에 포함되는 클래스입니다. Interceptor는 Spring MVC 스펙에 포함되어 있는 클래스입니다. Filter는 Servlet에서 전후처리를 담당하며, Interceptor는 Spring에서 Handler를 실행하기 전후나, ViewResolver를 통해 컨트롤러에서 리턴한 View Name으로부터 렌더링을 담당할 View 오브젝트를 준비해 돌려준 후 실제 View를 렌더링한 후에 어떠한 처리를 담당합니다. Filter는 Web Application(Tomcat을 사용할 경우 web.xml)에 등록하며, Interceptor는 Spring의 Application Context에 등록합니다. Filter는 Method Signature에 있는 Argument인 HttpServletRequest 혹은 HttpServeltResponse를 ServletRequest, ServletResponse 등으로 교체할 때 사용하거나, 데이터 변환(다운로드 파일의 압축 및 데이터 암호화 등), XSL/T를 이용한 XML 문서 변경, 사용자 인증, 자원 접근에 대한 로깅 등에 사용합니다. Interceptor의 경우 AOP를 흉내내거나, Spring 애플리케이션에서 전역적으로 전후처리 로직에서 예외를 사용하도록 하거나, Handler Method에서 사용자의 권한을 체크해서 다른 동작을 시켜준다거나 할 때 사용합니다."
BACKEND,Spring,Spring에서 CORS 에러를 해결하기 위한 방법을 설명해주세요.,"Servlet Filter를 사용하여 커스텀한 Cors 설정하거나, WebMvcConfiguer를 구현한 Configuration 클래스를 만들어서 addCorsMappings()를 재정의할 수도 있고, 마지막으로 Spring Security에서 CorsConfigurationSource를 Bean으로 등록하고 config에 추가해줌으로써 해결할 수 있습니다. Controller 클래스에 @Crossorigin 어노테이션을 통해 해결할 수 있습니다."
BACKEND,Spring,"Bean/Component 어노테이션에 대해서 설명해주시고, 둘의 차이점에 대해 설명해주세요.","두 어노테이션 모두 IoC 컨테이너에 Bean을 등록하기 위해 사용합니다 @Component : 개발자가 작성한 class를 기반으로 실행시점에 인스턴스 객체를 1회(싱글톤) 생성합니다 @Controller, @Service, @Repository 는 모두 @Component 이며 실행시점에 자동으로 의존성을 주입합니다 @Bean : 개발자가 작성한 method를 기반으로 메서드에서 반환하는 객체를 인스턴스 객체로 1회(싱글톤) 생성합니다"
BACKEND,Spring,POJO란 무엇인가요? Spring Framework에서 POJO는 무엇이 될 수 있을까요?,"POJO는 프레임워크 인터페이스, 클래스를 구현하거나 확장하지 않은 단순한 클래스로 Java에서 제공하는 API 외에 종속되지 않습니다. 특정 환경에 종속되지 않아 코드가 간결하고 테스트 자동화에 유리합니다. 스프링에서는 도메인과 비즈니스 로직을 수행하는 대상이 POJO대상이 될 수 있습니다."
BACKEND,Spring,"Spring Web MVC에서 요청 마다 Thread가 생성되어 Controller를 통해 요청을 수행할텐데, 어떻게 1개의 Controller만 생성될 수 있을까요?","@Controller 어노테이션을 타고 들어가보면 @Component라는 어노테이션이 붙어 있습니다. 따라서 컨트롤러는 IoC컨테이너에 등록되어 Spring bean으로 관리됩니다. Spring의 빈 생성 전략의 기본은 싱글턴입니다. IoC컨테이너에 Controller Bean은 싱글턴 전략에 의해 1개만 존재하고 Application이 Init 되는 시점에 초기화됩니다. 그리고 실제 사용되는 시점에 의존성 주입을 통해서 사용됩니다. 요청시마다 새로 Bean을 생성해서 사용하는 것이 아닌 이미 생성되어있는 Bean을 가져다 쓰게됨으로써 여러개의 Thread에서 Contoller를 사용해도 1개의 동일한 컨트롤러인 것입니다. 만약 요청이 올때마다 새로운 컨트롤러가 생기길 바란다면 Bean scope를 Singleton 이 아닌, request 등으로 설정하면 요청이 들어올 때 혹은 지정한 전략마다 새로운 컨트롤러 Bean이 생기도록 할 수 있습니다."
BACKEND,Spring,Spring WEB MVC의 근간에는 Java Servlet 이 있는데요. Spring 은 Servlet을 어떻게 구성해서 이를 구현했을까요?,"Servlet은 Java로 웹페이지를 구성할 때 동적으로 웹페이지를 구성해주는 자바 클래스 입니다. Spring에서도 이 Servlet을 사용하고 있지만 특성이 조금 다릅니다. 기본적으로 Java의 Servlet은 하나의 Request에 대해서 하나의 Servlet을 생성합니다. 이 방법은 간단하고 직관적이지만 Servlet이 많이 생성되면 관리하기 힘들어지는 단점이 있습니다. 반면 Spring의 경우에는 DispatcherServlet이라는 FrontController 패턴을 사용해서 중앙에서 하나의 Servlet이 요청을 받아서 HandlerMapping을 통해 그에 맞는 컨트롤러로 분배하는 방식을 사용합니다. 이렇게 할 경우 하나의 객체에서 모든 요청을 먼저 처리하기 때문에 재사용성 및 유연한 매핑, 인터셉터의 사용, 관리의 용이성 등이 있겠습니다."
BACKEND,Spring,"Filter는 Servlet의 스펙이고, Interceptor는 Spring MVC의 스펙입니다. Spring Application에서 Filter와 Interceptor를 통해 예외를 처리할 경우 어떻게 해야 할까요?",Filter는 DispatcherServlet 외부에 존재하기 때문에 예외가 발생했을 때 ErrorController에서 처리해야 합니다. 하지만 Interceptor는 DispatcherServlet 내부에 존재하기 때문에 @ControllerAdvice를 적용해서 처리할 수 있습니다.
BACKEND,Spring,Spring Application을 구동할 때 메서드를 실행시키는 방법에 대해 설명해주세요.,"CommandLineRunner, ApplicationRunner를 구현한 클래스를 만들어서 실행시키는 2가지 방법이 있습니다. 또한 Spring의 ApplicationEvent를 사용한 방법, @Postconstruct를 사용한 방법, InitializingBean 인터페이스를 구현하는 방법, @Bean의 initMethod를 사용한 방법이 있습니다."
BACKEND,Spring,의존성과 설정값을 생성자 인자로 주입해야 하는 이유에 대해 설명해주세요.,"모든 의존성을 생성자를 통해 주입하면, 인스턴스 생성 시 즉시 어떠한 동작을 실행할 수 있습니다. 또한 추가적인 설정은 필요하지 않으며, 뜻하지 않게 의존성과 설정값을 빠뜨리는 일이 발생하지 않고 테스트에도 용이합니다."
BACKEND,nodeJS,nodeJS는 싱글 스레드인가 멀티 스레드인가?,"nodeJS의 주 실행 흐름은 싱글 스레드 기반의 이벤트 루프 모델입니다. I/O 작업을 자신의 메인 스레드(이벤트 루프를 도는 싱글스레드)가 아닌 다른 스레드(libuv에서 관리하는 thread pool에 존재)에 위임함으로써 싱글 스레드로 non blocking I/O를 지원합니다. (참고: event-driven모델을 사용하는 서버는 대체로 event loop를 활용하여 동작합니다. 예시로 redis(multiplexing),spring webflux(Reactor) 등이 있습니다.)"
공통,자료구조,참조복사(얕은복사) vs 값복사(깊은복사),1) 얕은 복사(Shallow copy)는 참조 타입 데이터가 저장한 '메모리 주소 값'을 복사한 것을 의미한다. 따라서 원본까지 바뀌는것에 주의해야 한다. 2) 반대로 깊은 복사(Deep copy)는 새로운 메모리 공간을 확보해 완전히 복사하는 것을 의미한다.
공통,Python,List와 Tuple의 차이에 대해 설명해주세요.,"List와 Tuple의 가장 큰 차이점은 값을 변경할 수 있는가의 여부입니다. List는 값을 수정할 수 있지만, Tuple은 값을 변경할 수 없습니다. List는 []로 작성, Tuple은 ()를 이용하여 작성합니다."
공통,Python,파이썬 데코레이터에 대해 아는대로 설명해주세요.,"어떤 함수가 있을 때 해당 함수를 직접 수정하지 않고 함수에 기능을 추가하고자 할 때 데코레이터를 사용합니다. 즉, 함수의 전처리나 후처리에 대한 필요가 있을 때 보통 사용합니다. 이를 통해서 반복을 줄이고 메소드나 함수 책임을 확장시킬 수 있습니다."
공통,디자인 패턴,싱글톤 패턴에 대해서 설명해주세요.(생각보다 어려움),"전역 변수를 사용하지 않고 객체를 하나만 생성하도록 하며, 생성된 객체를 어디에서든지 참조할 수 있도록 하는 패턴입니다. 하나의 인스턴스만을 생성하며 getInstance메서드로 모든 클라이언트에게 동일한 인스턴스를 반환합니다. private 생성자를 가지는 특징을 가지며, 생성된 싱글톤 오브젝트는 저장할 수 있는 자신과 같은 타입의 스태틱 필드를 정의합니다. 싱글톤 패턴의 문제점은 다음과 같습니다. 의존 관계상 클라이언트가 구체 클래스에 의존합니다. private 생성자 때문에 테스트가 어렵습니다. 객체 인스턴스를 하나만 생성해서 공유하는 방식 때문에 싱글톤 객체를 stateful하게 설계 했을 경우 큰 장애 발생요인이 됩니다. 싱글톤의 단점을 해결하기 위해 무상태(stateless)로 설계해야 합니다. 특정 클라이언트에 의존적인 필드가 있으면 안됩니다. 특정 클라이언트가 값을 변경할 수 있는 필드가 있으면 안됩니다. 가급적 읽기 전용으로 만들고, 필드 대신에 자바에서 공유되지 않는 지역변수, 파라미터, ThreadLocal 등을 사용합니다."
공통,디자인 패턴,가교 패턴(브릿지 패턴)에 대해서 설명해주세요.,가교 패턴은 추상부와 구현부를 분리하는 디자인 패턴입니다. 해당 패턴에서 기능은 인터페이스를 통해 정의 및 이용되고 해당 인터페이스를 따르는 클래스를 통해 구현됩니다. 해당 패턴을 통해서 사용자는 추상부와 구현부를 독립적으로 수정 및 확장할 수 있습니다. 가교 패턴은 객체지향 설계의 SOLID 원칙 중 단일 책임 원칙(SRP)과 개방 폐쇄 원칙(OCP)에 부합한 패턴입니다.
공통,디자인 패턴,전략 패턴에 대해서 설명해주세요.,전략 패턴은 알고리즘을 객체 단위로 캡슐화하는 디자인 패턴입니다. 해당 패턴에서 알고리즘은 인터페이스를 통해 정의 및 이용되고 해당 인터페이스를 따르는 클래스를 통해 구현됩니다. 해당 패턴을 통해서 사용자는 알고리즘을 필요에 따라 바꿔서 사용할 수 있게 됩니다. 전략 패턴은 객체지향 설계의 SOLID 원칙 중 개방 폐쇄 원칙(OCP)에 부합한 패턴입니다. 전략 패턴은 가교 패턴과 구조가 비슷하지만 목적에 차이가 있습니다. 가교 패턴이 추상과 구현의 분리를 통한 독립적 개발의 용이성에 중점을 둔다면 전략 패턴은 알고리즘의 캡슐화를 통한 알고리즘 변경의 유연성에 중점을 둡니다.
공통,디자인 패턴,퍼사드 패턴에 대한 예를 들어주세요.,"바운디드 컨텍스트로 구분된 각각의 독립적인 애플리케이션을 UI 서버를 통해 파사드 역할을 담당하도록 두고 각 바운디드 컨텍스트에서 UI 서버와 통신하기 위해 HTTP, Protobuf, Thrift와 같은 방식을 이용할 수 있습니다."
BACKEND,인프라/클라우드,Fault-tolerant(무정지) 시스템으로 가기 위해 필요한 방법에 대한 생각을 말해주세요.,"다운 타임이 발생하지 않도록 두 대 이상의 서버를 서비스해야 하고 비용 절감을 위해 배포할 때에만 새롭게 서비스를 띄우고, 배포가 완료된 후에는 기존 서버는 셧다운 시키면 됩니다. 무정지 배포 방법 Rolling 로드 밸런서에서 서버를 빼고, 배포하고 다시 넣는 작업이 각 서버마다 이루어지도록 합니다. Rolling 배포의 단점은 배포할 서버가 너무 많다면, n대 단위로 배포하기도 하는데 배포가 모두 끝나기 전까지 클라이언트 중 누구는 이전 서비스를 제공 받고 누구는 신규 서비스를 제공 받게 되는 문제가 발생합니다. 또한 1대에 배포하는 것보다 최소 2배 이상 느립니다. 무정지 배포 방법 Canary 소수의 유저(혹은 사내)만 사용하는 환경(Canary 환경)에 신규 버전을 배포하고 문제가 없다고 판단됐을 때 다른 모든 서버에 배포합니다. 무정지 배포 방법 Blue/Green 실제로 서비스 중인 환경(Blue)과 새롭게 배포할 환경(Green)을 세트로 준비해서 배포하는 형식입니다. 새롭게 배포할 환경에만 배포하면 되기 때문에 배포 속도가 매우 빠르며, 언제나 Green 환경이 실행 중이기 때문에 만약 잘못된 버전으로 배포 했을 경우 신속하게 롤백이 가능합니다. Blue/Green 배포의 단점은 Green 환경이 항상 실행 중이어야 하기 때문에 비용이 많이 발생합니다."
BACKEND,DevOps,CI/CD가 무엇인가요? 왜 CI/CD가 장점이 될까요?,"보통 이 질문을 하는 동시에 어떤 CI/CD를 써봤는지 질문을 할 것입니다. 그때 썼던 CI/CD툴을 설명하고, 그 툴의 장단점을 설명하면 좋습니다. 코드 버전 관리를 하는 VCS 시스템에 push가 되면 테스트와 빌드가 수행되어 안정적인 배포파일을 만드는 과정을 CI(지속적 통합, continuous integration)이라고 하며, 이 빌드 결과를 자동으로 운영 서버에 배포까지 되는 과정을 CD(지속적 배포, continuous delivery or continuous deployment)라고 합니다. 푸시가 될 때마다 코드를 병합하고, 테스트 코드와 빌드를 수행하면서 자동으로 코드가 통합되어 더는 수동으로 코드를 통합할 필요가 없어져 개발에만 신경을 쓸 수 있습니다. 이 CI / CD의 중요한 것은 테스트 자동화입니다. 프로젝트의 완전한 상태임을 보장하기 위해 테스트 코드가 구현되어 있어야 합니다."
BACKEND,DevOps,DevOps가 무엇인지 설명해주세요.,"DevOps는 애플리케이션과 서비스를 빠른 속도로 제공할 수 있도록 조직의 역량을 향상시키는 문화와 방식이며 자동화, 측정, 공유를 수행하고 이 모든 것들을 축적해나가는 것입니다. DevOps를 수행하면, 기존의 개발 및 인프라 관리 프로세스를 사용하는 조직보다 제품을 더 빠르게 혁신하고 개선할 수 있습니다. 이를 통해서 고객 친화적이고, 시장에 효과적으로 대응할 수 있는 유연성을 얻을 수 있습니다."
BACKEND,네트워크,"gRPC는 무엇이며, RPC는 무엇인가요? 왜 쓸까요?","gRPC는 HTTP/JSON 방식의 비효율성을 개선하기 위해 나온 것입니다. RPC는 원격에 있는 프로시져(함수)를 로컬에 있는 것처럼 호출할 수 있도록 해주는 기술로 학습비용이 있기에 잘 사용되지 않았습니다. 최근의 아키텍쳐 트렌드는 MSA를 기반으로 한 분산시스템으로 구성됩니다. MSA는 결국 각 서비스의 API를 호출하는 식으로 네트워크 통신을 하게 되는데, HTTP/JSON보다는 gRPC/protobuf가 더 빠른 속도를 보이게 됩니다. 그로인해 서비스의 응답속도도 빨라질 수 있게됩니다."
BACKEND,보안,쿠버네티스가 무엇인가요? 왜 쿠버네티스를 쓸까요?,"Kubernetes(k8s)는 컨테이너화된 애플리케이션을 자동으로 배포하고, 스케일링하며, 운영을 관리해주는 오픈소스 플랫폼입니다. 도커로 만들어진 컨테이너를 대규모로 운영하려면 컨테이너 오케스트레이션이 필요한데, 쿠버네티스는 이 과정을 직관적으로 제시해줍니다. 애플리케이션 서비스가 커지고 마이크로서비스(MSA) 아키텍처로 분산화될수록, 다양한 컨테이너들이 끊임없이 생성·소멸되며 서로 통신하게 됩니다. 쿠버네티스는 이러한 복잡한 환경에서 컨테이너들을 자동으로 스케일링, 장애 감지 시 재시작, 서비스 디스커버리와 로드밸런싱을 유연하게 처리해줍니다. k8s를 사용하여 운영 복잡도를 줄이고, 안정적인 분산 시스템의 효율적 운영이 가능합니다."
AI,딥러닝,딥러닝이란 무엇인가?,"딥러닝은 인공 신경망(Artificial Neural Networks, ANN)을 기반으로 한 머신러닝의 한 분야이다. 딥러닝 모델은 여러 층의 뉴런으로 구성되어 있으며, 이를 통해 복잡한 데이터에서 패턴을 학습하고 추출할 수 있다. 대표적인 딥러닝 모델로는 컨볼루션 신경망(CNN), 순환 신경망(RNN), 변환자(Transformer)등이 있다."
AI,딥러닝,딥러닝과 머신러닝의 차이점는 무엇인가?,"머신러닝은 컴퓨터가 데이터를 기반으로 학습하고, 패턴을 인식하여 예측이나 분류를 수행하는 기술이다. 딥러닝은 머신러닝의 한 분야로, 인공 신경망을 사용해 학습을 수행한다. 딥러닝 모델은 데이터에서 복잡한 패턴을 추출할 수 있는 능력을 가지고 있어, 머신러닝 기법보다 높은 성능을 보여주는 경우가 많다. 따라서 딥러닝은 보다 복잡한 문제에 적합하다고 볼 수 있다."
AI,딥러닝,왜 딥러닝이 인공지능에 큰 영향을 미치고 있는가?,"자동 피처 추출 : 딥러닝 모델은 여러 층을 거치면서 데이터에서 자동으로 피처를 추출하고 학습할 수 있다. 이로 인해 사람의 개입이 줄어들고 더 정교한 패턴 인식이 가능해진다. 큰 데이터셋 처리 : 딥러닝은 대용량 데이터셋에서 복잡한 패턴을 학습하는 데 탁월한 성능을 보인다. 이는 인공지능의 발전에 필수적인 요소로 작용한다. 일반화 능력 : 딥러닝 모델은 새로운 데이터에 대한 예측이나 분류에서 높은 성능을 보여준다. 이는 다양한 인공지능 응용 분야에서 중요한 역할을 수행한다. 다양한 응용 분야 : 딥러닝 기술은 이미지 인식, 자연어 처리, 음성 인식, 추천 시스템 등 당야한 인공지능 분야에 적용된다. 이로 인해 인공지능의 연구 및 발전에 큰 기여를 하고 있다. 강력한 하드웨어 지원 : GPU와 같은 고성능 하드웨어의 발전으로 딥러닝 모델의 학습 속도가 크게 향상되다. 이로 인해 더욱 복잡하고 깊은 신경망 구조를 사용할 수 있게 되었고, 인공지능 분야의 발전을 가속화시켰다. 연구 및 기술 발전 : 딥러닝과 관련된 다양한 연구 및 기술이 계속 발전하고 있으며, 이를 통해 더욱 성능이 좋은 모델이 개발되고 있다. 이러한 연구와 기술의 발전은 인공지능 분야의 성장을 이끌고 있다. 딥러닝 기술의 성장과 발전은 인공지능 분야 전반에 큰 영향을 미치고 있다. 따라서 딥러닝은 인공지능의 핵심 기술로 인식되며, 앞으로도 계속해서 연구와 개발이 활발하게 진행될 것으로 예상된다."
AI,딥러닝,주요 딥러닝 알고리즘는 어떤 것들이 있나?,"주요 딥러닝 알고리즘에는 합성곱(CNN), 순환 신경망(RNN), 장단기 메모리(LSTM), 게이트 순환 유닛(GRU), 생성적 적대 신경망(GAN), 오토인코더(Autoencoder)등이 있다."
AI,딥러닝,"합성곱 신경망(CNN)이란 무엇이고, 언제 사용되는가?","CNN은 주로 이미지 인식과 관련된 문제를 해결하기 위한 딥러닝 구조이다. CNN은 합성곱 계층과 풀링 계층을 사용하여 이미지의 지역적 특징을 추출하고, 이를 기반으로 이미지를 분류하거나 다른 작업ㅇ르 수행한다. CNN은 이미지 분류, 객체 탐지, 이미지 생성, 시맨틱 분할 등 다양한 이미지 처리 작업에 활용되는 신경망이다."
AI,딥러닝,"순환 신경망(RNN)이란 무엇이고, 어떤 경우에 사용되는가?","RNN은 시퀀스 데이터를 처리하는 데 적합한 딥러닝 구조이다. RNN은 내부에 순환 구조를 가지고 있어 과거의 정보를 기억하고 이를 기반으로 시퀀스의 다음 값을 예측하거나 분류하는 데 사용된다. RNN은 자연어 처리, 음성 인식, 시계열 데이터 분석 등에 사용되는 신경망이다."
AI,딥러닝,강화학습이란 무엇이며 어떤 문제에 적합한가?,"강화학습은 에이전트가 환경과 상화작용하며 보상을 최대화하는 행동을 학습하는 머신러닝 방법이다. 강화학습은 의사결정, 로봇 제어, 자율주행 자동차, 게임 인공지능 등에 적합한 기법이다. 강화학습은 순차적인 의사결정 문제를 해결하는 데 특히 유용하다."
AI,딥러닝,역전파 알고리즘이란 무엇이며 왜 중요한가?,역전파(Backpropagation)는 신경망에서 사용되는 가중치를 최적화하기 위한 알고리즘이다. 손실 함수를 통해 게산된 오차를 출력층에서 입력층으로 거꾸로 전파하면서 각 가중치의 기울기를 계산하고 업데이트를 한다. 이를 통해 신경망의 학습이 가능해진다. 역전파는 딥러닝의 핵심 알고리즘으로 신경망의 성능 향상에 기여한다.
AI,딥러닝,딥러닝에서 사용되는 활성화 함수의 종류와 특징을 설명하시오.은(는) 무엇인가요?,"활성화 함수는 신경망의 비선형성을 추가하는 역할을 한다. 주요 활성화 함수에는 시그모이드(Sigmoid), 하이퍼볼릭 탄젠트(Tanh), 렐루(ReLU), 리키 렐루(Leaky ReLU), 소프트맥스(Softmax)등이 있다. 각 함수의 특징과 사용 사례에 따라 선택된다. 시그모이드 : 0과 1사이의 값을 출력하며, 이진 분류 문제에 주로 사용된다. 하이퍼볼릭 탄젠트 : -1과 1 사이의 값을 출력하며, 시구모이드보다 더 넓은 출력 범위를 가진다. 은닉층에서 주로 사용되며 시그모이드보다는 그래디언트 소실 문제가 덜 하다. 렐루(ReLU) : 입력이 0보다 클 때 입력 값을 그대로 출력하고, 0보다 작은 때는 0을 출력한다. 비선형성을 추가하면서도 계산이 간단하여 딥러닝에서 널리 사용되는 활성화 함수이다. 그러나 0 이하의 입력에 대한 그래디언트가 0이라는 단점이 있다. 리키 렐루(Leaky ReLU) : ReLU와 유사하지만, 입력이 0보다 작을 때 작은 양의 기울기를 가지게 된다. 이를 통해 ReLU의 0 그래디언트 문제를 완화한다. 소프트맥스(Softmax) : 다중 클래스 분류 문제에 사용되며, 출력 값의 합이 1이 되도록 정규화하여 확률 분포를 얻습니다."
AI,딥러닝,과적합(overfitting)이란 무엇이고 어떻게 피할 수 있나?,"과적합은 학습 데이터에 지나치게 최적화되어 새로운 데이터에 대한 일반화 성능이 떨어지는 현상이다. 과적합을 피하기 위한 방법에는 다음과 같은 것들이 있다. 데이터 증식(Data augmentation) : 데이터를 증시가여 학습 데이터의 다양성을 높인다. 규제화(Regularization) : 가중치에 규제를 적용하여 네트워크의 복잡도를 줄인다. L1 규제와 L2 규제가 대표적이다. 드롭아웃(Dropout) : 학습 과정에서 일부 뉴런을 무작위로 비활성화하여 네트워크의 복잡도를 줄인다. 조기 종료(Early stopping) : 검증 데이터 성능이 더 이상 향상되지 않을 때 학습을 중단한다. 모델의 복잡도 줄이기 : 네트워크의 층 수나 뉴런 수를 줄여 복잡도를 낮춘다. 크로스 밸리데이션(Cross-validation) : 학습 데이터를 여러 부분으로 나누어 일부 검증 데이터로 사용하여 모델의 성능을 평가하고, 이를 기반으로 과적합을 방지한다."
AI,딥러닝,"드롭아웃(dropout)이란 무엇이며, 왜 사용되는가?","드롭아웃은 학습 과정에서 일부 뉴런을 무작위로 비활성화하는 기법이다. 이를 통해 신경망의 과적합을 방지하고 일반화 성능을 향상시키는 데 도움이 된다. 드롭아웃은 각 뉴런이 독립적으로 학습되도록 강제함으로써 네트워크의 복잡도를 줄이고, 다양한 구조를 학습할 수 있게 한다."
AI,딥러닝,"배치 정규화(batch normalization)이란 무엇이며, 어떻게 동작하는가?","배치 정규화는 학습 과정에서 각 층의 입력 분포를 정규화하여 신경망의 학습을 더 빠르게 진행시키는 기법이다. 배치 정규화는 각 층의 입력에 대해 평균과 분산을 계산하고, 이를 이용해 정규화를 수행한다. 이를 통해 기울기 소실 문제를 완화하고, 학습률을 높게 설정할 수 있으며, 일반화 성능도 향상된다."
AI,딥러닝,딥러닝 모델의 손실 함수를 최적화하기 위해 사용되는 최적화 알고리즘는 어떤 것들이 있나?,"딥러닝 모델의 손실 함수를 최적화하기 위한 주요 알고리즘에는 확률적 경사 하강법(SGD), 모멘텀(Momentum), 아다그라드(Adagrad), 알엠에스프롭(RMSprop), 아담(Adam), 아다델타(Adadelta), AdamW등이 있다."
AI,딥러닝,확률적 경사하강법(SGD)과 아담(Adam) 최적화 알고리즘의 차이점는 무엇인가?,"확률적 경사 하강법(SGD)은 손실 함수의 그래디언트를 따라 하강하는 방식으로 가중치를 업데이트하는 방법이다. SGD는 간Ⅳ 구조와 빠른 계산 속도가 장점이지만, 학습률 조절이 어렵고, 특정 상황에서 최적화가 느리게 진행될 수 있다. 아담(Adam)은 모멘컴과 RMSprop의 아이디어를 결합한 최적화 알고리즘으로, 손실 함수의 그래디언트와 그래디언트의 제곱의 지수 가중 평균을 추정하여 가중치를 업데이트 한다. 아담은 학습률을 적응적으로 조정하며, 모멘텀의 관성 효과를 이용해 더 빠르고 안정적으로 최적화를 진행할 수 있다. 따라서 아담은 일반적으로 최적화 성능이 더 뛰어난 알고리즘으로 평가되며, 다양한 딥러닝 문제에 효과적으로 적용된다. AdamW : Adam에 L2 Regularization을 추갛여 보다 더 안정적으로 학습이 가능하게 해준다. AdamW : Adam에 L2 Regularization을 추갛여 보다 더 안정적으로 학습이 가능하게 해준다."
AI,딥러닝,L2 규제와 L2 규제의 차이점는 무엇인가?,"L1 규제와 L2 규제는 신경망 모델의 珝탭藍 방지하기 위해 가중치에 적용되는 규제 기법이다. L1 규제는 가중치의 절댓값에 비례하는 손실을 손실 함수에 추가한다. 이로 인해 가중치의 일부가 0이 되어 희소한 모델을 생성하게 되며, 이를 통해 모델의 복잡도를 줄이고 과적합을 방지한다. L1 규제는 특성 선택(feature selection)의 효과를 가지고 있어, 중요하지 않은 특성의 가중치를 0으로 만들 수 있다. L2 규제는 가중치의 제곱에 비례하는 손실을 손실 함수에 추가한다. 이로 인해 가중치가 너무 커지는 것을 방지하며, 모델의 복잡도를 줄이고 과적합을 방지한다. L2 규제는 모든 가중치에 대해 일정한 감소 효과를 주기 때문에, 가중치가 0이 되기보다는 작은 값으로 수렴하게 된다. L1 규제와 L2 규제는 서로 다른 특징과 효과를 가지고 있으며, 상황에 따라 적절한 규제를 선택하여 사용할 수 있다. 또한 두 규제를 함께 사용하는 엘라스틱넷(Elastic Net) 규제 기법도 존재한다."
AI,딥러닝,"전이학습(transfer learning)이란 무엇이고, 어떤 상황에서 사용되나?","전이학습은 이미 학습된 신경망 모델의 일부를 새로운 문제에 적용하여 빠르게 학습하는 기법이다. 전이 학습은 특히 학습 데이터가 부족한 상황이나, 새로운 문제가 기존 문제와 유사한 특성을 가질 때 효과적이다. 예를 들어, 사전에 학습된 이미지 분류 모델을 사용하여 새로운 카테고리의 이미지 분류 문제를 빠르게 해결할 수 있다."
AI,딥러닝,"데이터 증강(data augmentation)이란 무엇이며, 왜 사용하는가?","데이터 증강은 기존 학습 데이터를 변형하여 새로운 학습 데이터를 생성하는 기법이다. 데이터 증강을 통해 학습 데이터의 다양성을 높여 모델의 일반화 성능을 향상시킬 수 있다. 데이터 증강은 주로 이미지, 오디오 등의 비정형 데이터에 적용되며, 회전, 반전, 조명 변화, 노이즈 추가 등 다양한 변형 방법을 사용할 수 있다."
AI,딥러닝,오토인코더(autoencoder)와 생성적 적대 신경망(GAN)의 차이점는 무엇인가?,"오토인코더는 입력 데이터를 저차원 표현으로 압축하고 다시 복원하는 비지도 학습 모델이다. 데이터 압축, 노이즈 제거, 특성 추출 등의 목적으로 사용된다. 오토인코더는 인코더와 디코더로 구성되며, 인코더는 입력 데이터를 표현 벡터로 압축하고, 디코더는 표현 벡터를 원본 데이터로 복우너한다. 생성적 적대 신경망(GAN)은 실제 데이터와 유사한 가짜 데이터를 생성하는 모델이다. GAN은 생성자와 판별자로 구성되며, 생성자는 가짜 데이터를 생성하고, 판별자는 실제 데이터와 가짜 데이터를 구분한다. 싱성자와 판별자는서로 적대적인 관계로 학습되어 가짜 데이터의 질을 점차 향상시킨다. GAN은 이미지 생성, 스타일 변환, 데이터 생성 등 다양한 분야에 활용된다."
AI,딥러닝,"어텐션 메커니즘(attention mechanism)이란 무엇이며, 어던 문제에 도움이 되나?","어텐션 메커니즘은 입력 데이터의 중요한 부분에 가중치를 부여하여 모델의 성능을 향상시키는 기법이다. 기존의 시퀀스-투-시퀀스 모델에서는 입력 데이터의 정보를 고정된 길이의 벡터로 압축하는데, 이 때 중요한 정보가 손실될 수 있다. 어텐션 메커니즘은 이를 해결하기 위해 각 시간 단계의 정보가 가중치를 부여하여 중요한 정보를 집중적으로 활용할 수 있게 한다. 어텐션 메커니즘은 번역, 텍스트 요약, 질문-답변 등 다양한 자연어 처리 문제에 적용되어 성능 향상을 이루어 냈다."
AI,딥러닝,"시퀀스의투의시퀀스(sequence의to의sequence)모델이란 무엇이고, 어떤 경우에사용되는가?","시퀀스-투-시퀀스 모델은 입력 시퀀스를 다른 도메인의 출력 시퀀스로 변환하는 딥러닝 모델이다. 일반적으로 인코더와 디코더로 구성되며, 인코더는 입력 시퀀스를 고정된 길이의 표현 벡터로 압축하고, 디코더는 표현 벡터를 출력 시퀀스로 변환한다. 시퀀스-투-시퀀스 모델은 기계 번역, 음성 인식, 텍스트 요약, 대화 레 등 다양한 시퀀스 기반 문제에 사용된다."
AI,딥러닝,딥러닝에서의 하이퍼파라미터 최적화 방법는 어떤 것들이 있나?,"딥러닝에서의 하이퍼파라미터 최적화 방법은 다양한다. 대표적으로 그리드 탐색(Grid Search), 랜덤 탐색(Random Search), 베이지안 최적화(Bayesian Optimization), 유전 알고리즘(Genetic Algorithm), 그리고 하이퍼밴드(Hyperband)등이 있다. 이러한 방법들은 각각 다른 탐색 전략을 사용하여 하이퍼파라미터 공간에서 M거의 조합을 찾는다. 최적화 방법 선택은 문제의 복잡성, 연산 지원, 시간 등에 따라 달라질 수 있다."
AI,딥러닝,딥러닝 모델의 성능을 평가하는 지표들는 어떤 것들이 있나?,"딥러닝 모델의 성능 평가 지표는 문제의 종류에 따라 다릅니다. 회귀 문제의 경우, 평균 제곱 오차(Mean Squared Error, MSE), 평균 절대 오차(Mean Absolute Error, MAE) 등이 사용됩니다. 분류 문제에서는 정확도(Accuracy), 정밀도(Precision), 재현율(Recall), F1 스코어(F1 score) 등이 사용되며, 멀티 클래스 문제의 경우, 마이크로(micro) 및 매크로(macro) 평균 등의 평가 방법이 추가로 사용됩니다. 또한, AUC-ROC(Receiver Operating Characteristic curve)와 같은 지표도 사용됩니다."
AI,딥러닝,"정밀도(precision), 재현율(recall), F1 스코어(F1 score)의 차이점는 무엇인가요?","정밀도(Precision): 분류 모델이 양성이라고 예측한 것 중 실제로 양성인 것의 비율입니다. 즉, TP/(TP+FP)로 계산됩니다. 재현율(Recall): 실제 양성 중 모델이 양성이라고 예측한 것의 비율입니다. 즉, TP/(TP+FN)로 계산됩니다. F1 스코어(F1 score): 정밀도와 재현율의 조화 평균입니다. 불균형한 데이터셋에서 모델의 성능을 평가할 때 효과적인 지표입니다. F1 스코어는 2 (Precision Recall)/(Precision+Recall)로 계산됩니다."
AI,딥러닝,딥러닝 모델의 학습 속도를 향상시키기 위한 전략들는 무엇인가?,"미니 배치 경사 하강법(Mini-batch Gradient Descent) 사용 : 전체 데이터셋이 아닌 작은 미니 배치를 사용해 학습 속도를 높인다. GRU 활용 : 딥러닝 모델의 학습에 GPU를 사용하면 행렬 연산이 병렬로 처리되어 속도가 크게 향상된다. 초기 가중치 선택 : 가중치 초기화를 적절하게 선택하면 학습 속도와 수렴 성능이 향상된다. 예를 들어 He 초기화, Xavier 초기화 등이 있다. 학습률 스케줄링(Learning Rate Scheduling) : 학습률을 동적으로 조절하여 학습 속도를 높이고, 수렴 성능을 향상시킨다. 에를 들어, 지수 기반 스케줄링, 스텝 기반 스케줄링 등이 있다. 최적화 알고리즘 선택 : 딥러닝 모델에 적합한 최적화 알고리즘을 선택하여 학습 속도를 높인다. 예를 들어 Adam, RMSprop, Adagrad 등이 있다"
AI,딥러닝,"딥러닝 모델의 크기가 클 때, 어떤 어려움이 발생하며 이를 해결하는 방법는 무엇인가?","메모리 부족 : 모델의 크기가 커질수록 GPU 메모리가 부족할 수 있다. 이 문제를 해결하기 위해 모델 크기를 줄이거나, 미니 배치 크기를 줄이는 방법이 있다. 과적합 : 모델의 크기가 크면 학습 데이터에 과적합될 가능성이 높아진다. 이를 해결하기 위해 정규화 기법, 드롭아웃, 데이터 증강 등을 사용할 수 있다. 학습 속도 저하 : 모델이 크면 학습 시간이 길어질 수 있다. 이를 해결하기 위해 학습률 스케ㅈ줄링, 최적화 알고리즘 선택, GPU 사용 등의 전략을 적용할 수 있다. 매개변수 갱신 어려움 : 매개변수가 많으면 기울기 소실(Gradient Vanishing)이나 폭주(Exploding) 문제가 발생할 수 있다. 이 문제를 해결하기 위해 다음과 같은 방법을 사용할 수 있다. 배치 정규화(Batch Normalization) : 각 층의 출력을 정규화하여 기울기 소실이나 폭주 문제를 완화한다. 층 정규화(Layer Normalization) : 배치 정규화와 비슷한 역할을 하지만, 샘플 간의 독립성을 유지한다. 시퀀스 데이터에 적합하다. 잔차 연결(Residual Connection) : 모델에 스킵 연력(Skip Connection)을 추가하여 기울기 소실 문제를 완화합니다. 그래디언트 클리핑(Gradient Clipping) : 매개변수의 기울기를 일정 범위로 제한하여 폭주 문제를 해결한다. 적절한 활성화 함수 선택 : ReLU, Leaky, ReLU, ELU 등의 활성화 함수를 사용하여 기울기 소실 문제를 완화한다. 또한 모델 크기를 줄이는 방법으로는 가중치 공유(Weight Sharing), 모델 압축(Model Compression), 주목나한 특성을 학습 하는 층의 사용 등이 있다. 이렇게 하여 메모리 사용량을 줄이고, 학습 속도를 향상시키며, 과적합을 방지할 수 있다."
AI,딥러닝,딥러닝에서 사용되는 가중치 초기화 방법들에 대해서 설명하시요.은(는) 무엇인가요?,"제로 초기화(Zero Initialization) : 모든 가중치를 0으로 초기화한다. 이 방법은 모든 뉴런이 같은 출력을 생성하므로, 비추천한다. 무작위 초기화(Random Initialization) : 가중치를 작은 무작위 값으로 초기화 한다. 이 방법은 대칭을 깨고, 학습을 시작할 수 있도록 한다. Xavier 초기화(Glorot Initialization) : 가중치를 입력과 출력 뉴런 수에 따라 조정되는 값으로 초기화한다. 이 방법은 활성화 함수가 선형인 경우에 적합하다. He 초기화(He Initialization) : 가중치를 입력 뉴런 수에 따라 조정되는 값으로 초기화한다. 이 방법은 ReLU 계열의 활성화 함수에 적합하다."
AI,딥러닝,딥러닝 모델의 일반화를 향상시키기 위한 전략들는 무엇인가?,"데이터 증강(Data Augmentation) : 데이터셋의 다양성을 높여 일반화 성능을 향상시킨다. 정규화(Regularization) : L1, L2, Elastic Net 등의 정규화 기법을 사용하여 가중치르 제한하하고 과적합을 방지한다. 드롭아웃(Dropout) : 뉴런의 일부를 무작위로 비활성화하여 과적합을 방지한다. 배치 정규화(Batch Normalization) : 각 층의 출력을 정규화하여 학습 속도를 높이고 과적합을 방지한다. 조기 종류(Early Stopping) : 검증 세트의 성능이 향상되지 않으면 학습을 조기에 종료하여 과적합을 방지한다."
AI,딥러닝,"딥러닝 프레임워크 중 어떤 것들을 경험해 보았으며, 각각의 장단점는 무엇인가?","TensorFlow: 구글이 개발한 딥러닝 프레임워크로, 다양한 기능과 커뮤니티 지원이 장점입니다. 그러나 초보자에게는 사용하기 어려울 수 있습니다. Keras: TensorFlow를 기반으로 하는 고수준 API로, 사용하기 쉽고 직관적인 구조가 장점입니다. 그러나 낮은 수준의 커스터마이징이 어려울 수 있습니다. PyTorch: 페이스북이 개발한 딥러닝 프레임워크로, 동적 계산 그래프와 쉬운 디버깅이 장점입니다. 그러나 TensorFlow보다 지원하는 기능이 상대적으로 적을 수 있습니다. JAX : 구글 연구팀이 개발한 고성능 머신러닝 프레임워크로, 파이썬과 NumPy를 기반으로 하면서 자동 미분, XLA 컴파일러를 통한 GPU/TPU 가속화를 지원하여 딥러닝 및 수치 연산 작업을 빠르게 수행할 수 있다."
AI,딥러닝,모델의 설명 가능성(XAI)이 왜 중요한가? 이를 향상시키기 위한 기법들는 어떤 것들이 있는가?,"설명 간으성이 중요한 이유는 모델의 예측을 이해하고 신뢰할 수 있어야 하며, 잘못된 추론을 수정하거나 개선할 수있어야 한다. 또한, 법적 요구사항이나 윤리적 책임을 충족하기 위해서도 중요하다. 설명 간으성 향상 기법으로는 LIME(Local Interpretable Model-agnostic Explanations), SHAP(Shapley Additive Explanations), 특성 중요도(Feature Importance), 부분 의존성 플롯(Partial Dependence Plots) 등의 기법이 있다."
AI,딥러닝,최근 딥러닝 연구에서 가장 흥미로운 발전이라고 생각하는 것는 무엇이며 이유는 무엇인가?,"최근 딥러닝 연구에서 가장 흥미로운 발전은 Transformer 구조와 관련된 발전입니다. 이유는 다음과 같습니다: 자연어 처리 분야의 혁신: Transformer 구조는 어텐션 메커니즘을 기반으로 하여, RNN과 CNN 기반의 모델보다 더 높은 성능을 보여주며, 자연어 처리(NLP) 분야의 혁신을 이끌었습니다. BERT, GPT, RoBERTa 등의 모델은 다양한 NLP 작업에서 뛰어난 성능을 보여주고 있으며, 이들은 모두 Transformer 구조를 기반으로 합니다. 모델 확장성 및 크기: Transformer 기반 모델은 확장성이 높으며, 매개변수의 수가 증가함에 따라 성능이 계속 향상됩니다. 이러한 특징 덕분에 OpenAI의 GPT-3와 같이 굉장히 큰 모델이 등장하였고, 이를 통해 더욱 다양한 작업과 도메인에서 높은 성능을 보여주고 있습니다. 도메인 통합 및 전이 학습: Transformer 구조는 자연어 처리뿐만 아니라 이미지 처리, 음성 처리 등 다양한 도메인에 적용될 수 있습니다. 이를 통해 딥러닝 모델의 범용성이 향상되었으며, 전이 학습을 활용하여 한 도메인에서의 지식을 다른 도메인으로 전이하는 것이 가능해졌습니다. 모델의 해석 가능성: Transformer 기반 모델은 어텐션 메커니즘을 사용하여 입력 데이터 사이의 상호 작용을 명확하게 표현할 수 있습니다. 이를 통해 모델의 예측 과정을 시각화하고, 모델의 해석 가능성을 높일 수 있습니다. 자연어 처리 분야의 혁신: Transformer 구조는 어텐션 메커니즘을 기반으로 하여, RNN과 CNN 기반의 모델보다 더 높은 성능을 보여주며, 자연어 처리(NLP) 분야의 혁신을 이끌었습니다. BERT, GPT, RoBERTa 등의 모델은 다양한 NLP 작업에서 뛰어난 성능을 보여주고 있으며, 이들은 모두 Transformer 구조를 기반으로 합니다. 모델 확장성 및 크기: Transformer 기반 모델은 확장성이 높으며, 매개변수의 수가 증가함에 따라 성능이 계속 향상됩니다. 이러한 특징 덕분에 OpenAI의 GPT-3와 같이 굉장히 큰 모델이 등장하였고, 이를 통해 더욱 다양한 작업과 도메인에서 높은 성능을 보여주고 있습니다. 도메인 통합 및 전이 학습: Transformer 구조는 자연어 처리뿐만 아니라 이미지 처리, 음성 처리 등 다양한 도메인에 적용될 수 있습니다. 이를 통해 딥러닝 모델의 범용성이 향상되었으며, 전이 학습을 활용하여 한 도메인에서의 지식을 다른 도메인으로 전이하는 것이 가능해졌습니다. 모델의 해석 가능성: Transformer 기반 모델은 어텐션 메커니즘을 사용하여 입력 데이터 사이의 상호 작용을 명확하게 표현할 수 있습니다. 이를 통해 모델의 예측 과정을 시각화하고, 모델의 해석 가능성을 높일 수 있습니다. 이러한 이유로 인해 Transformer 구조와 관련된 발전이 최근 딥러닝 연구에서 가장 흥미로운 발전이라고 생각합니다. 이를 통해 딥러닝 모델이 더 높은 성능을 달성하고, 다양한 도메인에서 활용되며, 더욱 해석 가능한 방식으로 결과를 제공할 수 있게 되었습니다."
AI,머신러닝,머신러닝이란 무엇인가?,"머신러닝은 인공지능의 한 분야로, 컴퓨터가 데이터를 통해 스스로 학습하고 예측 및 결정을 내리는 알고리즘과 기술들을 연구하는 분야이다. 머신러닝 모델은 데이터로부터 패턴을 학습하며, 새로운 데이터에 대한 예측이나 분류를 수행할 수 있다. 이를 통해 수동적인 프로그래밍 대신 데이터를 기반으로 한 예측 및 의사결정을 할 수 있다."
AI,머신러닝,머신러닝과 딥러닝의 차이점는 무엇안가?,"머신러닝은 컴퓨터가 데이터를 통해 학습하는 알고리즘과 기술들을 포함하는 분야이다. 딥러닝은 머신런이의 한 부분으로, 인공싱경만(Artificial Neural Networks)을 기반으로 한 방법론입니다. 딥러닝은 복잡한 문제를 해결하기 위해 다양한 계층(layer)으로 구성된 신경망을 사용하여 데이터의 추상적인 표현을 학습한다. 딥러닝은 특히 대용량 데이터를 처리하할 때 높은 성능을 보이며, 이미지 인식, 자연어 처리 등의 복잡한 문제를 해결하는 데 사용되고 있다."
AI,머신러닝,머신러닝 알고리즘의 주요 종류는 무엇인가?,"머신러닝 알고리즘은 크게 지도학습(Supervised Learning), 비지도학습(Unsupervised Learning), 준지도학습(Semi-supervised Learning), 강화학습(Reinforcement Learning)으로 나눌 수 있다. 대표적인 알고리즘으로는 선형 회귀(Linear Regression), 로지스틱회귀(Logistic Regression), 서포트 벡터 머신(SVM), 의사결정 트리(Decision Tree), 랜덤 포레스트(Random Forest), k-최근접 이웃(K-NN), 신경망(Neural Networks)등이 있다. Self-supervised Learning : Self-supervised Learning :"
AI,머신러닝,지도학습이란 무엇이며 언제 사용되는가?,"지도학습은 레이블이 있는 데이터를 사용하여 모델을 학습하는 방법이다. 지도학습 알고리즘은 입력 데이터와 해당 데이터의 정답(레이블)을 이용해 학습하며, 새로운 데이터에 대한 예측이나 분류를 수행할 수 있다. 지도학습은 주로 분류(Classification)와 회귀(Regression)문제를 해결하는 데 사용된다. 분류 문제는 데이터를 미리 정의된 클래스로 분류하는 것으로, 이진 분류(Binary Classification)와 다중 클래스 분류(Multiclass Classification)로 나눌 수 있다. 회귀 문제는 데이터를 통해 연속적인 값을 예측하는 것으로, 주택 가격 예측이나 주식 가격 예측 등과 같은 문제를 해결할 때 사용된다."
AI,머신러닝,"비지도학습이란 무엇이며, 언제 사용되는가?","비지도 학습은 레이블이 없는 데이터를 사용하여 모델을 학습하는 방법이다. 비지도학습 알고리즘은 레이블이 없는 데이터에서 패턴, 구조, 상관곤계 등을 찾아내는 데 사용됩니다. 비지도학습은 주로 군집화(Clustering)와 차원 축소(Dimensionality Reduction)문제를 해결하는 데 사용된다. 군집화는 유사한 특성을 갖는 데이터를 그룹으로 묶는 것이며, 차우너 축소는 데이터의 차원을 줄이면서 중요한 정보를 유지하는 것이다. 이러한 비지도 학습 기법은 데이터 시각화, 데이터 전처리, 특성 추출 등에 활용된다."
AI,머신러닝,준지도학습이란 무엇이며 왜 사용되는가?,"준지도 학습은 레이블이 있는 데이터와 레이블이 없는 데이터가 혼합된 경우에 사용되는 학습 방법이다. 일반적으로 레이블이 있는 데이터는 수가 적고, 레이블이 없는 데이터는 많은 경우가 많다. 준지도 학습은 레이블이 없는 데이터의 패턴을 이용하여 레이블이 있는 데이터로 학습된 모델의 성능을 향상 시키는 데 사용된다. 이 방법은 레이블링 비용이 높거나 데이터 수집이 어려운 경우에 유용하다."
AI,머신러닝,"강화학습이란 무엇이며, 어떻게 작동하는가?","강화학습은 에이전트(agent)가 환경(environment)과 상호작용하며, 보상(reward)을 최대화하는 행동(action)을 학습하는 머신러닝의 한 방법이다. 에이전트는 상태(state)를 관찰하고 행동을 취한 후, 그 결과로 보상을 받는다. 보상은 긍정적이거나 부정적일 수 있으며, 에이전트는 누적 보상을 최대화하는 행동을 학습하려고 한다. 강화학습은 게임, 로봇 제어, 자율 주행 차량 등 다양한 분야에서 적용되고 있다."
AI,머신러닝,분류와 회귀의 차이점는 무엇인가?,"분류는 데이터를 미리 정의된 클래스로 나누는 문제이다. 이진 분류는 두 개의 클래스로 나누는 문제이며, 다중 클래스 분류는 세 개 이상의 클래스로 나누는 문제이다. 반면 회귀는 연속적인 값을 예측하는 문제이다. 회귀 문제의 예로는 주택 가격 예측, 주식 가격 예측 등이 있다. 분류와 회귀의 주요 차이점은 출력 변수의 형태이다. 분류에서 범주형 변수를 예측하고, 회귀에서는 연속형 변수를 예측한다."
AI,머신러닝,"k의최근접 이유(k의NN) 알고리즘는 무엇이며, 어떻게 작동하는가?","k-최근접 이유 알고리즘은 분류 및 회귀 문제를 해결하는 데 사용되는 지도학습 방법이다. k-NN 알고리즘은 새로운 데이터 포인트에 대한 예측을 수행하기 위해 주변의 k개의 가장 가까운 이웃 데이터 포인트를 참조한다. 이웃들의 클래스 또는 값을 분석하여 새 데이터 포인트의 클래스 또는 값을 예측한다. 분류에서는 가장 많은 이웃을 가진 클래스를 선택하고, 회귀에서는 이웃 값의 평균을 계산한다. k-NN은 새롱누 데이터에 대한 예측이 이웃 데이터 포인트와 유사할 것이라는 가정이 기반한다."
AI,머신러닝,"서포트 벡트 머신(SVM)이란 무엇이며, 언제 사용되는가?","서포트 벡터 머신은 지도 학습 알고리즘으로, 주로 분류 및 회귀 문제에 사용된다. SVM의 핵심 아이디어는 클래스 간의 마진을 최대화하는 초평면(hyperplane)을 찾는 것이다. 마진은 초평면과 가장 가깡누 데이터 포인트(서포트 벡트) 사이의 거리로 정의된다. 이렇게 하면 새로운 데이터에 대한 일반화 성능이 향상된다. 비선형 문제에 대해서는 커널 트릭(kernel tirck)을 사용하여 고차우너 공간으로 변환한 후 초평면을 찾는다. SVM은 이미지 인식, 텍스트 분류, 생물정보학 등 다양한 분야에서 좋은 성능을 보여주며, 작은 데이터셋에서도 효과적이다."
AI,머신러닝,"의사결정 트리(Decision Tree)알고리즘이란 무엇이며, 어떻게 작동하는가?","의사결정 트리는 분류 및 회귀 문제에 사용되는 지도학습 알고리즘이다. 데이터를 분석하여 일련의 질문과 결정을 통해 결과를 도출하는 트리 구조를만든다. 각 노드는 특정 속성에 기L나 질문이며, 각 분기는 해당 질문에 대 의사결정을 나타낸다. 잎 노드는 최종 에측 클래스 또는 값을 나타낸다. 의사결정 트리는 의사결정 과정을 이해하기 쉽고 해석하기 쉬운 시각적 표현을 제공한다. 작동 원리는 재귀적 분할을 통해 데이터를 순수한 하위 집합으로 나누는 것이다. 이 분할은 엔트로피, 지니 불순도 등의 기준에 따라 결정된다."
AI,머신러닝,랜덤 포레스트(Random Forest)와 그래디언 부스팅(Gradient Boosting)의 차이점는 무엇인가?,"랜덤 포레스트와 그래디언 부스팅은 모두 앙상블 기법을 사용하는 머신러닝 알고리즘이다. 랜덤 포레스트는 여러 개의 의사결정 트리를 만드록, 각 트리의 예측 결과를 집계하여 최종 결과를 얻는다. 이 트리들은 독립적으로 생성되며, 부스트트랩 샘플링과 특성 무작위를 선택을 사용하여 다양성을 부여한다. 그래디언트 부스팅은 순차적으로 개선된 여러 의사결정 트리를 만들어 학습한다. 각 트리는 이전 트리의 오차를 줄이는 방향으로 학습되며, 경사하강법을 사용하여 손실 함수를 최소화한다. 그래디언트 부스팅은 일반적으로 더 나은 성능을 제공하지만, 랜덤 포레스트보다 학습 시간이 오래 걸린다."
AI,머신러닝,군집화 알고리즘의 종류와 특징을 설명하시오.은(는) 무엇인가요?,"군집화는 비지도학습 기법으로, 데이터를 유사한 그룹으로 분류하는 과정이다. 주요 군집화 알고리즘은 다음과 가n. K-평균(K-means) 군집화 : K-means는 주어진 데이터를 K개의 클러스터로 묶는 알고리즘이다. 초기 중심점을 무작위로 선택한 후, 각 데이터 포인트를 가장 가까운 중심점에 할당하고, 중심점을 그룹 내 데이터 포인트들의 평균으로 업데이트한다. 이 과정을 중심점이 수렴할 때까지 반복을 한다. K-means는 속도가 빠르고 구현이 쉽지만, K값을 미리 정해야 하고 초기 중심점 선택에 민감하다. 계층적 군집화 : 계층적 군집화는 데이터 포인트를 계층 구조의 클러스터로 구성한다. 점진적으로 병합하거나 분할하는 방법에 따라 두 가지 유형으로 나뉜다. 병합 계층 군집화는 모든 데이터 포인트를 개별 클러스터로 시작하여 가장 유사한 클러스터를 병합하는 과정을 반복한다. 분할 계층 군집화는 전체 데이터 세트를 하나의 클러스터로 시작하여 클러스터를 재귀적으로 분할하는 방식이다. DBSCAN(Density-Based Spatial Clustering of Applications with Noise) : DBSCAN은 밀도 기반 군집화 알고리즘으로, 데이터 포인트의 밀도를 기반으로 클러스터를 형성하며, 동시에 노이즈 포인트를 구분한다. 이 알고리즘은 특정 밀도를 가진 영역에서 포인트를 찾아 클러스터를 확장하고, 밀도가 낮은 영역을 노이즈로 처리한다. DBSCAN은 클러스터의 개수를 미리 지정할 필요가 없으며, 임의의 모양의 클러스터를 찾을 수 있다."
AI,머신러닝,"주성분 분석(PCA)이란 무엇이며, 왜 사용되는가?","주성분 분석(PCA)은 차원 축소 기법 중 하나로, 고차우너 데이터에서 주요한 변동성을 설명하는 새로운 축을 찾아 데이터를 낮은 차원으로 투영한다. 이 과정은 공분산 행렬의 고유벡터와 고유값 분석을 통해 이루어진다. PCA는 다음과 같은 목적으로 사용된다. 데이터 시각화, 노이즈 제거, 계산 효율성 향상, 특성 간 상관성 제거 등"
AI,머신러닝,"교차 검증(cross에서 validation)이란 무엇이며, 어떻게 사용되는가?","교차 검증은 머신러닝 모델의 성능을 평가하고 일반화 능력을 측정하는 방법이다. 데이터 세트를 여러 개의 하위 집합으로 나누고, 이를 통해 모델을 반복적으로 훈련 및 검증하는 과정을 거칩니다. 이 과정에서 사용되는 대표적인 교차 검증 방법은 K-겹 교차 검증이다. 데이터를 K개의 동일한 크기의 부분으로 집합으로 나눈 후, k-1개의 부분 집합으로 모델을 훈련하고 나머지 하나의 부분 집합으로 모델을 검증한다. 이 과정을 K번 반복하며, 각 반복마다 다른 부분 집합을 검증 데이터로 사용한다. 최정적으로 K개의 결과를 평균내어 모델의 성능을 평가한다. 교차 검증을 사용하면 모델이 훈련 데이터에 과적합되는 것을 방지하고, 모델의 일반화 능력을 높일 수 있다."
AI,머신러닝,"정규화(regularization)란 무엇이며, 왜 필요한다?","정규화는 머신러닝 모델의 복잡성을 줄이고 과적합을 방지하기 위한 기법이다. 이는 모델의 가중치에 일정한 제약을 부과하여, 가중치가 너무 커지지 않도록 한다. 정규화를 사용하면 모델이 훈련 데이터에 너무 적합하지 않아 일반화 능력이 향상된다. 대표적인 정규화 방법으로는 L1 규제와 L2 규제가 있다."
AI,머신러닝,과적합(overfiting)과 과소적합(underfition)의 차이점는 무엇인가?,"과적합은 모델이 훈련 데이터에 지나치게 적합하여, 새로운 데이터에 대한 일반화 성능이 저하되는 현상입니다. 이는 모델이 훈련 데이터의 노이즈까지 학습하여 발생합니다. 반면 과소적합은 모델이 훈련 데이터를 충분히 학습하지 못해, 훈련 데이터와 새로운 데이터 모두에 대한 성능이 저하되는 현상이다. 이는 모델의 복잡성이 너무 낮거나 학습이 제대로 이루어지지 않을 때 발생한다."
AI,머신러닝,"정확도(accuracy), 정밀도(precision), 재현율(reclaa)의 차이점는 무엇인가?",정확도(accuracy)는 전체 예측 중 올바른 예측의 비율 (TP+TN)/(TP+TN+FP+FN) 정밀도(precision)는 양성으로 예측한 것 중 실제로 양성인 비율 TP/(TP+FP) 재현율(recall)은 실제 양성 중 양성으로 예측한 비율 TP/(TP+FN)
AI,머신러닝,ROC 곡선과 AUC의 개념을 설명하시오.은(는) 무엇인가요?,"ROC(Receiver Operating Characteristic) 곡선은 이진 분류 문제에서 모델으 성능을 평가하는 데 사용되는 그래프이다. ROC 곡선은 False Positive Rate(FPR)을 x 축으로, True Positive Rate(TPR, 재현율)을 y축으로 놓고, 다양한 분류 임계에 대해 그린 곡선이다. 이 곡선은 모델의 성능이 얼마나 민감한지를 보여준다. -AUC(Area Under the Curve)는 ROC 곡선 아래의 면적을 나타내며, 모델의 성능을 하나의 숫자로 표현하는 데 사용된다. AUC 값이 1에 가까울수록 모델의 성능이 좋다고 평가할 수 있으며, 0.5는 무작위 예측과 동일한 성능을 의미한다."
AI,머신러닝,하이퍼파라미터 최적화 방법들에 대해 설명하시오.은(는) 무엇인가요?,"하이퍼파라미터 최적화는 머신러닝 모델의 성능을 향상시키기 위해 모델의 하이퍼파라미터를 조정하는 과정이다. 주요 하이퍼파라미터 최적화 방법에는 다음과 같은 것들이 있다. 그리드 탐색(Grid Search) : 가능한 모든 하이퍼파라미터 조합을 탐색하여 최적의 조합을 찾는 방법이다. 계산 비용이 높을 수 있지만, 완전한 탐색을 수행한다. 랜덤 탐색(Random Search) : 하이퍼파라미터 공간에서 무작위로 조합을 선택하여 찾는 방법이다. 계산 비용이 낮고, 일정 시간 내에 근사적인 해를 찾을 수 있다. 베이지안 최적화(Bayesian Optimization) : 과거의 하이퍼파라미터 조합에 대한 결과를 활용하여 새로운 조합을 선택하는 확률 모델을 구축하는 방법이다. 보다 효율적인 탐색을 수행할 수 있다."
AI,머신러닝,그리드 탐색(Grid Search)과 랜덤 탐색(Random Search)의 차이점는 무엇인가?,"그리드 탐색은 하이퍼파라미터 공간을 균일하게 탐색하여 최적의 하이퍼파라미터 조합을 찾는 방법이다. 이 방법은 모든 가능한 조합을 시도하므로 계산 비용이 높을 수 있지만, 완전한 탐색을 수행한다. 그리드 탐색은 하이퍼파라미터의 가능한 값들을 미리 정의하고, 이들의 조합을 시스템적으로 탐색하며, 교차 검증을 사용하여 모델의 성능을 평가한다. 반면 랜덤 탐색은 하이퍼파라미터 공간에서 무작위로 조합을 선택하여 최적의 조합을 v는 방법이다. 계산 비용이 낮고, 일정 시간 내에 근사적인 해를 찾을 수 있다. 랜덤 탐색은 하이퍼파라미터의 값들을 무작위로 샘플링하며, 그리드 탐색보다 더 넓은 하이퍼파라미터 공간을 탐색할 수 있다. 또한, 일부 하이퍼파라미터의 영향이 크지 않을 때, 랜덤 탐색이 효율적ㅇ니 해를 더 빠르게 찾을 수 있다."
AI,머신러닝,특성 선택(feature selection)의 목적과 방법들에 대해서 설명해주세요.은(는) 무엇인가요?,"특성 선택은 머신러닝 모델의 성능을 향상시키기 위해 중요한 특성만 선택하고, 불필요한 특성을 제거하는 과정이다. 특성 선택의 주요 목적은 다음과 같다. 차원의 저주(curse of dimensionality) 해결 : 고차원 데이터에서 모델 학습이 어려운 문제를 완화한다. 과적합(overfitting) 방지 : 불필요한 특성을 제거함으로써 모델의 복잡도를 줄이고 일반화 성능을 향상시킨다. 계산 비용 감소 : 학습 시간과 추론 시간을 줄인다. 해석력 향상 : 모델의 결과를 이해하기 쉽게 만든다. 특성 선택 방법에는 다음과 같은 것들이 있다. 필터 방식(filter methods) : 특성 간의 상관성, 카이제곱 검정, 정보 이득 등 통계적 기준을 사용하여 특성을 선택한다. 래퍼 방식(wrapper methods) : 모델의 성능을 기준으로 하여 특성을 선택한다. 순차적 특성 선택(sequential feature selection), 재귀적 특성 제거(recursive feature elimination) 등이 있다. 임베디드 방식(embedded methods) : 학습 알고리즘 자체가 특성 선택을 수행한다. Lasso 회귀, 의사결정 트리(decision trees), 랜덤 포레스트(random forests) 등이 있다."
AI,머신러닝,차원 축소(dimensionality reduction)의 목적과 기법들에 대해 설명하시오.은(는) 무엇인가요?,"차원 축소는 고차원 데이터를 저차원 공간으로 변환하는 과정이다. 차원 축소의 주요 목적은 다음과 같다. 데이터 시각화 : 고차원 데이터를 2D 또는 3D 공간에 표현하여 패턴을 쉽게 파악할 수 있다. 차원의 저주 해결 : 차원이 낮아지면서 학습이 더 쉬워지고 모델의 성능이 향상된다 계산 비용 감소 : 데이터 크기가 줄어들어 학습 시간과 추론 시간이 줄어든다. 차원 축소 기법에는 다음과 같은 것들이 있다 주성분 분석(PCA, Principal Component Analysis) : 데이터의 분산을 최대한 보존하는 새로운 축을 찾아 변환 t-SNE(t-Distributed Stochastic Neighbor Embedding) : 원래 공간에서 데이터 포인트 간의 거리를 확률 분포로 나타내고, 저차원 공간에서도 유사한 확률 분포를 갖도록 데이터를 매핑한다. 이 방법은 주로 데이터 시각화에 사용된다. 선형 판별 분석(LDA, Linear Discriminant Analysis) : 클래스 간의 분산을 최대화하고, 클래스 내 분산을 최소화 하는 축을 찾아 데이터를 변환한다. LDA는 지도학습 방식의 차원 축소 기법으로 분류 문제에 주로 사용된다."
AI,머신러닝,"머신러닝 프로젝트를 진행할 때, 데이터 전처리 과정에서 이루어지는 작업들는 무엇이 있는가?","데이터 전처리는 머신러닝 프로젝트에서 매우 중요한 단계로, 모델 성능에 큰 영향을 미친다. 전처리 과정에서 이루어지는 주요 작업들은 다음과 같다. 결측치 처리 : 데이터에 결측치가 있을 경우, 해당 값을 대치하거나 해당 샘플이나 특성을 제거햐야 한다. 이상치 처리 : 이상치는 데이터의 분포를 왜곡할 수 있으므로, 이를 탐지하고 적절하게 처리해야한다. 데이터 인코딩 : 범주형 데이터를 머신러닝 알고리즘이 처리할 수 있는 형태로 변환해야 한다. 원-핫 인코딩이나 레이블 인코딩 등의 방법이 사용된다. 데이터 스케일링 : 다양한 범위의 특성 값을 동일한 범위로 조정하는 것으로, 정규화와 표준화가 대표적인 방법이다. 특성 생성 : 기존의 특성들을 이용해 새로운 특성을 생성할 수 있다. 이를 통해 모델 성능을 개선할 수 있다. 특성 선택 : 중요한 특성만을 선택하여 차원을 축소하고 모델의 복잡도를 줄일 수 있다."
AI,머신러닝,"데이터 분균형이란 무엇이며, 이를 해결하기 위한 방법들을 설명하시오.은(는) 무엇인가요?","데이터 불균형은 머신러닝에서 클래스 레이블의 분포가 고르지 않은 상황을 의미한다. 이러한 불균형은 모델이 소수 클래스에 대해 제대로 학습하지 못하게 만들어 성능 저하를 초래할 수 있다. 데이터 불균형을 해결하기 위한 주요 방법들은 다음과 같다. 오버샘플링(Over-sampling) : 소수 클래스의 샘플을 복제하여 데이터 불균형을 해결하는 방법이다. SMOTE(Synthetic Minority Over-sampling Technique)와 같은 방법을 사용할 수 있다. 언더샘플링(Under-sampling) : 다수 클래스의 샘플을 제거하여 데이터 불균형을 해결하는 방법이다. Tomek Links나 Neighbourhood Cleaning Rule 등의 방법이 있다. 비용 민감 모델(Cost-sensitive learning) : 소수 클래스에 대한 예측 오류에 더 높은 비용을 할당함으로써, 모델이 소수 클래스에 더 많은 주의를 기울이도록 하는 방법이다. 이를 통해 모델이 소수 클래스에 대해 더 잘 학습할 수 있게 된다. 앙상블 기법(Ensemble methods) : 여러 개의 기본 모델을 결합하여 불균형 데이터에 대한 예측 성능을 향상시키는 방법이다. 예를 들어, 랜덤 포레스트나 그래디언트 부스팅과 같은 앙상블 모델은 데이터 불균형 문제를 완화하는 데 도움이 될 수 있다. 임계값 조정(Threshold adjustment) : 모델의 예측 확률 임계값을 조정하여 소수 클래스에 대한 예측을 개선하는 방법이다. 기본적으로 0.5설정된 임계값을 조정하여 소수 클래스에 엿 예측률을 높일 수 있다. 데이터 불균형 문제를 해결하기 위한 최적의 방법은 문제 도메인, 데이터의 특성 및 모델의 종류에 따라 다를 수 있다. 따라서, 여러 가지 방법을 시도해 보고 실험을 통해 가장 효과적인 방법을 선택하는 것이 좋다."
AI,머신러닝,"다중 공선성(multicollinearity)이란 무엇이며, 왜 문제가 되는지 설명하시오. 이를 해결하는 방법는 무엇인가?","다중 공선성은 머신러닝에서 독립 변수들 간에 강한 상관관계가 존재하는 상황을 의미한다. 다중 공선성이 발생하면 다음과 같은 문제가 발생할 수 있다. 모델의 해설력이 떨어짐 : 변수 간의 강한 상관관계 때문에 각 변수의 독립적인 영향력을 알기 어려워 진다. 모델의 불안정성 : 변수 간의 상관고나계가 크면, 작은 데이터 변화에도 모델 계수가 크게 변할 수 있다. 다중 공선성을 해결하기 위한 주요 방법들은 다음과 같다. 변수 제거 : 상관관계가 높은 변수 중 하나를 제거하여 다중 공선성 문제를 해결할 수 있다. 이때 도메인 지식을 활용하여 중요하지 않은 변수를 선택하는 것이 좋다. 변수 결합 : 상관관계가 높은 변수들을 결합하여 새로운 변수를 생성할 수 있다. 예를 들어, 가격과 면적이 상관관계가 높다면, 가격/면적 변수를 생성할 수 있다. 차원 축소 : 주성분 분석(PCA)과 같은 차우너 축소 기법을 사용하여 다중 공선성 문제를 완화할 수 있다. 차원 축소를 통해 상관관계가 높은 변수들의 영향을 줄일 수 있다. 정규화(Regularization) : 릿시(Ridge) 회귀와 같은 정규화 기법은 다중 공선성 문제를 완화하는 데 도움이 된다. 정규화를 통해 모델 계수의 크기를 제한하여 불안정성을 줄일 수 있다."
AI,머신러닝,"앙상블 학습(Ensemble Learning)이란 무엇이며, 어떻게 작동하나요? 주요 앙상블 기법들을 설명하시오.은(는) 무엇인가요?","앙상블 학습은 어러 개의 기본 학습 모델을 결합하여 전체적인 예측 성능을 향상시키는 머신러닝 기법이다. 이 방법은 개별 모델의 단점을 서로 상쇄하고 강점을 조합함으로써, 더 안정적이고 정확한 예측 결과를 도출할 수 있다. 주요 앙상블 기법들은 다음과 같다. 배깅(Bagging) : 부트스트랩 표본(Boostrap samples)을 추출하여 각 표폰에 대해 기본 모델을 학습시키고, 이들 모델의 예측을 집계함으로써 최종 예측을 얻는 방법이다. 대표적인 예로 랜덤 포레스트(Random Forest)가 있습니다. 부스팅(Boosting) : 순차적으로 모델을 학습시키면서, 이전 모델의 오류를 줄이는 방향으로 가중치를 조절해 나가는 방법이다. 그래디언트 부스팅(Gradient Boosting)과 XGBoost, LightGBM, catBoost 등이 대표적인 부스팅 기법이다. 스태킹(Stacking) : 여러 개의 기본 모델을 학습시킨 후, 이들 모델의 예측 결과를 입력으로 사용하여 새로운 메타 모델(meta-model)을 학습시키는 방법이다. 이렇게 하면 기본 모델들의 예측을 조합하여 더 좋은 성능을 얻을 수 있다."
AI,머신러닝,"텍스트 데이터를 처리할 때, 어떤 전처리 작업들이 필요가며, 이를 어떻게 구현하나?","텍스트 데이터 전처리는 머신러닝 모델에 입력하기에 적합한 형태로 변환하는 과정이다. 주요 전처리 작업은 다음과 같다. 토큰화(Tokenization) : 텍스트를 단어, 문장, 혹은 다른 의미 있는 단위로 분리하는 과정이다. 정규화(Normalization) : 단어를 기본 형태로 변환하는 과정으로, 대소문자 통일, 어간 추출(stemming), 표제어 추출(lemmatization) 등이 포함된다. 불용어 제거(Stopword removal) : 빈번하게 등장하지만 의미가 거의 없는 단어들을 제거하는 과정이다. 예를 들어 ""a"", ""an"", ""the"", ""and"", ""in"" 등의 단어들이 불용어로 간주된다 특수 문자 및 숫자 제거 : 텍스트에서 특수 문자와 숫자를 제거하여 노이즈를 줄이는 작업이다. 하지만 일부 경우에는 숫자나 특수 문자가 유용한 정보를 제공할 수 있으므로, 이를 제거할지 여부는 상화에 따라 결정해야 한다. 단어 임베딩(Word Embedding) : 텍스트 데이터를 고정된 크기의 벡터로 변환하는 과정이다. 이를 통해 텍스트 데이터를 머신러닝 모델에 적용할 수 있다. 대표적인 방법으로는 Word2Vec, GloVe, FastText 등이 있다. 이러한 전처리 작업들은 대부분의 프로그래밍 언어에서 사용 가능ㅎ나 라이브러리를 통해 구현할수 있다. 예를 들어, 파이썬에서는 NLTK(Natural Language Toolkit), SpaCy, Gensim 등의 라이브러리를 활용할 수 있다."
AI,머신러닝,"시계열 데이터를 처리할 때 어떤 특성이 고려되어야 하며, 어떤 모델을 사용하는가?","시계열 데이터는 시간 순서에 따라 측정된 데이터로, 일정한 간격으로 수집되거나 불규칙한 간격으로 수집될 수 있다. 시계열 데이터를 처리할 때 고려해야할 주요 특성은 다음과 같다. 계절성(Seasonality) : 일정한 시간 간격으로 반복되는 패턴이다. 예를 들어, 매년 여럼철에 전력 사용량이 증가하는 경우 계절성을 고려해야 한다. 추세(Trend) : 시계열 데이터에서 관측되는 장긱적인 증가 혹은 감소의 경향이다. 주기(Cyclicity) : 시간에 따라 반복되는 패턴으로, 일정하지 않은 주기를 갖는다. 불규칙성(Irregularity) : 시계열 데이터에서 예측하기 어려운 무작위 변동성을 나타낸다. 시계열 데이터를 처리하기 위한 모델에는 다양한 방법이 있다. 주요 모델은 다음과 같다. ARIMA(AutoRegressive Integrated Moving Average) : 자귀회귀, 이동평균, 차분을 결합한 선형 모델로, 시계열 데이터의 추세와 게절성을 모델링한다. 상태 공간 모델(StatesSpace Model) 및 칼만 필터(Kalman Filter) : 시간에 따라 변화하는 시스템의 상태를 추정하고 예측하는 모델이다. 숨겨진 상태 변수와 관측 변수 간의 관계를 모델링하여 시계열 데이터를 분석한다. LSTM(Long Short-Term Memory) 및 GRU(Gated Recurrent Unit) : 순환 신경망(RNN)의 변형으로, 시계열 데이터의 장기 패턴을 학습하는 데 효과적이다. 이러한 레은 시퀀스 데이터를 처리하기 때문에 시계열 데이터에 적합하다. Prophet : 페이스북에서 개발한 시계열 예측 라이브러리로, 비선형 추세, 계절성 및 휴일 효과를 고려한 모델링이 가능하다 다변량 시계열 레(Multivariate Time Series Model) : 여러 시계열 변수를 동시에 고려하는 모델로 VAR(Vector Autoregression) 및 VARIMA(Vector AutoRegressive Integrated moving Average)등이 있다. 이 외에도 다양한 시계열 분석 및 예측 모델이 존재하며, 데이터의 특성과 문제 설정에 따라 적합한 모델을 선택하는 것이 중요하다. 또한, 피처 엔지니어링(Feature Engineering)을 통해 시계열 데이터의 정보를 더욱 효과적으로 활용할 수 있다."
AI,머신러닝,머신러닝 모델의 성능을 평가하기 위한 지표들는 무엇인가?,"정확도(Accuracy) : 정확도는 전체 예측 중 올바르게 예측한 비율을 나타낸다. 정확도는 분류 문제에서 가장 간단하고 직관적인 성능 지표이다. 그러나 데이터 불균형이 있는 경우 정확도만으로는 모델 성능을 제대로 평가하기가 어렵다. 정밀도(Precision) : 정밀도는 양성 클래스로 예측한 새플 중 실제로 양성 클래스인샘플의 비율이다. 즉, 모델이 얼마나 정확하게 양성 클래스를 예측하는지를 타나낸다. 재현율(Recall) : 재현율은 실제 양성 클래스 중 모델이 양성 클래스로 예측한 비율이다. 즉, 실제 양성 클래스를 얼마나 잘 찾아내는지를 나타낸다. F1 스코어(F1 Score) : 정밀도와 재현율의 조화 평균으로, 두 지표의 균형을 나타낸다. F1 Score는 정밀도와 재현율이 동시에 고려되어야 하는 경우에 유용한 지표이다. ROC 곡선(Receiver Operating Characteristic Curve)과 AUC(Area Under the Curve) : ROC 곡선은 여러 임계값에서의 모델 성능을 시각화하며, AUC는 ROC 곡선 아래의 면적이다. AUC는 0에서 1사이의 값을 가지며, 값이 클수록 모델의 성능이 좋다고 판단된다. 평균 제곱 오차(Mean Squared Error, Mse) 및 평균 절대 제곱 오차(Mean Absolute Error, MAE) : 회귀 문제의 경우, MSE와 MAE는 모델이 예측한 값과 실제 값 사이의 차이를 측정하는 지표이다. 두 지표 모두 낮을수록 모델의 성능이 좋다고 판단한다. 정확도(Accuracy) : 정확도는 전체 예측 중 올바르게 예측한 비율을 나타낸다. 정확도는 분류 문제에서 가장 간단하고 직관적인 성능 지표이다. 그러나 데이터 불균형이 있는 경우 정확도만으로는 모델 성능을 제대로 평가하기가 어렵다. 정밀도(Precision) : 정밀도는 양성 클래스로 예측한 새플 중 실제로 양성 클래스인샘플의 비율이다. 즉, 모델이 얼마나 정확하게 양성 클래스를 예측하는지를 타나낸다. 재현율(Recall) : 재현율은 실제 양성 클래스 중 모델이 양성 클래스로 예측한 비율이다. 즉, 실제 양성 클래스를 얼마나 잘 찾아내는지를 나타낸다. F1 스코어(F1 Score) : 정밀도와 재현율의 조화 평균으로, 두 지표의 균형을 나타낸다. F1 Score는 정밀도와 재현율이 동시에 고려되어야 하는 경우에 유용한 지표이다. ROC 곡선(Receiver Operating Characteristic Curve)과 AUC(Area Under the Curve) : ROC 곡선은 여러 임계값에서의 모델 성능을 시각화하며, AUC는 ROC 곡선 아래의 면적이다. AUC는 0에서 1사이의 값을 가지며, 값이 클수록 모델의 성능이 좋다고 판단된다. 평균 제곱 오차(Mean Squared Error, Mse) 및 평균 절대 제곱 오차(Mean Absolute Error, MAE) : 회귀 문제의 경우, MSE와 MAE는 모델이 예측한 값과 실제 값 사이의 차이를 측정하는 지표이다. 두 지표 모두 낮을수록 모델의 성능이 좋다고 판단한다. 머신러닝 모델의 성능 평가는 문제의 특성과 목적이 따라 적절한 지표를 선택해야한다. 일부 지표는 특정 상황에서 더 유용할 수 있으므로, 상황에 맞는 지표를 사용하여 모델의 성능을 평가하는 것이 중요하다. 추갖거으로 다음과 같은 지표들도 고려할 수 있다. 결정계수(R-squared) : 회귀 문제에서 사용되는 결정계수는 모델이 설명하는 데이터의 분산 비율을 나타낸다. 0에서 1사이의 값을 가지며 값이 클수록 모델이 데이터를 잘 설명하고 있다고 판단한다. 로그 손실(Log Loss) : 로그 손실은 분류 문제에 사용되며, 모델이 예측한 확률 분포와 실제 확률 분포 사이의 차이를 측정한다. 로그 손실이 작을수록 모델의 성능이 좋다고 판단한다. Matthews 상관 계수(Matthews Correlation Coefficient, MCC): MCC는 이진 분류 문제에서 사용되며, TP(True Positive), TN(True Negative), FP(False Positive), FN(False Negative) 값을 사용해 계산합니다. MCC는 -1에서 1 사이의 값을 가지며, 값이 클수록 모델의 성능이 좋다고 판단합니다. 쿨백-라이블러 발산(Kullback-Leibler Divergence): 쿨백-라이블러 발산은 두 확률 분포 간의 차이를 측정합니다. 이 지표는 분류 문제에서 모델이 예측한 확률 분포와 실제 확률 분포 사이의 차이를 평가하는 데 사용됩니다. 각 성능 지표는 특정 상황이나 문제에 적합할 수 있으므로, 모델을 평가하고 개선할 때 여러 지표를 고려하는 것이 좋습니다. 이를 통해 모델의 성능을 더 정확하게 이해하고, 더 나은 결정을 내릴 수 있습니다."
공통,Python,"리스트, 튜플, 딕셔너리, 집합의 차이점는 무엇인가요?","리스트(list) : 변경 가능한(mutable) 순서가 있는 데이터 구조이다. 대괄호([])를 사용하여 정의하며, 중복된 값이 포함될 수 있다. 튜플(tupe) : 변경 불간으한(immutable) 순서가 있는 데이터 구조이다. 소괄호(())를 사용하여 정의하며, 중복된 값이 포함될 수 있다. 딕셔너리(dictionary) : 변경 가능한(mutable) 순서가 없는 데이터 구조로, 키와 값의 쌍으로 이루어져 있다. 중괄호({})를 사용하여 정의하며, 키는 중복될 수 없다. 집합(set) : 변경 가능한(mutable) 순서가 없는 데이터 구조로, 중복된 값을 포함할 수 없다. 중괄호({})를 사용하여 정의한다."
공통,Python,람다 함수란 무엇인가?,"람다 함수는 이름 없는(익명) 한 줄짜리 함수이다. 간단한 작업을 수행하는 함수를 생성할 때 사용되며, 람다 함수는 재사용이 필요하지 않은 경유 유용하다. lambda 키워드를 사용하여 정의한다. 코드의 형식은 다음과 같다. lambda 매개변수:결과"
공통,Python,pass와 continue의 차이는 무엇인가?,pass는 아무 작업도 수행하지 않는 키워드 이다. 빈 블록을 정의하는데 사용된다. pass를 사용하면 코드의 실행 흐름이 다음 문장으로 넘어간다. continue는 반복문의 실행 중 현재 반복을 중단하고 다음 반복으로 넘어가는 키워드이다. for loop나 while loop에서 사용된다.
공통,Python,파이썬의 장단점는 무엇인가는 무엇인가요?,장점 문법이 간결하고 읽기 쉽다. 다양한 라이브러리와 패키지로 인해 다양한 분야에서 활용할 수 있다. 커뮤니티가 크가 활발하여 도움을 받기 쉽다. 단점 다른 언어에 비해 실행 속도가 느릴 수 있다. 모바일 애플리케이션 개발에는 적합하지 않다. GIL(Global Interpreter Lock)로 인해 멀티코어 환경에서의 병렬 처리에 제한이 있다.
공통,Python,Numpy와 Pandas의 차이점는 무엇가?,"Numpy는 수치 데이터를 다루기 위한 고성능 다차우너 배열 객체인 ndarray를 제공하고, 배열에 대한 수학적 연산을 수행하는 라이브러리이다. 선형대수, 통계, 푸리에 변환 등의 기능을 제공한다. Numpy는 벡터화도니 연산을 지우너하여 빠른 처리가 가능하다. Pandas는 데이터 분석 및 조작을 위한 라이브러리로, DataFrame과 Series와 같은 데이터 구조를 제공한다 데이터를 쉽게 필터링, 정렬, 그룹화하고, 결측치를 처리하거나 통계를 계산하는 기능을 제공한다. Pandas는 테이블 형태의 데이터를 다루기에 적합하며, Numpy를 기반으로 만들어 졌다. Numpy와 Pandas의 주요 차이점은 다음과 같다. Numpy는 주로 다차우너 배열을 처리하는 데 사용되고, Pandas는 테이블형태의 데이터를 처리하는 데 사용된다. Numpy는 수치 데이터에 최적화되어 있고, Pandas는 다양한 유형의 데이터를 처리할 수 있다 Pandas는 데이터 조작 및 분석을 위한 편리한 기능을 제공하며, Numpy는 수학적 연산에 초점을 맞추고 있다."
공통,Python,Python에서 상속이란 무엇인가?,"상속은 객체 지향 프로그래밍에서 한 클래스의 속성과 메서드를 다른 클래스가 이어받는 기능이다. 상속을 통해 코드의 재사용성을 높이고, 모듈화를 쉽게 할 수 있다. Python에서 상속은 class ChildClass(ParentClass):와 같은 형식으로 구현할 수 있다."
공통,Python,리스트에서 중복값을 제외하려면 어떻게 해야하는가?,"리스트에서 중복값을 제외하려면, 집합(set) 자료형을 활용할 수 있다. 예를들어 unique_list = list(set(original_list))처럼 사용하여 중복값이 제거된 새로운 리스트를 얻을 수 있다."
공통,Python,컴파일 언어와 인터프리터 언어의 차이점는 무엇인가?,"컴팡리 언어는 코드를 기계어로 번역하는 컴파일 과정을 거친 후 실행되며, 이 과정에서 발생하는 오류를 수정해야 한다. 컴파일 언어의 예로는 C, C++, Java등이 있다. 인터프리터 언어는 코드를 한 줄씩 실행함녀서 해석하는 방식으로 오류가 발생하면 해당 지점에서 프로그램이 중단된다. 인터프리터 언어의 예로는 Python, JavaScript, Ruby등 이 있다."
공통,Python,.pyc 파일과 .py 파일과 .ipynb의 차이점는 무엇인가?,".py 파일은 Python 소스 코드 파일로, 텍스트 형식으로 저장되어 있다. .pyc 파일은 Python 소스 크드가 컴파일된 바이트코드 파일로, Python 인터프리터가 빠르게 실행할 수 있도록 변환된 형태이다. .ipynb 파일은 Jupyter Notebook에서 사용되는 파일로, 코드와 텍스트, 그래프 등을 함께 저장할 수 있는 JSON 형식의 파일이다. 대화형으로 코드를 실행하고 결과를 확인할 수 있어, 데이터 분석이나 머신러닝 과정을 시각적으로 보여주기에 적합하다"
공통,Python,"함수, 클래스, 객체 개념에 대해서 설명하시오.은(는) 무엇인가요?","함수 : 코드의 재사용성을 높이기 위해 작성된 특정 긴으을 수행하는 코드 블록이다. 함수는 입력 값을 받아 처리한 결과를 반환할 수 있다. 클래스 : 객체 지향 프로그래밍에서 사용되는 설계도록, 속성(attribute)과 메서드(method)를 정의한다. 클래스를 통해 객체를 생성할 수 있으며, 동일한 클래스로부터 생성된 객체들은 같은 속성과 메서드를 확장하거나 수정할 수 있어 다형성을 구현할 수 있다. 이러한 클래스의 특성을 활용하여 각 컴포넌트들이 독립적으로 작동하면서도 서로 협력하는 프로그램으로 구현할 수 있다. 객체(Object) : 클래스를 통해 생성된 인스턴스로, 클래스에서 정의된 속성과 메서드를 가지고 있다. 객체는 독립적으로 상태와 행동을 관리할 수 있으며, 객체 간에 메시지를 주고받아 상호작용을 할 수 있다. 객체 지향 프로그래밍의 핵심은 객체들이 함께 작동하여 프로그램을 구성하는 것이다. 함수, 클래스, 객체의 관계를 요약하면 함수는 특정 기능을 수행하는 코드 블록이며, 클래스는 객체의 설계도 역할을 하고, 객체는 클래스를 통해 생성되어 독립적으로 상태와 행동을 관리한다. 이를 통해 프로그램을 모듈화하고 코드의 재사용성을 높일 수 있다."
공통,Python,인터프리터와 컴파일의 차이점는 무엇인가?,"인터프리터는 프로그램을 실행할 때 소스 코드를 한 줄씩 해석하며 실행ㅎ나다. 따라서 실행 시간이 오래 걸리지만, 개발과 디버깅이 쉽다. 파이썬은 대표적인 인터프리터언어이다. 컴파일러는 프로그램을 실행하기 전에 소스 코드를 기계어로 번역하여 목적 파일을 생성한다. 이로 인해 실행 시간이 빠르지만 개발과 디버깅이 어렵다. C, C++이 대표적인 컴파일 언어이다."
공통,Python,파이썬의 기본 자료형에는 어떤 것이 있나?,"파이썬의 기본 자료형에는 정수(int), 실수(float), 문자열(str), 불린(bool)이 있다. 이외에도 리스트, 튜플, 딕셔너리, 집합 등의 컬렉션 자료형이 잇다."
공통,Python,변수와 상수의 차이점는 무엇인가?,"변수는 프로그램 실행 도중 값이 변경될 수 있는 저장 공간을 의미한다. 상수는 값이 변하지 않는 저장 공간을 의미하며, 일반적으로 대문자로 표기한다. 파이썬은 상소를 내장하지 않지만, 개발자들은 관례적으로 대문자로 표기하여 상수임을 명시한다."
공통,Python,가비지와 컬렉션의 개념과 작동 원리는 무엇인가?,"가비지 컬렉션은 프로그램 실행 도중 사용하지 않는 메모리를 자동으로 회수하는 메커니즘입니다. 파이썬의 경우, 참조 카운터를 사용하여 객체에 대한 참조 횟수를 세고, 참조 카운트가 0이 되면 메모리를 회수합니다. 또한, 순환 참조를 처리하기 위해 가비지 컬렉터를 사용합니다."
공통,Python,얕는 복사와 깊는 복사의 차이는 무엇인가요?,"얕은 복사는 객체의 최상위 요소를 복사하지만, 내부 요소는 원본과 동일한 참조를 가리킵니다. 깊은 복사는 객체의 모든 요소를 재귀적으로 복사하여 완전히 독립적인 복사본을 생성합니다. 파이썬에서는 copy 모듈의 shallow() 함수를 사용하여 얕은 복사를, deepcopy() 함수를 사용하여 깊은 복사를 수행할 수 있습니다."
공통,Python,멀티스레딩과 멀티프로세싱의 차이점는 무엇인가요?,"멀티스레딩은 프로세스 내에서 여러 개의 스레드를 동시에 실행하는 기법입니다. 스레드는 같은 프로세스의 메모리를 공유하므로, 메모리 사용이 효율적입니다. 그러나 파이썬에서 GIL 때문에 CPU-bound 작업에서 병목 현상이 발생할 수 있습니다. 멀티프로세싱은 여러 개의 독립적인 프로세스를 동시에 실행하는 기법입니다. 각 프로세스는 독립된 메모리 공간을 가지므로, GIL의 영향을 받지 않아 CPU-bound 작업에서 더 효율적일 수 있습니다. 그러나 프로세스간 메모리를 공유하기 어렵고, 통신 오버헤드가 발생할 수 있습니다."
공통,Python,동시성과 병렬성의 차이점는 무엇인가요?,"동시성은 여러 작업이 동시에 실행되는 것처럼 보이는 것을 말합니다. 실제로는 작업들이 시간을 나눠서 번갈아 실행되지만, 사용자에게는 동시에 진행되는 것처럼 느껴집니다. 병렬성은 여러 작업이 실제로 동시에 실행되는 것을 말합니다. 멀티코어 프로세서를 사용할 때 여러 개의 코어가 동시에 작업을 처리할 수 있어 병렬 실행이 가능합니다."
공통,Python,CIL(Golbal Interperter Lock)이란 무엇인가?,"GIL은 파이썬 인터프리터가 한 번에 하나의 스레드만 실행할 수 있도록 제한하는 메커니즘입니다. 이는 메모리 관리와 객체의 동기화를 간단하게 만들어주지만, 멀티스레딩 환경에서 CPU-bound 작업의 성능을 저하시킬 수 있습니다."
공통,Python,*args와 **kwargs의 사용법과 차이점는 무엇인가?,"*args는 함수에 가변 개수의 위치 인자를 전달하는 데 사용됩니다. 이를 통해 함수는 몇 개의 위치 인자가 오든 처리할 수 있습니다. 반면, **kwargs는 함수에 가변 개수의 키워드 인자를 전달하는 데 사용됩니다. 이를 통해 함수는 몇 개의 키워드 인자가 오든 처리할 수 있습니다."
공통,Python,제너레이터와 이터레이터의 차이점는 무엇인가?,"이터레이터는 iter()와 next() 메소드를 구현한 객체입니다. 이터레이터를 사용하여 순차적으로 컬렉션의 요소에 접근할 수 있습니다. 이터레이터는 메모리를 효율적으로 사용할 수 있지만, 사용자 정의 이터레이터를 만들려면 별도의 클래스를 작성해야 할 수도 있습니다. 제너레이터는 이터레이터를 더 쉽게 생성하는 방법으로, 함수 내부에 yield 키워드를 사용하여 구현합니다. yield를 사용하면 함수의 실행을 일시 중단하고, 다음 호출 시 중단된 지점부터 계속 실행할 수 있습니다. 이를 통해 메모리를 더 효율적으로 사용할 수 있으며, 이터레이터에 비해 코드가 간결하고 가독성이 높아집니다. 그러나 제너레이터는 상태를 유지하므로, 일반 함수에 비해 구현이 복잡할 수 있습니다."
공통,Python,리스트 컴프리헨션을 사용하는 이유와 방법을 설명하시오는 무엇인가요?,"리스트 컴프리헨션은 리스트를 생성하는 간결하고 가독성 높은 방법입니다. for 문이나 다른 반복문을 사용하는 것보다 코드가 짧아지고, 실행 시간도 일반적으로 더 짧습니다. 리스트 컴프리헨션을 사용하는 방법은 다음과 같습니다. [expression for item in iterable if condition] 예를 들어, 0부터 9까지의 제곱값을 구하는 리스트 컴프리헨션은 다음과 같습니다. squares = [x * x for x in range(10)]"
공통,Python,정규 표현식을 다루는 방법을 설명하시오는 무엇인가요?,"Python에서 정규 표현식을 다루기 위해 re 모듈을 사용합니다. 주요 함수들은 search(), match(), findall(), finditer(), sub(), split() 등이 있습니다. 정규 표현식을 사용하여 문자열에서 패턴을 찾거나, 대체하거나, 나누는 등의 작업을 수행할 수 있습니다."
공통,Python,메모리 관리는 어떻게 이루어지나요는 무엇인가요?,"Python은 가비지 컬렉션(GC) 메커니즘을 사용하여 메모리를 관리합니다. 가장 일반적인 GC 방법은 참조 카운팅입니다. 객체에 대한 참조가 더 이상 없으면 메모리가 해제됩니다. 또한, 순환 참조 같은 메모리 누수 문제를 방지하기 위해 generational GC 알고리즘도 사용됩니다."
공통,Python,예외 처리를 하는 방법을 설명하시오.은(는) 무엇인가요?,"예외 처리를 위해 Python에서는 try, except, finally, else 키워드를 사용합니다. try 블록에서 예외가 발생할 수 있는 코드를 작성하고, except 블록에서 예외를 처리합니다. finally 블록은 예외 발생 여부와 관계없이 항상 실행되는 코드를 작성합니다. else 블록은 예외가 발생하지 않을 때 실행되는 코드를 작성합니다."
공통,Python,파일 입출력을 하는 방법는 어떻게 되는가?,"Python에서 파일 입출력을 위해 open() 함수를 사용하여 파일을 엽니다. 파일을 열 때는 파일 모드를 지정할 수 있습니다. (예: 읽기 모드 'r', 쓰기 모드 'w', 추가 모드 'a', 이진 모드 'b' 등) 파일 작업을 완료한 후에는 close() 메서드를 사용하여 파일을 닫습니다. with 문을 사용하면 파일이 자동으로 닫히므로 권장되는 방식입니다."
공통,Python,모듈과 패키지의 차이점는 무엇인가?,"모듈은 Python 파일입니다. 이 파일에는 Python 코드, 변수, 함수, 클래스 등이 포함될 수 있습니다. 다른 Python 코드에서 import 문을 사용하여 모듈을 가져올 수 있습니다. 패키지는 여러 모듈을 구조화하는 방법입니다. 패키지는 디렉토리 구조로 구성되며, 각 디렉토리에는 init.py 파일이 포함되어 있습니다. 이 파일은 해당 디렉토리가 패키지의 일부임을 Python에 알려줍니다. 패키지를 사용하면 관련된 모듈을 논리적으로 그룹화하여 코드의 재사용성과 가독성을 높일 수 있습니다. 패키지에서 모듈을 가져오려면 import 문을 사용하고, 점 표기법으로 패키지와 모듈을 지정합니다. 예를 들어, 패키지 my_package 안에 모듈 my_module이 있다고 가정할 때, 다음과 같이 가져올 수 있습니다. import my_package.my_module / from my_package import my_module"
공통,Python,"파이썬의 메타클래스(meta에서 classes)는 무엇이며, 어떻게 사용하나요?","메타클래스는 클래스의 클래스로, 클래스의 행동을 정의하는데 사용됩니다. 메타클래스를 사용하면 클래스 생성 과정을 사용자 정의할 수 있으며, 이를 통해 동적으로 클래스를 생성하거나 수정할 수 있습니다. type 함수를 사용하여 메타클래스를 정의할 수 있습니다."
공통,Python,"Python에서 메모이제이션(memoization)이란 무엇이며, 어떻게 구현하나요?",메모이제이션은 컴퓨팅 결과를 캐시에 저장하여 동일한 입력에 대한 계산을 반복하지 않도록 함으로써 프로그램의 실행 시간을 줄이는 최적화 기법입니다. 파이썬에서는 functools.lru_cache 데코레이터를 사용하여 메모이제이션을 쉽게 구현할 수 있습니다.
공통,Python,Python에서 동적 타이핑(dynamic typing)과 정적 타이핑(static typing)의 차이점는 무엇인가요?,동적 타이핑은 변수의 타입이 실행 시점에 결정되는 방식입니다. 파이썬은 기본적으로 동적 타이핑 언어입니다. 정적 타이핑은 변수의 타입이 선언 시점에 결정되는 방식입니다. 파이썬 3.5부터 typing 모듈을 사용하여 타입 힌팅(type hinting)을 통해 정적 타이핑을 지원합니다.
공통,Python,"Python의 GIL(Global Interpreter Lock)이란 무엇이며, 왜 문제가 되는지 설명해주세요.은(는) 무엇인가요?","GIL은 파이썬 인터프리터에서 스레드간의 동시 접근을 제한하기 위해 사용되는 동기화 메커니즘이며, 한 번에 하나의 스레드만 실행되도록 합니다. 이로 인해 멀티 스레딩을 사용해도 병렬 처리가 제한되어 CPU 병렬성을 최대한 활용할 수 없게 됩니다. GIL 문제를 해결하기 위해 멀티프로세싱 모듈을 사용하거나 GIL을 회피하는 C/C++ 확장을 사용할 수 있습니다."
BACKEND,개발 상식,Object Oriented Programming은(는) 무엇인가요?,"객체 지향 프로그래밍 이전의 프로그래밍 패러다임을 살펴보면, 중심이 컴퓨터에 있었다. 컴퓨터가 사고하는대로 프로그래밍을 하는 것이다. 하지만 객체지향 프로그래밍이란 인간 중심적 프로그래밍 패러다임이라고 할 수 있다. 즉, 현실 세계를 프로그래밍으로 옮겨와 프로그래밍하는 것을 말한다. 현실 세계의 사물들을 객체라고 보고 그 객체로부터 개발하고자 하는 애플리케이션에 필요한 특징들을 뽑아와 프로그래밍 하는 것이다. 이것을 추상화라한다. OOP 로 코드를 작성하면 이미 작성한 코드에 대한 재사용성이 높다. 자주 사용되는 로직을 라이브러리로 만들어두면 계속해서 사용할 수 있으며 그 신뢰성을 확보 할 수 있다. 또한 라이브러리를 각종 예외상황에 맞게 잘 만들어두면 개발자가 사소한 실수를 하더라도 그 에러를 컴파일 단계에서 잡아낼 수 있으므로 버그 발생이 줄어든다. 또한 내부적으로 어떻게 동작하는지 몰라도 개발자는 라이브러리가 제공하는 기능들을 사용할 수 있기 때문에 생산성이 높아지게 된다. 객체 단위로 코드가 나눠져 작성되기 때문에 디버깅이 쉽고 유지보수에 용이하다. 또한 데이터 모델링을 할 때 객체와 매핑하는 것이 수월하기 때문에 요구사항을 보다 명확하게 파악하여 프로그래밍 할 수 있다. 객체 간의 정보 교환이 모두 메시지 교환을 통해 일어나므로 실행 시스템에 많은 overhead 가 발생하게 된다. 하지만 이것은 하드웨어의 발전으로 많은 부분 보완되었다. 객체 지향 프로그래밍의 치명적인 단점은 함수형 프로그래밍 패러다임의 등장 배경을 통해서 알 수 있다. 바로 객체가 상태를 갖는다는 것이다. 변수가 존재하고 이 변수를 통해 객체가 예측할 수 없는 상태를 갖게 되어 애플리케이션 내부에서 버그를 발생시킨다는 것이다. 이러한 이유로 함수형 패러다임이 주목받고 있다."
BACKEND,개발 상식,Object Oriented Programming에서 객체 지향적 설계 원칙는 무엇인가요?,1. SRP(Single Responsibility Principle) : 단일 책임 원칙 클래스는 단 하나의 책임을 가져야 하며 클래스를 변경하는 이유는 단 하나의 이유이어야 한다. 2. OCP(Open-Closed Principle) : 개방-폐쇄 원칙 확장에는 열려 있어야 하고 변경에는 닫혀 있어야 한다. 3. LSP(Liskov Substitution Principle) : 리스코프 치환 원칙 상위 타입의 객체를 하위 타입의 객체로 치환해도 상위 타입을 사용하는 프로그램은 정상적으로 동작해야 한다. 4. ISP(Interface Segregation Principle) : 인터페이스 분리 원칙 인터페이스는 그 인터페이스를 사용하는 클라이언트를 기준으로 분리해야 한다. 5. DIP(Dependency Inversion Principle) : 의존 역전 원칙 고수준 모듈은 저수준 모듈의 구현에 의존해서는 안된다.
BACKEND,개발 상식,RESTful API은(는) 무엇인가요?,"우선, 위키백과의 정의를 요약해보자면 다음과 같다. > 월드 와이드 웹(World Wide Web a.k.a WWW)과 같은 분산 하이퍼미디어 시스템을 위한 소프트웨어 아키텍처의 한 형식으로 자원을 정의하고 자원에 대한 주소를 지정하는 방법 전반에 대한 패턴 `REST`란, REpresentational State Transfer 의 약자이다. 여기에 ~ful 이라는 형용사형 어미를 붙여 ~한 API 라는 표현으로 사용된다. 즉, REST 의 기본 원칙을 성실히 지킨 서비스 디자인은 'RESTful'하다라고 표현할 수 있다. `REST`가 디자인 패턴이다, 아키텍처다 많은 이야기가 존재하는데, 하나의 아키텍처로 볼 수 있다. 좀 더 정확한 표현으로 말하자면, REST 는 `Resource Oriented Architecture` 이다. API 설계의 중심에 자원(Resource)이 있고 HTTP Method 를 통해 자원을 처리하도록 설계하는 것이다."
BACKEND,개발 상식,RESTful API에서 REST 6 가지 원칙는 무엇인가요?,* Uniform Interface * Stateless * Caching * Client-Server * Hierarchical system * Code on demand
BACKEND,개발 상식,RESTful API에서 RESTful 하게 API 를 디자인 한다는 것는 무엇을 의미하는가.(요약)은(는) 무엇인가요?,"1. 리소스 와 행위 를 명시적이고 직관적으로 분리한다. * 리소스는 `URI`로 표현되는데 리소스가 가리키는 것은 `명사`로 표현되어야 한다. * 행위는 `HTTP Method`로 표현하고, `GET(조회)`, `POST(생성)`, `PUT(기존 entity 전체 수정)`, `PATCH(기존 entity 일부 수정)`, `DELETE(삭제)`을 분명한 목적으로 사용한다. 2. Message 는 Header 와 Body 를 명확하게 분리해서 사용한다. * Entity 에 대한 내용은 body 에 담는다. * 애플리케이션 서버가 행동할 판단의 근거가 되는 컨트롤 정보인 API 버전 정보, 응답받고자 하는 MIME 타입 등은 header 에 담는다. * header 와 body 는 http header 와 http body 로 나눌 수도 있고, http body 에 들어가는 json 구조로 분리할 수도 있다. 3. API 버전을 관리한다. * 환경은 항상 변하기 때문에 API 의 signature 가 변경될 수도 있음에 유의하자. * 특정 API 를 변경할 때는 반드시 하위호환성을 보장해야 한다. 4. 서버와 클라이언트가 같은 방식을 사용해서 요청하도록 한다. * 브라우저는 form-data 형식의 submit 으로 보내고 서버에서는 json 형태로 보내는 식의 분리보다는 json 으로 보내든, 둘 다 form-data 형식으로 보내든 하나로 통일한다. * 다른 말로 표현하자면 URI 가 플랫폼 중립적이어야 한다."
BACKEND,개발 상식,RESTful API에서 어떠한 장점이 존재하는가?,1. Open API 를 제공하기 쉽다 2. 멀티플랫폼 지원 및 연동이 용이하다. 3. 원하는 타입으로 데이터를 주고 받을 수 있다. 4. 기존 웹 인프라(HTTP)를 그대로 사용할 수 있다.
BACKEND,개발 상식,RESTful API에서 단점는 뭐가 있을까?,1. 사용할 수 있는 메소드가 한정적이다. 2. 분산환경에는 부적합하다. 3. HTTP 통신 모델에 대해서만 지원한다. 위 내용은 간단히 요약된 내용이므로 보다 자세한 내용은 다음 Reference 를 참고하시면 됩니다 :)
BACKEND,개발 상식,TDD 란 무엇인가,Test-Driven Development(TDD)는 매우 짧은 개발 사이클의 반복에 의존하는 소프트웨어 개발 프로세스이다. 우선 개발자는 요구되는 새로운 기능에 대한 자동화된 테스트케이스를 작성하고 해당 테스트를 통과하는 가장 간단한 코드를 작성한다. 일단 테스트 통과하는 코드를 작성하고 상황에 맞게 리팩토링하는 과정을 거치는 것이다. 말 그대로 테스트가 코드 작성을 주도하는 개발방식인 것이다. 추천 자료: * (도서) [켄트 벡 - 테스트 주도 개발]
BACKEND,개발 상식,TDD에서 Add a test은(는) 무엇인가요?,"테스트 주도형 개발에선, 새로운 기능을 추가하기 전 테스트를 먼저 작성한다. 테스트를 작성하기 위해서, 개발자는 해당 기능의 요구사항과 명세를 분명히 이해하고 있어야 한다. 이는 사용자 케이스와 사용자 스토리 등으로 이해할 수 있으며, 이는 개발자가 코드를 작성하기 전에 보다 요구사항에 집중할 수 있도록 도와준다. 이는 정말 중요한 부분이자 테스트 주도 개발이 주는 이점이라고 볼 수 있다. 추천 자료: * (도서) [켄트 벡 - 테스트 주도 개발]"
BACKEND,개발 상식,TDD에서 Run all tests and see if new one fails은(는) 무엇인가요?,"어떤 새로운 기능을 추가하면 잘 작동하던 기능이 제대로 작동하지 않는 경우가 발생할 수 있다. 더 위험한 경우는 개발자가 이를 미처 인지하지 못하는 경우이다. 이러한 경우를 방지하기 위해 테스트 코드를 작성하는 것이다. 새로운 기능을 추가할 때 테스트 코드를 작성함으로써, 새로운 기능이 제대로 작동함과 동시에 기존의 기능들이 잘 작동하는지 테스트를 통해 확인할 수 있는 것이다. 추천 자료: * (도서) [켄트 벡 - 테스트 주도 개발]"
BACKEND,개발 상식,TDD에서 Refactor code은(는) 무엇인가요?,"좋은 코드'를 작성하기란 정말 쉽지가 않다. 코드를 작성할 때 고려해야 할 요소가 한 두 가지가 아니기 때문이다. 가독성이 좋게 coding convention 을 맞춰야 하며, 네이밍 규칙을 적용하여 메소드명, 변수명, 클래스명에 일관성을 줘야하며, 앞으로의 확장성 또한 고려해야 한다. 이와 동시에 비즈니스 로직에 대한 고려도 반드시 필요하며, 예외처리 부분 역시 빠뜨릴 수 없다. 물론 코드량이 적을 때는 이런 저런 것들을 모두 신경쓰면서 코드를 작성할 수 있지만 끊임없이 발견되는 버그들을 디버깅하는 과정에서 코드가 더럽혀지기 마련이다. 이러한 이유로 코드량이 방대해지면서 리팩토링을 하게 된다. 이 때 테스트 주도 개발을 통해 개발을 해왔다면, 테스트 코드가 그 중심을 잡아줄 수 있다. 뚱뚱해진 함수를 여러 함수로 나누는 과정에서 해당 기능이 오작동을 일으킬 수 있지만 간단히 테스트를 돌려봄으로써 이에 대한 안심을 하고 계속해서 리팩토링을 진행할 수 있다. 결과적으로 리팩토링 속도도 빨라지고 코드의 퀄리티도 그만큼 향상하게 되는 것이다. 코드 퀄리티 부분을 조금 상세히 들어가보면, 보다 객체지향적이고 확장 가능이 용이한 코드, 재설계의 시간을 단축시킬 수 있는 코드, 디버깅 시간이 단축되는 코드가 TDD 와 함께 탄생하는 것이다. 어차피 코드를 작성하고나서 제대로 작동하는지 판단해야하는 시점이 온다. 물론 중간 중간 수동으로 확인도 할 것이다. 또 테스트에 대한 부분에 대한 문서도 만들어야 한다. 그 부분을 자동으로 해주면서, 코드 작성에 도움을 주는 것이 TDD 인 것이다. 끊임없이 TDD 찬양에 대한 말만 했다. TDD 를 처음 들어보는 사람은 이 좋은 것을 왜 안하는가에 대한 의문이 들 수도 있다. 추천 자료: * (도서) [켄트 벡 - 테스트 주도 개발]"
BACKEND,개발 상식,TDD에서 코드 생산성에 문제가 있지는 않나?,"두 배는 아니더라도 분명 코드량이 늘어난다. 비즈니스 로직, 각종 코드 디자인에도 시간이 많이 소요되는데, 거기에다가 테스트 코드까지 작성하기란 여간 벅찬 일이 아닐 것이다. 코드 퀄리티보다는 빠른 생산성이 요구되는 시점에서 TDD 는 큰 걸림돌이 될 수 있다. 추천 자료: * (도서) [켄트 벡 - 테스트 주도 개발]"
BACKEND,개발 상식,TDD에서 테스트 코드를 작성하기가 쉬운가?,"이 또한 TDD 라는 개발 방식을 적용하기에 큰 걸림돌이 된다. 진입 장벽이 존재한다는 것이다. 어떠한 부분을 테스트해야할 지, 어떻게 테스트해야할 지, 여러 테스트 프레임워크 중 어떤 것이 우리의 서비스와 맞는지 등 여러 부분들에 대한 학습이 필요하고 익숙해지는데에도 시간이 걸린다. 팀에서 한 명만 익숙해진다고 해결될 일이 아니다. 개발은 팀 단위로 수행되기 때문에 팀원 전체의 동의가 필요하고 팀원 전체가 익숙해져야 비로소 테스트 코드가 빛을 발하게 되는 것이다. 추천 자료: * (도서) [켄트 벡 - 테스트 주도 개발]"
BACKEND,개발 상식,TDD에서 모든 상황에 대해서 테스트 코드를 작성할 수 있는가? 작성해야 하는가?,"세상에는 다양한 사용자가 존재하며, 생각지도 못한 예외 케이스가 존재할 수 있다. 만약 테스트를 반드시 해봐야 하는 부분에 있어서 테스트 코드를 작성하는데 어려움이 발생한다면? 이러한 상황에서 주객이 전도하는 상황이 발생할 수 있다. 분명 실제 코드가 더 중심이 되어야 하는데 테스트를 위해서 코드의 구조를 바꿔야 하나하는 고민이 생긴다. 또한 발생할 수 있는 상황에 대한 테스트 코드를 작성하기 위해 배보다 배꼽이 더 커지는 경우가 허다하다. 실제 구현 코드보다 방대해진 코드를 관리하는 것도 쉽지만은 않은 일이 된 것이다. 모든 코드에 대해서 테스트 코드를 작성할 수 없으며 작성할 필요도 없다. 또한 테스트 코드를 작성한다고 해서 버그가 발생하지 않는 것도 아니다. 애초에 TDD 는 100% coverage 와 100% 무결성을 주장하지 않았다. #### Personal Recommendation * (도서) [켄트 벡 - 테스트 주도 개발] 추천 자료: * (도서) [켄트 벡 - 테스트 주도 개발]"
BACKEND,개발 상식,함수형 프로그래밍는 무엇인가요?,함수형 프로그래밍의 가장 큰 특징 두 가지는 `immutable data`와 `first class citizen으로서의 function`이다.
BACKEND,개발 상식,함수형 프로그래밍에서 immutable vs mutable은(는) 무엇인가요?,"우선 `immutable`과 `mutable`의 차이에 대해서 이해를 하고 있어야 한다. `immutable`이란 말 그대로 변경 불가능함을 의미한다. `immutable` 객체는 객체가 가지고 있는 값을 변경할 수 없는 객체를 의미하여 값이 변경될 경우, 새로운 객체를 생성하고 변경된 값을 주입하여 반환해야 한다. 이와는 달리, `mutable` 객체는 해당 객체의 값이 변경될 경우 값을 변경한다."
BACKEND,개발 상식,함수형 프로그래밍 의 first의class citizen은(는) 무엇인가요?,"함수형 프로그래밍 패러다임을 따르고 있는 언어에서의 `함수(function)`는 `일급 객체(first class citizen)`로 간주된다. 일급 객체라 함은 다음과 같다. * 변수나 데이터 구조안에 함수를 담을 수 있어서 함수의 파라미터로 전달할 수 있고, 함수의 반환값으로 사용할 수 있다. * 할당에 사용된 이름과 관계없이 고유한 구별이 가능하다. * 함수를 리터럴로 바로 정의할 수 있다."
BACKEND,개발 상식,함수형 프로그래밍에서 Reactive Programming은(는) 무엇인가요?,"반응형 프로그래밍(Reactive Programming)은 선언형 프로그래밍(declarative programming)이라고도 불리며, 명령형 프로그래밍(imperative programming)의 반대말이다. 또 함수형 프로그래밍 패러다임을 활용하는 것을 말한다. 반응형 프로그래밍은 기본적으로 모든 것을 스트림(stream)으로 본다. 스트림이란 값들의 집합으로 볼 수 있으며 제공되는 함수형 메소드를 통해 데이터를 immutable 하게 관리할 수 있다."
BACKEND,개발 상식,MVC 패턴이란 무엇인가?,그림과 함께 설명하는 것이 더 좋다고 판단하여 [포스팅]으로 대체한다.
BACKEND,개발 상식,Git 과 GitHub 에 대해서는 무엇인가요?,"Git 이란 VCS(Version Control System)에 대해서 기본적인 이해를 요구하고 있다. * [Git 을 조금 더 알아보자 slide share] Git 을 사용하기 위한 각종 전략(strategy)들이 존재한다. 해당 전략들에 대한 이해를 기반으로 Git 을 사용해야 하기 때문에 면접에서 자주 물어본다. 주로 사용되는 strategy 중심으로 질문이 들어오며 유명한 세 가지를 비교한 글을 첨부한다. * [Gitflow vs GitHub flow vs GitLab flow] 많은 회사들이 GitHub 을 기반으로 협업을 하게 되는데, (BitBucket 이라는 훌륭한 도구도 존재합니다.) GitHub 에서 어떤 일을 할 수 있는지, 어떻게 GitHub Repository 에 기여를 하는지 정리한 글을 첨부한다. * [오픈소스 프로젝트에 컨트리뷰트 하기] * [GitHub Cheetsheet]"
공통,자료구조,Array vs Linked List에서 Array은(는) 무엇인가요?,"가장 기본적인 자료구조인 `Array` 자료구조는, 논리적 저장 순서와 물리적 저장 순서가 일치한다. 따라서 `인덱스`(index)로 해당 원소(element)에 접근할 수 있다. 그렇기 때문에 찾고자 하는 원소의 인덱스 값을 알고 있으면 `Big-O(1)`에 해당 원소로 접근할 수 있다. 즉 random access 가 가능하다는 장점이 있는 것이다. 하지만 삭제 또는 삽입의 과정에서는 해당 원소에 접근하여 작업을 완료한 뒤(O(1)), 또 한 가지의 작업을 추가적으로 해줘야 하기 때문에, 시간이 더 걸린다. 만약 배열의 원소 중 어느 원소를 삭제했다고 했을 때, 배열의 연속적인 특징이 깨지게 된다. 즉 빈 공간이 생기는 것이다. 따라서 삭제한 원소보다 큰 인덱스를 갖는 원소들을 `shift`해줘야 하는 비용(cost)이 발생하고 이 경우의 시간 복잡도는 O(n)가 된다. 그렇기 때문에 Array 자료구조에서 삭제 기능에 대한 time complexity 의 worst case 는 O(n)이 된다. 삽입의 경우도 마찬가지이다. 만약 첫번째 자리에 새로운 원소를 추가하고자 한다면 모든 원소들의 인덱스를 1 씩 shift 해줘야 하므로 이 경우도 O(n)의 시간을 요구하게 된다. 추천 자료: * Array 를 기반으로한 Linked List 구현 * ArrayList 를 기반으로한 Linked List 구현 ---"
공통,자료구조,Array vs Linked List에서 Linked List은(는) 무엇인가요?,"이 부분에 대한 문제점을 해결하기 위한 자료구조가 linked list 이다. 각각의 원소들은 자기 자신 다음에 어떤 원소인지만을 기억하고 있다. 따라서 이 부분만 다른 값으로 바꿔주면 삭제와 삽입을 O(1) 만에 해결할 수 있는 것이다. 하지만 Linked List 역시 한 가지 문제가 있다. 원하는 위치에 삽입을 하고자 하면 원하는 위치를 Search 과정에 있어서 첫번째 원소부터 다 확인해봐야 한다는 것이다. Array 와는 달리 논리적 저장 순서와 물리적 저장 순서가 일치하지 않기 때문이다. 이것은 일단 삽입하고 정렬하는 것과 마찬가지이다. 이 과정 때문에, 어떠한 원소를 삭제 또는 추가하고자 했을 때, 그 원소를 찾기 위해서 O(n)의 시간이 추가적으로 발생하게 된다. 결국 linked list 자료구조는 search 에도 O(n)의 time complexity 를 갖고, 삽입, 삭제에 대해서도 O(n)의 time complexity 를 갖는다. 그렇다고 해서 아주 쓸모없는 자료구조는 아니기에, 우리가 학습하는 것이다. 이 Linked List 는 Tree 구조의 근간이 되는 자료구조이며, Tree 에서 사용되었을 때 그 유용성이 드러난다. #### Personal Recommendation * Array 를 기반으로한 Linked List 구현 * ArrayList 를 기반으로한 Linked List 구현 --- 추천 자료: * Array 를 기반으로한 Linked List 구현 * ArrayList 를 기반으로한 Linked List 구현 ---"
공통,자료구조,Stack and Queue에서 Stack은(는) 무엇인가요?,선형 자료구조의 일종으로 `Last In First Out (LIFO)` - 나중에 들어간 원소가 먼저 나온다. 또는 `First In Last Out (FILO)` - 먼저 들어간 원소가 나중에 나온다. 이것은 Stack 의 가장 큰 특징이다. 차곡차곡 쌓이는 구조로 먼저 Stack 에 들어가게 된 원소는 맨 바닥에 깔리게 된다. 그렇기 때문에 늦게 들어간 녀석들은 그 위에 쌓이게 되고 호출 시 가장 위에 있는 녀석이 호출되는 구조이다. 추천 자료: * Stack 을 사용하여 미로찾기 구현하기 * Queue 를 사용하여 Heap 자료구조 구현하기 * Stack 두 개로 Queue 자료구조 구현하기 * Stack 으로 괄호 유효성 체크 코드 구현하기 ---
공통,자료구조,Stack and Queue에서 Queue은(는) 무엇인가요?,"선형 자료구조의 일종으로 `First In First Out (FIFO)`. 즉, 먼저 들어간 놈이 먼저 나온다. Stack 과는 반대로 먼저 들어간 놈이 맨 앞에서 대기하고 있다가 먼저 나오게 되는 구조이다. 참고로 Java Collection 에서 Queue 는 인터페이스이다. 이를 구현하고 있는 `Priority queue`등을 사용할 수 있다. #### Personal Recommendation * Stack 을 사용하여 미로찾기 구현하기 * Queue 를 사용하여 Heap 자료구조 구현하기 * Stack 두 개로 Queue 자료구조 구현하기 * Stack 으로 괄호 유효성 체크 코드 구현하기 --- 추천 자료: * Stack 을 사용하여 미로찾기 구현하기 * Queue 를 사용하여 Heap 자료구조 구현하기 * Stack 두 개로 Queue 자료구조 구현하기 * Stack 으로 괄호 유효성 체크 코드 구현하기 ---"
공통,자료구조,Tree은(는) 무엇인가요?,트리는 스택이나 큐와 같은 선형 구조가 아닌 비선형 자료구조이다. 트리는 계층적 관계(Hierarchical Relationship)을 표현하는 자료구조이다. 이 `트리`라는 자료구조는 표현에 집중한다. 무엇인가를 저장하고 꺼내야 한다는 사고에서 벗어나 트리라는 자료구조를 바라보자. 추천 자료: * Binary Search Tree 구현하기 * 주어진 트리가 Binary 트리인지 확인하는 알고리즘 구현하기
공통,자료구조,Tree에서 트리를 구성하고 있는 구성요소들(용어)은(는) 무엇인가요?,"* Node (노드) : 트리를 구성하고 있는 각각의 요소를 의미한다. * Edge (간선) : 트리를 구성하기 위해 노드와 노드를 연결하는 선을 의미한다. * Root Node (루트 노드) : 트리 구조에서 최상위에 있는 노드를 의미한다. * Terminal Node ( = leaf Node, 단말 노드) : 하위에 다른 노드가 연결되어 있지 않은 노드를 의미한다. * Internal Node (내부노드, 비단말 노드) : 단말 노드를 제외한 모든 노드로 루트 노드를 포함한다. 추천 자료: * Binary Search Tree 구현하기 * 주어진 트리가 Binary 트리인지 확인하는 알고리즘 구현하기"
공통,자료구조,Tree에서 Binary Tree (이진 트리)은(는) 무엇인가요?,"루트 노드를 중심으로 두 개의 서브 트리(큰 트리에 속하는 작은 트리)로 나뉘어 진다. 또한 나뉘어진 두 서브 트리도 모두 이진 트리어야 한다. 재귀적인 정의라 맞는듯 하면서도 이해가 쉽지 않을 듯하다. 한 가지 덧붙이자면 공집합도 이진 트리로 포함시켜야 한다. 그래야 재귀적으로 조건을 확인해갔을 때, leaf node 에 다다랐을 때, 정의가 만족되기 때문이다. 자연스럽게 노드가 하나 뿐인 것도 이진 트리 정의에 만족하게 된다. 트리에서는 각 `층별로` 숫자를 매겨서 이를 트리의 `Level(레벨)`이라고 한다. 레벨의 값은 0 부터 시작하고 따라서 루트 노드의 레벨은 0 이다. 그리고 트리의 최고 레벨을 가리켜 해당 트리의 `height(높이)`라고 한다. 추천 자료: * Binary Search Tree 구현하기 * 주어진 트리가 Binary 트리인지 확인하는 알고리즘 구현하기"
공통,자료구조,Tree에서 BST (Binary Search Tree)은(는) 무엇인가요?,"효율적인 탐색을 위해서는 어떻게 찾을까만 고민해서는 안된다. 그보다는 효율적인 탐색을 위한 저장방법이 무엇일까를 고민해야 한다. 이진 탐색 트리는 이진 트리의 일종이다. 단 이진 탐색 트리에는 데이터를 저장하는 규칙이 있다. 그리고 그 규칙은 특정 데이터의 위치를 찾는데 사용할 수 있다. * 규칙 1. 이진 탐색 트리의 노드에 저장된 키는 유일하다. * 규칙 2. 부모의 키가 왼쪽 자식 노드의 키보다 크다. * 규칙 3. 부모의 키가 오른쪽 자식 노드의 키보다 작다. * 규칙 4. 왼쪽과 오른쪽 서브트리도 이진 탐색 트리이다. 이진 탐색 트리의 탐색 연산은 O(log n)의 시간 복잡도를 갖는다. 사실 정확히 말하면 O(h)라고 표현하는 것이 맞다. 트리의 높이를 하나씩 더해갈수록 추가할 수 있는 노드의 수가 두 배씩 증가하기 때문이다. 하지만 이러한 이진 탐색 트리는 Skewed Tree(편향 트리)가 될 수 있다. 저장 순서에 따라 계속 한 쪽으로만 노드가 추가되는 경우가 발생하기 때문이다. 이럴 경우 성능에 영향을 미치게 되며, 탐색의 Worst Case 가 되고 시간 복잡도는 O(n)이 된다. 배열보다 많은 메모리를 사용하며 데이터를 저장했지만 탐색에 필요한 시간 복잡도가 같게 되는 비효율적인 상황이 발생한다. 이를 해결하기 위해 `Rebalancing` 기법이 등장하였다. 균형을 잡기 위한 트리 구조의 재조정을 `Rebalancing`이라 한다. 이 기법을 구현한 트리에는 여러 종류가 존재하는데 그 중에서 하나가 뒤에서 살펴볼 `Red-Black Tree`이다. #### Personal Recommendation * Binary Search Tree 구현하기 * 주어진 트리가 Binary 트리인지 확인하는 알고리즘 구현하기 추천 자료: * Binary Search Tree 구현하기 * 주어진 트리가 Binary 트리인지 확인하는 알고리즘 구현하기"
공통,자료구조,Binary Heap은(는) 무엇인가요?,"자료구조의 일종으로 Tree 의 형식을 하고 있으며, Tree 중에서도 배열에 기반한 `Complete Binary Tree`이다. 배열에 트리의 값들을 넣어줄 때, 0 번째는 건너뛰고 1 번 index 부터 루트노드가 시작된다. 이는 노드의 고유번호 값과 배열의 index 를 일치시켜 혼동을 줄이기 위함이다. `힙(Heap)`에는 `최대힙(max heap)`, `최소힙(min heap)` 두 종류가 있다. `Max Heap`이란, 각 노드의 값이 해당 children 의 값보다 크거나 같은 `complete binary tree`를 말한다. ( Min Heap 은 그 반대이다.) `Max Heap`에서는 Root node 에 있는 값이 제일 크므로, 최대값을 찾는데 소요되는 연산의 time complexity 이 O(1)이다. 그리고 `complete binary tree`이기 때문에 배열을 사용하여 효율적으로 관리할 수 있다. (즉, random access 가 가능하다. Min heap 에서는 최소값을 찾는데 소요되는 연산의 time complexity 가 O(1)이다.) 하지만 heap 의 구조를 계속 유지하기 위해서는 제거된 루트 노드를 대체할 다른 노드가 필요하다. 여기서 heap 은 맨 마지막 노드를 루트 노드로 대체시킨 후, 다시 heapify 과정을 거쳐 heap 구조를 유지한다. 이런 경우에는 결국 O(log n)의 시간복잡도로 최대값 또는 최소값에 접근할 수 있게 된다. #### Personal Recommendation * Heapify 구현하기 추천 자료: * Heapify 구현하기"
공통,자료구조,Red Black Tree은(는) 무엇인가요?,"RBT(Red-Black Tree)는 BST 를 기반으로하는 트리 형식의 자료구조이다. 결론부터 말하자면 Red-Black Tree 에 데이터를 저장하게되면 Search, Insert, Delete 에 O(log n)의 시간 복잡도가 소요된다. 동일한 노드의 개수일 때, depth 를 최소화하여 시간 복잡도를 줄이는 것이 핵심 아이디어이다. 동일한 노드의 개수일 때, depth 가 최소가 되는 경우는 tree 가 complete binary tree 인 경우이다."
공통,자료구조,Red Black Tree 의 Red의Black Tree 의 정의는 무엇인가요?,Red-Black Tree 는 다음의 성질들을 만족하는 BST 이다. 1. 각 노드는 `Red` or `Black`이라는 색깔을 갖는다. 2. Root node 의 색깔은 `Black`이다. 3. 각 leaf node 는 `black`이다. 4. 어떤 노드의 색깔이 `red`라면 두 개의 children 의 색깔은 모두 black 이다. 5. 각 노드에 대해서 노드로부터 descendant leaves 까지의 단순 경로는 모두 같은 수의 black nodes 들을 포함하고 있다. 이를 해당 노드의 `Black-Height`라고 한다.
공통,자료구조,Red Black Tree 의 Red의Black Tree 의 특징는 무엇인가요?,1. Binary Search Tree 이므로 BST 의 특징을 모두 갖는다. 2. Root node 부터 leaf node 까지의 모든 경로 중 최소 경로와 최대 경로의 크기 비율은 2 보다 크지 않다. 이러한 상태를 `balanced` 상태라고 한다. 3. 노드의 child 가 없을 경우 child 를 가리키는 포인터는 NIL 값을 저장한다. 이러한 NIL 들을 leaf node 로 간주한다.
공통,자료구조,Red Black Tree에서 삽입는 무엇인가요?,"우선 BST 의 특성을 유지하면서 노드를 삽입을 한다. 그리고 삽입된 노드의 색깔을 RED 로 지정한다. Red 로 지정하는 이유는 Black-Height 변경을 최소화하기 위함이다. 삽입 결과 RBT 의 특성 위배(violation)시 노드의 색깔을 조정하고, Black-Height 가 위배되었다면 rotation 을 통해 height 를 조정한다. 이러한 과정을 통해 RBT 의 동일한 height 에 존재하는 internal node 들의 Black-height 가 같아지게 되고 최소 경로와 최대 경로의 크기 비율이 2 미만으로 유지된다."
공통,자료구조,Red Black Tree에서 삭제는 무엇인가요?,"삭제도 삽입과 마찬가지로 BST 의 특성을 유지하면서 해당 노드를 삭제한다. 삭제될 노드의 child 의 개수에 따라 rotation 방법이 달라지게 된다. 그리고 만약 지워진 노드의 색깔이 Black 이라면 Black-Height 가 1 감소한 경로에 black node 가 1 개 추가되도록 rotation 하고 노드의 색깔을 조정한다. 지워진 노드의 색깔이 red 라면 Violation 이 발생하지 않으므로 RBT 가 그대로 유지된다. Java Collection 에서 TreeMap 도 내부적으로 RBT 로 이루어져 있고, HashMap 에서의 `Separate Chaining`에서도 사용된다. 그만큼 효율이 좋고 중요한 자료구조이다. ---"
공통,자료구조,Hash Table은(는) 무엇인가요?,"`hash`는 내부적으로 `배열`을 사용하여 데이터를 저장하기 때문에 빠른 검색 속도를 갖는다. 특정한 값을 Search 하는데 데이터 고유의 `인덱스`로 접근하게 되므로 average case 에 대하여 Time Complexity 가 O(1)이 되는 것이다.(항상 O(1)이 아니고 average case 에 대해서 O(1)인 것은 collision 때문이다.) 하지만 문제는 이 인덱스로 저장되는 `key`값이 불규칙하다는 것이다. 그래서 특별한 알고리즘을 이용하여 저장할 데이터와 연관된 고유한 숫자를 만들어 낸 뒤 이를 인덱스로 사용한다. 특정 데이터가 저장되는 인덱스는 그 데이터만의 고유한 위치이기 때문에, 삽입 연산 시 다른 데이터의 사이에 끼어들거나, 삭제 시 다른 데이터로 채울 필요가 없으므로 연산에서 추가적인 비용이 없도록 만들어진 구조이다."
공통,자료구조,Hash Table에서 Hash Function은(는) 무엇인가요?,특별한 알고리즘'이란 것을 통해 고유한 인덱스 값을 설정하는 것이 중요해보인다. 위에서 언급한 '특별한 알고리즘'을 `hash method` 또는 `해시 함수(hash function)`라고 하고 이 메소드에 의해 반환된 데이터의 고유 숫자 값을 `hashcode`라고 한다. 저장되는 값들의 key 값을 `hash function`을 통해서 작은 범위의 값들로 바꿔준다. 하지만 어설픈 `hash function`을 통해서 key 값들을 결정한다면 동일한 값이 도출될 수가 있다. 이렇게 되면 동일한 key 값에 복수 개의 데이터가 하나의 테이블에 존재할 수 있게 되는 것인데 이를 `Collision` 이라고 한다.
공통,자료구조,Hash Table에서 그렇다면 좋는 `hash function`는 어떠한 조건들을 갖추고 있어야 하는가?,일반적으로 좋은 `hash function`는 키의 일부분을 참조하여 해쉬 값을 만들지 않고 키 전체를 참조하여 해쉬 값을 만들어 낸다. 하지만 좋은 해쉬 함수는 키가 어떤 특성을 가지고 있느냐에 따라 달라지게 된다. `hash function`를 무조건 1:1 로 만드는 것보다 Collision 을 최소화하는 방향으로 설계하고 발생하는 Collision 에 대비해 어떻게 대응할 것인가가 더 중요하다. 1:1 대응이 되도록 만드는 것이 거의 불가능하기도 하지만 그런 `hash function`를 만들어봤자 그건 array 와 다를바 없고 메모리를 너무 차지하게 된다. Collision 이 많아질 수록 Search 에 필요한 Time Complexity 가 O(1)에서 O(n)에 가까워진다. 어설픈 `hash function`는 hash 를 hash 답게 사용하지 못하도록 한다. 좋은 `hash function`를 선택하는 것은 hash table 의 성능 향상에 필수적인 것이다. 따라서 hashing 된 인덱스에 이미 다른 값이 들어 있다면 새 데이터를 저장할 다른 위치를 찾은 뒤에야 저장할 수 있는 것이다. 따라서 충돌 해결은 필수이며 그 방법들에 대해 알아보자.
공통,자료구조,Hash Table에서 Resolve Conflict은(는) 무엇인가요?,"기본적인 두 가지 방법부터 알아보자. 해시 충돌을 해결하기 위한 다양한 자료가 있지만, 다음 두 가지 방법을 응용한 방법들이기 때문이다."
공통,자료구조,Hash Table에서 1. Open Address 방식 (개방주소법)은(는) 무엇인가요?,"해시 충돌이 발생하면, (즉 삽입하려는 해시 버킷이 이미 사용 중인 경우) 다른 해시 버킷에 해당 자료를 삽입하는 방식 이다. 버킷이란 바구니와 같은 개념으로 데이터를 저장하기 위한 공간이라고 생각하면 된다. 다른 해시 버킷이란 어떤 해시 버킷을 말하는 것인가? 공개 주소 방식이라고도 불리는 이 알고리즘은 Collision 이 발생하면 데이터를 저장할 장소를 찾아 헤맨다. Worst Case 의 경우 비어있는 버킷을 찾지 못하고 탐색을 시작한 위치까지 되돌아 올 수 있다. 이 과정에서도 여러 방법들이 존재하는데, 다음 세 가지에 대해 알아보자. 1. Linear Probing 순차적으로 탐색하며 비어있는 버킷을 찾을 때까지 계속 진행된다. 2. Quadratic probing 2 차 함수를 이용해 탐색할 위치를 찾는다. 3. Double hashing probing 하나의 해쉬 함수에서 충돌이 발생하면 2 차 해쉬 함수를 이용해 새로운 주소를 할당한다. 위 두 가지 방법에 비해 많은 연산량을 요구하게 된다."
공통,자료구조,Hash Table에서 2. Separate Chaining 방식 (분리 연결법)은(는) 무엇인가요?,"일반적으로 Open Addressing 은 Separate Chaining 보다 느리다. Open Addressing 의 경우 해시 버킷을 채운 밀도가 높아질수록 Worst Case 발생 빈도가 더 높아지기 때문이다. 반면 Separate Chaining 방식의 경우 해시 충돌이 잘 발생하지 않도록 보조 해시 함수를 통해 조정할 수 있다면 Worst Case 에 가까워 지는 빈도를 줄일 수 있다. Java 7 에서는 Separate Chaining 방식을 사용하여 HashMap 을 구현하고 있다. Separate Chaining 방식으로는 두 가지 구현 방식이 존재한다. * 연결 리스트를 사용하는 방식(Linked List) 각각의 버킷(bucket)들을 연결리스트(Linked List)로 만들어 Collision 이 발생하면 해당 bucket 의 list 에 추가하는 방식이다. 연결 리스트의 특징을 그대로 이어받아 삭제 또는 삽입이 간단하다. 하지만 단점도 그대로 물려받아 작은 데이터들을 저장할 때 연결 리스트 자체의 오버헤드가 부담이 된다. 또 다른 특징으로는, 버킷을 계속해서 사용하는 Open Address 방식에 비해 테이블의 확장을 늦출 수 있다. * Tree 를 사용하는 방식 (Red-Black Tree) 기본적인 알고리즘은 Separate Chaining 방식과 동일하며 연결 리스트 대신 트리를 사용하는 방식이다. 연결 리스트를 사용할 것인가와 트리를 사용할 것인가에 대한 기준은 하나의 해시 버킷에 할당된 key-value 쌍의 개수이다. 데이터의 개수가 적다면 링크드 리스트를 사용하는 것이 맞다. 트리는 기본적으로 메모리 사용량이 많기 때문이다. 데이터 개수가 적을 때 Worst Case 를 살펴보면 트리와 링크드 리스트의 성능 상 차이가 거의 없다. 따라서 메모리 측면을 봤을 때 데이터 개수가 적을 때는 링크드 리스트를 사용한다. 앞에서 말했듯이 기준은 하나의 해시 버킷에 할당된 key-value 쌍의 개수이다. 이 키-값 쌍의 개수가 6 개, 8 개를 기준으로 결정한다. 기준이 두 개 인것이 이상하게 느껴질 수 있다. 7 은 어디로 갔는가? 링크드 리스트의 기준과 트리의 기준을 6 과 8 로 잡은 것은 변경하는데 소요되는 비용을 줄이기 위함이다. 해시 버킷에 6 개 의 key-value 쌍이 들어있었다. 그리고 하나의 값이 추가되었다. 만약 기준이 6 과 7 이라면 자료구조를 링크드 리스트에서 트리로 변경해야 한다. 그러다 바로 하나의 값이 삭제된다면 다시 트리에서 링크드 리스트로 자료구조를 변경해야 한다. 각각 자료구조로 넘어가는 기준이 1 이라면 Switching 비용이 너무 많이 필요하게 되는 것이다. 그래서 2 라는 여유를 남겨두고 기준을 잡아준 것이다. 따라서 데이터의 개수가 6 개에서 7 개로 증가했을 때는 링크드 리스트의 자료구조를 취하고 있을 것이고 8 개에서 7 개로 감소했을 때는 트리의 자료구조를 취하고 있을 것이다."
공통,자료구조,Hash Table에서 `Open Address` vs `Separate Chaining`은(는) 무엇인가요?,일단 두 방식 모두 Worst Case 에서 O(M)이다. 하지만 `Open Address`방식은 연속된 공간에 데이터를 저장하기 때문에 `Separate Chaining`에 비해 캐시 효율이 높다. 따라서 데이터의 개수가 충분히 적다면 `Open Address`방식이 `Separate Chaining`보다 더 성능이 좋다. 한 가지 차이점이 더 존재한다. `Separate Chaining`방식에 비해 `Open Address`방식은 버킷을 계속해서 사용한다. 따라서 `Separate Chaining` 방식은 테이블의 확장을 보다 늦출 수 있다.
공통,자료구조,Hash Table에서 보조 해시 함수는 무엇인가요?,보조 해시 함수(supplement hash function)의 목적은 `key`의 해시 값을 변형하여 해시 충돌 가능성을 줄이는 것이다. `Separate Chaining` 방식을 사용할 때 함께 사용되며 보조 해시 함수로 Worst Case 에 가까워지는 경우를 줄일 수 있다.
공통,자료구조,Hash Table에서 해시 버킷 동적 확장(Resize)은(는) 무엇인가요?,해시 버킷의 개수가 적다면 메모리 사용을 아낄 수 있지만 해시 충돌로 인해 성능 상 손실이 발생한다. 그래서 HashMap 은 key-value 쌍 데이터 개수가 일정 개수 이상이 되면 해시 버킷의 개수를 두 배로 늘린다. 이렇게 늘리면 해시 충돌로 인한 성능 손실 문제를 어느 정도 해결할 수 있다. 또 애매모호한 '일정 개수 이상'이라는 표현이 등장했다. 해시 버킷 크기를 두 배로 확장하는 임계점은 현재 데이터 개수가 해시 버킷의 개수의 75%가 될 때이다. `0.75`라는 숫자는 load factor 라고 불린다.
공통,자료구조,Graph에서 Undirected Graph 와 Directed Graph (Digraph)은(는) 무엇인가요?,"말 그대로 정점과 간선의 연결관계에 있어서 방향성이 없는 그래프를 Undirected Graph 라 하고, 간선에 방향성이 포함되어 있는 그래프를 Directed Graph 라고 한다. * Directed Graph (Digraph) ``` V = {1, 2, 3, 4, 5, 6} E = {(1, 4), (2,1), (3, 4), (3, 4), (5, 6)} (u, v) = vertex u에서 vertex v로 가는 edge ``` * Undirected Graph ``` V = {1, 2, 3, 4, 5, 6} E = {(1, 4), (2,1), (3, 4), (3, 4), (5, 6)} (u, v) = vertex u와 vertex v를 연결하는 edge ```"
공통,자료구조,Graph에서 Degree은(는) 무엇인가요?,"Undirected Graph 에서 각 정점(Vertex)에 연결된 Edge 의 개수를 Degree 라 한다. Directed Graph 에서는 간선에 방향성이 존재하기 때문에 Degree 가 두 개로 나뉘게 된다. 각 정점으로부터 나가는 간선의 개수를 Outdegree 라 하고, 들어오는 간선의 개수를 Indegree 라 한다."
공통,자료구조,Graph에서 가중치 그래프(Weight Graph)와 부분 그래프(Sub Graph)은(는) 무엇인가요?,"가중치 그래프란 간선에 가중치 정보를 두어서 구성한 그래프를 말한다. 반대의 개념인 비가중치 그래프 즉, 모든 간선의 가중치가 동일한 그래프도 물론 존재한다. 부분 집합과 유사한 개념으로 부분 그래프라는 것이 있다. 부분 그래프는 본래의 그래프의 일부 정점 및 간선으로 이루어진 그래프를 말한다."
공통,자료구조,Graph에서 인접 행렬 (adjacent matrix) : 정방 행렬을 사용하는 방법는 무엇인가요?,해당하는 위치의 value 값을 통해서 vertex 간의 연결 관계를 O(1) 으로 파악할 수 있다. Edge 개수와는 무관하게 V^2 의 Space Complexity 를 갖는다. Dense graph 를 표현할 때 적절할 방법이다.
공통,자료구조,Graph에서 인접 리스트 (adjacent list) : 연결 리스트를 사용하는 방법는 무엇인가요?,vertex 의 adjacent list 를 확인해봐야 하므로 vertex 간 연결되어있는지 확인하는데 오래 걸린다. Space Complexity 는 O(E + V)이다. Sparse graph 를 표현하는데 적당한 방법이다.
공통,자료구조,그래프 탐색는 무엇인가요?,그래프는 정점의 구성 뿐만 아니라 간선의 연결에도 규칙이 존재하지 않기 때문에 탐색이 복잡하다. 따라서 그래프의 모든 정점을 탐색하기 위한 방법은 다음의 두 가지 알고리즘을 기반으로 한다.
공통,자료구조,Graph에서 깊이 우선 탐색 (Depth First Search: DFS)은(는) 무엇인가요?,그래프 상에 존재하는 임의의 한 정점으로부터 연결되어 있는 한 정점으로만 나아간다라는 방법을 우선으로 탐색한다. 일단 연결된 정점으로 탐색하는 것이다. 연결할 수 있는 정점이 있을 때까지 계속 연결하다가 더 이상 연결될 수 있는 정점이 없으면 바로 그 전 단계의 정점으로 돌아가서 연결할 수 있는 정점이 있는지 살펴봐야 할 것이다. 갔던 길을 되돌아 오는 상황이 존재하는 미로찾기처럼 구성하면 되는 것이다. 어떤 자료구조를 사용해야할까? 바로 Stack 이다. Time Complexity : O(V+E) … vertex 개수 + edge 개수
공통,자료구조,Graph에서 너비 우선 탐색 (Breadth First Search: BFS)은(는) 무엇인가요?,"그래프 상에 존재하는 임의의 한 정점으로부터 연결되어 있는 모든 정점으로 나아간다. Tree 에서의 Level Order Traversal 형식으로 진행되는 것이다. BFS 에서는 자료구조로 Queue 를 사용한다. 연락을 취할 정점의 순서를 기록하기 위한 것이다. 우선, 탐색을 시작하는 정점을 Queue 에 넣는다.(enqueue) 그리고 dequeue 를 하면서 dequeue 하는 정점과 간선으로 연결되어 있는 정점들을 enqueue 한다. 즉 vertex 들을 방문한 순서대로 queue 에 저장하는 방법을 사용하는 것이다. Time Complexity : O(V+E) … vertex 개수 + edge 개수"
공통,자료구조,Graph에서 Minimum Spanning Tree은(는) 무엇인가요?,그래프 G 의 spanning tree 중 edge weight 의 합이 최소인 `spanning tree`를 말한다. 여기서 말하는 `spanning tree`란 그래프 G 의 모든 vertex 가 cycle 이 없이 연결된 형태를 말한다.
공통,자료구조,Graph에서 Kruskal Algorithm은(는) 무엇인가요?,초기화 작업으로 edge 없이 vertex 들만으로 그래프를 구성한다. 그리고 weight 가 제일 작은 edge 부터 검토한다. 그러기 위해선 Edge Set 을 non-decreasing 으로 sorting 해야 한다. 그리고 가장 작은 weight 에 해당하는 edge 를 추가하는데 추가할 때 그래프에 cycle 이 생기지 않는 경우에만 추가한다. spanning tree 가 완성되면 모든 vertex 들이 연결된 상태로 종료가 되고 완성될 수 없는 그래프에 대해서는 모든 edge 에 대해 판단이 이루어지면 종료된다. [Kruskal Algorithm의 세부 동작과정] [Kruskal Algorithm 관련 Code]
공통,자료구조,Graph에서 어떻게 cycle 생성 여부를 판단하는가?,"Graph 의 각 vertex 에 `set-id`라는 것을 추가적으로 부여한다. 그리고 초기화 과정에서 모두 1~n 까지의 값으로 각각의 vertex 들을 초기화 한다. 여기서 0 은 어떠한 edge 와도 연결되지 않았음을 의미하게 된다. 그리고 연결할 때마다 `set-id`를 하나로 통일시키는데, 값이 동일한 `set-id` 개수가 많은 `set-id` 값으로 통일시킨다."
공통,자료구조,Graph에서 Time Complexity은(는) 무엇인가요?,1. Edge 의 weight 를 기준으로 sorting - O(E log E) 2. cycle 생성 여부를 검사하고 set-id 를 통일 - O(E + V log V) => 전체 시간 복잡도 : O(E log E)
공통,자료구조,Graph에서 Prim Algorithm은(는) 무엇인가요?,초기화 과정에서 한 개의 vertex 로 이루어진 초기 그래프 A 를 구성한다. 그리고나서 그래프 A 내부에 있는 vertex 로부터 외부에 있는 vertex 사이의 edge 를 연결하는데 그 중 가장 작은 weight 의 edge 를 통해 연결되는 vertex 를 추가한다. 어떤 vertex 건 간에 상관없이 edge 의 weight 를 기준으로 연결하는 것이다. 이렇게 연결된 vertex 는 그래프 A 에 포함된다. 위 과정을 반복하고 모든 vertex 들이 연결되면 종료한다.
공통,자료구조,Graph에서 Time Complexity은(는) 무엇인가요?,#ERROR!
BACKEND,네트워크,HTTP의 GET과 POST 비교,둘 다 HTTP 프로토콜을 이용해서 서버에 무엇인가를 요청할 때 사용하는 방식이다. 하지만 둘의 특징을 제대로 이해하여 기술의 목적에 맞게 알맞은 용도에 사용해야한다.
BACKEND,네트워크,HTTP에서 GET은(는) 무엇인가요?,우선 GET 방식은 요청하는 데이터가 `HTTP Request Message`의 Header 부분에 url 이 담겨서 전송된다. 때문에 url 상에 `?` 뒤에 데이터가 붙어 request 를 보내게 되는 것이다. 이러한 방식은 url 이라는 공간에 담겨가기 때문에 전송할 수 있는 데이터의 크기가 제한적이다. 또 보안이 필요한 데이터에 대해서는 데이터가 그대로 url 에 노출되므로 `GET`방식은 적절하지 않다. (ex. password)
BACKEND,네트워크,HTTP에서 POST은(는) 무엇인가요?,POST 방식의 request 는 `HTTP Request Message`의 Body 부분에 데이터가 담겨서 전송된다. 때문에 바이너리 데이터를 요청하는 경우 POST 방식으로 보내야 하는 것처럼 데이터 크기가 GET 방식보다 크고 보안면에서 낫다.(하지만 보안적인 측면에서는 암호화를 하지 않는 이상 고만고만하다.) 우선 GET 은 가져오는 것이다. 서버에서 어떤 데이터를 가져와서 보여준다거나 하는 용도이지 서버의 값이나 상태 등을 변경하지 않는다. SELECT 적인 성향을 갖고 있다고 볼 수 있는 것이다. 반면에 POST 는 서버의 값이나 상태를 변경하기 위해서 또는 추가하기 위해서 사용된다. 부수적인 차이점을 좀 더 살펴보자면 GET 방식의 요청은 브라우저에서 Caching 할 수 있다. 때문에 POST 방식으로 요청해야 할 것을 보내는 데이터의 크기가 작고 보안적인 문제가 없다는 이유로 GET 방식으로 요청한다면 기존에 caching 되었던 데이터가 응답될 가능성이 존재한다. 때문에 목적에 맞는 기술을 사용해야 하는 것이다.
BACKEND,네트워크,TCP에서 way Handshake은(는) 무엇인가요?,일부 그림이 포함되어야 하는 설명이므로 링크를 대신 첨부합니다.
BACKEND,네트워크,UDP은(는) 무엇인가요?,"`UDP(User Datagram Protocol, 사용자 데이터그램 프로토콜)`는 비연결형 프로토콜 이다. IP 데이터그램을 캡슐화하여 보내는 방법과 연결 설정을 하지 않고 보내는 방법을 제공한다. `UDP`는 흐름제어, 오류제어 또는 손상된 세그먼트의 수신에 대한 재전송을 하지 않는다. 이 모두가 사용자 프로세스의 몫이다. `UDP`가 행하는 것은 포트들을 사용하여 IP 프로토콜에 인터페이스를 제공하는 것이다. 종종 클라이언트는 서버로 짧은 요청을 보내고, 짧은 응답을 기대한다. 만약 요청 또는 응답이 손실된다면, 클라이언트는 time out 되고 다시 시도할 수 있으면 된다. 코드가 간단할 뿐만 아니라 TCP 처럼 초기설정(initial setup)에서 요구되는 프로토콜보다 적은 메시지가 요구된다. `UDP`를 사용한 것들에는 `DNS`가 있다. 어떤 호스트 네임의 IP 주소를 찾을 필요가 있는 프로그램은, DNS 서버로 호스트 네임을 포함한 UDP 패킷을 보낸다. 이 서버는 호스트의 IP 주소를 포함한 UDP 패킷으로 응답한다. 사전에 설정이 필요하지 않으며 그 후에 해제가 필요하지 않다."
BACKEND,네트워크,TCP은(는) 무엇인가요?,"대부분의 인터넷 응용 분야들은 신뢰성 과 순차적인 전달 을 필요로 한다. UDP 로는 이를 만족시킬 수 없으므로 다른 프로토콜이 필요하여 탄생한 것이 `TCP`이다. `TCP(Transmission Control Protocol, 전송제어 프로토콜)`는 신뢰성이 없는 인터넷을 통해 종단간에 신뢰성 있는 바이트 스트림을 전송 하도록 특별히 설계되었다. TCP 서비스는 송신자와 수신자 모두가 소켓이라고 부르는 종단점을 생성함으로써 이루어진다. TCP 에서 연결 설정(connection establishment)는 `3-way handshake`를 통해 행해진다. 모든 TCP 연결은 전이중(full-duplex), 점대점(point to point)방식이다. 전이중이란 전송이 양방향으로 동시에 일어날 수 있음을 의미하며 점대점이란 각 연결이 정확히 2 개의 종단점을 가지고 있음을 의미한다. TCP 는 멀티캐스팅이나 브로드캐스팅을 지원하지 않는다."
BACKEND,네트워크,HTTP 의 문제점?,#NAME?
BACKEND,네트워크,HTTP와 HTTPS에서 보완 방법는 무엇인가요?,"1. 통신 자체를 암호화 `SSL(Secure Socket Layer)` or `TLS(Transport Layer Security)`라는 다른 프로토콜을 조합함으로써 HTTP 의 통신 내용을 암호화할 수 있다. SSL 을 조합한 HTTP 를 `HTTPS(HTTP Secure)` or `HTTP over SSL`이라고 부른다. 2. 콘텐츠를 암호화 말 그대로 HTTP 를 사용해서 운반하는 내용인, HTTP 메시지에 포함되는 콘텐츠만 암호화하는 것이다. 암호화해서 전송하면 받은 측에서는 그 암호를 해독하여 출력하는 처리가 필요하다."
BACKEND,네트워크,HTTP와 HTTPS에서 통신 상대를 확인하지 않기 때문에 위장이 가능하다.은(는) 무엇인가요?,HTTP 에 의한 통신에는 상대가 누구인지 확인하는 처리는 없기 때문에 누구든지 리퀘스트를 보낼 수 있다. IP 주소나 포트 등에서 그 웹 서버에 액세스 제한이 없는 경우 리퀘스트가 오면 상대가 누구든지 무언가의 리스폰스를 반환한다. 이러한 특징은 여러 문제점을 유발한다. 1. 리퀘스트를 보낸 곳의 웹 서버가 원래 의도한 리스폰스를 보내야 하는 웹 서버인지를 확인할 수 없다. 2. 리스폰스를 반환한 곳의 클라이언트가 원래 의도한 리퀘스트를 보낸 클라이언트인지를 확인할 수 없다. 3. 통신하고 있는 상대가 접근이 허가된 상대인지를 확인할 수 없다. 4. 어디에서 누가 리퀘스트 했는지 확인할 수 없다. 5. 의미없는 리퀘스트도 수신한다. ?> DoS 공격을 방지할 수 없다.
BACKEND,네트워크,HTTP와 HTTPS에서 보완 방법는 무엇인가요?,위 암호화 방법으로 언급된 `SSL`로 상대를 확인할 수 있다. SSL 은 상대를 확인하는 수단으로 증명서 를 제공하고 있다. 증명서는 신뢰할 수 있는 제 3 자 기관에 의해 발행되는 것이기 때문에 서버나 클라이언트가 실재하는 사실을 증명한다. 이 증명서를 이용함으로써 통신 상대가 내가 통신하고자 하는 서버임을 나타내고 이용자는 개인 정보 누설 등의 위험성이 줄어들게 된다. 한 가지 이점을 더 꼽자면 클라이언트는 이 증명서로 본인 확인을 하고 웹 사이트 인증에서도 이용할 수 있다.
BACKEND,네트워크,HTTP와 HTTPS에서 완전성을 증명할 수 없기 때문에 변조가 가능하인가요?,여기서 완전성이란 정보의 정확성 을 의미한다. 서버 또는 클라이언트에서 수신한 내용이 송신측에서 보낸 내용과 일치한다라는 것을 보장할 수 없는 것이다. 리퀘스트나 리스폰스가 발신된 후에 상대가 수신하는 사이에 누군가에 의해 변조되더라도 이 사실을 알 수 없다. 이와 같이 공격자가 도중에 리퀘스트나 리스폰스를 빼앗아 변조하는 공격을 중간자 공격(Man-in-the-Middle)이라고 부른다.
BACKEND,네트워크,HTTP와 HTTPS에서 보완 방법는 무엇인가요?,"`MD5`, `SHA-1` 등의 해시 값을 확인하는 방법과 파일의 디지털 서명을 확인하는 방법이 존재하지만 확실히 확인할 수 있는 것은 아니다. 확실히 방지하기에는 `HTTPS`를 사용해야 한다. SSL 에는 인증이나 암호화, 그리고 다이제스트 기능을 제공하고 있다."
BACKEND,네트워크,HTTPS은(는) 무엇인가요?,"> HTTP 에 암호화와 인증, 그리고 완전성 보호를 더한 HTTPS `HTTPS`는 SSL 의 껍질을 덮어쓴 HTTP 라고 할 수 있다. 즉, HTTPS 는 새로운 애플리케이션 계층의 프로토콜이 아니라는 것이다. HTTP 통신하는 소켓 부분을 `SSL(Secure Socket Layer)` or `TLS(Transport Layer Security)`라는 프로토콜로 대체하는 것 뿐이다. HTTP 는 원래 TCP 와 직접 통신했지만, HTTPS 에서 HTTP 는 SSL 과 통신하고 SSL 이 TCP 와 통신 하게 된다. SSL 을 사용한 HTTPS 는 암호화와 증명서, 안전성 보호를 이용할 수 있게 된다. HTTPS 의 SSL 에서는 공통키 암호화 방식과 공개키 암호화 방식을 혼합한 하이브리드 암호 시스템을 사용한다. 공통키를 공개키 암호화 방식으로 교환한 다음에 다음부터의 통신은 공통키 암호를 사용하는 방식이다."
BACKEND,네트워크,모든 웹 페이지에서 HTTPS를 사용해도 될까?,"평문 통신에 비해서 암호화 통신은 CPU나 메모리 등 리소스를 더 많이 요구한다. 통신할 때마다 암호화를 하면 추가적인 리소스를 소비하기 때문에 서버 한 대당 처리할 수 있는 리퀘스트의 수가 상대적으로 줄어들게 된다. 하지만 최근에는 하드웨어의 발달로 인해 HTTPS를 사용하더라도 속도 저하가 거의 일어나지 않으며, 새로운 표준인 HTTP 2.0을 함께 이용한다면 오히려 HTTPS가 HTTP보다 더 빠르게 동작한다. 따라서 웹은 과거의 민감한 정보를 다룰 때만 HTTPS에 의한 암호화 통신을 사용하는 방식에서 현재 모든 웹 페이지에서 HTTPS를 적용하는 방향으로 바뀌어가고 있다."
BACKEND,네트워크,DNS round robin 방식에서 DNS Round Robin 방식의 문제점는 무엇인가요?,"1. 서버의 수 만큼 공인 IP 주소가 필요함. <br/> 부하 분산을 위해 서버의 대수를 늘리기 위해서는 그 만큼의 공인 IP 가 필요하다. 2. 균등하게 분산되지 않음. <br/> 모바일 사이트 등에서 문제가 될 수 있는데, 스마트폰의 접속은 캐리어 게이트웨이 라고 하는 프록시 서버를 경유 한다. 프록시 서버에서는 이름변환 결과가 일정 시간 동안 캐싱되므로 같은 프록시 서버를 경유 하는 접속은 항상 같은 서버로 접속된다. 또한 PC 용 웹 브라우저도 DNS 질의 결과를 캐싱하기 때문에 균등하게 부하분산 되지 않는다. DNS 레코드의 TTL 값을 짧게 설정함으로써 어느 정도 해소가 되지만, TTL 에 따라 캐시를 해제하는 것은 아니므로 반드시 주의가 필요하다. 3. 서버가 다운되도 확인 불가. <br/> DNS 서버는 웹 서버의 부하나 접속 수 등의 상황에 따라 질의결과를 제어할 수 없다. 웹 서버의 부하가 높아서 응답이 느려지거나 접속수가 꽉 차서 접속을 처리할 수 없는 상황인 지를 전혀 감지할 수가 없기 때문에 어떤 원인으로 다운되더라도 이를 검출하지 못하고 유저들에게 제공한다. 이때문에 유저들은 간혹 다운된 서버로 연결이 되기도 한다. DNS 라운드 로빈은 어디까지나 부하분산 을 위한 방법이지 다중화 방법은 아니므로 다른 S/W 와 조합해서 관리할 필요가 있다."
BACKEND,네트워크,DNS round robin 방식에서 Weighted round robin (WRR)은(는) 무엇인가요?,각각의 웹 서버에 가중치를 가미해서 분산 비율을 변경한다. 물론 가중치가 큰 서버일수록 빈번하게 선택되므로 처리능력이 높은 서버는 가중치를 높게 설정하는 것이 좋다.
BACKEND,네트워크,DNS round robin 방식에서 Least connection은(는) 무엇인가요?,접속 클라이언트 수가 가장 적은 서버를 선택한다. 로드밸런서에서 실시간으로 connection 수를 관리하거나 각 서버에서 주기적으로 알려주는 것이 필요하다.
BACKEND,네트워크,브라우저는 무엇인가요?,"1. url 에 입력된 값을 브라우저 내부에서 결정된 규칙에 따라 그 의미를 조사한다. 2. 조사된 의미에 따라 HTTP Request 메시지를 만든다. 3. 만들어진 메시지를 웹 서버로 전송한다. 이 때 만들어진 메시지 전송은 브라우저가 직접하는 것이 아니다. 브라우저는 메시지를 네트워크에 송출하는 기능이 없으므로 OS에 의뢰하여 메시지를 전달한다. 우리가 택배를 보낼 때 직접 보내는게 아니라, 이미 서비스가 이루어지고 있는 택배 시스템(택배 회사)을 이용하여 보내는 것과 같은 이치이다. 단, OS에 송신을 의뢰할 때는 도메인명이 아니라 ip주소로 메시지를 받을 상대를 지정해야 하는데, 이 과정에서 DNS서버를 조회해야 한다. 추천 자료: - (도서) [성공과 실패를 결정하는 1% 네트워크 원리] - (도서) [그림으로 배우는 Http&Network basic] - (도서) [HTTP 완벽 가이드] - Socket programming (Multi-chatting program)"
BACKEND,네트워크,"프로토콜 스택, LAN 어댑터는 무엇인가요?","1. 프로토콜 스택(운영체제에 내장된 네트워크 제어용 소프트웨어)이 브라우저로부터 메시지를 받는다. 2. 브라우저로부터 받은 메시지를 패킷 속에 저장한다. 3. 그리고 수신처 주소 등의 제어정보를 덧붙인다. 4. 그런 다음, 패킷을 LAN 어댑터에 넘긴다. 5. LAN 어댑터는 다음 Hop의 MAC주소를 붙인 프레임을 전기신호로 변환시킨다. 6. 신호를 LAN 케이블에 송출시킨다. 프로토콜 스택은 통신 중 오류가 발생했을 때, 이 제어 정보를 사용하여 고쳐 보내거나, 각종 상황을 조절하는 등 다양한 역할을 하게 된다. 네트워크 세계에서는 비서가 있어서 우리가 비서에게 물건만 건네주면, 받는 사람의 주소와 각종 유의사항을 써준다! 여기서는 프로토콜 스택이 비서의 역할을 한다고 볼 수 있다. 추천 자료: - (도서) [성공과 실패를 결정하는 1% 네트워크 원리] - (도서) [그림으로 배우는 Http&Network basic] - (도서) [HTTP 완벽 가이드] - Socket programming (Multi-chatting program)"
BACKEND,네트워크,"허브, 스위치, 라우터는 무엇인가요?",1. LAN 어댑터가 송신한 프레임은 스위칭 허브를 경유하여 인터넷 접속용 라우터에 도착한다. 2. 라우터는 패킷을 프로바이더(통신사)에게 전달한다. 3. 인터넷으로 들어가게 된다. 추천 자료: - (도서) [성공과 실패를 결정하는 1% 네트워크 원리] - (도서) [그림으로 배우는 Http&Network basic] - (도서) [HTTP 완벽 가이드] - Socket programming (Multi-chatting program)
BACKEND,네트워크,"액세스 회선, 프로바이더는 무엇인가요?","1. 패킷은 인터넷의 입구에 있는 액세스 회선(통신 회선)에 의해 POP(Point Of Presence, 통신사용 라우터)까지 운반된다. 2. POP 를 거쳐 인터넷의 핵심부로 들어가게 된다. 3. 수 많은 고속 라우터들 사이로 패킷이 목적지를 향해 흘러가게 된다. 추천 자료: - (도서) [성공과 실패를 결정하는 1% 네트워크 원리] - (도서) [그림으로 배우는 Http&Network basic] - (도서) [HTTP 완벽 가이드] - Socket programming (Multi-chatting program)"
BACKEND,네트워크,"방화벽, 캐시서버는 무엇인가요?",1. 패킷은 인터넷 핵심부를 통과하여 웹 서버측의 LAN 에 도착한다. 2. 기다리고 있던 방화벽이 도착한 패킷을 검사한다. 3. 패킷이 웹 서버까지 가야하는지 가지 않아도 되는지를 판단하는 캐시서버가 존재한다. 굳이 서버까지 가지 않아도 되는 경우를 골라낸다. 액세스한 페이지의 데이터가 캐시서버에 있으면 웹 서버에 의뢰하지 않고 바로 그 값을 읽을 수 있다. 페이지의 데이터 중에 다시 이용할 수 있는 것이 있으면 캐시 서버에 저장된다. 추천 자료: - (도서) [성공과 실패를 결정하는 1% 네트워크 원리] - (도서) [그림으로 배우는 Http&Network basic] - (도서) [HTTP 완벽 가이드] - Socket programming (Multi-chatting program)
BACKEND,네트워크,웹 서버는 무엇인가요?,1. 패킷이 물리적인 웹 서버에 도착하면 웹 서버의 프로토콜 스택은 패킷을 추출하여 메시지를 복원하고 웹 서버 애플리케이션에 넘긴다. 2. 메시지를 받은 웹 서버 애플리케이션은 요청 메시지에 따른 데이터를 응답 메시지에 넣어 클라이언트로 회송한다. 3. 왔던 방식대로 응답 메시지가 클라이언트에게 전달된다. #### Personal Recommendation - (도서) [성공과 실패를 결정하는 1% 네트워크 원리] - (도서) [그림으로 배우는 Http&Network basic] - (도서) [HTTP 완벽 가이드] - Socket programming (Multi-chatting program) 추천 자료: - (도서) [성공과 실패를 결정하는 1% 네트워크 원리] - (도서) [그림으로 배우는 Http&Network basic] - (도서) [HTTP 완벽 가이드] - Socket programming (Multi-chatting program)
BACKEND,운영체제,프로세스(Process)은(는) 무엇인가요?,"프로세스는 실행 중인 프로그램으로, 디스크로부터 메모리에 적재되어 CPU 의 할당을 받을 수 있는 것을 말한다. 운영체제로부터 주소 공간, 파일, 메모리 등을 할당받으며 이것들을 총칭하여 프로세스라고 한다. 구체적으로 살펴보면 프로세스는 함수의 매개 변수, 복귀 주소, 로컬 변수와 같은 임시 자료를 갖는 프로세스 스택과 전역 변수들을 수록하는 데이터 섹션을 포함한다. 또한 프로세스는 프로세스 실행 중에 동적으로 할당되는 메모리인 힙을 포함한다."
BACKEND,운영체제,"프로세스 제어 블록(Process Control Block, PCB)은(는) 무엇인가요?","PCB 는 특정 프로세스에 대한 중요한 정보를 저장 하고 있는 운영체제의 자료 구조이다. 운영체제는 프로세스를 관리하기 위해 프로세스의 생성과 동시에 고유한 PCB 를 생성 한다. 프로세스는 CPU 를 할당받아 작업을 처리하다가도 프로세스 전환이 발생하면 진행하던 작업을 저장하고 CPU 를 반환해야 하는데, 이때 작업의 진행 상황을 모두 PCB 에 저장하게 된다. 그리고 다시 CPU 를 할당받게 되면 PCB 에 저장되어 있던 내용을 불러와 이전에 종료됐던 시점부터 다시 작업을 수행한다. * 프로세스 식별자(Process ID, PID) : 프로세스 식별 번호 * 프로세스 상태 : new, ready, running, waiting, terminated 등의 상태를 저장 * 프로그램 카운터 : 프로세스가 다음에 실행할 명령어의 주소 * CPU 레지스터 * CPU 스케줄링 정보 : 프로세스의 우선순위, 스케줄 큐에 대한 포인터 등 * 메모리 관리 정보 : 페이지 테이블 또는 세그먼트 테이블 등과 같은 정보를 포함 * 입출력 상태 정보 : 프로세스에 할당된 입출력 장치들과 열린 파일 목록 * 어카운팅 정보 : 사용된 CPU 시간, 시간제한, 계정 번호 등"
BACKEND,운영체제,스레드(Thread)은(는) 무엇인가요?,"스레드는 프로세스의 실행 단위라고 할 수 있다. 한 프로세스 내에서 동작하는 여러 실행 흐름으로, 프로세스 내의 주소 공간이나 자원을 공유할 수 있다. 스레드는 스레드 ID, 프로그램 카운터, 레지스터 집합, 그리고 스택으로 구성된다. 같은 프로세스에 속한 다른 스레드와 코드, 데이터 섹션, 그리고 열린 파일이나 신호와 같은 운영체제 자원들을 공유한다. 하나의 프로세스를 다수의 실행 단위로 구분하여 자원을 공유하고 자원의 생성과 관리의 중복성을 최소화하여 수행 능력을 향상하는 것을 멀티스레딩이라고 한다. 이 경우 각각의 스레드는 독립적인 작업을 수행해야 하기 때문에 각자의 스택과 PC 레지스터 값을 갖고 있다."
BACKEND,운영체제,스택을 스레드마다 독립적으로 할당하는 이유는 무엇인가요?,"스택은 함수 호출 시 전달되는 인자, 되돌아갈 주소값 및 함수 내에서 선언하는 변수 등을 저장하기 위해 사용되는 메모리 공간이므로 스택 메모리 공간이 독립적이라는 것은 독립적인 함수 호출이 가능하다는 것이고 이는 독립적인 실행 흐름이 추가되는 것이다. 따라서 스레드의 정의에 따라 독립적인 실행 흐름을 추가하기 위한 최소 조건으로 독립된 스택을 할당한다."
BACKEND,운영체제,PC Register 를 스레드마다 독립적으로 할당하는 이유는 무엇인가요?,"PC 값은 스레드가 명령어의 어디까지 수행하였는지를 나타낸다. 스레드는 CPU 를 할당받았다가 스케줄러에 의해 다시 선점당한다. 그렇기 때문에 명령어가 연속적으로 수행되지 못하고, 어느 부분까지 수행했는지 기억할 필요가 있다. 따라서 PC 레지스터를 독립적으로 할당한다. ---"
BACKEND,운영체제,멀티스레딩의 장점는 무엇인가요?,프로세스를 이용하여 동시에 처리하던 일을 스레드로 구현할 경우 메모리 공간과 시스템 자원 소모가 줄어들게 된다. 스레드 간의 통신이 필요한 경우에도 별도의 자원을 이용하는 것이 아니라 전역 변수의 공간 또는 동적으로 할당된 공간인 힙 영역을 이용하여 데이터를 주고받을 수 있다. 그렇기 때문에 프로세스 간 통신 방법에 비해 스레드 간 통신 방법이 훨씬 간단하다. 심지어 스레드의 context switch 는 프로세스 context switch 와는 달리 캐시 메모리를 비울 필요가 없기 때문에 더 빠르다. 따라서 시스템의 throughput 이 향상되고 자원 소모가 줄어들며 자연스럽게 프로그램의 응답 시간이 단축된다. 이러한 장점 때문에 여러 프로세스로 할 수 있는 작업들을 하나의 프로세스에서 스레드로 나눠 수행하는 것이다.
BACKEND,운영체제,멀티스레딩의 문제점는 무엇인가요?,"멀티프로세스 기반으로 프로그래밍할 때는 프로세스 간 공유하는 자원이 없기 때문에 동일한 자원에 동시에 접근하는 일이 없었지만, 멀티스레딩을 기반으로 프로그래밍할 때는 이 부분을 신경 써야 한다. 서로 다른 스레드가 데이터와 힙 영역을 공유하기 때문에 어떤 스레드가 다른 스레드에서 사용 중인 변수나 자료 구조에 접근하여 엉뚱한 값을 읽어오거나 수정할 수 있다. 그렇기 때문에 멀티스레딩 환경에서는 동기화 작업이 필요하다. 동기화를 통해 작업 처리 순서를 컨트롤하고 공유 자원에 대한 접근을 컨트롤하는 것이다. 하지만 이로 인해 병목 현상이 발생하여 성능이 저하될 가능성이 높다. 그러므로 과도한 록(lock)으로 인한 병목 현상을 줄여야 한다."
BACKEND,운영체제,멀티스레드 vs 멀티프로세스는 무엇인가요?,"멀티스레드는 멀티프로세스보다 적은 메모리 공간을 차지하고 문맥 전환이 빠르다는 장점이 있지만, 오류로 인해 하나의 스레드가 종료되면 전체 스레드가 종료될 수 있다는 점과 동기화 문제를 안고 있다. 반면 멀티프로세스 방식은 하나의 프로세스가 죽더라도 다른 프로세스에는 영향을 끼치지 않고 정상적으로 수행된다는 장점이 있지만, 멀티스레드보다 많은 메모리 공간과 CPU 시간을 차지한다는 단점이 존재한다. 이 두 가지는 동시에 여러 작업을 수행한다는 점에서 같지만 적용해야 하는 시스템에 따라 적합/부적합이 구분된다. 따라서 대상 시스템의 특징에 따라 적합한 동작 방식을 선택하고 적용해야 한다. ---"
BACKEND,운영체제,스케줄러는 무엇인가요?,* Job Queue : 현재 시스템 내에 있는 모든 프로세스의 집합 * Ready Queue : 현재 메모리 내에 있으면서 CPU 를 잡아서 실행되기를 기다리는 프로세스의 집합 * Device Queue : Device I/O 작업을 대기하고 있는 프로세스의 집합 각각의 Queue 에 프로세스들을 넣고 빼주는 스케줄러에도 크게 세 가지 종류가 존재한다.
BACKEND,운영체제,장기스케줄러(Long의term scheduler or job scheduler)은(는) 무엇인가요?,"메모리는 한정되어 있는데 많은 프로세스들이 한꺼번에 메모리에 올라올 경우, 대용량 메모리(일반적으로 디스크)에 임시로 저장된다. 이 pool 에 저장되어 있는 프로세스 중 어떤 프로세스에 메모리를 할당하여 ready queue 로 보낼지 결정하는 역할을 한다. * 메모리와 디스크 사이의 스케줄링을 담당. * 프로세스에 memory(및 각종 리소스)를 할당(admit) * degree of Multiprogramming 제어 (실행중인 프로세스의 수 제어) * 프로세스의 상태 new -> ready(in memory)"
BACKEND,운영체제,단기스케줄러(Short의term scheduler or CPU scheduler)은(는) 무엇인가요?,* CPU 와 메모리 사이의 스케줄링을 담당. * Ready Queue 에 존재하는 프로세스 중 어떤 프로세스를 running 시킬지 결정. * 프로세스에 CPU 를 할당(scheduler dispatch) * 프로세스의 상태 ready -> running -> waiting -> ready
BACKEND,운영체제,중기스케줄러(Medium의term scheduler or Swapper)은(는) 무엇인가요?,* 여유 공간 마련을 위해 프로세스를 통째로 메모리에서 디스크로 쫓아냄 (swapping) * 프로세스에게서 memory 를 deallocate * degree of Multiprogramming 제어 * 현 시스템에서 메모리에 너무 많은 프로그램이 동시에 올라가는 것을 조절하는 스케줄러. * 프로세스의 상태 ready -> suspended
BACKEND,운영체제,스케줄러에서 Process state 의 suspended은(는) 무엇인가요?,Suspended(stopped) : 외부적인 이유로 프로세스의 수행이 정지된 상태로 메모리에서 내려간 상태를 의미한다. 프로세스 전부 디스크로 swap out 된다. blocked 상태는 다른 I/O 작업을 기다리는 상태이기 때문에 스스로 ready state 로 돌아갈 수 있지만 이 상태는 외부적인 이유로 suspending 되었기 때문에 스스로 돌아갈 수 없다. ---
BACKEND,운영체제,FCFS(First Come First Served)의 특징는 무엇인가요?,"* 먼저 온 고객을 먼저 서비스해주는 방식, 즉 먼저 온 순서대로 처리. * 비선점형(Non-Preemptive) 스케줄링 일단 CPU 를 잡으면 CPU burst 가 완료될 때까지 CPU 를 반환하지 않는다. 할당되었던 CPU 가 반환될 때만 스케줄링이 이루어진다."
BACKEND,운영체제,FCFS(First Come First Served)의 문제점는 무엇인가요?,* convoy effect 소요시간이 긴 프로세스가 먼저 도달하여 효율성을 낮추는 현상이 발생한다.
BACKEND,운영체제,SJF(Shortest - Job - First)의 특징는 무엇인가요?,* 다른 프로세스가 먼저 도착했어도 CPU burst time 이 짧은 프로세스에게 선 할당 * 비선점형(Non-Preemptive) 스케줄링
BACKEND,운영체제,SJF(Shortest - Job - First)의 문제점는 무엇인가요?,* starvation 효율성을 추구하는게 가장 중요하지만 특정 프로세스가 지나치게 차별받으면 안되는 것이다. 이 스케줄링은 극단적으로 CPU 사용이 짧은 job 을 선호한다. 그래서 사용 시간이 긴 프로세스는 거의 영원히 CPU 를 할당받을 수 없다.
BACKEND,운영체제,SRTF(Shortest Remaining Time First)의 특징는 무엇인가요?,* 새로운 프로세스가 도착할 때마다 새로운 스케줄링이 이루어진다. * 선점형 (Preemptive) 스케줄링 현재 수행중인 프로세스의 남은 burst time 보다 더 짧은 CPU burst time 을 가지는 새로운 프로세스가 도착하면 CPU 를 뺏긴다.
BACKEND,운영체제,SRTF(Shortest Remaining Time First)의 문제점는 무엇인가요?,* starvation * 새로운 프로세스가 도달할 때마다 스케줄링을 다시하기 때문에 CPU burst time(CPU 사용시간)을 측정할 수가 없다.
BACKEND,운영체제,Priority Scheduling의 특징는 무엇인가요?,* 우선순위가 가장 높은 프로세스에게 CPU 를 할당하는 스케줄링이다. 우선순위란 정수로 표현하게 되고 작은 숫자가 우선순위가 높다. * 선점형 스케줄링(Preemptive) 방식 더 높은 우선순위의 프로세스가 도착하면 실행중인 프로세스를 멈추고 CPU 를 선점한다. * 비선점형 스케줄링(Non-Preemptive) 방식 더 높은 우선순위의 프로세스가 도착하면 Ready Queue 의 Head 에 넣는다.
BACKEND,운영체제,Priority Scheduling의 문제점는 무엇인가요?,* starvation * 무기한 봉쇄(Indefinite blocking) 실행 준비는 되어있으나 CPU 를 사용못하는 프로세스를 CPU 가 무기한 대기하는 상태
BACKEND,운영체제,Priority Scheduling의 해결책는 무엇인가요?,* aging 아무리 우선순위가 낮은 프로세스라도 오래 기다리면 우선순위를 높여주자.
BACKEND,운영체제,Round Robin의 특징는 무엇인가요?,* 현대적인 CPU 스케줄링 * 각 프로세스는 동일한 크기의 할당 시간(time quantum)을 갖게 된다. * 할당 시간이 지나면 프로세스는 선점당하고 ready queue 의 제일 뒤에 가서 다시 줄을 선다. * `RR`은 CPU 사용시간이 랜덤한 프로세스들이 섞여있을 경우에 효율적 * `RR`이 가능한 이유는 프로세스의 context 를 save 할 수 있기 때문이다.
BACKEND,운영체제,Round Robin의 장점는 무엇인가요?,"* `Response time`이 빨라진다. n 개의 프로세스가 ready queue 에 있고 할당시간이 q(time quantum)인 경우 각 프로세스는 q 단위로 CPU 시간의 1/n 을 얻는다. 즉, 어떤 프로세스도 (n-1)q time unit 이상 기다리지 않는다. * 프로세스가 기다리는 시간이 CPU 를 사용할 만큼 증가한다. 공정한 스케줄링이라고 할 수 있다."
BACKEND,운영체제,Round Robin의 주의할 점는 무엇인가요?,설정한 `time quantum`이 너무 커지면 `FCFS`와 같아진다. 또 너무 작아지면 스케줄링 알고리즘의 목적에는 이상적이지만 잦은 context switch 로 overhead 가 발생한다. 그렇기 때문에 적당한 `time quantum`을 설정하는 것이 중요하다. ---
BACKEND,운영체제,동기와 비동기의 차이를 비유를 들어 쉽게 설명하라,"해야할 일(task)가 빨래, 설거지, 청소 세 가지가 있다고 가정한다. 이 일들을 동기적으로 처리한다면 빨래를 하고 설거지를 하고 청소를 한다. 비동기적으로 일을 처리한다면 빨래하는 업체에게 빨래를 시킨다. 설거지 대행 업체에 설거지를 시킨다. 청소 대행 업체에 청소를 시킨다. 셋 중 어떤 것이 먼저 완료될지는 알 수 없다. 일을 모두 마친 업체는 나에게 알려주기로 했으니 나는 다른 작업을 할 수 있다. 이 때는 백그라운드 스레드에서 해당 작업을 처리하는 경우의 비동기를 의미한다."
BACKEND,운영체제,동기와 비동기의 차이에서 Sync vs Async은(는) 무엇인가요?,"일반적으로 동기와 비동기의 차이는 메소드를 실행시킴과 `동시에` 반환 값이 기대되는 경우를 동기 라고 표현하고 그렇지 않은 경우에 대해서 비동기 라고 표현한다. 동시에라는 말은 실행되었을 때 값이 반환되기 전까지는 `blocking`되어 있다는 것을 의미한다. 비동기의 경우, `blocking`되지 않고 이벤트 큐에 넣거나 백그라운드 스레드에게 해당 task 를 위임하고 바로 다음 코드를 실행하기 때문에 기대되는 값이 바로 반환되지 않는다."
BACKEND,운영체제,프로세스 동기화에서 Critical Section(임계영역)은(는) 무엇인가요?,"멀티스레딩의 문제점에서 나오듯, 동일한 자원을 동시에 접근하는 작업(e.g. 공유하는 변수 사용, 동일 파일을 사용하는 등)을 실행하는 코드 영역을 Critical Section 이라 칭한다."
BACKEND,운영체제,프로세스 동기화에서 Critical Section Problem(임계영역 문제)은(는) 무엇인가요?,프로세스들이 Critical Section 을 함께 사용할 수 있는 프로토콜을 설계하는 것이다.
BACKEND,운영체제,프로세스 동기화에서 Requirements(해결을 위한 기본조건)은(는) 무엇인가요?,"* Mutual Exclusion(상호 배제) 프로세스 P1 이 Critical Section 에서 실행중이라면, 다른 프로세스들은 그들이 가진 Critical Section 에서 실행될 수 없다. * Progress(진행) Critical Section 에서 실행중인 프로세스가 없고, 별도의 동작이 없는 프로세스들만 Critical Section 진입 후보로서 참여될 수 있다. * Bounded Waiting(한정된 대기) P1 가 Critical Section 에 진입 신청 후 부터 받아들여질 때가지, 다른 프로세스들이 Critical Section 에 진입하는 횟수는 제한이 있어야 한다."
BACKEND,운영체제,프로세스 동기화의 해결책으로써 Mutex Lock는 무엇인가요?,"* 동시에 공유 자원에 접근하는 것을 막기 위해 Critical Section 에 진입하는 프로세스는 Lock 을 획득하고 Critical Section 을 빠져나올 때, Lock 을 방출함으로써 동시에 접근이 되지 않도록 한다."
BACKEND,운영체제,Mutex Lock의 한계는 무엇인가요?,* 다중처리기 환경에서는 시간적인 효율성 측면에서 적용할 수 없다.
BACKEND,운영체제,Semaphores(세마포)은(는) 무엇인가요?,* 소프트웨어상에서 Critical Section 문제를 해결하기 위한 동기화 도구
BACKEND,운영체제,Semaphores(세마포)의 종류는 무엇인가요?,"OS 는 Counting/Binary 세마포를 구분한다 * 카운팅 세마포 가용한 개수를 가진 자원 에 대한 접근 제어용으로 사용되며, 세마포는 그 가용한 자원의 개수 로 초기화 된다. 자원을 사용하면 세마포가 감소, 방출하면 세마포가 증가 한다. * 이진 세마포 MUTEX 라고도 부르며, 상호배제의 (Mutual Exclusion)의 머릿글자를 따서 만들어졌다. 이름 그대로 0 과 1 사이의 값만 가능하며, 다중 프로세스들 사이의 Critical Section 문제를 해결하기 위해 사용한다."
BACKEND,운영체제,Semaphores(세마포)의 단점는 무엇인가요?,"* Busy Waiting(바쁜 대기) Spin lock이라고 불리는 Semaphore 초기 버전에서 Critical Section 에 진입해야하는 프로세스는 진입 코드를 계속 반복 실행해야 하며, CPU 시간을 낭비했었다. 이를 Busy Waiting이라고 부르며 특수한 상황이 아니면 비효율적이다. 일반적으로는 Semaphore에서 Critical Section에 진입을 시도했지만 실패한 프로세스에 대해 Block시킨 뒤, Critical Section에 자리가 날 때 다시 깨우는 방식을 사용한다. 이 경우 Busy waiting으로 인한 시간낭비 문제가 해결된다."
BACKEND,운영체제,프로세스 동기화에서 Deadlock(교착상태)은(는) 무엇인가요?,"* 세마포가 Ready Queue 를 가지고 있고, 둘 이상의 프로세스가 Critical Section 진입을 무한정 기다리고 있고, Critical Section 에서 실행되는 프로세스는 진입 대기 중인 프로세스가 실행되야만 빠져나올 수 있는 상황을 지칭한다."
BACKEND,운영체제,프로세스 동기화에서 모니터는 무엇인가요?,"* 고급 언어의 설계 구조물로서, 개발자의 코드를 상호배제 하게끔 만든 추상화된 데이터 형태이다. * 공유자원에 접근하기 위한 키 획득과 자원 사용 후 해제를 모두 처리한다. (세마포어는 직접 키 해제와 공유자원 접근 처리가 필요하다. ) ---"
BACKEND,운영체제,메모리 관리 배경는 무엇인가요?,"각각의 프로세스 는 독립된 메모리 공간을 갖고, 운영체제 혹은 다른 프로세스의 메모리 공간에 접근할 수 없는 제한이 걸려있다. 단지, 운영체제 만이 운영체제 메모리 영역과 사용자 메모리 영역의 접근에 제약을 받지 않는다. Swapping : 메모리의 관리를 위해 사용되는 기법. 표준 Swapping 방식으로는 round-robin 과 같은 스케줄링의 다중 프로그래밍 환경에서 CPU 할당 시간이 끝난 프로세스의 메모리를 보조 기억장치(e.g. 하드디스크)로 내보내고 다른 프로세스의 메모리를 불러 들일 수 있다. > 이 과정을 swap (스왑시킨다) 이라 한다. 주 기억장치(RAM)으로 불러오는 과정을 swap-in, 보조 기억장치로 내보내는 과정을 swap-out 이라 한다. swap 에는 큰 디스크 전송시간이 필요하기 때문에 현재에는 메모리 공간이 부족할때 Swapping 이 시작된다. 단편화 (Fragmentation) : 프로세스들이 메모리에 적재되고 제거되는 일이 반복되다보면, 프로세스들이 차지하는 메모리 틈 사이에 사용 하지 못할 만큼의 작은 자유공간들이 늘어나게 되는데, 이것이 단편화 이다. 단편화는 2 가지 종류로 나뉜다. | `Process A` | free | `Process B` | free | `Process C` | &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; free &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; | `Process D` | | ----------- | ---- | ----------- | ---- | ----------- | :--------------------------------------------------------------------------------------: | ----------- | * 외부 단편화: 메모리 공간 중 사용하지 못하게 되는 일부분. 물리 메모리(RAM)에서 사이사이 남는 공간들을 모두 합치면 충분한 공간이 되는 부분들이 분산되어 있을때 발생한다고 볼 수 있다. * 내부 단편화: 프로세스가 사용하는 메모리 공간 에 포함된 남는 부분. 예를들어 메모리 분할 자유 공간이 10,000B 있고 Process A 가 9,998B 사용하게되면 2B 라는 차이 가 존재하고, 이 현상을 내부 단편화라 칭한다. 압축 : 외부 단편화를 해소하기 위해 프로세스가 사용하는 공간들을 한쪽으로 몰아, 자유공간을 확보하는 방법론 이지만, 작업효율이 좋지 않다. (위의 메모리 현황이 압축을 통해 아래의 그림 처럼 바뀌는 효과를 가질 수 있다) | `Process A` | `Process B` | `Process C` | `Process D` | &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; free &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; | | ----------- | ----------- | ----------- | :---------: | ------------------------------------------------------------------------------------------------------------------ |"
BACKEND,운영체제,메모리 관리 전략에서 Paging(페이징)은(는) 무엇인가요?,"하나의 프로세스가 사용하는 메모리 공간이 연속적이어야 한다는 제약을 없애는 메모리 관리 방법이다. 외부 단편화와 압축 작업을 해소 하기 위해 생긴 방법론으로, 물리 메모리는 Frame 이라는 고정 크기로 분리되어 있고, 논리 메모리(프로세스가 점유하는)는 페이지라 불리는 고정 크기의 블록으로 분리된다.(페이지 교체 알고리즘에 들어가는 페이지) 페이징 기법을 사용함으로써 논리 메모리는 물리 메모리에 저장될 때, 연속되어 저장될 필요가 없고 물리 메모리의 남는 프레임에 적절히 배치됨으로 외부 단편화를 해결할 수 있는 큰 장점이 있다. 하나의 프로세스가 사용하는 공간은 여러개의 페이지로 나뉘어서 관리되고(논리 메모리에서), 개별 페이지는 순서에 상관없이 물리 메모리에 있는 프레임에 mapping 되어 저장된다고 볼 수 있다. * 단점 : 내부 단편화 문제의 비중이 늘어나게 된다. 예를들어 페이지 크기가 1,024B 이고 프로세스 A 가 3,172B 의 메모리를 요구한다면 3 개의 페이지 프레임(1,024 * 3 = 3,072) 하고도 100B 가 남기때문에 총 4 개의 페이지 프레임이 필요한 것이다. 결론적으로 4 번째 페이지 프레임에는 924B(1,024 - 100)의 여유 공간이 남게 되는 내부 단편화 문제가 발생하는 것이다."
BACKEND,운영체제,메모리 관리 전략에서 Segmentation(세그멘테이션)은(는) 무엇인가요?,"페이징에서처럼 논리 메모리와 물리 메모리를 같은 크기의 블록이 아닌, 서로 다른 크기의 논리적 단위인 세그먼트(Segment)로 분할 사용자가 두 개의 주소로 지정(세그먼트 번호 + 변위) 세그먼트 테이블에는 각 세그먼트의 기준(세그먼트의 시작 물리 주소)과 한계(세그먼트의 길이)를 저장 * 단점 : 서로 다른 크기의 세그먼트들이 메모리에 적재되고 제거되는 일이 반복되다 보면, 자유 공간들이 많은 수의 작은 조각들로 나누어져 못 쓰게 될 수도 있다.(외부 단편화) ---"
BACKEND,운영체제,가상 메모리는 무엇인가요?,"다중 프로그래밍을 실현하기 위해서는 많은 프로세스들을 동시에 메모리에 올려두어야 한다. 가상메모리는 프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 기법 이며, 프로그램이 물리 메모리보다 커도 된다는 주요 장점이 있다."
BACKEND,운영체제,가상 메모리에서 가상 메모리 개발 배경는 무엇인가요?,"실행되는 코드의 전부를 물리 메모리에 존재시켜야 했고, 메모리 용량보다 큰 프로그램은 실행시킬 수 없었다. 또한, 여러 프로그램을 동시에 메모리에 올리기에는 용량의 한계와, 페이지 교체등의 성능 이슈가 발생하게 된다. 또한, 가끔만 사용되는 코드가 차지하는 메모리들을 확인할 수 있다는 점에서, 불필요하게 전체의 프로그램이 메모리에 올라와 있어야 하는게 아니라는 것을 알 수 있다."
BACKEND,운영체제,가상 메모리에서 프로그램의 일부분만 메모리에 올릴 수 있다면 어떻게 될까요?,"* 물리 메모리 크기에 제약받지 않게 된다. * 더 많은 프로그램을 동시에 실행할 수 있게 된다. 이에 따라 `응답시간`은 유지되고, `CPU 이용률`과 `처리율`은 높아진다. * [swap](#메모리-관리-배경)에 필요한 입출력이 줄어들기 때문에 프로그램들이 빠르게 실행된다."
BACKEND,운영체제,가상 메모리가 하는 일는 무엇인가요?,가상 메모리는 실제의 물리 메모리 개념과 사용자의 논리 메모리 개념을 분리한 것으로 정리할 수 있다. 이로써 작은 메모리를 가지고도 얼마든지 큰 `가상 주소 공간`을 프로그래머에게 제공할 수 있다.
BACKEND,운영체제,가상 주소 공간는 무엇인가요?,"* 한 프로세스가 메모리에 저장되는 논리적인 모습을 가상메모리에 구현한 공간이다. 프로세스가 요구하는 메모리 공간을 가상메모리에서 제공함으로써 현재 직접적으로 필요치 않은 메모리 공간은 실제 물리 메모리에 올리지 않는 것으로 물리 메모리를 절약할 수 있다. * 예를 들어, 한 프로그램이 실행되며 논리 메모리로 100KB 가 요구되었다고 하자. 하지만 실행까지에 필요한 메모리 공간`(Heap영역, Stack 영역, 코드, 데이터)`의 합이 40KB 라면, 실제 물리 메모리에는 40KB 만 올라가 있고, 나머지 60KB 만큼은 필요시에 물리메모리에 요구한다고 이해할 수 있겠다. | `Stack` | &nbsp;&nbsp;&nbsp; free (60KB) &nbsp;&nbsp;&nbsp;&nbsp; | `Heap` | `Data` | `Code` | | ------- | ------------------------------------------------------- | :----: | ------ | ------ |"
BACKEND,운영체제,가상 메모리에서 프로세스간의 페이지 공유는 무엇인가요?,"가상 메모리는... * `시스템 라이브러리`가 여러 프로세스들 사이에 공유될 수 있도록 한다. 각 프로세스들은 `공유 라이브러리`를 자신의 가상 주소 공간에 두고 사용하는 것처럼 인식하지만, 라이브러리가 올라가있는 `물리 메모리 페이지`들은 모든 프로세스에 공유되고 있다. * 프로세스들이 메모리를 공유하는 것을 가능하게 하고, 프로세스들은 공유 메모리를 통해 통신할 수 있다. 이 또한, 각 프로세스들은 각자 자신의 주소 공간처럼 인식하지만, 실제 물리 메모리는 공유되고 있다. * `fork()`를 통한 프로세스 생성 과정에서 페이지들이 공유되는 것을 가능하게 한다."
BACKEND,운영체제,가상 메모리에서 Demand Paging(요구 페이징)은(는) 무엇인가요?,"프로그램 실행 시작 시에 프로그램 전체를 디스크에서 물리 메모리에 적재하는 대신, 초기에 필요한 것들만 적재하는 전략을 `요구 페이징`이라 하며, 가상 메모리 시스템에서 많이 사용된다. 그리고 가상 메모리는 대개 [페이지](#paging페이징)로 관리된다. 요구 페이징을 사용하는 가상 메모리에서는 실행과정에서 필요해질 때 페이지들이 적재된다. 한 번도 접근되지 않은 페이지는 물리 메모리에 적재되지 않는다. 프로세스 내의 개별 페이지들은 `페이저(pager)`에 의해 관리된다. 페이저는 프로세스 실행에 실제 필요한 페이지들만 메모리로 읽어 옮으로써, 사용되지 않을 페이지를 가져오는 시간낭비와 메모리 낭비를 줄일 수 있다."
BACKEND,운영체제,가상 메모리에서 페이지 교체는 무엇인가요?,"`요구 페이징` 에서 언급된대로 프로그램 실행시에 모든 항목이 물리 메모리에 올라오지 않기 때문에, 프로세스의 동작에 필요한 페이지를 요청하는 과정에서 `page fault(페이지 부재)`가 발생하게 되면, 원하는 페이지를 보조저장장치에서 가져오게 된다. 하지만, 만약 물리 메모리가 모두 사용 중인 상황이라면, 페이지 교체가 이뤄져야 한다.(또는, 운영체제가 프로세스를 강제 종료하는 방법이 있다.)"
BACKEND,운영체제,가상 메모리의 기본적인 방법는 무엇인가요?,"물리 메모리가 모두 사용 중인 상황에서의 메모리 교체 흐름이다. 1. 디스크에서 필요한 페이지의 위치를 찾는다 1. 빈 페이지 프레임을 찾는다. 1. `페이지 교체 알고리즘`을 통해 희생될(victim) 페이지를 고른다. 1. 희생될 페이지를 디스크에 기록하고, 관련 페이지 테이블을 수정한다. 1. 새롭게 비워진 페이지 테이블 내 프레임에 새 페이지를 읽어오고, 프레임 테이블을 수정한다. 1. 사용자 프로세스 재시작"
BACKEND,운영체제,가상 메모리에서 페이지 교체 알고리즘는 무엇인가요?,"##### FIFO 페이지 교체 가장 간단한 페이지 교체 알고리즘으로 FIFO(first-in first-out)의 흐름을 가진다. 즉, 먼저 물리 메모리에 들어온 페이지 순서대로 페이지 교체 시점에 먼저 나가게 된다는 것이다. * 장점 * 이해하기도 쉽고, 프로그램하기도 쉽다. * 단점 * 오래된 페이지가 항상 불필요하지 않은 정보를 포함하지 않을 수 있다(초기 변수 등) * 처음부터 활발하게 사용되는 페이지를 교체해서 페이지 부재율을 높이는 부작용을 초래할 수 있다. * `Belady의 모순`: 페이지를 저장할 수 있는 페이지 프레임의 갯수를 늘려도 되려 페이지 부재가 더 많이 발생하는 모순이 존재한다. ##### 최적 페이지 교체(Optimal Page Replacement) `Belady의 모순`을 확인한 이후 최적 교체 알고리즘에 대한 탐구가 진행되었고, 모든 알고리즘보다 낮은 페이지 부재율을 보이며 `Belady의 모순`이 발생하지 않는다. 이 알고리즘의 핵심은 `앞으로 가장 오랫동안 사용되지 않을 페이지를 찾아 교체`하는 것이다. 주로 비교 연구 목적을 위해 사용한다. * 장점 * 알고리즘 중 가장 낮은 페이지 부재율을 보장한다. * 단점 * 구현의 어려움이 있다. 모든 프로세스의 메모리 참조의 계획을 미리 파악할 방법이 없기 때문이다. ##### LRU 페이지 교체(LRU Page Replacement) `LRU: Least-Recently-Used` 최적 알고리즘의 근사 알고리즘으로, 가장 오랫동안 사용되지 않은 페이지를 선택하여 교체한다. * 특징 * 대체적으로 `FIFO 알고리즘`보다 우수하고, `OPT알고리즘`보다는 그렇지 못한 모습을 보인다. ##### LFU 페이지 교체(LFU Page Replacement) `LFU: Least Frequently Used` 참조 횟수가 가장 적은 페이지를 교체하는 방법이다. 활발하게 사용되는 페이지는 참조 횟수가 많아질 거라는 가정에서 만들어진 알고리즘이다. * 특징 * 어떤 프로세스가 특정 페이지를 집중적으로 사용하다, 다른 기능을 사용하게되면 더 이상 사용하지 않아도 계속 메모리에 머물게 되어 초기 가정에 어긋나는 시점이 발생할 수 있다 * 최적(OPT) 페이지 교체를 제대로 근사하지 못하기 때문에, 잘 쓰이지 않는다. ##### MFU 페이지 교체(MFU Page Replacement) `MFU: Most Frequently Used` 참조 회수가 가장 작은 페이지가 최근에 메모리에 올라왔고, 앞으로 계속 사용될 것이라는 가정에 기반한다. * 특징 * 최적(OPT) 페이지 교체를 제대로 근사하지 못하기 때문에, 잘 쓰이지 않는다. ---"
BACKEND,운영체제,캐시의 지역성 원리는 무엇인가요?,"캐시 메모리는 속도가 빠른 장치와 느린 장치 간의 속도 차에 따른 병목 현상을 줄이기 위한 범용 메모리이다. 이러한 역할을 수행하기 위해서는 CPU 가 어떤 데이터를 원할 것인가를 어느 정도 예측할 수 있어야 한다. 캐시의 성능은 작은 용량의 캐시 메모리에 CPU 가 이후에 참조할, 쓸모 있는 정보가 어느 정도 들어있느냐에 따라 좌우되기 때문이다. 이때 `적중율(hit rate)`을 극대화하기 위해 데이터 `지역성(locality)의 원리`를 사용한다. 지역성의 전제 조건으로 프로그램은 모든 코드나 데이터를 균등하게 access 하지 않는다는 특성을 기본으로 한다. 즉, `locality`란 기억 장치 내의 정보를 균일하게 access 하는 것이 아닌 어느 한순간에 특정 부분을 집중적으로 참조하는 특성이다. 데이터 지역성은 대표적으로 시간 지역성(temporal locality)과 공간 지역성(spatial locality)으로 나뉜다. * 시간 지역성 : 최근에 참조된 주소의 내용은 곧 다음에 다시 참조되는 특성 * 공간 지역성 : 대부분의 실제 프로그램이 참조된 주소와 인접한 주소의 내용이 다시 참조되는 특성"
BACKEND,운영체제,Caching Line은(는) 무엇인가요?,"언급했듯이 캐시(cache)는 프로세서 가까이에 위치하면서 빈번하게 사용되는 데이터를 놔두는 장소이다. 하지만 캐시가 아무리 가까이 있더라도 찾고자 하는 데이터가 어느 곳에 저장되어 있는지 몰라 모든 데이터를 순회해야 한다면 시간이 오래 걸리게 된다. 즉, 캐시에 목적 데이터가 저장되어 있다면 바로 접근하여 출력할 수 있어야 캐시가 의미 있게 된다는 것이다. 그렇기 때문에 캐시에 데이터를 저장할 때 특정 자료 구조를 사용하여 `묶음`으로 저장하게 되는데 이를 캐싱 라인 이라고 한다. 프로세스는 다양한 주소에 있는 데이터를 사용하므로 빈번하게 사용하는 데이터의 주소 또한 흩어져 있다. 따라서 캐시에 저장하는 데이터에는 데이터의 메모리 주소 등을 기록해 둔 태그를 달아 놓을 필요가 있다. 이러한 태그들의 묶음을 캐싱 라인이라고 하고 메모리로부터 가져올 때도 캐싱 라인을 기준으로 가져온다. 종류로는 대표적으로 세 가지 방식이 존재한다. 1. Full Associative 2. Set Associative 3. Direct Map ---"
BACKEND,데이터베이스,데이터베이스를 사용하는 이유는 무엇인가요?,"데이터베이스가 존재하기 이전에는 파일 시스템을 이용하여 데이터를 관리하였다. (현재도 부분적으로 사용되고 있다.) 데이터를 각각의 파일 단위로 저장하며 이러한 일들을 처리하기 위한 독립적인 애플리케이션과 상호 연동이 되어야 한다. 이 때의 문제점은 데이터 종속성 문제와 중복성, 데이터 무결성이다."
BACKEND,데이터베이스,데이터베이스의 특징는 무엇인가요?,1. 데이터의 독립성 * 물리적 독립성 : 데이터베이스 사이즈를 늘리거나 성능 향상을 위해 데이터 파일을 늘리거나 새롭게 추가하더라도 관련된 응용 프로그램을 수정할 필요가 없다. * 논리적 독립성 : 데이터베이스는 논리적인 구조로 다양한 응용 프로그램의 논리적 요구를 만족시켜줄 수 있다. 2. 데이터의 무결성 여러 경로를 통해 잘못된 데이터가 발생하는 경우의 수를 방지하는 기능으로 데이터의 유효성 검사를 통해 데이터의 무결성을 구현하게 된다. 3. 데이터의 보안성 인가된 사용자들만 데이터베이스나 데이터베이스 내의 자원에 접근할 수 있도록 계정 관리 또는 접근 권한을 설정함으로써 모든 데이터에 보안을 구현할 수 있다. 4. 데이터의 일관성 연관된 정보를 논리적인 구조로 관리함으로써 어떤 하나의 데이터만 변경했을 경우 발생할 수 있는 데이터의 불일치성을 배제할 수 있다. 또한 작업 중 일부 데이터만 변경되어 나머지 데이터와 일치하지 않는 경우의 수를 배제할 수 있다. 5. 데이터 중복 최소화 데이터베이스는 데이터를 통합해서 관리함으로써 파일 시스템의 단점 중 하나인 자료의 중복과 데이터의 중복성 문제를 해결할 수 있다.
BACKEND,데이터베이스,데이터베이스의 성능?,데이터베이스의 성능 이슈는 디스크 I/O 를 어떻게 줄이느냐에서 시작된다. 디스크 I/O 란 디스크 드라이브의 플래터(원판)을 돌려서 읽어야 할 데이터가 저장된 위치로 디스크 헤더를 이동시킨 다음 데이터를 읽는 것을 의미한다. 이 때 데이터를 읽는데 걸리는 시간은 디스크 헤더를 움직여서 읽고 쓸 위치로 옮기는 단계에서 결정된다. 즉 디스크의 성능은 디스크 헤더의 위치 이동 없이 얼마나 많은 데이터를 한 번에 기록하느냐에 따라 결정된다고 볼 수 있다. 그렇기 때문에 순차 I/O 가 랜덤 I/O 보다 빠를 수 밖에 없다. 하지만 현실에서는 대부분의 I/O 작업이 랜덤 I/O 이다. 랜덤 I/O 를 순차 I/O 로 바꿔서 실행할 수는 없을까? 이러한 생각에서부터 시작되는 데이터베이스 쿼리 튜닝은 랜덤 I/O 자체를 줄여주는 것이 목적이라고 할 수 있다.
BACKEND,데이터베이스,인덱스(Index)란 무엇인가?,"인덱스는 말 그대로 책의 맨 처음 또는 맨 마지막에 있는 색인이라고 할 수 있다. 이 비유를 그대로 가져와서 인덱스를 살펴본다면 데이터는 책의 내용이고 데이터가 저장된 레코드의 주소는 인덱스 목록에 있는 페이지 번호가 될 것이다. DBMS 도 데이터베이스 테이블의 모든 데이터를 검색해서 원하는 결과를 가져 오려면 시간이 오래 걸린다. 그래서 칼럼의 값과 해당 레코드가 저장된 주소를 키와 값의 쌍으로 인덱스를 만들어 두는 것이다. DBMS 의 인덱스는 항상 정렬된 상태를 유지하기 때문에 원하는 값을 탐색하는데는 빠르지만 새로운 값을 추가하거나 삭제, 수정하는 경우에는 쿼리문 실행 속도가 느려진다. 결론적으로 DBMS 에서 인덱스는 데이터의 저장 성능을 희생하고 그 대신 데이터의 읽기 속도를 높이는 기능이다. SELECT 쿼리 문장의 WHERE 조건절에 사용되는 칼럼이라고 전부 인덱스로 생성하면 데이터 저장 성능이 떨어지고 인덱스의 크기가 비대해져서 오히려 역효과만 불러올 수 있다."
BACKEND,데이터베이스,Index 자료구조는 무엇인가요?,그렇다면 DBMS 는 인덱스를 어떻게 관리하고 있는가
BACKEND,데이터베이스,B+의Tree 인덱스 알고리즘는 무엇인가요?,"일반적으로 사용되는 인덱스 알고리즘은 B+-Tree 알고리즘이다. B+-Tree 인덱스는 칼럼의 값을 변형하지 않고(사실 값의 앞부분만 잘라서 관리한다.), 원래의 값을 이용해 인덱싱하는 알고리즘이다."
BACKEND,데이터베이스,Hash 인덱스 알고리즘는 무엇인가요?,"칼럼의 값으로 해시 값을 계산해서 인덱싱하는 알고리즘으로 매우 빠른 검색을 지원한다. 하지만 값을 변형해서 인덱싱하므로, 특정 문자로 시작하는 값으로 검색을 하는 전방 일치와 같이 값의 일부만으로 검색하고자 할 때는 해시 인덱스를 사용할 수 없다. 주로 메모리 기반의 데이터베이스에서 많이 사용한다."
BACKEND,데이터베이스,왜 index 를 생성하는데 b의tree 를 사용하는가?,데이터에 접근하는 시간복잡도가 O(1)인 hash table 이 더 효율적일 것 같은데? SELECT 질의의 조건에는 부등호(<>) 연산도 포함이 된다. hash table 을 사용하게 된다면 등호(=) 연산이 아닌 부등호 연산의 경우에 문제가 발생한다. 동등 연산(=)에 특화된 `hashtable`은 데이터베이스의 자료구조로 적합하지 않다.
BACKEND,데이터베이스,Primary Index vs Secondary Index은(는) 무엇인가요?,#NAME?
BACKEND,데이터베이스,Clustered Index vs Non의clustered Index은(는) 무엇인가요?,"클러스터(Cluster)란 여러 개를 하나로 묶는다는 의미로 주로 사용되는데, 클러스터드 인덱스도 크게 다르지 않다. 인덱스에서 클러스터드는 비슷한 것들을 묶어서 저장하는 형태로 구현되는데, 이는 주로 비슷한 값들을 동시에 조회하는 경우가 많다는 점에서 착안된 것이다. 여기서 비슷한 값들은 물리적으로 *인접한 장소에 저장* 되어 있는 데이터들을 말한다. - 클러스터드 인덱스(Clustered Index)는 인덱스가 적용된 속성 값에 의해 레코드의 물리적 저장 위치가 결정되는 인덱스이다. - 일반적으로 데이터베이스 시스템은 Primary Key에 대해서 기본적으로 클러스터드 인덱스를 생성한다. - Primary Key는 행마다 고유하며 Null 값을 가질 수 없기 때문에 물리적 정렬 기준으로 적합하기 때문이다. - 이러한 경우에는 Primary Key 값이 비슷한 레코드끼리 묶어서 저장하게 된다. - 물론 Primary Key가 아닌 다른 칼럼에 대해서도 클러스터드 인덱스를 생성할 수 있다. - 클러스터드 인덱스에서는 인덱스가 적용된 속성 값(주로 Primary Key)에 의해 *레코드의 저장 위치가 결정* 되며 속성 값이 변경되면 그 레코드의 물리적인 저장 위치 또한 변경되어야 한다. - 그렇기 때문에 어떤 속성에 클러스터드 인덱스를 적용할지 신중하게 결정하고 사용해야 한다. - 클러스터드 인덱스는 테이블 당 한 개만 생성할 수 있다. - 논클러스터드 인덱스(Non-clustered Index)는 데이터를 물리적으로 정렬하지 않는다. - 논클러스터드 인덱스는 별도의 인덱스 테이블을 만들어 실제 데이터 테이블의 행을 참조한다. - 테이블 당 여러 개의 논클러스터드 인덱스를 생성할 수 있다."
BACKEND,데이터베이스,Composite Index은(는) 무엇인가요?,"인덱스로 설정하는 필드의 속성이 중요하다. title, author 이 순서로 인덱스를 설정한다면 title 을 search 하는 경우, index 를 생성한 효과를 볼 수 있지만, author 만으로 search 하는 경우, index 를 생성한 것이 소용이 없어진다. 따라서 SELECT 질의를 어떻게 할 것인가가 인덱스를 어떻게 생성할 것인가에 대해 많은 영향을 끼치게 된다."
BACKEND,데이터베이스,Index 의 성능과 고려해야할 사항는 무엇인가요?,"SELECT 쿼리의 성능을 월등히 향상시키는 INDEX 항상 좋은 것일까? 쿼리문의 성능을 향상시킨다는데, 모든 컬럼에 INDEX 를 생성해두면 빨라지지 않을까? 우선, 첫번째 이유는 INDEX 를 생성하게 되면 INSERT, DELETE, UPDATE 쿼리문을 실행할 때 별도의 과정이 추가적으로 발생한다. INSERT 의 경우 INDEX 에 대한 데이터도 추가해야 하므로 그만큼 성능에 손실이 따른다. DELETE 의 경우 INDEX 에 존재하는 값은 삭제하지 않고 사용 안한다는 표시로 남게 된다. 즉 row 의 수는 그대로인 것이다. 이 작업이 반복되면 어떻게 될까? 실제 데이터는 10 만건인데 데이터가 100 만건 있는 결과를 낳을 수도 있는 것이다. 이렇게 되면 인덱스는 더 이상 제 역할을 못하게 되는 것이다. UPDATE 의 경우는 INSERT 의 경우, DELETE 의 경우의 문제점을 동시에 수반한다. 이전 데이터가 삭제되고 그 자리에 새 데이터가 들어오는 개념이기 때문이다. 즉 변경 전 데이터는 삭제되지 않고 insert 로 인한 split 도 발생하게 된다. 하지만 더 중요한 것은 컬럼을 이루고 있는 데이터의 형식에 따라서 인덱스의 성능이 악영향을 미칠 수 있다는 것이다. 즉, 데이터의 형식에 따라 인덱스를 만들면 효율적이고 만들면 비효율적은 데이터의 형식이 존재한다는 것이다. 어떤 경우에 그럴까? `이름`, `나이`, `성별` 세 가지의 필드를 갖고 있는 테이블을 생각해보자. 이름은 온갖 경우의 수가 존재할 것이며 나이는 INT 타입을 갖을 것이고, 성별은 남, 녀 두 가지 경우에 대해서만 데이터가 존재할 것임을 쉽게 예측할 수 있다. 이 경우 어떤 컬럼에 대해서 인덱스를 생성하는 것이 효율적일까? 결론부터 말하자면 이름에 대해서만 인덱스를 생성하면 효율적이다. 왜 성별이나 나이는 인덱스를 생성하면 비효율적일까? 10000 레코드에 해당하는 테이블에 대해서 2000 단위로 성별에 인덱스를 생성했다고 가정하자. 값의 range 가 적은 성별은 인덱스를 읽고 다시 한 번 디스크 I/O 가 발생하기 때문에 그 만큼 비효율적인 것이다."
BACKEND,데이터베이스,정규화는 어떤 배경에서 생겨났는가?,"한 릴레이션에 여러 엔티티의 애트리뷰트들을 혼합하게 되면 정보가 중복 저장되며, 저장 공간을 낭비하게 된다. 또 중복된 정보로 인해 `갱신 이상`이 발생하게 된다. 동일한 정보를 한 릴레이션에는 변경하고, 나머지 릴레이션에서는 변경하지 않은 경우 어느 것이 정확한지 알 수 없게 되는 것이다. 이러한 문제를 해결하기 위해 정규화 과정을 거치는 것이다."
BACKEND,데이터베이스,정규화에서 갱신 이상에는 어떠한 것들이 있는가?,"* 삽입 이상(insertion anomalies) 원하지 않는 자료가 삽입된다든지, 삽입하는데 자료가 부족해 삽입이 되지 않아 발생하는 문제점을 말한다. * 삭제 이상(deletion anomalies) 하나의 자료만 삭제하고 싶지만, 그 자료가 포함된 튜플 전체가 삭제됨으로 원하지 않는 정보 손실이 발생하는 문제점을 말한다. * 수정(갱신)이상(modification anomalies) 정확하지 않거나 일부의 튜플만 갱신되어 정보가 모호해지거나 일관성이 없어져 정확한 정보 파악이 되지 않는 문제점을 말한다."
BACKEND,데이터베이스,정규화란 무엇인가?,"관계형 데이터베이스에서 중복을 최소화하기 위해 데이터를 구조화하는 작업이다. 좀 더 구체적으로는 불만족스러운 나쁜 릴레이션의 애트리뷰트들을 나누어서 좋은 작은 릴레이션으로 분해하는 작업을 말한다. 정규화 과정을 거치게 되면 정규형을 만족하게 된다. 정규형이란 특정 조건을 만족하는 릴레이션의 스키마의 형태를 말하며 제 1 정규형, 제 2 정규형, 제 3 정규형, … 등이 존재한다."
BACKEND,데이터베이스,정규화에서 ‘나쁜' 릴레이션는 어떻게 파악하는가?,"엔티티를 구성하고 있는 애트리뷰트 간에 함수적 종속성(Functional Dependency)을 판단한다. 판단된 함수적 종속성은 좋은 릴레이션 설계의 정형적 기준으로 사용된다. 즉, 각각의 정규형마다 어떠한 함수적 종속성을 만족하는지에 따라 정규형이 정의되고, 그 정규형을 만족하지 못하는 정규형을 나쁜 릴레이션으로 파악한다."
BACKEND,데이터베이스,정규화에서 함수적 종속성이란 무엇인가?,"함수적 종속성이란 애트리뷰트 데이터들의 의미와 애트리뷰트들 간의 상호 관계로부터 유도되는 제약조건의 일종이다. X 와 Y 를 임의의 애트리뷰트 집합이라고 할 때, X 의 값이 Y 의 값을 유일하게(unique) 결정한다면 ""X 는 Y 를 함수적으로 결정한다""라고 한다. 함수적 종속성은 실세계에서 존재하는 애트리뷰트들 사이의 제약조건으로부터 유도된다. 또한 각종 추론 규칙에 따라서 애트리뷰트들간의 함수적 종속성을 판단할 수 있다."
BACKEND,데이터베이스,정규화에서 각각의 정규형는 어떠한 조건을 만족해야 하는가?,1. 분해의 대상인 분해 집합 D 는 무손실 조인 을 보장해야 한다. 2. 분해 집합 D 는 함수적 종속성을 보존해야 한다.
BACKEND,데이터베이스,정규화에서 제 1 정규형는 무엇인가요?,"애트리뷰트의 도메인이 오직 `원자값`만을 포함하고, 튜플의 모든 애트리뷰트가 도메인에 속하는 하나의 값을 가져야 한다. 즉, 복합 애트리뷰트, 다중값 애트리뷰트, 중첩 릴레이션 등 비 원자적인 애트리뷰트들을 허용하지 않는 릴레이션 형태를 말한다."
BACKEND,데이터베이스,정규화에서 제 2 정규형는 무엇인가요?,"모든 비주요 애트리뷰트들이 주요 애트리뷰트에 대해서 완전 함수적 종속이면 제 2 정규형을 만족한다고 볼 수 있다. 완전 함수적 종속이란 `X -> Y` 라고 가정했을 때, X 의 어떠한 애트리뷰트라도 제거하면 더 이상 함수적 종속성이 성립하지 않는 경우를 말한다. 즉, 키가 아닌 열들이 각각 후보키에 대해 결정되는 릴레이션 형태를 말한다."
BACKEND,데이터베이스,정규화에서제 3 정규형는 무엇인가요?,"어떠한 비주요 애트리뷰트도 기본키에 대해서 이행적으로 종속되지 않으면 제 3 정규형을 만족한다고 볼 수 있다. 이행 함수적 종속이란 `X - >Y`, `Y -> Z`의 경우에 의해서 추론될 수 있는 `X -> Z`의 종속관계를 말한다. 즉, 비주요 애트리뷰트가 비주요 애트리뷰트에 의해 종속되는 경우가 없는 릴레이션 형태를 말한다."
BACKEND,데이터베이스,정규화에서 BCNF(Boyce의Codd) 정규형는 무엇인가요?,여러 후보 키가 존재하는 릴레이션에 해당하는 정규화 내용이다. 복잡한 식별자 관계에 의해 발생하는 문제를 해결하기 위해 제 3 정규형을 보완하는데 의미가 있다. 비주요 애트리뷰트가 후보키의 일부를 결정하는 분해하는 과정을 말한다. * 모든 제 2 정규형 릴레이션은 제 1 정규형을 갖는다. * 모든 제 3 정규형 릴레이션은 제 2 정규형을 갖는다. * 모든 BCNF 정규형 릴레이션은 제 3 정규형을 갖는다. 수많은 정규형이 있지만 관계 데이터베이스 설계의 목표는 각 릴레이션이 3NF(or BCNF)를 갖게 하는 것이다.
BACKEND,데이터베이스,정규화의 장점은 무엇인가,"1. 데이터베이스 변경 시 이상 현상(Anomaly) 제거 위에서 언급했던 각종 이상 현상들이 발생하는 문제점을 해결할 수 있다. 2. 데이터베이스 구조 확장 시 재 디자인 최소화 정규화된 데이터베이스 구조에서는 새로운 데이터 형의 추가로 인한 확장 시, 그 구조를 변경하지 않아도 되거나 일부만 변경해도 된다. 이는 데이터베이스와 연동된 응용 프로그램에 최소한의 영향만을 미치게 되며 응용프로그램의 생명을 연장시킨다. 3. 사용자에게 데이터 모델을 더욱 의미있게 제공 정규화된 테이블들과 정규화된 테이블들간의 관계들은 현실 세계에서의 개념들과 그들간의 관계들을 반영한다."
BACKEND,데이터베이스,정규화의단점는 없는가?,"릴레이션의 분해로 인해 릴레이션 간의 연산(JOIN 연산)이 많아진다. 이로 인해 질의에 대한 응답 시간이 느려질 수 있다. 조금 덧붙이자면, 정규화를 수행한다는 것은 데이터를 결정하는 결정자에 의해 함수적 종속을 가지고 있는 일반 속성을 의존자로 하여 입력/수정/삭제 이상을 제거하는 것이다. 데이터의 중복 속성을 제거하고 결정자에 의해 동일한 의미의 일반 속성이 하나의 테이블로 집약되므로 한 테이블의 데이터 용량이 최소화되는 효과가 있다. 따라서 정규화된 테이블은 데이터를 처리할 때 속도가 빨라질 수도 있고 느려질 수도 있는 특성이 있다."
BACKEND,데이터베이스,정규화의 단점에서 미루어보았을 때 어떠한 상황에서 정규화를 진행해야 하는가? 단점에 대한 대응책는?,조회를 하는 SQL 문장에서 조인이 많이 발생하여 이로 인한 성능저하가 나타나는 경우에 반정규화를 적용하는 전략이 필요하다.
BACKEND,데이터베이스,"반정규화(De의normalization, 비정규화)는 무엇인가요?","`반정규화`는 정규화된 엔티티, 속성, 관계를 시스템의 성능 향상 및 개발과 운영의 단순화를 위해 중복 통합, 분리 등을 수행하는 데이터 모델링 기법 중 하나이다. 디스크 I/O 량이 많아서 조회 시 성능이 저하되거나, 테이블끼리의 경로가 너무 멀어 조인으로 인한 성능 저하가 예상되거나, 칼럼을 계산하여 조회할 때 성능이 저하될 것이 예상되는 경우 반정규화를 수행하게 된다. 일반적으로 조회에 대한 처리 성능이 중요하다고 판단될 때 부분적으로 반정규화를 고려하게 된다."
BACKEND,데이터베이스,무엇이 반정규화의 대상이 되는가?,"1. 자주 사용되는 테이블에 액세스하는 프로세스의 수가 가장 많고, 항상 일정한 범위만을 조회하는 경우 2. 테이블에 대량 데이터가 있고 대량의 범위를 자주 처리하는 경우, 성능 상 이슈가 있을 경우 3. 테이블에 지나치게 조인을 많이 사용하게 되어 데이터를 조회하는 것이 기술적으로 어려울 경우"
BACKEND,데이터베이스,반정규화 과정에서 주의할 점는?,"반정규화를 과도하게 적용하다 보면 데이터의 무결성이 깨질 수 있다. 또한 입력, 수정, 삭제의 질의문에 대한 응답 시간이 늦어질 수 있다."
BACKEND,데이터베이스,트랜잭션(Transaction)이란 무엇인가?,"트랜잭션은 작업의 완전성 을 보장해주는 것이다. 즉, 논리적인 작업 셋을 모두 완벽하게 처리하거나 또는 처리하지 못할 경우에는 원 상태로 복구해서 작업의 일부만 적용되는 현상이 발생하지 않게 만들어주는 기능이다. 사용자의 입장에서는 작업의 논리적 단위로 이해를 할 수 있고 시스템의 입장에서는 데이터들을 접근 또는 변경하는 프로그램의 단위가 된다."
BACKEND,데이터베이스,트랜잭션과 Lock은(는) 무엇인가요?,"잠금(Lock)과 트랜잭션은 서로 비슷한 개념 같지만 사실 잠금은 동시성을 제어하기 위한 기능이고 트랜잭션은 데이터의 정합성을 보장하기 위한 기능이다. 잠금은 여러 커넥션에서 동시에 동일한 자원을 요청할 경우 순서대로 한 시점에는 하나의 커넥션만 변경할 수 있게 해주는 역할을 한다. 여기서 자원은 레코드나 테이블을 말한다. 이와는 조금 다르게 트랜잭션은 꼭 여러 개의 변경 작업을 수행하는 쿼리가 조합되었을 때만 의미있는 개념은 아니다. 트랜잭션은 하나의 논리적인 작업 셋 중 하나의 쿼리가 있든 두 개 이상의 쿼리가 있든 관계없이 논리적인 작업 셋 자체가 100% 적용되거나 아무것도 적용되지 않아야 함을 보장하는 것이다. 예를 들면 HW 에러 또는 SW 에러와 같은 문제로 인해 작업에 실패가 있을 경우, 특별한 대책이 필요하게 되는데 이러한 문제를 해결하는 것이다."
BACKEND,데이터베이스,트랜잭션의 특성는 무엇인가요?,Transaction 은 다음의 ACID 라는 4 가지 특성을 만족해야 한다.
BACKEND,데이터베이스,Transaction에서 원자성(Atomicity)은(는) 무엇인가요?,만약 트랜잭션 중간에 어떠한 문제가 발생한다면 트랜잭션에 해당하는 어떠한 작업 내용도 수행되어서는 안되며 아무런 문제가 발생되지 않았을 경우에만 모든 작업이 수행되어야 한다.
BACKEND,데이터베이스,Transaction에서 일관성(Consistency)은(는) 무엇인가요?,트랜잭션이 완료된 다음의 상태에서도 트랜잭션이 일어나기 전의 상황과 동일하게 데이터의 일관성을 보장해야 한다.
BACKEND,데이터베이스,Transaction에서 고립성(Isolation)은(는) 무엇인가요?,각각의 트랜잭션은 서로 간섭없이 독립적으로 수행되어야 한다.
BACKEND,데이터베이스,Transaction에서 지속성(Durability)은(는) 무엇인가요?,트랜잭션이 정상적으로 종료된 다음에는 영구적으로 데이터베이스에 작업의 결과가 저장되어야 한다.
BACKEND,데이터베이스,Transaction에서 Active은(는) 무엇인가요?,트랜잭션의 활동 상태. 트랜잭션이 실행중이며 동작중인 상태를 말한다.
BACKEND,데이터베이스,Transaction에서 Failed은(는) 무엇인가요?,트랜잭션 실패 상태. 트랜잭션이 더이상 정상적으로 진행 할 수 없는 상태를 말한다.
BACKEND,데이터베이스,Transaction에서 Partially Committed은(는) 무엇인가요?,트랜잭션의 `Commit` 명령이 도착한 상태. 트랜잭션의 `commit`이전 `sql`문이 수행되고 `commit`만 남은 상태를 말한다.
BACKEND,데이터베이스,Transaction에서 Committed은(는) 무엇인가요?,트랜잭션 완료 상태. 트랜잭션이 정상적으로 완료된 상태를 말한다.
BACKEND,데이터베이스,Transaction에서 Aborted은(는) 무엇인가요?,트랜잭션이 취소 상태. 트랜잭션이 취소되고 트랜잭션 실행 이전 데이터로 돌아간 상태를 말한다.
BACKEND,데이터베이스,Transaction에서 Partially Committed 와 Committed 의 차이점는 무엇인가요?,"`Commit` 요청이 들어오면 상태는 `Partial Commited` 상태가 된다. 이후 `Commit`을 문제없이 수행할 수 있으면 `Committed` 상태로 전이되고, 만약 오류가 발생하면 `Failed` 상태가 된다. 즉, `Partial Commited`는 `Commit` 요청이 들어왔을때를 말하며, `Commited`는 `Commit`을 정상적으로 완료한 상태를 말한다."
BACKEND,데이터베이스,트랜잭션을 사용할 때 주의할 점는 무엇인가요?,트랜잭션은 꼭 필요한 최소의 코드에만 적용하는 것이 좋다. 즉 트랜잭션의 범위를 최소화하라는 의미다. 일반적으로 데이터베이스 커넥션은 개수가 제한적이다. 그런데 각 단위 프로그램이 커넥션을 소유하는 시간이 길어진다면 사용 가능한 여유 커넥션의 개수는 줄어들게 된다. 그러다 어느 순간에는 각 단위 프로그램에서 커넥션을 가져가기 위해 기다려야 하는 상황이 발생할 수도 있는 것이다.
BACKEND,데이터베이스,Transaction에서 교착상태란 무엇인가는 무엇인가요?,"복수의 트랜잭션을 사용하다보면 교착상태가 일어날수 있다. 교착상태란 두 개 이상의 트랜잭션이 특정 자원(테이블 또는 행)의 잠금(Lock)을 획득한 채 다른 트랜잭션이 소유하고 있는 잠금을 요구하면 아무리 기다려도 상황이 바뀌지 않는 상태가 되는데, 이를 `교착상태`라고 한다."
BACKEND,데이터베이스,Transaction에서 교착상태의 예(MySQL)은(는) 무엇인가요?,![classic deadlock 출처: ] 트랜잭션 1이 테이블 B의 첫번째 행의 잠금을 얻고 트랜잭션 2도 테이블 A의 첫번째 행의 잠금을 얻었다고 하자. ```SQL Transaction 1> create table B (i1 int not null primary key) engine = innodb; Transaction 2> create table A (i1 int not null primary key) engine = innodb; Transaction 1> start transaction; insert into B values(1); Transaction 2> start transaction; insert into A values(1); ``` 트랜잭션을 commit 하지 않은채 서로의 첫번째 행에 대한 잠금을 요청하면 ```SQL Transaction 1> insert into A values(1); Transaction 2> insert into B values(1); ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction ``` Deadlock 이 발생한다. 일반적인 DBMS는 교착상태를 독자적으로 검출해 보고한다.
BACKEND,데이터베이스,Transaction에서 교착 상태의 빈도를 낮추는 방법는 무엇인가요?,"* 트랜잭션을 자주 커밋한다. * 정해진 순서로 테이블에 접근한다. 위에서 트랜잭션 1 이 테이블 B -> A 의 순으로 접근했고, 트랜잭션 2 는 테이블 A -> B의 순으로 접근했다. 트랜잭션들이 동일한 테이블 순으로 접근하게 한다. * 읽기 잠금 획득 (SELECT ~ FOR UPDATE)의 사용을 피한다. * 한 테이블의 복수 행을 복수의 연결에서 순서 없이 갱신하면 교착상태가 발생하기 쉽다, 이 경우에는 테이블 단위의 잠금을 획득해 갱신을 직렬화 하면 동시성은 떨어지지만 교착상태를 회피할 수 있다."
BACKEND,데이터베이스,Statement vs PreparedStatement은(는) 무엇인가요?,"우선 속도 면에서 `PreparedStatement`가 빠르다고 알려져 있다. 이유는 쿼리를 수행하기 전에 이미 쿼리가 컴파일 되어 있으며, 반복 수행의 경우 프리 컴파일된 쿼리를 통해 수행이 이루어지기 때문이다. `Statement`에는 보통 변수를 설정하고 바인딩하는 `static sql`이 사용되고 `Prepared Statement`에서는 쿼리 자체에 조건이 들어가는 `dynamic sql`이 사용된다. `PreparedStatement`가 파싱 타임을 줄여주는 것은 분명하지만 `dynamic sql`을 사용하는데 따르는 퍼포먼스 저하를 고려하지 않을 수 없다. 하지만 성능을 고려할 때 시간 부분에서 가장 큰 비중을 차지하는 것은 테이블에서 레코드(row)를 가져오는 과정이고 SQL 문을 파싱하는 시간은 이 시간의 10 분의 1 에 불과하다. 그렇기 때문에 `SQL Injection` 등의 문제를 보완해주는 `PreparedStatement`를 사용하는 것이 옳다."
BACKEND,데이터베이스,NoSQL에서 일관성(Consistency)은(는) 무엇인가요?,"일관성은 동시성 또는 동일성이라고도 하며 다중 클라이언트에서 같은 시간에 조회하는 데이터는 항상 동일한 데이터임을 보증하는 것을 의미한다. 이것은 관계형 데이터베이스가 지원하는 가장 기본적인 기능이지만 일관성을 지원하지 않는 NoSQL 을 사용한다면 데이터의 일관성이 느슨하게 처리되어 동일한 데이터가 나타나지 않을 수 있다. 느슨하게 처리된다는 것은 데이터의 변경을 시간의 흐름에 따라 여러 노드에 전파하는 것을 말한다. 이러한 방법을 최종적으로 일관성이 유지된다고 하여 최종 일관성 또는 궁극적 일관성을 지원한다고 한다. 각 NoSQL 들은 분산 노드 간의 데이터 동기화를 위해서 두 가지 방법을 사용한다. 첫번째로 데이터의 저장 결과를 클라이언트로 응답하기 전에 모든 노드에 데이터를 저장하는 동기식 방법이 있다. 그만큼 느린 응답시간을 보이지만 데이터의 정합성을 보장한다. 두번째로 메모리나 임시 파일에 기록하고 클라이언트에 먼저 응답한 다음, 특정 이벤트 또는 프로세스를 사용하여 노드로 데이터를 동기화하는 비동기식 방법이 있다. 빠른 응답시간을 보인다는 장점이 있지만, 쓰기 노드에 장애가 발생하였을 경우 데이터가 손실될 수 있다."
BACKEND,데이터베이스,NoSQL에서 가용성(Availability)은(는) 무엇인가요?,가용성이란 모든 클라이언트의 읽기와 쓰기 요청에 대하여 항상 응답이 가능해야 함을 보증하는 것이며 내고장성이라고도 한다. 내고장성을 가진 NoSQL 은 클러스터 내에서 몇 개의 노드가 망가지더라도 정상적인 서비스가 가능하다. 몇몇 NoSQL 은 가용성을 보장하기 위해 데이터 복제(Replication)을 사용한다. 동일한 데이터를 다중 노드에 중복 저장하여 그 중 몇 대의 노드가 고장나도 데이터가 유실되지 않도록 하는 방법이다. 데이터 중복 저장 방법에는 동일한 데이터를 가진 저장소를 하나 더 생성하는 Master-Slave 복제 방법과 데이터 단위로 중복 저장하는 Peer-to-Peer 복제 방법이 있다.
BACKEND,데이터베이스,NoSQL에서 네트워크 분할 허용성(Partition tolerance)은(는) 무엇인가요?,분할 허용성이란 지역적으로 분할된 네트워크 환경에서 동작하는 시스템에서 두 지역 간의 네트워크가 단절되거나 네트워크 데이터의 유실이 일어나더라도 각 지역 내의 시스템은 정상적으로 동작해야 함을 의미한다.
BACKEND,데이터베이스,NoSQL에서 저장 방식에 따른 NoSQL 분류는 무엇인가요?,"`Key-Value Model`, `Document Model`, `Column Model`, `Graph Model`로 분류할 수 있다."
BACKEND,데이터베이스,NoSQL 의 Key의Value Model은(는) 무엇인가요?,"가장 기본적인 형태의 NoSQL 이며 키 하나로 데이터 하나를 저장하고 조회할 수 있는 단일 키-값 구조를 갖는다. 단순한 저장구조로 인하여 복잡한 조회 연산을 지원하지 않는다. 또한 고속 읽기와 쓰기에 최적화된 경우가 많다. 사용자의 프로필 정보, 웹 서버 클러스터를 위한 세션 정보, 장바구니 정보, URL 단축 정보 저장 등에 사용한다. 하나의 서비스 요청에 다수의 데이터 조회 및 수정 연산이 발생하면 트랜잭션 처리가 불가능하여 데이터 정합성을 보장할 수 없다."
BACKEND,데이터베이스,NoSQL에서 Document Model은(는) 무엇인가요?,"키-값 모델을 개념적으로 확장한 구조로 하나의 키에 하나의 구조화된 문서를 저장하고 조회한다. 논리적인 데이터 저장과 조회 방법이 관계형 데이터베이스와 유사하다. 키는 문서에 대한 ID 로 표현된다. 또한 저장된 문서를 컬렉션으로 관리하며 문서 저장과 동시에 문서 ID 에 대한 인덱스를 생성한다. 문서 ID 에 대한 인덱스를 사용하여 O(1) 시간 안에 문서를 조회할 수 있다. 대부분의 문서 모델 NoSQL 은 B 트리 인덱스를 사용하여 2 차 인덱스를 생성한다. B 트리는 크기가 커지면 커질수록 새로운 데이터를 입력하거나 삭제할 때 성능이 떨어지게 된다. 그렇기 때문에 읽기와 쓰기의 비율이 7:3 정도일 때 가장 좋은 성능을 보인다. 중앙 집중식 로그 저장, 타임라인 저장, 통계 정보 저장 등에 사용된다."
BACKEND,데이터베이스,NoSQL에서 Column Model은(는) 무엇인가요?,"하나의 키에 여러 개의 컬럼 이름과 컬럼 값의 쌍으로 이루어진 데이터를 저장하고 조회한다. 모든 컬럼은 항상 타임 스탬프 값과 함께 저장된다. 구글의 빅테이블이 대표적인 예로 차후 컬럼형 NoSQL 은 빅테이블의 영향을 받았다. 이러한 이유로 Row key, Column Key, Column Family 같은 빅테이블 개념이 공통적으로 사용된다. 저장의 기본 단위는 컬럼으로 컬럼은 컬럼 이름과 컬럼 값, 타임스탬프로 구성된다. 이러한 컬럼들의 집합이 로우(Row)이며, 로우키(Row key)는 각 로우를 유일하게 식별하는 값이다. 이러한 로우들의 집합은 키 스페이스(Key Space)가 된다. 대부분의 컬럼 모델 NoSQL 은 쓰기와 읽기 중에 쓰기에 더 특화되어 있다. 데이터를 먼저 커밋로그와 메모리에 저장한 후 응답하기 때문에 빠른 응답속도를 제공한다. 그렇기 때문에 읽기 연산 대비 쓰기 연산이 많은 서비스나 빠른 시간 안에 대량의 데이터를 입력하고 조회하는 서비스를 구현할 때 가장 좋은 성능을 보인다. 채팅 내용 저장, 실시간 분석을 위한 데이터 저장소 등의 서비스 구현에 적합하다."
공통,디자인 패턴,Singleton에서 필요성는 무엇인가요?,"`Singleton pattern(싱글턴 패턴)`이란 애플리케이션에서 인스턴스를 하나만 만들어 사용하기 위한 패턴이다. 커넥션 풀, 스레드 풀, 디바이스 설정 객체 등의 경우, 인스턴스를 여러 개 만들게 되면 자원을 낭비하게 되거나 버그를 발생시킬 수 있으므로 오직 하나만 생성하고 그 인스턴스를 사용하도록 하는 것이 이 패턴의 목적이다."
공통,디자인 패턴,Singleton에서 구현는 무엇인가요?,"하나의 인스턴스만을 유지하기 위해 인스턴스 생성에 특별한 제약을 걸어둬야 한다. new 를 실행할 수 없도록 생성자에 private 접근 제어자를 지정하고, 유일한 단일 객체를 반환할 수 있도록 정적 메소드를 지원해야 한다. 또한 유일한 단일 객체를 참조할 정적 참조변수가 필요하다. ```java public class Singleton { private static Singleton singletonObject; private Singleton() {} public static Singleton getInstance() { if (singletonObject == null) { singletonObject = new Singleton(); } return singletonObject; } } ``` 이 코드는 정말 위험하다. 멀티스레딩 환경에서 싱글턴 패턴을 적용하다보면 문제가 발생할 수 있다. 동시에 접근하다가 하나만 생성되어야 하는 인스턴스가 두 개 생성될 수 있는 것이다. 그렇게 때문에 `getInstance()` 메소드를 동기화시켜야 멀티스레드 환경에서의 문제가 해결된다. ```java public class Singleton { private static Singleton singletonObject; private Singleton() {} public static synchronized Singleton getInstance() { if (singletonObject == null) { singletonObject = new Singleton(); } return singletonObject; } } ``` `synchronized` 키워드를 사용하게 되면 성능상에 문제점이 존재한다. 좀 더 효율적으로 제어할 수는 없을까? ```java public class Singleton { private static volatile Singleton singletonObject; private Singleton() {} public static Singleton getInstance() { if (singletonObject == null) { synchronized (Singleton.class) { if(singletonObject == null) { singletonObject = new Singleton(); } } } return singletonObject; } } ``` `DCL(Double Checking Locking)`을 써서 `getInstance()`에서 동기화 되는 영역을 줄일 수 있다. 초기에 객체를 생성하지 않으면서도 동기화하는 부분을 작게 만들었다. 그러나 이 코드는 멀티코어 환경에서 동작할 때, 하나의 CPU 를 제외하고는 다른 CPU 가 lock 이 걸리게 된다. 그렇기 때문에 다른 방법이 필요하다. ```java public class Singleton { private static volatile Singleton singletonObject = new Singleton(); private Singleton() {} public static Singleton getSingletonObject() { return singletonObject; } } ``` 클래스가 로딩되는 시점에 미리 객체를 생성해두고 그 객체를 반환한다."
공통,알고리즘,코딩 테스트의 목적는 무엇인가요?,1. 문제 해결 여부 2. 예외 상황과 경계값 처리 3. 코드 가독성과 중복 제거 여부 등 코드 품질 4. 언어 이해도 5. 효율성 궁극적으로는 문제 해결 능력을 측정하기 위함이며 이는 '어떻게 이 문제를 창의적으로 해결할 것인가'를 측정하기 위함이라고 볼 수 있다.
공통,알고리즘,접근하기는 무엇인가요?,"1. 문제를 공격적으로 받아들이고 필요한 정보를 추가적으로 요구하여, 해당 문제에 대해 완벽하게 이해하는게 우선이다. 2. 해당 문제를 익숙한 용어로 재정의하거나 문제를 해결하기 위한 정보를 추출한다. 이 과정을 추상화라고 한다. 3. 추상화된 데이터를 기반으로 이 문제를 어떻게 해결할 지 계획을 세운다. 이 때 사용할 알고리즘과 자료구조를 고민한다. 4. 세운 계획에 대해 검증을 해본다. 수도 코드 작성도 해당될 수 있고 문제 출제자에게 의견을 물어볼 수도 있다. 5. 세운 계획으로 문제를 해결해본다. 해결이 안 된다면 앞선 과정을 되짚어본다."
공통,알고리즘,생각할 때는 무엇인가요?,* 비슷한 문제를 생각해본다. * 단순한 방법으로 시작하여 점진적으로 개선해나간다. * 작은 값을 생각해본다. * 그림으로 그려본다. * 수식으로 표현해본다. * 순서를 강제해본다. * 뒤에서부터 생각해본다.
공통,알고리즘,DP(동적 계획법)은(는) 무엇인가요?,"복잡한 문제를 간단한 여러 개의 하위 문제(sub-problem)로 나누어 푸는 방법을 말한다. DP 에는 두 가지 구현 방식이 존재한다. * top-down : 여러 개의 하위 문제(sub-problem) 나눴을시에 하위 문제를 결합하여 최종적으로 최적해를 구한다. * 같은 하위 문제를 가지고 있는 경우가 존재한다. 그 최적해를 저장해서 사용하는 경우 하위 문제수가 기하급수적으로 증가할 때 유용하다. 위 방법을 memoization 이라고 한다. * bottom-up : top-down 방식과는 하위 문제들로 상위 문제의 최적해를 구한다. Fibonacci 수열을 예로 들어보면, ``` top-down f (int n) { if n == 0 : return 0 elif n == 1: return 1 if dp[n] has value : return dp[n] else : dp[n] = f(n-2) + f(n-1) return dp[n] } ``` ``` bottom-up f (int n){ f[0] = 0 f[1] = 1 for (i = 2; i <= n; i++) { f[i] = f[i-2] + f[i-1] } return f[n] } ```"
공통,알고리즘,Greedy (탐욕법)은(는) 무엇인가요?,모든 선택지를 고려해보고 그 중 가장 좋은 것을 찾는 방법이 Divide conquer or dp 였다면 greedy 는 각 단계마다 지금 당장 가장 좋은 방법만을 선택하는 해결 방법이다. 탐욕법은 동적 계획법보다 수행 시간이 훨씬 빠르기 때문에 유용하다. 많은 경우 최적해를 찾지 못하고 적용될 수 있는 경우가 두 가지로 제한된다. 1. 탐욕법을 사용해도 항상 최적해를 구할 수 있는 경우 2. 시간이나 공간적 제약으로 최적해 대신 근사해를 찾아서 해결하는 경우
공통,알고리즘,접근 방법는 무엇인가요?,"1. 문제의 답을 만드는 과정을 여러 조각으로 나눈다. 2. 각 조각마다 어떤 우선순위로 선택을 내려야 할지 결정한다. 작은 입력을 손으로 풀어본다. 3. 다음 두 속성이 적용되는지 확인해본다. 1) 탐욕적 성택 속성 : 항상 각 단계에서 우리가 선택한 답을 포함하는 최적해가 존재하는가 2) 최적 부분 구조 : 각 단계에서 항상 최적의 선택만을 했을 때, 전체 최적해를 구할 수 있는가"
공통,알고리즘,Divide and Conquer (분할 정복)은(는) 무엇인가요?,"분할 정복은 큰 문제를 작은 문제로 쪼개어 답을 찾아가는 방식이다. 하부구조(non-overlapping subproblem)가 반복되지 않는 문제를 해결할 때 사용할 수 있다. 최적화 문제(가능한 해답의 범위 중 최소, 최대를 구하는 문제), 최적화가 아닌 문제 모두에 적용할 수 있다. top-down 접근 방식을 사용한다. 재귀적 호출 구조를 사용한다. 이때 call stack을 사용한다. (call stack에서의 stack overflow에 유의해야 한다.)"
공통,알고리즘,문제 해결을 위한 전략적 접근에서 DP vs DIVIDE&CONQUER vs GREEDY은(는) 무엇인가요?,"|Divide and Conquer|Dynamic Programming|Greedy| |:---:|:---:|:---:| |non-overlapping한 문제를 작은 문제로 쪼개어 해결하는데 non-overlapping|overlapping substructure를 갖는 문제를 해결한다.|각 단계에서의 최적의 선택을 통해 해결한다.| |top-down 접근|top-down, bottom-up 접근|| |재귀 함수를 사용한다.|재귀적 관계(점화식)를 이용한다.(점화식)|반복문을 사용한다.| |call stack을 통해 답을 구한다.|look-up-table, 즉 행렬에 반복적인 구조의 solution을 저장해 놓는 방식으로 답을 구한다.|solution set에 단계별 답을 추가하는 방식으로 답을 구한다.| |분할 - 정복 - 병합|점화식 도출 - look-up-table에 결과 저장 - 나중에 다시 꺼내씀|단계별 최적의 답을 선택 - 조건에 부합하는지 확인 - 마지막에 전체조건에 부합하는지 확인| |이분탐색, 퀵소트, 머지소트|최적화 이분탐색, 이항계수 구하디, 플로이드-와샬|크루스칼, 프림, 다익스트라, 벨만-포드|"
공통,알고리즘,Sorting Algorithm은(는) 무엇인가요?,Sorting 알고리즘은 크게 Comparisons 방식과 Non-Comparisons 방식으로 나눌 수 있다.
공통,알고리즘,Sorting Algorithm에서 Comparisons Sorting Algorithm (비교 방식 알고리즘)은(는) 무엇인가요?,"`Bubble Sort`, `Selection Sort`, `Insertion Sort`, `Merge Sort`, `Heap Sort`, `Quick Sort` 를 소개한다."
공통,알고리즘,Sorting Algorithm에서 Bubble Sort은(는) 무엇인가요?,"n 개의 원소를 가진 배열을 정렬할 때, In-place sort 로 인접한 두 개의 데이터를 비교해가면서 정렬을 진행하는 방식이다. 가장 큰 값을 배열의 맨 끝에다 이동시키면서 정렬하고자 하는 원소의 개수 만큼을 두 번 반복하게 된다. | Space Complexity | Time Complexity | | :--------------: | :-------------: | | O(1) | O(n^2) |"
공통,알고리즘,Sorting Algorithm에서 Selection Sort은(는) 무엇인가요?,"n 개의 원소를 가진 배열을 정렬할 때, 계속해서 바꾸는 것이 아니라 비교하고 있는 값의 index 를 저장해둔다. 그리고 최종적으로 한 번만 바꿔준다. 하지만 여러 번 비교를 하는 것은 마찬가지이다. | Space Complexity | Time Complexity | | :--------------: | :-------------: | | O(1) | O(n^2) |"
공통,알고리즘,Sorting Algorithm에서 Insertion Sort은(는) 무엇인가요?,"n 개의 원소를 가진 배열을 정렬할 때, i 번째를 정렬할 순서라고 가정하면, 0 부터 i-1 까지의 원소들은 정렬되어있다는 가정하에, i 번째 원소와 i-1 번째 원소부터 0 번째 원소까지 비교하면서 i 번째 원소가 비교하는 원소보다 클 경우 서로의 위치를 바꾸고, 작을 경우 위치를 바꾸지 않고 다음 순서의 원소와 비교하면서 정렬해준다. 이 과정을 정렬하려는 배열의 마지막 원소까지 반복해준다. | Space Complexity | Time Complexity | | :--------------: | :-------------: | | O(1) | O(n^2) |"
공통,알고리즘,Sorting Algorithm에서 Merge Sort은(는) 무엇인가요?,"기본적인 개념으로는 n 개의 원소를 가진 배열을 정렬할 때, 정렬하고자 하는 배열의 크기를 작은 단위로 나누어 정렬하고자 하는 배열의 크기를 줄이는 원리를 사용한다. `Divide and conquer`라는, ""분할하여 정복한다""의 원리인 것이다. 말 그대로 복잡한 문제를 복잡하지 않은 문제로 분할하여 정복하는 방법이다. 단 분할(divide)해서 정복했으니 정복(conquer)한 후에는 결합(combine) 의 과정을 거쳐야 한다. `Merge Sort`는 더이상 나누어지지 않을 때 까지 반 씩(1/2) 분할하다가 더 이상 나누어지지 않은 경우(원소가 하나인 배열일 때)에는 자기 자신, 즉 원소 하나를 반환한다. 원소가 하나인 경우에는 정렬할 필요가 없기 때문이다. 이 때 반환한 값끼리 `combine`될 때, 비교가 이뤄지며, 비교 결과를 기반으로 정렬되어 임시 배열에 저장된다. 그리고 이 임시 배열에 저장된 순서를 합쳐진 값으로 반환한다. 실제 정렬은 나눈 것을 병합하는 과정에서 이뤄지는 것이다. 결국 하나씩 남을 때까지 분할하는 것이면, 바로 하나씩 분할해버리면 되지 않을까? 재귀적으로 정렬하는 원리인 것이다. 재귀적 구현을 위해 1/2 씩 분할한다. | Space Complexity | Time Complexity | | :--------------: | :-------------: | | O(n) | O(nlogn) |"
공통,알고리즘,Sorting Algorithm에서 Heap Sort은(는) 무엇인가요?,"`binary heap` 자료구조를 활용할 Sorting 방법에는 두 가지 방법이 존재한다. 하나는 정렬의 대상인 데이터들을 힙에 넣었다가 꺼내는 원리로 Sorting 을 하게 되는 방법이고, 나머지 하나는 기존의 배열을 `heapify`(heap 으로 만들어주는 과정)을 거쳐 꺼내는 원리로 정렬하는 방법이다. `heap`에 데이터를 저장하는 시간 복잡도는 `O(log n)`이고, 삭제 시간 복잡도 또한 `O(log n)`이 된다. 때문에 힙 자료구조를 사용하여 Sorting 을 하는데 time complexity 는 `O(log n)`이 된다. 이 정렬을 하려는 대상이 n 개라면 time complexity 는 `O(nlogn)`이 된다. | Space Complexity | Time Complexity | | :--------------: | :-------------: | | O(1) | O(nlogn) |"
공통,알고리즘,Sorting Algorithm에서 Quick Sort은(는) 무엇인가요?,"Sorting 기법 중 가장 빠르다고 해서 quick 이라는 이름이 붙여졌다. 하지만 Worst Case 에서는 시간복잡도가 O(n^2)가 나올 수도 있다. 하지만 `constant factor`가 작아서 속도가 빠르다. `Quick Sort` 역시 `Divide and Conquer` 전략을 사용하여 Sorting 이 이루어진다. Divide 과정에서 `pivot`이라는 개념이 사용된다. 입력된 배열에 대해 오름차순으로 정렬한다고 하면 이 pivot 을 기준으로 좌측은 pivot 으로 설정된 값보다 작은 값이 위치하고, 우측은 큰 값이 위치하도록 `partition`된다. 이렇게 나뉜 좌, 우측 각각의 배열을 다시 재귀적으로 Quick Sort 를 시키면 또 partition 과정이 적용된다.이 때 한 가지 주의할 점은 partition 과정에서 pivot 으로 설정된 값은 다음 재귀과정에 포함시키지 않아야 한다. 이미 partition 과정에서 정렬된 자신의 위치를 찾았기 때문이다."
공통,알고리즘,Sorting Algorithm에서 Quick Sort's worst case은(는) 무엇인가요?,"그렇다면 어떤 경우가 Worst Case 일까? Quick Sort 로 오름차순 정렬을 한다고 하자. 그렇다면 Worst Case 는 partition 과정에서 pivot value 가 항상 배열 내에서 가장 작은 값 또는 가장 큰 값으로 설정되었을 때이다. 매 partition 마다 `unbalanced partition`이 이뤄지고 이렇게 partition 이 되면 비교 횟수는 원소 n 개에 대해서 n 번, (n-1)번, (n-2)번 … 이 되므로 시간 복잡도는 O(n^2) 이 된다."
공통,알고리즘,Sorting Algorithm 의 Balanced의partitioning은(는) 무엇인가요?,"자연스럽게 Best-Case 는 두 개의 sub-problems 의 크기가 동일한 경우가 된다. 즉 partition 과정에서 반반씩 나뉘게 되는 경우인 것이다. 그렇다면 Partition 과정에서 pivot 을 어떻게 정할 것인가가 중요해진다. 어떻게 정하면 정확히 반반의 partition 이 아니더라도 balanced-partitioning 즉, 균형 잡힌 분할을 할 수 있을까? 배열의 맨 뒤 또는 맨 앞에 있는 원소로 설정하는가? Random 으로 설정하는 것은 어떨까? 특정 위치의 원소를 pivot 으로 설정하지 않고 배열 내의 원소 중 임의의 원소를 pivot 으로 설정하면 입력에 관계없이 일정한 수준의 성능을 얻을 수 있다. 또 악의적인 입력에 대해 성능 저하를 막을 수 있다."
공통,알고리즘,Sorting Algorithm에서 Partitioning은(는) 무엇인가요?,"정작 중요한 Partition 은 어떻게 이루어지는가에 대한 이야기를 하지 않았다. 가장 마지막 원소를 pivot 으로 설정했다고 가정하자. 이 pivot 의 값을 기준으로 좌측에는 작은 값 우측에는 큰 값이 오도록 해야 하는데, 일단 pivot 은 움직이지 말자. 첫번째 원소부터 비교하는데 만약 그 값이 pivot 보다 작다면 그대로 두고 크다면 맨 마지막에서 그 앞의 원소와 자리를 바꿔준다. 즉 pivot value 의 index 가 k 라면 k-1 번째와 바꿔주는 것이다. 이 모든 원소에 대해 실행하고 마지막 과정에서 작은 값들이 채워지는 인덱스를 가리키고 있는 값에 1 을 더한 index 값과 pivot 값을 바꿔준다. 즉, 최종적으로 결정될 pivot 의 인덱스를 i 라고 했을 때, 0 부터 i-1 까지는 pivot 보다 작은 값이 될 것이고 i+1 부터 k 까지는 pivot 값보다 큰 값이 될 것이다. | Space Complexity | Time Complexity | | :--------------: | :-------------: | | O(log(n)) | O(nlogn) |"
공통,알고리즘,Sorting Algorithm 의 non의Comparisons Sorting Algorithm은(는) 무엇인가요?,"`Counting Sort`, `Radix Sort` 를 소개한다."
공통,알고리즘,Sorting Algorithm에서 Counting Sort은(는) 무엇인가요?,Count Sort 는 말 그대로 몇 개인지 개수를 세어 정렬하는 방식이다. 정렬하고자 하는 값 중 최대값에 해당하는 값을 size 로 하는 임시 배열 을 만든다. 만들어진 배열의 index 중 일부는 정렬하고자 하는 값들이 되므로 그 값에는 그 값들의 개수 를 나타낸다. 정렬하고자 하는 값들이 몇 개씩인지 파악하는 임시 배열이 만들어졌다면 이 임시 배열을 기준으로 정렬을 한다. 그 전에 임시 배열에서 한 가지 작업을 추가적으로 수행해주어야 하는데 큰 값부터 즉 큰 index 부터 시작하여 누적된 값으로 변경해주는 것이다. 이 누적된 값은 정렬하고자 하는 값들이 정렬될 index 값을 나타내게 된다. 작업을 마친 임시 배열의 index 는 정렬하고자 하는 값을 나타내고 value 는 정렬하고자 하는 값들이 정렬되었을 때의 index 를 나타내게 된다. 이를 기준으로 정렬을 해준다. 점수와 같이 0~100 으로 구성되는 좁은 범위에 존재하는 데이터들을 정렬할 때 유용하게 사용할 수 있다. | Space Complexity | Time Complexity | | :--------------: | :-------------: | | O(n) | O(n) |
공통,알고리즘,Sorting Algorithm에서 Radix Sort은(는) 무엇인가요?,"정렬 알고리즘의 한계는 O(n log n)이지만, 기수 정렬은 이 한계를 넘어설 수 있는 알고리즘이다. 단, 한 가지 단점이 존재하는데 적용할 수 있는 범위가 제한적이라는 것이다. 이 범위는 데이터 길이 에 의존하게 된다. 정렬하고자 하는 데이터의 길이가 동일하지 않은 데이터에 대해서는 정렬이 불가능하다. 숫자말고 문자열의 경우도 마찬가지이다. (불가능하다는 것은 기존의 정렬 알고리즘에 비해 기수 정렬 알고리즘으로는 좋은 성능을 내는데 불가능하다는 것이다.) 기수(radix)란 주어진 데이터를 구성하는 기본요소를 의미한다. 이 기수를 이용해서 정렬을 진행한다. 하나의 기수마다 하나의 버킷을 생성하여, 분류를 한 뒤에, 버킷 안에서 또 정렬을 하는 방식이다. 기수 정렬은 `LSD(Least Significant Digit)` 방식과 `MSD(Most Significant Digit)` 방식 두 가지로 나뉜다. LSD 는 덜 중요한 숫자부터 정렬하는 방식으로 예를 들어 숫자를 정렬한다고 했을 때, 일의 자리부터 정렬하는 방식이다. MSD 는 중요한 숫자부터 정렬하는 방식으로 세 자리 숫자면 백의 자리부터 정렬하는 방식이다. 두 가지 방식의 Big-O 는 동일하다. 하지만 주로 기수정렬을 이야기할 때는 LSD 를 이야기한다. LSD 는 중간에 정렬 결과를 볼 수 없다. 무조건 일의 자리부터 시작해서 백의 자리까지 모두 정렬이 끝나야 결과를 확인할 수 있고, 그 때서야 결과가 나온다. 하지만 MSD 는 정렬 중간에 정렬이 될 수 있다. 그러므로 정렬하는데 걸리는 시간을 줄일 수 있다. 하지만 정렬이 완료榮쩝 확인하는 과정이 필요하고 이 때문에 메모리를 더 사용하게 된다. 또 상황마다 일관적인 정렬 알고리즘을 사용하여 정렬하는데 적용할 수 없으므로 불편하다. 이러한 이유들로 기수 정렬을 논할 때는 주로 LSD 에 대해서 논한다. | Space Complexity | Time Complexity | | :--------------: | :-------------: | | O(n) | O(n) |"
공통,알고리즘,Sorting Algorithm에서 Sorting Algorithm's Complexity 정리는 무엇인가요?,| Algorithm | Space Complexity | (average) Time Complexity | (worst) Time Complexity | | :------------: | :--------------: | :-----------------------: | :---------------------: | | Bubble sort | O(1) | O(n^2) | O(n^2) | | Selection sort | O(1) | O(n^2) | O(n^2) | | Insertion sort | O(1) | O(n^2) | O(n^2) | | Merge sort | O(n) | O(nlogn) | O(nlogn) | | Heap sort | O(1) | O(nlogn) | O(nlogn) | | Quick sort | O(1) | O(nlogn) | O(n^2) | | Count sort | O(n) | O(n) | O(n) | | Radix sort | O(n) | O(n) | O(n) |
공통,알고리즘,Prime Number Algorithm이란?,"소수란 양의 약수를 딱 두 개만 갖는 자연수를 소수라 부른다. 2, 3, 5, 7, 11, …이 그런 수들인데, 소수를 판별하는 방법으로 첫 번째로 3보다 크거나 같은 임의의 양의 정수 N이 소수인지 판별하기 위해서는 N 을 2 부터 N 보다 1 작은 수까지 나누어서 나머지가 0 인 경우가 있는지 검사하는 방법과 두 번째로 `에라토스테네스의 체`를 사용할 수 있다. 아래 코드는 2부터 N - 1까지를 순회하며 소수인지 판별하는 코드와 2부터 √N까지 순회하며 소수인지 판별하는 코드이다. ```cpp // Time complexity: O(N) bool is_prime(int N) { if(N == 1) return false; for(int i = 2; i < N - 1; ++i) { if(N % i == 0) { return false; } } return true; } ``` ```cpp // Time complexity: O(√N) bool is_prime(int N) { if(N == 1) return false; for(long long i = 2; i * i <= N; ++i) { // 주의) i를 int로 선언하면 i*i를 계산할 때 overflow가 발생할 수 있다. if(N % i == 0) { return false; } } return true; } ```"
공통,알고리즘,Prime Number Algorithm에서 에라토스테네스의 체 [Eratosthenes’ sieve]은(는) 무엇인가요?,"`에라토스테네스의 체(Eratosthenes’ sieve)`는, 임의의 자연수에 대하여, 그 자연수 이하의 `소수(prime number)`를 모두 찾아 주는 방법이다. 입자의 크기가 서로 다른 가루들을 섞어 체에 거르면 특정 크기 이하의 가루들은 다 아래로 떨어지고, 그 이상의 것들만 체 위에 남는 것처럼, 에라토스테네스의 체를 사용하면 특정 자연수 이하의 합성수는 다 지워지고 소수들만 남는 것이다. 방법은 간단하다. 만일 `100` 이하의 소수를 모두 찾고 싶다면, `1` 부터 `100` 까지의 자연수를 모두 나열한 후, 먼저 소수도 합성수도 아닌 `1`을 지우고, `2`외의 `2`의 배수들을 다 지우고, `3`외의 `3`의 배수들을 다 지우고, `5`외의 `5`의 배수들을 지우는 등의 이 과정을 의 `100`제곱근인 `10`이하의 소수들에 대해서만 반복하면, 이때 남은 수들이 구하고자 하는 소수들이다. 에라토스테네스의 체를 이용하여 50 까지의 소수를 구하는 순서를 그림으로 표현하면 다음과 같다. 1. 초기 상태 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | | 11 | 12 | 13 | 14 | 15 | 16 | 17 | 18 | 19 | 20 | | 21 | 22 | 23 | 24 | 25 | 26 | 27 | 28 | 29 | 30 | | 31 | 32 | 33 | 34 | 35 | 36 | 37 | 38 | 39 | 40 | | 41 | 42 | 43 | 44 | 45 | 46 | 47 | 48 | 49 | 50 | 2. 소수도 합성수도 아닌 1 제거 | x | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | | 11 | 12 | 13 | 14 | 15 | 16 | 17 | 18 | 19 | 20 | | 21 | 22 | 23 | 24 | 25 | 26 | 27 | 28 | 29 | 30 | | 31 | 32 | 33 | 34 | 35 | 36 | 37 | 38 | 39 | 40 | | 41 | 42 | 43 | 44 | 45 | 46 | 47 | 48 | 49 | 50 | 3. 2 외의 2 의 배수들을 제거 | x | 2 | 3 | x | 5 | x | 7 | x | 9 | x | | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | | 11 | x | 13 | x | 15 | x | 17 | x | 19 | x | | 21 | x | 23 | x | 25 | x | 27 | x | 29 | x | | 31 | x | 33 | x | 35 | x | 37 | x | 39 | x | | 41 | x | 43 | x | 45 | x | 47 | x | 49 | x | 4. 3 외의 3 의 배수들을 제거 | x | 2 | 3 | x | 5 | x | 7 | x | x | x | | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | | 11 | x | 13 | x | x | x | 17 | x | 19 | x | | x | x | 23 | x | 25 | x | x | x | 29 | x | | 31 | x | x | x | 35 | x | 37 | x | x | x | | 41 | x | 43 | x | x | x | 47 | x | 49 | x | 5. 5 외의 5 의 배수들을 제거 | x | 2 | 3 | x | 5 | x | 7 | x | x | x | | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | | 11 | x | 13 | x | x | x | 17 | x | 19 | x | | x | x | 23 | x | x | x | x | x | 29 | x | | 31 | x | x | x | x | x | 37 | x | x | x | | 41 | x | 43 | x | x | x | 47 | x | 49 | x | 6. 7 외의 7 의 배수들을 제거(50 이하의 소수 판별 완료) | x | 2 | 3 | x | 5 | x | 7 | x | x | x | | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | | 11 | x | 13 | x | x | x | 17 | x | 19 | x | | x | x | 23 | x | x | x | x | x | 29 | x | | 31 | x | x | x | x | x | 37 | x | x | x | | 41 | x | 43 | x | x | x | 47 | x | x | x | | Space Complexity | Time Complexity | | :--------------: | :-------------: | | O(n) | O(nloglogn) |"
공통,알고리즘,Prime Number Algorithm에서 Time Complexity은(는) 무엇인가요?,O(1) < O(log N) < O(N) < O(N log N) < O(N^2) < O(N^3) O(2^N) : 크기가 N 인 집합의 부분 집합 O(N!) : 크기가 N 인 순열
공통,알고리즘,알고리즘 문제 연습 사이트는 무엇인가요?,* algospot.com * codeforces.com * topcoder.com * acmicpc.net * leetcode.com * programmers.co.kr * hackerrank.com * codingdojang.com * codeup.kr * euler.synap.co.kr * koistudy.net * codewars.com * codility.com * swexpertacademy.com * codeground.org * onlinejudge.org
공통,Java,Collection은(는) 무엇인가요?,"Java Collection 에는 `List`, `Map`, `Set` 인터페이스를 기준으로 여러 구현체가 존재한다. 이에 더해 `Stack`과 `Queue` 인터페이스도 존재한다. 왜 이러한 Collection 을 사용하는 것일까? 그 이유는 다수의 Data 를 다루는데 표준화된 클래스들을 제공해주기 때문에 DataStructure 를 직접 구현하지 않고 편하게 사용할 수 있기 때문이다. 또한 배열과 다르게 객체를 보관하기 위한 공간을 미리 정하지 않아도 되므로, 상황에 따라 객체의 수를 동적으로 정할 수 있다. 이는 프로그램의 공간적인 효율성 또한 높여준다. * List `List` 인터페이스를 직접 `@Override`를 통해 사용자가 정의하여 사용할 수도 있으며, 대표적인 구현체로는 `ArrayList`가 존재한다. 이는 기존에 있었던 `Vector`를 개선한 것이다. 이외에도 `LinkedList` 등의 구현체가 있다. * Map 대표적인 구현체로 `HashMap`이 존재한다. (밑에서 살펴볼 멀티스레드 환경에서의 개발 부분에서 HashTable 과의 차이점에 대해 살펴본다.) key-value 의 구조로 이루어져 있으며 Map 에 대한 구체적인 내용은 DataStructure 부분의 hashtable 과 일치한다. key 를 기준으로 중복된 값을 저장하지 않으며 순서를 보장하지 않는다. key 에 대해서 순서를 보장하기 위해서는 `LinkedHashMap`을 사용한다. * Set 대표적인 구현체로 `HashSet`이 존재한다. `value`에 대해서 중복된 값을 저장하지 않는다. 사실 Set 자료구조는 Map 의 key-value 구조에서 key 대신에 value 가 들어가 value 를 key 로 하는 자료구조일 뿐이다. 마찬가지로 순서를 보장하지 않으며 순서를 보장해주기 위해서는 `LinkedHashSet`을 사용한다. * Stack 과 Queue `Stack` 객체는 직접 `new` 키워드로 사용할 수 있으며, `Queue` 인터페이스는 JDK 1.5 부터 `LinkedList`에 `new` 키워드를 적용하여 사용할 수 있다. 자세한 부분은 DataStructure 부분의 설명을 참고하면 된다."
공통,Java,Annotation은(는) 무엇인가요?,"어노테이션이란 본래 주석이란 뜻으로, 인터페이스를 기반으로 한 문법이다. 주석과는 그 역할이 다르지만 주석처럼 코드에 달아 클래스에 특별한 의미를 부여하거나 기능을 주입할 수 있다. 또 해석되는 시점을 정할 수도 있다.(Retention Policy) 어노테이션에는 크게 세 가지 종류가 존재한다. JDK 에 내장되어 있는 `built-in annotation`과 어노테이션에 대한 정보를 나타내기 위한 어노테이션인 `Meta annotation` 그리고 개발자가 직접 만들어 내는 `Custom Annotation`이 있다. built-in annotation 은 상속받아서 메소드를 오버라이드 할 때 나타나는 @Override 어노테이션이 그 대표적인 예이다. 어노테이션의 동작 대상을 결정하는 Meta-Annotation 에도 여러 가지가 존재한다."
공통,Java,Generic은(는) 무엇인가요?,"제네릭은 자바에서 안정성을 맡고 있다고 할 수 있다. 다양한 타입의 객체들을 다루는 메서드나 컬렉션 클래스에서 사용하는 것으로, 컴파일 과정에서 타입체크를 해주는 기능이다. 객체의 타입을 컴파일 시에 체크하기 때문에 객체의 타입 안전성을 높이고 형변환의 번거로움을 줄여준다. 자연스럽게 코드도 더 간결해진다. 예를 들면, Collection 에 특정 객체만 추가될 수 있도록, 또는 특정한 클래스의 특징을 갖고 있는 경우에만 추가될 수 있도록 하는 것이 제네릭이다. 이로 인한 장점은 collection 내부에서 들어온 값이 내가 원하는 값인지 별도의 로직처리를 구현할 필요가 없어진다. 또한 api 를 설계하는데 있어서 보다 명확한 의사전달이 가능해진다."
공통,Java,final keyword은(는) 무엇인가요?,"* final class 다른 클래스에서 상속하지 못한다. * final method 다른 메소드에서 오버라이딩하지 못한다. * final variable 변하지 않는 상수값이 되어 새로 할당할 수 없는 변수가 된다. 추가적으로 혼동할 수 있는 두 가지를 추가해봤다. * finally `try-catch` or `try-catch-resource` 구문을 사용할 때, 정상적으로 작업을 한 경우와 에러가 발생했을 경우를 포함하여 마무리 해줘야하는 작업이 존재하는 경우에 해당하는 코드를 작성해주는 코드 블록이다. * finalize() keyword 도 아니고 code block 도 아닌 메소드이다. `GC`에 의해 호출되는 함수로 절대 호출해서는 안 되는 함수이다. `Object` 클래스에 정의되어 있으며 GC 가 발생하는 시점이 불분명하기 때문에 해당 메소드가 실행된다는 보장이 없다. 또한 `finalize()` 메소드가 오버라이딩 되어 있으면 GC 가 이루어질 때 바로 Garbage Collecting 되지 않는다. GC 가 지연되면서 OOME(Out of Memory Exception)이 발생할 수 있다."
공통,Java,Overriding vs Overloading은(는) 무엇인가요?,"둘 다 다형성을 높여주는 개념이고 비슷한 이름이지만, 전혀 다른 개념이라고 봐도 무방할 만큼 차이가 있다(오버로딩은 다른 시그니쳐를 만든다는 관점에서 다형성으로 보지 않는 의견도 있다). 공통점으로는 같은 이름의 다른 함수를 호출한다는 것이다. * 오버라이딩(Overriding) 상위 클래스 혹은 인터페이스에 존재하는 메소드를 하위 클래스에서 필요에 맞게 재정의하는 것을 의미한다. 자바의 경우는 오버라이딩 시 동적바인딩된다. 예)<br> 아래와 같은 경우, SuperClass의 fun이라는 인터페이스를 통해 SubClass의 fun이 실행된다. ```java SuperClass object = new SubClass(); object.fun(); ``` * 오버로딩(Overloading) 메소드의 이름은 같다. return 타입은 동일하거나 다를 수 있지만, return 타입만 다를 수는 없다. 매개변수의 타입이나 갯수가 다른 메소드를 만드는 것을 의미한다. 다양한 상황에서 메소드가 호출될 수 있도록 한다. 언어마다 다르지만, 자바의경우 오버로딩은 다른 시그니쳐를 만드는 것으로, 아예 다른함수를 만든것과 비슷하다고 생각하면 된다. 시그니쳐가 다르므로 정적바인딩으로 처리 가능하며, 자바의 경우 정적으로 바인딩된다. 예)<br> 아래와 같은 경우,fun(SuperClass super)이 실행된다. ```java main(blabla) { SuperClass object = new SubClass(); fun(object); } fun(SuperClass super) { blabla.... } fun(SubClass sub) { blabla.... } ```"
공통,Java,Access Modifier은(는) 무엇인가요?,변수 또는 메소드의 접근 범위를 설정해주기 위해서 사용하는 Java 의 예약어를 의미하며 총 네 가지 종류가 존재한다. * public 어떤 클래스에서라도 접근이 가능하다. * protected 클래스가 정의되어 있는 해당 패키지 내 그리고 해당 클래스를 상속받은 외부 패키지의 클래스에서 접근이 가능하다. * (default) 클래스가 정의되어 있는 해당 패키지 내에서만 접근이 가능하도록 접근 범위를 제한한다. * private 정의된 해당 클래스에서만 접근이 가능하도록 접근 범위를 제한한다.
공통,Java,Wrapper class은(는) 무엇인가요?,"기본 자료형(Primitive data type)에 대한 클래스 표현을 Wrapper class 라고 한다. `Integer`, `Float`, `Boolean` 등이 Wrapper class 의 예이다. int 를 Integer 라는 객체로 감싸서 저장해야 하는 이유가 있을까? 일단 컬렉션에서 제네릭을 사용하기 위해서는 Wrapper class 를 사용해줘야 한다. 또한 `null` 값을 반환해야만 하는 경우에는 return type 을 Wrapper class 로 지정하여 `null`을 반환하도록 할 수 있다. 하지만 이러한 상황을 제외하고 일반적인 상황에서 Wrapper class 를 사용해야 하는 이유는 객체지향적인 프로그래밍을 위한 프로그래밍이 아니고서야 없다. 일단 해당 값을 비교할 때, Primitive data type 인 경우에는 `==`로 바로 비교해줄 수 있다. 하지만 Wrapper class 인 경우에는 `.intValue()` 메소드를 통해 해당 Wrapper class 의 값을 가져와 비교해줘야 한다."
공통,Java,Wrapper class에서 AutoBoxing은(는) 무엇인가요?,JDK 1.5 부터는 `AutoBoxing`과 `AutoUnBoxing`을 제공한다. 이 기능은 각 Wrapper class 에 상응하는 Primitive data type 일 경우에만 가능하다. ```java List<Integer> lists = new ArrayList<>(); lists.add(1); ``` 우린 `Integer`라는 Wrapper class 로 설정한 collection 에 데이터를 add 할 때 Integer 객체로 감싸서 넣지 않는다. 자바 내부에서 `AutoBoxing`해주기 때문이다.
공통,Java,Multi에서 Thread 환경에서의 개발는 무엇인가요?,개발을 시작하는 입장에서 멀티 스레드를 고려한 프로그램을 작성할 일이 별로 없고 실제로 부딪히기 힘든 문제이기 때문에 많은 입문자들이 잘 모르고 있는 부분 중 하나라고 생각한다. 하지만 이 부분은 정말 중요하며 고려하지 않았을 경우 엄청난 버그를 양산할 수 있기 때문에 정말 중요하다. 추천 자료: * (도서) [Effective Java 2nd Edition](http://www.yes24.com/24/goods/14283616?scode=032&OzSrank=9) * (도서) [스프링 입문을 위한 자바 객체 지향의 원리와 이해](http://www.yes24.com/24/Goods/17350624?Acode=101)
공통,Java,Multi의Thread 환경에서의 개발 시 Field member은(는) 무엇인가요?,`필드(field)`란 클래스에 변수를 정의하는 공간을 의미한다. 이곳에 변수를 만들어두면 메소드 끼리 변수를 주고 받는 데 있어서 참조하기 쉬우므로 정말 편리한 공간 중 하나이다. 하지만 객체가 여러 스레드가 접근하는 싱글톤 객체라면 field 에서 상태값을 갖고 있으면 안된다. 모든 변수를 parameter 로 넘겨받고 return 하는 방식으로 코드를 구성해야 한다. 추천 자료: * (도서) [Effective Java 2nd Edition](http://www.yes24.com/24/goods/14283616?scode=032&OzSrank=9) * (도서) [스프링 입문을 위한 자바 객체 지향의 원리와 이해](http://www.yes24.com/24/Goods/17350624?Acode=101)
공통,Java,Multi의Thread 환경에서의 개발 시 동기화(Synchronized)은(는) 무엇인가요?,"`synchronized` 키워드를 직접 사용해서 특정 메소드나 구간에 Lock을 걸어 스레드 간 상호 배제를 구현할 수 있는 이 때 메서드에 직접 걸 수 도 있으며 블록으로 구간을 직접 지정해줄 수 있다. 메서드에 직접 걸어줄 경우에는 해당 class 인스턴스에 대해 Lock을 걸고 synchronized 블록을 이용할 경우에는 블록으로 감싸진 구간만 Lock이 걸린다. 때문에 Lock을 걸 때에는 이 개념에 대해 충분히 고민해보고 적절하게 사용해야만 한다. 그렇다면 필드에 Collection 이 불가피하게 필요할 때는 어떠한 방법을 사용할까? `synchronized` 키워드를 기반으로 구현된 Collection 들도 많이 존재한다. `List`를 대신하여 `Vector`를 사용할 수 있고, `Map`을 대신하여 `HashTable`을 사용할 수 있다. 하지만 이 Collection 들은 제공하는 API 가 적고 성능도 좋지 않다. 기본적으로는 `Collections`라는 util 클래스에서 제공되는 static 메소드를 통해 이를 해결할 수 있다. `Collections.synchronizedList()`, `Collections.synchronizedSet()`, `Collections.synchronizedMap()` 등이 존재한다. JDK 1.7 부터는 `concurrent package`를 통해 `ConcurrentHashMap`이라는 구현체를 제공한다. Collections util 을 사용하는 것보다 `synchronized` 키워드가 적용된 범위가 좁아서 보다 좋은 성능을 낼 수 있는 자료구조이다. 추천 자료: * (도서) [Effective Java 2nd Edition](http://www.yes24.com/24/goods/14283616?scode=032&OzSrank=9) * (도서) [스프링 입문을 위한 자바 객체 지향의 원리와 이해](http://www.yes24.com/24/Goods/17350624?Acode=101)"
공통,Java,Multi의Thread 환경에서의 개발 시 ThreadLocal은(는) 무엇인가요?,"스레드 사이에 간섭이 없어야 하는 데이터에 사용한다. 멀티스레드 환경에서는 클래스의 필드에 멤버를 추가할 수 없고 매개변수로 넘겨받아야 하기 때문이다. 즉, 스레드 내부의 싱글톤을 사용하기 위해 사용한다. 주로 사용자 인증, 세션 정보, 트랜잭션 컨텍스트에 사용한다. 스레드 풀 환경에서 ThreadLocal 을 사용하는 경우 ThreadLocal 변수에 보관된 데이터의 사용이 끝나면 반드시 해당 데이터를 삭제해 주어야 한다. 그렇지 않을 경우 재사용되는 쓰레드가 올바르지 않은 데이터를 참조할 수 있다. 1. ThreadLocal 객체를 생성한다. 2. ThreadLocal.set() 메서드를 이용해서 현재 스레드의 로컬 변수에 값을 저장한다. 3. ThreadLocal.get() 메서드를 이용해서 현재 스레드의 로컬 변수 값을 읽어온다. 4. ThreadLocal.remove() 메서드를 이용해서 현재 스레드의 로컬 변수 값을 삭제한다."
공통,JavaScript,Hoisting에서 정의는 무엇인가요?,"`hoist` 라는 단어의 사전적 정의는 끌어올리기 라는 뜻이다. 자바스크립트에서 끌어올려지는 것은 변수이다. `var` keyword 로 선언된 모든 변수 선언은 호이스트 된다. 호이스트란 변수의 정의가 그 범위에 따라 `선언`과 `할당`으로 분리되는 것을 의미한다. 즉, 변수가 함수 내에서 정의되었을 경우, 선언이 함수의 최상위로, 함수 바깥에서 정의되었을 경우, 전역 컨텍스트의 최상위로 변경이 된다. 우선, 선언(Declaration)과 할당(Assignment)을 이해해야 한다. 끌어올려지는 것은 선언이다. ```js function getX() { console.log(x); // undefined var x = 100; console.log(x); // 100 } getX(); ``` 다른 언어의 경우엔, 변수 x 를 선언하지 않고 출력하려 한다면 오류를 발생할 것이다. 하지만 자바스크립트에서는 `undefined`라고 하고 넘어간다. `var x = 100;` 이 구문에서 `var x;`를 호이스트하기 때문이다. 즉, 작동 순서에 맞게 코드를 재구성하면 다음과 같다. ```js function getX() { var x; console.log(x); x = 100; console.log(x); } getX(); ``` 선언문은 항시 자바스크립트 엔진 구동시 가장 최우선으로 해석하므로 호이스팅 되고, 할당 구문은 런타임 과정에서 이루어지기 때문에 호이스팅 되지 않는다. 함수가 자신이 위치한 코드에 상관없이 함수 선언문 형태로 정의한 함수의 유효범위는 전체 코드의 맨 처음부터 시작한다. 함수 선언이 함수 실행 부분보다 뒤에 있더라도 자바스크립트 엔진이 함수 선언을 끌어올리는 것을 의미한다. 함수 호이스팅은 함수를 끌어올리지만 변수의 값은 끌어올리지 않는다. ```js foo( ); function foo( ){ console.log(‘hello’); }; // console> hello ``` foo 함수에 대한 선언을 호이스팅하여 global 객체에 등록시키기 때문에 `hello`가 제대로 출력된다. ```js foo( ); var foo = function( ) { console.log(‘hello’); }; // console> Uncaught TypeError: foo is not a function ``` 이 두번째 예제의 함수 표현은 함수 리터럴을 할당하는 구조이기 때문에 호이스팅 되지 않으며 그렇기 때문에 런타임 환경에서 `Type Error`를 발생시킨다."
공통,JavaScript,Closure은(는) 무엇인가요?,"Closure(클로저)는 두 개의 함수로 만들어진 환경 으로 이루어진 특별한 객체의 한 종류이다. 여기서 환경 이라 함은 클로저가 생성될 때 그 범위 에 있던 여러 지역 변수들이 포함된 `context`를 말한다. 이 클로저를 통해서 자바스크립트에는 없는 비공개(private) 속성/메소드, 공개 속성/메소드를 구현할 수 있는 방안을 마련할 수 있다."
공통,JavaScript,Closure에서 클로저 생성하기는 무엇인가요?,"다음은 클로저가 생성되는 조건이다. 1. 내부 함수가 익명 함수로 되어 외부 함수의 반환값으로 사용된다. 2. 내부 함수는 외부 함수의 실행 환경(execution environment)에서 실행된다. 3. 내부 함수에서 사용되는 변수 x 는 외부 함수의 변수 스코프에 있다. ```js function outer() { var name = `closure`; function inner() { console.log(name); } inner(); } outer(); // console> closure ``` `outer`함수를 실행시키는 `context`에는 `name`이라는 변수가 존재하지 않는다는 것을 확인할 수 있다. 비슷한 맥락에서 코드를 조금 변경해볼 수 있다. ```js var name = `Warning`; function outer() { var name = `closure`; return function inner() { console.log(name); }; } var callFunc = outer(); callFunc(); // console> closure ``` 위 코드에서 `callFunc`를 클로저라고 한다. `callFunc` 호출에 의해 `name`이라는 값이 console 에 찍히는데, 찍히는 값은 `Warning`이 아니라 `closure`라는 값이다. 즉, `outer` 함수의 context 에 속해있는 변수를 참조하는 것이다. 여기서 `outer`함수의 지역변수로 존재하는 `name`변수를 `free variable(자유변수)`라고 한다. 이처럼 외부 함수 호출이 종료되더라도 외부 함수의 지역 변수 및 변수 스코프 객체의 체인 관계를 유지할 수 있는 구조를 클로저라고 한다. 보다 정확히는 외부 함수에 의해 반환되는 내부 함수를 가리키는 말이다."
공통,JavaScript,this는 무엇인가요?,자바스크립트에서 모든 함수는 실행될 때마다 함수 내부에 `this`라는 객체가 추가된다. `arguments`라는 유사 배열 객체와 함께 함수 내부로 암묵적으로 전달되는 것이다. 그렇기 때문에 자바스크립트에서의 `this`는 함수가 호출된 상황에 따라 그 모습을 달리한다.
공통,JavaScript,객체의 메서드를 호출할 때 this의 역할은?,"객체의 프로퍼티가 함수일 경우 메서드라고 부른다. `this`는 함수를 실행할 때 함수를 소유하고 있는 객체(메소드를 포함하고 있는 인스턴스)를 참조한다. 즉 해당 메서드를 호출한 객체로 바인딩된다. `A.B`일 때 `B`함수 내부에서의 `this`는 `A`를 가리키는 것이다. ```js var myObject = { name: ""foo"", sayName: function() { console.log(this); } }; myObject.sayName(); // console> Object {name: ""foo"", sayName: sayName()} ```"
공통,JavaScript,함수를 호출할 때는 무엇인가요? this의 역할은?,"특정 객체의 메서드가 아니라 함수를 호출하면, 해당 함수 내부 코드에서 사용된 this 는 전역객체에 바인딩 된다. `A.B`일 때 `A`가 전역 객체가 되므로 `B`함수 내부에서의 `this`는 당연히 전역 객체에 바인딩 되는 것이다. ```js var value = 100; var myObj = { value: 1, func1: function() { console.log(`func1's this.value: ${this.value}`); var func2 = function() { console.log(`func2's this.value ${this.value}`); }; func2(); } }; myObj.func1(); // console> func1's this.value: 1 // console> func2's this.value: 100 ``` `func1`에서의 `this`는 상황 1 과 같다. 그렇기 때문에 `myObj`가 `this`로 바인딩되고 `myObj`의 `value`인 1 이 console 에 찍히게 된다. 하지만 `func2`는 상황 2 로 해석해야 한다. `A.B`구조에서 `A`가 없기 때문에 함수 내부에서 `this`가 전역 객체를 참조하게 되고 `value`는 100 이 되는 것이다."
공통,JavaScript,생성자 함수를 통해 객체를 생성할 때 this의 역할은?,"그냥 함수를 호출하는 것이 아니라 `new`키워드를 통해 생성자 함수를 호출할 때는 또 `this`가 다르게 바인딩 된다. `new` 키워드를 통해서 호출된 함수 내부에서의 `this`는 객체 자신이 된다. 생성자 함수를 호출할 때의 `this` 바인딩은 생성자 함수가 동작하는 방식을 통해 이해할 수 있다. `new` 연산자를 통해 함수를 생성자로 호출하게 되면, 일단 빈 객체가 생성되고 this 가 바인딩 된다. 이 객체는 함수를 통해 생성된 객체이며, 자신의 부모인 프로토타입 객체와 연결되어 있다. 그리고 return 문이 명시되어 있지 않은 경우에는 `this`로 바인딩 된 새로 생성한 객체가 리턴된다. ```js var Person = function(name) { console.log(this); this.name = name; }; var foo = new Person(""foo""); // Person console.log(foo.name); // foo ```"
공통,JavaScript,Promise은(는) 무엇인가요?,"Javascript 에서는 대부분의 작업들이 비동기로 이루어진다. 콜백 함수로 처리하면 되는 문제였지만 요즘에는 프론트엔드의 규모가 커지면서 코드의 복잡도가 높아지는 상황이 발생하였다. 이러면서 콜백이 중첩되는 경우가 따라서 발생하였고, 이를 해결할 방안으로 등장한 것이 Promise 패턴이다. Promise 패턴을 사용하면 비동기 작업들을 순차적으로 진행하거나, 병렬로 진행하는 등의 컨트롤이 보다 수월해진다. 또한 예외처리에 대한 구조가 존재하기 때문에 오류 처리 등에 대해 보다 가시적으로 관리할 수 있다. 이 Promise 패턴은 ECMAScript6 스펙에 정식으로 포함되었다."
공통,JavaScript,Async/Await은(는) 무엇인가요?,"비동기 코드를 작성하는 새로운 방법이다. Javascript 개발자들이 훌륭한 비동기 처리 방안이 Promise로 만족하지 못하고 더 훌륭한 방법을 고안 해낸 것이다(사실 async/await는 promise기반). 절차적 언어에서 작성하는 코드와 같이 사용법도 간단하고 이해하기도 쉽다. function 키워드 앞에 async를 붙여주면 되고 function 내부의 promise를 반환하는 비동기 처리 함수 앞에 await를 붙여주기만 하면 된다. async/await의 가장 큰 장점은 Promise보다 비동기 코드의 겉모습을 더 깔끔하게 한다는 것이다. 이 것은 es8의 공식 스펙이며 node8LTS에서 지원된다(바벨이 async/await를 지원해서 곧바로 쓸수 있다고 한다!). * `promise`로 구현 ```js function makeRequest() { return getData() .then(data => { if(data && data.needMoreRequest) { return makeMoreRequest(data) .then(moreData => { console.log(moreData); return moreData; }).catch((error) => { console.log('Error while makeMoreRequest', error); }); } else { console.log(data); return data; } }).catch((error) => { console.log('Error while getData', error); }); } ``` * `async/await` 구현 ```js async function makeRequest() { try { const data = await getData(); if(data && data.needMoreRequest) { const moreData = await makeMoreRequest(data); console.log(moreData); return moreData; } else { console.log(data); return data; } } catch (error) { console.log('Error while getData', error); } } ```"
공통,JavaScript,Arrow Function은(는) 무엇인가요?,"화살표 함수 표현식은 기존의 function 표현방식보다 간결하게 함수를 표현할 수 있다. 화살표 함수는 항상 익명이며, 자신의 this, arguments, super 그리고 new.target을 바인딩하지 않는다. 그래서 생성자로는 사용할 수 없다. - 화살표 함수 도입 영향: 짧은 함수, 상위 스코프 this"
공통,JavaScript,Arrow Function에서 상위 스코프 this은(는) 무엇인가요?,"```js function Person(){ this.age = 0; setInterval(() => { this.age++; // |this|는 person 객체를 참조 }, 1000); } var p = new Person(); ``` 일반 함수에서 this는 자기 자신을 this로 정의한다. 하지만 화살표 함수 this는 Person의 this와 동일한 값을 갖는다. setInterval로 전달된 this는 Person의 this를 가리키며, Person 객체의 age에 접근한다."
공통,Python,GIL 과 그로 인한 성능 문제를 말하라,"GIL 때문에 성능 문제가 대두되는 경우는 압축, 정렬, 인코딩 등 수행시간에 CPU 의 영향이 큰 작업(CPU bound)을 멀티 스레드로 수행하도록 한 경우다. 이 땐 GIL 때문에 멀티 스레드로 작업을 수행해도 싱글 스레드일 때와 별반 차이가 나지 않는다. 이를 해결하기 위해선 멀티 스레드는 파일, 네트워크 IO 같은 IO bound 프로그램에 사용하고 멀티 프로세스를 활용해야한다."
공통,Python,GIL(Global Interpreter Lock)은(는) 무엇인가요?,GIL 은 스레드에서 사용되는 Lock 을 인터프리터 레벨로 확장한 개념인데 여러 스레드가 동시에 실행되는걸 방지한다. 더 정확히 말하자면 어느 시점이든 하나의 Bytecode 만이 실행되도록 강제한다. 각 스레드는 다른 스레드에 의해 GIL 이 해제되길 기다린 후에야 실행될 수 있다. 즉 멀티 스레드로 만들었어도 본질적으로 싱글 스레드로 동작한다.
공통,Python,GIL 의 장점는 무엇인가요?,"코어 개수는 점점 늘어만 가는데 이 GIL 때문에 그 장점을 제대로 살리지 못하기만 하는 것 같으나 이 GIL 로 인한 장점도 존재한다. GIL 을 활용한 멀티 스레드가 그렇지 않은 멀티 스레드보다 구현이 쉬우며, 레퍼런스 카운팅을 사용하는 메모리 관리 방식에서 GIL 덕분에 오버헤드가 적어 싱글 스레드일 때 fine grained lock 방식보다 성능이 우월하다. 또한 C extension 을 활용할 때 GIL 은 해제되므로 C library 를 사용하는 CPU bound 프로그램을 멀티 스레드로 실행하는 경우 더 빠를 수 있다."
공통,Python,GC 작동 방식은 무엇인가요?,"파이썬에선 기본적으로 garbage collection(가비지 컬렉션)과 reference counting(레퍼런스 카운팅)을 통해 할당 된 메모리를 관리한다. 기본적으로 참조 횟수가 0 이된 객체를 메모리에서 해제하는 레퍼런스 카운팅 방식을 사용하지만, 참조 횟수가 0 은 아니지만 도달할 수 없는 상태인 reference cycles(순환 참조)가 발생했을 때는 가비지 컬렉션으로 그 상황을 해결한다. > 엄밀히 말하면 레퍼런스 카운팅 방식을 통해 객체를 메모리에서 해제하는 행위가 가비지 컬렉션의 한 형태지만 여기서는 순환 참조가 발생했을 때 cyclic garbage collector 를 통한 가비지 컬렉션과 레퍼런스 카운팅을 통한 가비지 컬렉션을 구분했다. 여기서 '순환 참조가 발생한건 어떻게 탐지하지?', '주기적으로 감시한다면 그 주기의 기준은 뭘까?', '가비지 컬렉션은 언제 발생하지?' 같은 의문이 들 수 있는데 이 의문을 해결하기 전에 잠시 레퍼런스 카운팅, 순환 참조, 파이썬의 가비지 컬렉터에 대한 간단한 개념을 짚고 넘어가자. 이 개념을 알고 있다면 바로 [가비지 컬렉션의 작동 방식 단락](#가비지-컬렉션의-작동-방식)을 읽으면 된다."
공통,Python,GC 작동 방식에서 레퍼런스 카운팅는 무엇인가요?,모든 객체는 참조당할 때 레퍼런스 카운터를 증가시키고 참조가 없어질 때 카운터를 감소시킨다. 이 카운터가 0 이 되면 객체가 메모리에서 해제한다. 어떤 객체의 레퍼런스 카운트를 보고싶다면 `sys.getrefcount()`로 확인할 수 있다. <details> <summary> </summary> <br> 카운터를 증감시키는 명령은 아래와 같이 object.h에 선언되어있는데 카운터를 증가시킬 때는 단순히 `ob_refcnt`를 1 증가시키고 감소시킬때는 1 감소시킴과 동시에 카운터가 0 이되면 메모리에서 객체를 해제하는 것을 확인할 수 있다. ```c #define Py_INCREF(op) (  ((PyObject *)(op))->ob_refcnt++) #define Py_DECREF(op)  do {  else  } while (0) ``` 더 정확한 정보는 파이썬 공식 문서를 참고하면 자세하게 설명되어있다.
공통,Python,GC 작동 방식에서 순환 참조는 무엇인가요?,순환 참조의 간단한 예제는 자기 자신을 참조하는 객체다. ```python >>> l = [] >>> l.append(l) >>> del l ``` `l`의 참조 횟수는 1 이지만 이 객체는 더이상 접근할 수 없으며 레퍼런스 카운팅 방식으로는 메모리에서 해제될 수 없다. 또 다른 예로는 서로를 참조하는 객체다. ```python >>> a = Foo() # 0x60 >>> b = Foo() # 0xa8 >>> a.x = b # 0x60의 x는 0xa8를 가리킨다. >>> b.x = a # 0xa8의 x는 0x60를 가리킨다. # 이 시점에서 0x60의 레퍼런스 카운터는 a와 b.x로 2 # 0xa8의 레퍼런스 카운터는 b와 a.x로 2다. >>> del a # 0x60은 1로 감소한다. 0xa8은 b와 0x60.x로 2다. >>> del b # 0xa8도 1로 감소한다. ``` 이 상태에서 `0x60.x`와 `0xa8.x`가 서로를 참조하고 있기 때문에 레퍼런스 카운트는 둘 다 1 이지만 도달할 수 없는 가비지가 된다.
공통,Python,GC 작동 방식에서 가비지 컬렉터는 무엇인가요?,"파이썬의 `gc` 모듈을 통해 가비지 컬렉터를 직접 제어할 수 있다. `gc` 모듈은 cyclic garbage collection 을 지원하는데 이를 통해 reference cycles(순환 참조)를 해결할 수 있다. gc 모듈은 오로지 순환 참조를 탐지하고 해결하기위해 존재한다. `gc` 파이썬 공식문서에서도 순환 참조를 만들지 않는다고 확신할 수 있으면 `gc.disable()`을 통해 garbage collector 를 비활성화 시켜도 된다고 언급하고 있다. > Since the collector supplements the reference counting already used in Python, you can disable the collector if you are sure your program does not create reference cycles."
공통,Python,GC 작동 방식에서 가비지 컬렉션의 작동 방식는 무엇인가요?,순환 참조 상태도 해결할 수 있는 cyclic garbage collection 이 어떤 방식으로 동작하는지는 결국 어떤 기준으로 가비지 컬렉션이 발생하고 어떻게 순환 참조를 감지하는지에 관한 내용이다. 이에 대해 차근차근 알아보자.
공통,Python,GC 작동 방식에서 어떤 기준으로 가비지 컬렉션이 일어나는가는 무엇인가요?,"앞에서 제기했던 의문은 결국 발생 기준에 관한 의문이다. 가비지 컬렉터는 내부적으로 `generation`(세대)과 `threshold`(임계값)로 가비지 컬렉션 주기와 객체를 관리한다. 세대는 0 세대, 1 세대, 2 세대로 구분되는데 최근에 생성된 객체는 0 세대(young)에 들어가고 오래된 객체일수록 2 세대(old)에 존재한다. 더불어 한 객체는 단 하나의 세대에만 속한다. 가비지 컬렉터는 0 세대일수록 더 자주 가비지 컬렉션을 하도록 설계되었는데 이는 [generational hypothesis](http://www.memorymanagement.org/glossary/g.html#term-generational-hypothesis)에 근거한다. <details> <summary>generational hypothesis의 두 가지 가설</summary> <br> * 대부분의 객체는 금방 도달할 수 없는 상태(unreachable)가 된다. * 오래된 객체(old)에서 젊은 객체(young)로의 참조는 아주 적게 존재한다. Reference: Naver D2 - Java Garbage Collection <hr> </details> 주기는 threshold 와 관련있는데 `gc.get_threshold()`로 확인해 볼 수 있다. ```python >>> gc.get_threshold() (700, 10, 10) ``` 각각 `threshold 0`, `threshold 1`, `threshold 2`을 의미하는데 n 세대에 객체를 할당한 횟수가 `threshold n`을 초과하면 가비지 컬렉션이 수행되며 이 값은 변경될 수 있다. 0 세대의 경우 메모리에 객체가 할당된 횟수에서 해제된 횟수를 뺀 값, 즉 객체 수가 `threshold 0`을 초과하면 실행된다. 다만 그 이후 세대부터는 조금 다른데 0 세대 가비지 컬렉션이 일어난 후 0 세대 객체를 1 세대로 이동시킨 후 카운터를 1 증가시킨다. 이 1 세대 카운터가 `threshold 1`을 초과하면 그 때 1 세대 가비지 컬렉션이 일어난다. 러프하게 말하자면 0 세대 가비지 컬렉션이 객체 생성 700 번만에 일어난다면 1 세대는 7000 번만에, 2 세대는 7 만번만에 일어난다는 뜻이다. 이를 말로 풀어서 설명하려니 조금 복잡해졌지만 간단하게 말하면 메모리 할당시 `generation[0].count++`, 해제시 `generation[0].count--`가 발생하고, `generation[0].count > threshold[0]`이면 `genreation[0].count = 0`, `generation[1].count++`이 발생하고 `generation[1].count > 10`일 때 0 세대, 1 세대 count 를 0 으로 만들고 `generation[2].count++`을 한다는 뜻이다. "
공통,Python,GC 작동 방식에서 라이프 사이클는 무엇인가요?,"이렇듯 가비지 컬렉터는 세대와 임계값을 통해 가비지 컬렉션의 주기를 관리한다. 이제 가비지 컬렉터가 어떻게 순환 참조를 발견하는지 알아보기에 앞서 가비지 컬렉션의 실행 과정(라이프 사이클)을 간단하게 알아보자. 새로운 객체가 만들어 질 때 파이썬은 객체를 메모리와 0 세대에 할당한다. 만약 0 세대의 객체 수가 `threshold 0`보다 크면 `collect_generations()`를 실행한다. <details> <summary>코드와 함께하는 더 자세한 설명</summary> <br> ```c // ... gc.generations[0].count++; /* 0세대 카운터 증가 */ if (gc.generations[0].count > gc.generations[0].threshold && /* 임계값을 초과하며 */ gc.enabled && /* 사용가능하며 */ gc.generations[0].threshold && /* 임계값이 0이 아니고 */ !gc.collecting) /* 컬렉션 중이 아니면 */ { gc.collecting = 1; collect_generations(); gc.collecting = 0; } // ... } ``` 참고로 `gc`를 끄고싶으면 `gc.disable()`보단 `gc.set_threshold(0)`이 더 확실하다. `disable()`의 경우 서드 파티 라이브러리에서 `enable()`하는 경우가 있다고 한다. <hr> </details> `collect_generations()`이 호출되면 모든 세대(기본적으로 3 개의 세대)를 검사하는데 가장 오래된 세대(2 세대)부터 역으로 확인한다. 해당 세대에 객체가 할당된 횟수가 각 세대에 대응되는 `threshold n`보다 크면 `collect()`를 호출해 가비지 컬렉션을 수행한다. <details> <summary>코드</summary> <br> `collect()`가 호출될 때 해당 세대보다 어린 세대들은 모두 통합되어 가비지 컬렉션이 수행되기 때문에 `break`를 통해 검사를 중단한다. 다음은 `collect_generations()`을 간략화 한 소스이다.  ```c collect_generations(void) { int i; for (i = NUM_GENERATIONS-1; i >= 0; i--) { if (gc.generations[i].count > gc.generations[i].threshold) { break; } } } { // ... result = collect(generation, &collected, &uncollectable, 0); // ... } ``` <hr> </details> `collect()` 메서드는 순환 참조 탐지 알고리즘을 수행하고 특정 세대에서 도달할 수 있는 객체(reachable)와 도달할 수 없는 객체(unreachable)를 구분하고 도달할 수 없는 객체 집합을 찾는다. 도달할 수 있는 객체 집합은 다음 상위 세대로 합쳐지고(0 세대에서 수행되었으면 1 세대로 이동), 도달할 수 없는 객체 집합은 콜백을 수행 한 후 메모리에서 해제된다. 이제 정말 순환 참조 탐지 알고리즘을 알아볼 때가 됐다."
공통,Python,GC 작동 방식에서 어떻게 순환 참조를 감지하는가는 무엇인가요?,"먼저 순환 참조는 컨테이너 객체(e.g. `tuple`, `list`, `set`, `dict`, `class`)에 의해서만 발생할 수 있음을 알아야한다. 컨테이너 객체는 다른 객체에 대한 참조를 보유할 수 있다. 그러므로 정수, 문자열은 무시한채 관심사를 컨테이너 객체에만 집중할 수 있다. 순환 참조를 해결하기 위한 아이디어로 모든 컨테이너 객체를 추적한다. 여러 방법이 있겠지만 객체 내부의 링크 필드에 더블 링크드 리스트를 사용하는 방법이 가장 좋다. 이렇게 하면 추가적인 메모리 할당 없이도 컨테이너 객체 집합에서 객체를 빠르게 추가하고 제거할 수 있다. 컨테이너 객체가 생성될 때 이 집합에 추가되고 제거될 때 집합에서 삭제된다. <details> <summary> <code>PyGC_Head</code>에 선언된 더블 링크드 리스트 </summary> <br> 더블 링크드 리스트는 다음과 같이 선언되어 있으며 objimpl.h 코드에서 확인해볼 수 있다. ```c struct { } gc; double dummy; /* force worst-case alignment */ } PyGC_Head; ``` <hr> </details> 이제 모든 컨테이터 객체에 접근할 수 있으니 순환 참조를 찾을 수 있어야 한다. 순환 참조를 찾는 과정은 다음과 같다. 1. 객체에 `gc_refs` 필드를 레퍼런스 카운트와 같게 설정한다. 2. 각 객체에서 참조하고 있는 다른 컨테이너 객체를 찾고, 참조되는 컨테이너의 `gc_refs`를 감소시킨다. 3. `gc_refs`가 0 이면 그 객체는 컨테이너 집합 내부에서 자기들끼리 참조하고 있다는 뜻이다. 4. 그 객체를 unreachable 하다고 표시한 뒤 메모리에서 해제한다. 이제 우리는 가비지 콜렉터가 어떻게 순환 참조 객체를 탐지하고 메모리에서 해제하는지 알았다."
공통,Python,GC 작동 방식에서 예제는 무엇인가요?,"아래 예제는 보기 쉽게 가공한 예제이며 실제 `collect()`의 동작과는 차이가 있다. 정확한 작동 방식은 아래에서 다시 서술한다. 혹은 `collect()` 코드를 참고하자. 아래의 예제를 통해 가비지 컬렉터가 어떤 방법으로 순환 참조 객체인 `Foo(0)`과 `Foo(1)`을 해제하는지 알아보겠다. ```python a = [1] # Set: a:[1] b = ['a'] # Set: a:[1] <-> b:['a'] c = [a, b] # Set: a:[1] <-> b:['a'] <-> c:[a, b] d = c # Set: a:[1] <-> b:['a'] <-> c,d:[a, b] # 컨테이너 객체가 생성되지 않았기에 레퍼런스 카운트만 늘어난다. e = Foo(0) # Set: a:[1] <-> b:['a'] <-> c,d:[a, b] <-> e:Foo(0) f = Foo(1) # Set: a:[1] <-> b:['a'] <-> c,d:[a, b] <-> e:Foo(0) <-> f:Foo(1) e.x = f # Set: a:[1] <-> b:['a'] <-> c,d:[a, b] <-> e:Foo(0) <-> f,Foo(0).x:Foo(1) f.x = e # Set: a:[1] <-> b:['a'] <-> c,d:[a, b] <-> e,Foo(1).x:Foo(0) <-> f,Foo(0).x:Foo(1) del e # Set: a:[1] <-> b:['a'] <-> c,d:[a, b] <-> Foo(1).x:Foo(0) <-> f,Foo(0).x:Foo(1) del f # Set: a:[1] <-> b:['a'] <-> c,d:[a, b] <-> Foo(1).x:Foo(0) <-> Foo(0).x:Foo(1) ``` 위 상황에서 각 컨테이너 객체의 레퍼런스 카운트는 다음과 같다. ```py # ref count [1] <- a,c = 2 ['a'] <- b,c = 2 [a, b] <- c,d = 2 Foo(0) <- Foo(1).x = 1 Foo(1) <- Foo(0).x = 1 ``` 1 번 과정에서 각 컨테이너 객체의 `gc_refs`가 설정된다. ```py # gc_refs [1] = 2 ['a'] = 2 [a, b] = 2 Foo(0) = 1 Foo(1) = 1 ``` 2 번 과정에서 컨테이너 집합을 순회하며 `gc_refs`을 감소시킨다. ```py [1] = 1 # [a, b]에 의해 참조당하므로 1 감소 ['a'] = 1 # [a, b]에 의해 참조당하므로 1 감소 [a, b] = 2 # 참조당하지 않으므로 그대로 Foo(0) = 0 # Foo(1)에 의해 참조당하므로 1 감소 Foo(1) = 0 # Foo(0)에 의해 참조당하므로 1 감소 ``` 3 번 과정을 통해 `gc_refs`가 0 인 순환 참조 객체를 발견했다. 이제 이 객체를 unreachable 집합에 옮겨주자. ```py unreachable | reachable | [1] = 1 Foo(0) = 0 | ['a'] = 1 Foo(1) = 0 | [a, b] = 2 ``` 이제 `Foo(0)`와 `Foo(1)`을 메모리에서 해제하면 가비지 컬렉션 과정이 끝난다."
공통,Python,GC 작동 방식에서 더 정확하고 자세한 설명는 무엇인가요?,"`collect()` 메서드는 현재 세대와 어린 세대를 합쳐 순환 참조를 검사한다. 이 합쳐진 세대를 `young`으로 이름 붙이고 다음의 과정을 거치며 최종적으로 도달 할 수 없는 객체가 모인 unreachable 리스트를 메모리에서 해제하고 young 에 남아있는 객체를 다음 세대에 할당한다. ```c update_refs(young) subtract_refs(young) move_unreachable(young, &unreachable) ``` `update_refs()`는 모든 객체의 레퍼런스 카운트 사본을 만든다. 이는 가비지 컬렉터가 실제 레퍼런스 카운트를 건드리지 않게 하기 위함이다. <details> <summary>예제 보기</summary> <br> ```py a, b = Foo(0), Foo(1) a.x = b b.x = a c = b del a del b # 위 상황을 요약하면 다음과 같다. Foo(0).x = Foo(1) Foo(1).x = Foo(0) c = Foo(1) ``` 이 때 상황은 다음과 같은데 `Foo(0)`의 `gc_refs`가 0 이어도 뒤에 나올 `Foo(1)`을 통해 도달 할 수 있다. | young | ref count | gc_refs | reachable | | :------: | :-------: | :-----: | :-------: | | `Foo(0)` | 1 | 0 | `c.x` | | `Foo(1)` | 2 | 1 | `c` | <hr> </details> <details> <summary>예제 보기</summary> <br> ```py a, b = Foo(0), Foo(1) a.x = b b.x = a c = b d = Foo(2) d.x = d a.y = d del d del a del b # 위 상황을 요약하면 다음과 같다. Foo(0).x = Foo(1) Foo(1).x = Foo(0) c = Foo(1) Foo(0).y = Foo(2) ``` | young | ref count | gc_refs | reachable | | :------: | :-------: | :-----: | :-------: | | `Foo(0)` | 1 | 0 | `c.x` | | `Foo(1)` | 2 | 1 | `c` | | `Foo(2)` | 1 | 0 | `c.x.y` | 이 상황에서 `Foo(0)`은 `unreachable` 리스트에 있다가 `Foo(1)`을 조사하며 다시 `young` 리스트의 맨 뒤로 돌아왔고, `Foo(2)`도 `unreachable` 리스트에 갔지만 곧 `Foo(0)`에 의해 참조될 수 있음을 알고 다시 `young` 리스트로 돌아온다. <hr> </details> `young` 리스트의 전체 스캔이 끝나면 이제 `unreachable` 리스트에 있는 객체는 정말 도달할 수 없다. 이제 이 객체들을 메모리에서 해제되고 `young` 리스트의 객체들은 상위 세대로 합쳐진다."
공통,Python,Celery은(는) 무엇인가요?,"Celery는 메시지 패싱 방식의 분산 비동기 작업 큐다. 작업(Task)은 브로커(Broker)를 통해 메시지(Message)로 워커(Worker)에 전달되어 처리된다. 작업은 멀티프로세싱, eventlet, gevent 를 사용해 하나 혹은 그 이상의 워커에서 동시적으로 실행되며 백그라운드에서 비동기적으로 실행될 수 있다."
공통,Python,PyPy은(는) 무엇인가요?,PyPy 는 파이썬으로 만들어진 파이썬 인터프리터다. 일반적으로 파이썬 인터프리터를 다시 한번 파이썬으로 구현한 것이기에 속도가 매우 느릴거라 생각하지만 실제 PyPy 는 스피드 센터에서 볼 수 있듯 CPython 보다 빠르다.
공통,Python,실행 추적 JIT 컴파일는 무엇인가요?,메소드 단위로 최적화 하는 전통적인 JIT 과 다르게 런타임에서 자주 실행되는 루프를 최적화한다.
공통,Python,RPython(Restricted Python)은(는) 무엇인가요?,"RPython은 이런 실행 추적 JIT 컴파일을 C 로 구현해 툴체인을 포함한다. 그래서 RPython 으로 인터프리터를 작성하고 툴체인으로 힌트를 추가하면 인터프리터에 실행추적 JIT 컴파일러를 빌드한다. 참고로 RPython 은 PyPy 프로젝트 팀이 만든 일종의 인터프리터 제작 프레임워크(언어)다. 동적 언어인 Python 에서 표준 라이브러리와 문법에 제약을 가해 변수의 정적 컴파일이 가능하도록 RPython 을 만들었으며, 동적 언어 인터프리터를 구현하는데 사용된다. 이렇게 언어 사양(파이썬 언어 규칙, BF 언어 규칙 등)과 구현(실제 인터프리터 제작)을 분리함으로써 어떤 동적 언어에 대해서라도 자동으로 JIT(Just-in-Time) 컴파일러를 생성할 수 있게 되었다."
공통,Python,메모리 누수가 발생할 수 있는 경우를 말하시오,메모리 누수를 어떻게 정의하냐에 따라 조금 다르다. `a = 1`을 선언한 후에 프로그램에서 더 이상 `a`를 사용하지 않아도 이것을 메모리 누수라고 볼 수 있다. 다만 여기서는 사용자의 부주의로 인해 발생하는 메모리 누수만 언급한다. 대표적으로 mutable 객체를 기본 인자값으로 사용하는 경우에 메모리 누수가 일어난다. ```python def foo(a=[]): a.append(time.time()) return a ``` 위의 경우 `foo()`를 호출할 때마다 기본 인자값인 `a`에 타임스탬프 값이 추가된다. 이는 의도하지 않은 결과를 초래하므로 보통의 경우 `a=None`으로 두고 함수 내부에서 `if a is None` 구문으로 빈 리스트를 할당해준다. 다른 경우로 웹 애플리케이션에서 timeout 이 없는 캐시 데이터를 생각해 볼 수 있다. 요청이 들어올수록 캐시 데이터는 쌓여만 가는데 이를 해제할 루틴을 따로 만들어두지 않는다면 이도 메모리 누수를 초래한다.
공통,Python,Duck Typing은(는) 무엇인가요?,"Duck typing이란 특히 동적 타입을 가지는 프로그래밍 언어에서 많이 사용되는 개념으로, 객체의 실제 타입보다는 객체의 변수와 메소드가 그 객체의 적합성을 결정하는 것을 의미한다. Duck typing이라는 용어는 흔히 duck test라고 불리는 한 구절에서 유래됐다. > If it walks like a duck and it quacks like a duck, then it must be a duck. > > 만일 그 새가 오리처럼 걷고, 오리처럼 꽥꽥거린다면 그 새는 오리일 것이다. 동적 타입 언어인 파이썬은 메소드 호출이나 변수 접근시 타입 검사를 하지 않으므로 duck typing을 넒은 범위에서 활용할 수 있다. 다음은 간단한 duck typing의 예시다. ```py class Duck: def walk(self): print('뒤뚱뒤뚱') def quack(self): print('Quack!') class Mallard: # 청둥오리 def walk(self): print('뒤뚱뒤뒤뚱뒤뚱') def quack(self): print('Quaaack!') class Dog: def run(self): print('타다다다') def bark(self): print('왈왈') animal.walk() animal.quack() ``` 그러나 `Dog` 는 두 메소드 모두 구현되어 있지 않으므로 해당 함수의 인자로서 부적합하다. 즉, `Dog` 는 적절한 duck typing에 실패한 것이다. 이와 같은 방식은 일반적으로 `interface`를 구현하거나 클래스를 상속하는 방식으로 인자나 변수의 적합성을 runtime 이전에 판단하는 정적 타입 언어들과 비교된다. 자바나 스칼라에서는 `interface`, c++는 `template` 을 활용하여 타입의 적합성을 보장한다. (c++의 경우 `template`으로 duck typing과 같은 효과를 낼 수 있다 [참고](http://www.drdobbs.com/templates-and-duck-typing/184401971))"
공통,Python,Timsort에서 Python의 내부 sort를 설명하라,"python의 내부 sort는 timsort 알고리즘으로 구현되어있다. 2.3 버전부터 적용되었으며, merge sort와 insert sort가 병합된 형태의 안정정렬이다. timsort는 merge sort의 최악 시간 복잡도와 insert sort의 최고 시간 복잡도를 보장한다. 따라서 O(n) ~ O(n log n)의 시간복잡도를 보장받을 수 있고, 공간복잡도의 경우에도 최악의 경우 O(n)의 공간복잡도를 가진다. 또한 안정정렬으로 동일한 키를 가진 요소들의 순서가 섞이지 않고 보장된다. "
공통,Java,JDBC(Java Database Connectivity)란 무엇인가요?,"• 자바와 데이터베이스를 연결하기 위한 Java 표준 인터페이스입니다.
• MySQL, PostgreSQL, SQL Server 등 다양한 DB 미들웨어의 드라이버를 제공합니다.
• Java 표준이기 때문에, JVM 위에서 운영되는 모든 애플리케이션에서 사용 가능합니다."
공통,Java,JDBC을 사용하기 위해 해야하는 동작을 말해주세요.,"1. 가장 먼저 사용할 DB Driver를 선택합니다.
2. 드라이버를 선택 후 커넥션 객체를 통해 데이터베이스와 연결합니다.
3. SQL 쿼리를 실행하기 위해 Statement 객체를 생성합니다.
4. 쿼리 실행 후 ResultSet 객체를 통해 받습니다.
5. 마지막으로 커넥션 종료 시에는 메모리 누수 방지를 위해 리소스를 명시적으로 해제해야 합니다.
   예를 들어, Statement, Connection, ResultSet을 close() 메서드로 닫아야 합니다."
공통,Java,JDBC의 단점에 대해 설명해주세요.,"단점
  • 리소스를 명시적으로 해제해야 합니다. 예를 들어, 커넥션 종료 시, 
    Statement, Connection, ResultSet 모두 close() 메서드로 종료해야 메모리 누수가 발생하지 않습니다.
  • 간단한 SQL 실행에도 중복된 코드가 반복적으로 사용됩니다.
  • DB에 따라 일관성없는 정보를 가진 채 Checked Exception으로 처리됩니다.
  
  • CheckedException
    • RuntimeException을 상속받지 않는 클래스 (ex: IOException, SQLExceptin, InterrupedException)
    • 컴파일 시점에 컴파일러를 확인하는 예외이기 때문에, 반드시 에외 처리를 해야 한다.
  • UncheckedException
    • RuntimeException을 상속하는 클래스 (ex: NPE)
    • 런타임 시점에 확인이 가능한 예외이기 때문에, 예외 처리를 강제하지 않는다."
공통,Spring,Spring JDBC에 대해 설명해주세요.,"Spring JDBC는 스프링 프레임워크에서 제공하는 JDBC 기반의 데이터 액세스 기술입니다.
• Spring JDBC는 JDBC를 보다 쉽고 효율적으로 사용할 수 있도록 추상화된 기능을 제공하는데,
  이를 통해 개발자는 반복적이고 번거로운 JDBC 작업을 간소화하고 생산성을 향상시킬 수 있다."
공통,Spring,Spring JDBC 장단점을 설명하세요.,"장점
  1) Spring JDBC는 자동으로 데이터베이스 연결, SQL 쿼리, ResultSet을 관리하고 닫아주기 때문에 
     코드를 간소화하고 메모리 누수를 방지합니다.
  2) Spring JDBC는 CheckException을 모두 UncheckedException으로 변환해 예외 처리 코드를 단순화해줍니다.
  3) Spring JDBC는 JdbcTemplate 등과 같은 다양한 템플릿과 헬퍼 클래스를 제공해 반복적인 코드를 줄이고
     데이터베이스 작업도 효율적으로 만들어줍니다. (헬퍼 클래스 : 도움을 주는 클래스)
단점
  1) 단, 동적 SQL 쿼리를 처리하기 어렵습니다.
  2) 또한 IF 문이나, Switch Case로 인해 코드가 길어지고 지저분해질 수 있습니다."
공통,Java,JdbcTemplate 기능에 대해 설명하세요.,"1) SQL 실행
  • 간단한 방식으로 SQL 문을 실행할 수 있습니다. 
  • 예를 들어, execute() 메서드를 사용하여 INSERT, UPDATE, DELETE 등의 작업을 실행할 수 있습니다.
  • 예를 들어, query() 메서드를 사용하여 SELECT 문을 실행하고 결과를 반환할 수 있습니다.
2) PreparedStatement 자동 처리
  • PreparedStatement를 사용하여 SQL 문을 실행합니다.
  • 또한 JdbcTemplate이 자동으로 PreparedStatement를 생성하고 파라미터 값을 설정하기 때문에, SQL 인젝션 공격을 방지할 수 있습니다.
3) ResultSet 매핑
  • ResultSet을 자동으로 자바 객체로 매핑해줍니다.
  • RowMapper 인터페이스를 구현하여 ResultSet의 각 행을 객체로 변환할 수 있습니다.
4) 트랜잭션 관리
  • 트랜잭션 경계 설정, 롤백, 커밋 등의 작업을 편리하게 처리할 수 있습니다.
  • @Transactional 어노테이션을 사용하여 메서드 레벨에서 트랜잭션을 선언할 수도 있습니다.
5) 예외 처리 및 자원 관리
  • JDBC 작업에서 발생하는 예외를 일관되게 처리하고, 연결 및 리소스 관리를 자동으로 처리합니다.
  • 즉, 예외 발생 시, 일관된 예외 계층 구조를 사용하여 예외를 처리할 수 있고, 자원의 올바른 해제를 보장합니다."
공통,Java,SQL Mapper에 대해 설명해주세요.,"• 객체와 SQL의 필드를 매핑해 데이터를 객체화하는 기술입니다.
• 이는 객체와 테이블 간 관계를 매핑하는 것이 아니라, SQL문을 직접 작성하여 쿼리 수행 결과를 어떤 객체에 매핑하는 것을 말합니다.
• 예를 들어, JDBCTemplate 혹은 MyBatis를 의미합니다."
공통,Java,MyBatis에 대해 설명하세요.,"MyBatis는 자바 언어를 위한 데이터 매퍼 프레임워크입니다.
• Spring JDBC는 코드에 직접 쿼리를 작성하지만 MyBatis는 XML 파일에서 SQL 쿼리를 관리하고
  SQL 결과와 객체 인스턴스의 매핑을 수행합니다."
공통,Java,MyBatis 장/단점을 설명하세요.,"장점
  • SQL 쿼리를 직접 작성하므로 최적화된 쿼리를 구현할 수 있습니다.
  • 복잡한 쿼리도 SQL 쿼리만 작성할 수 있다면 손쉽게 작성할 수 있습니다.
  • 엔티티에 종속받지 않고 다양한 테이블을 조합할 수 있습니다.
단점
  • 스키마 변경 시 SQL 쿼리를 직접 수정해주어야 합니다.
  • 반복된 쿼리가 발생하여 반복 작업이 있습니다.
  • 런타임 시에 오류를 확인할 수 있습니다.
  • 쿼리를 직접 작성하기 때문에 데이터베이스에 종속된 쿼리문이 발생할 수 있습니다. 
    즉, 데이터베이스 변경 시 로직도 함께 수정해주어야 합니다.
  • SQL 중심적인 개발을 하기 때문에, 객체와 관계형 테이블 구조간 패러다임 불일치 문제가 발생합니다."
공통,Java,패러다임 불일치 문제는 무엇이 있나요?,"객체에는 상속 개념이 있지만 테이블에는 상속 개념이 존재하지 않습니다.
• 객체는 연관 관계를 참조로 표현하고 테이블은 외래키로 표현합니다.
• 객체는 그래프 탐색이 가능해야 하지만 테이블은 불가능합니다.
• 객체는 동등성/동일성으로 비교하지만 테이블은 Row의 ID 값을 기준으로 조회합니다.
  • 동일성(Identity) : 두 객체가 완전히 같은 경우. 즉, 두 객체의 메모리 주소값이 같습니다.
  • 동등성(Equality) : 두 객체가 같은 정보를 갖고 있는 경우. 즉, 주소값이 달라도 값만 같으면 동등하다 표현합니다."
공통,Java,SQL 중심적인 개발의 문제점에 대해 설명하세요.,"SQL에 의존적인 개발이 되기 때문에, 비지니스 로직이 SQL에 종속적이게 됩니다.
즉, SQL에 의존적인 상황에서 개발자들이 엔티티를 신뢰하고 사용할 수 없게 됩니다.
예를 들어, SQL 변경 시, 자바 코드도 변경해야 하므로 유지보수도 어려워집니다.

최종적으로 패러다임 불일치 문제가 발생합니다. 객체지향 프로그래밍과 관계형 데이터베이스는 서로 다른 패러다임을 가지고 있습니다. 
이 둘의 차이를 중앙에서 해결해주지 않으면 개발자가 많은 코드를 작성해야 하며, 복잡성이 증가합니다."
공통,Java,현업에서는 JPA를 많이 사용하긴 하지만 아직까지 JDBCTemplate 혹은 Mybatis를 사용하는 곳이 많습니다. 그 이유가 무엇일까요?,"SQL Mapper는 개발자가 SQL을 직접 작성하기 때문에, 지루하고 반복적인 코드를 작성하긴 하지만,
SQL 지식만 충분하다면, 세밀한 SQL 쿼리 최적화가 가능하고, 복잡한 쿼리를 짜는데 용이합니다.
또한 Entity 기준으로 동작하는 JPA보다 조회된 데이터를 바로 DTO로 변환해 응답하기가 편리합니다.

그리고 JPA는 처음엔 사용하기 쉬울지 몰라도 점차 애플리케이션이 고도화된다면 오히려 더 손이 많이 가는 경우가 많아 
아직까지 MyBatis를 사용하는 곳이 있다고 생각합니다."
공통,Java,ORM(Object Relational Mapping)이란 무엇인가요?,"• 객체와 Database 테이블을 매핑하여 데이터를 객체화하는 기술입니다.
• 즉, 객체지향 프로그래밍 언어를 사용해 데이터베이스를 관리할 수 있게 합니다.
• 대표적으로 Hibernate가 있습니다."
공통,Java,JPA를 Hibernate와 함께 설명해주세요.,"JPA는 자바 ORM 기술에 대한 표준 명세를 의미합니다.즉, ORM을 사용하기 위한 인터페이스를 모아둔 것으로
  자바에서 관계형 데이터베이스를 어떻게 사용해야 하는 지 정의되어 있기만 하고 구현되어 있지 않습니다.
• 이 JPA를 구현한 것이 바로 Hibernate입니다. 즉, 하이버네이트는 JPA를 구현한 ORM 프레임워크입니다.
  때문에 하이버네이트를 사용하면 SQL를 사용하지 않고 직관적인 메서드를 이용해 데이터를 조작할 수 있습니다.
  단, SQL을 사용하지 않는다고 해서 JDBC를 사용하지 않는 것은 아닙니다."
공통,Spring,Spring Data JPA란 무엇인가요?,"Spring에서 제공하는 모듈 중 하나로 개발자가 JPA를 더 쉽고 편하게 사용할 수 있도록 도와줍니다.
• 예를 들어 JPA를 한 단게 추상화시킨 Repository 인터페이스를 제공합니다."
공통,Spring,Spring Data JPA 장/단점을 설명하세요.,"장점
  • 1차캐시, 쓰기지연, 변경감지, 지연로딩을 제공하여 성능상 이점을 얻을 수 있습니다.
  • 코드 레벨로 관리 되므로 사용하기 용이하고 생산성이 높습니다.
  • 컴파일 타임에 오류를 확인할 수 있습니다.
  • 데이터베이스에 종속적이지 않으므로 특정 쿼리를 사용하지 않아 추상적으로 기술 구현이 가능합니다.
  • 개발 초기에는 쿼리에 대한 이해가 부족해도 코드 레벨로 어느 정도 커버가 가능합니다.
  • 객체지향적으로 데이터를 관리하기 때문에, 패러다임 불일치 문제가 해결됩니다.
  • 부족한 부분은 다양한 쿼리 빌더와 호환하여 보안할 수 있습니다.
단점
  • JPA만 사용하여 복잡한 연산을 수행하게 되면, 로직이 복잡해지거나 불필요한 쿼리가 발생할 수 있습니다.
  • 초기에는 생산성이 높을 수 있으나 점차 사용하다 보면 N+1과 같은 성능상 이슈가 발생할 수 있습니다.
  • 고도화 될수록 성능 이슈를 해결하기 위해, 학습 곡선이 높아질 수 있습니다."
공통,Spring,@Transactional 어노테이션은 어떤 기능을 하나요?,"스프링에서 트랜잭션 처리는 이 어노테이션을 많이 사용하는데, 이는 클래스 또는 메소드 레벨에 사용할 수 있으며,
@Transactional이 포함된 메소드가 호출될 경우, 프록시 객체가 생성됩니다. 이 프록시 객체는 해당 메소드 실행 이전에
PlatformTransactionManager를 사용하여 트랜잭션을 시작하고 결과에 따라 Commit 또는 Rollback 합니다.
• 선언적 트랜잭션 관리 방법을 제공하는 어노테이션으로 클래스와 메서드 레벨에서 사용이 가능합니다.
• 예를 들어, 해당 어노테이션을 붙이면 메서드나 클래스 내의 작업들이 하나의 트랜잭션으로 묶여 데이터 일관성을 유지할 수 있습니다.
• 이는 JDBC에서 트랜잭션 사용을 위해 사용되던 코드를 단축시켜주기 때문에 매우 편리합니다.
• 추가적으로 Spring AOP 방식으로 동작하기 때문에, 프록시 객체로 외부에서 접근이 가능한 인터페이스를 제공해야 합니다. 즉, public 메서드여야 합니다. 또한 다른 AOP 기능들과 충돌을 고려도 하고 기본적으로 대부분의 Checked Exception은 롤백되지 않으니 예외처리도 고려해야 합니다."
공통,Spring,@Transactional 동작원리에 대해 설명해주세요.,"1. 일단 @Transactional 어노테이션은 Spring AOP를 통해 프록시 객체를 생성하여 사용됩니다.
2. 트랜잭션 어노테이션이 붙은 메서드가 실행되면 스프링은 트랜잭션을 시작합니다.
3. 메서드가 정상적으로 종료된다면 커밋, 예외가 발생하면 롤백 처리를 합니다.
4. 즉, 비정상 종료되어 롤백 발생 시, 트랜잭션 작업만 데이터베이스에 반영되는 것을 방지해, 데이터 일관성을 유지합니다."
공통,Spring,@Transactional 특징을 말해보세요.,"1. 자동 롤백 : 트랜잭션 내 예외 발생 시, 스프링은 자동으로 롤백합니다.
2. 전파 행위 지정 : 트랜잭션의 전파행위를 지정할 수 있습니다.
3. 격리 수준 설정 : 데이터베이스의 트랜잭션 거리 수준을 설정할 수 있습니다.
4. 읽기 전용 설정 : 트랜잭션을 읽기 전용으로 설정해, 데이터 변경이 없는 작업에 대해 성능 최적화를 할 수 있습니다.
5. 타임아웃 설정 : 트랜잭션이 너무 오래 실행되는 것을 방지하기 위해 타임아웃을 설정할 수 있습니다."
공통,Spring,@Transactional(readonly'true)는 어떤 기능인가요?,"조회용 메서드에 붙이는 것으로 영속성 컨텍스트에 snapshot을 찍지 않고, flush 모드를 수동으로 바꿔 
의도치 않은 변경이 일어나지 않고 메모리의 성능을 높여주는 장점이 있습니다.

• 이는 JPA의 플러시 모드를 MANUAL로 설정합니다. 즉, 트랜잭션 내에서 강제로 flush()를 호출하지 않는 한, 
  커밋 시 영속성 컨텍스트가 자동으로 flush 되지 않으므로 조회 용으로 가져온 Entity의 예상치 못한 수정을 방지할 수 있습니다.
• 또한, JPA는 해당 트랜잭션 내에서 조회하는 Entity는 조회 용임을 인식해 변경 감지를 위한 
  Snapshot을 따로 보관하지 않으므로 메모리가 절약되기 때문에, 성능면에서의 이점도 존재합니다.

MANUAL 모드
  • 하이버네이트 스펙에서만 지원하는 모드
  • 모든 자동 플러시가 비활성화되고, 개발자가 명시적으로 플러시 코드를 작성해야 플러시가 동작"
공통,Spring,조회용 메서드에 @Transactional 어노테이션을 안 붙여도 되지 않을까요?,"• 조회용 메서드에 대해 @Transactional 어노테이션 유무의 차이는 OSIV가 꺼져있을 때 알 수 있습니다.
• 즉, 기본적으로 별도의 설정을 하지 않는다면 OSIV는 true로 설정되어 있어 @Transactional 어노테이션 유무의 차이를 알 수 없지만,
• OSIV를 false로 설정한다면 영속성 컨텍스트는 트랜잭션 범위를 벗어나는 순간 Entity는 영속성 컨텍스트의 관리를 받지 않는 준영속 상태가 됩니다. 
• 따라서 영속성 컨텍스트의 관리를 받지 않는 준영속 상태는 Lazy Loading의 동작도 불가능해져 LazyInitializationException이 발생할 수 있습니다.
• 결론적으로 OSIV가 꺼져있는 상태에서는 @Transactional 어노테이션이 없을 때에 Lazy Loading의 동작을 수행할 수 없다는 문제점이 있으므로 
  조회용 메서드에 대해서도 @Transactional 어노테이션을 붙여주어야 한다고 생각합니다."
공통,Spring,"그렇다면, 무조건 @Transactional 어노테이션을 붙이는 것이 좋을까요?","@Transactional 어노테이션을 붙이게 되면 해당 영역에서는 JPA의 스냅샷 유지, flush의 필요성, DB 커넥션을 오래 물고 있는 등의 관리적인 측면이 발생합니다.
• 따라서, 지연로딩, 레플리케이션과 같이 트랜잭션 범위 내에서 수행해야 되는 동작이 있는 경우에 대해서 적절히 @Transactional 어노테이션을 활용하는 것이 좋다고 생각합니다.
• 만약, 무분별하게 @Transactional 어노테이션을 사용한다면, 스냅샷 유지, flush의 필요 등 관리적/메모리적 측면에서 오히려 좋지 않을 수 있고,
  커넥션을 오래 가지고 있어 커넥션 부족 등의 문제가 발생할 수도 있을 거라 생각합니다."
공통,Java,JPQL(Java Persistence Query Language)이란 무엇인가요?,"• JPQL은 SQL과 비슷한 문법을 가지고 있지만, JPQL은 엔티티 객체를 조회하는 객체지향 쿼리입니다.
• 또한 JPQL은 SQL을 추상화한 것이기 때문에, 특정 데이터베이스에 의존하지 않습니다. 즉, 데이터베이스 방언이 바뀌어도 JPQL을 수정하지 않아도 됩니다."
공통,Java,"JPQL 사용 시, 영속 상태가 되는 경우는 어떤 것이 있을까요?","JPQL의 조회 대상은 엔티티, 임베디드 타입, 값 타입 같이 다양한 종류가 있습니다.
단, JPQL는 조회한 엔티티만 영속성 컨텍스트에서 관리합니다.
예를 들어, 임베디드 타입을 조회하거나 특정 엔티티의 필드만 조회하면 영속성 컨텍스트에서 관리되지 않습니다."
공통,Java,"JPQL 사용 시, 기존 영속성 컨텍스트의 데이터가 갱신될까요?","JPQL 호출 시, flush가 발생하기 때문에 갱신됩니다.

EntityMamager의 find() 메서드와 달리 JPQL은 항상 데이터베이스 SQL을 실행하며 조회합니다.
즉, JPQL은 영속성 컨텍스트 내에 있는 데이터를 고려하지 않고 데이터베이스를 조회합니다.
다만, 영속성 컨텍스트에 동일한 데이터가 있다면, 데이터베이스에서 조회한 데이터는 버리고
영속성 컨텍스트 내에 있던 데이터를 반환됩니다. 때문에, 데이터 무결성을 위해, 플러시 모드를 AUTO로 하여,
쿼리 실행 직전에 플러시하여 데이터베이스에 반영해야 합니다. 만약 성능 최적화가 필요한 로직이라면, 
플러시 모드를 COMMIT으로 하여, 플러시 횟수를 줄일 수도 있습니다. 단, 데이터 무결성 문제가 발생할 수 있으니 주의해야 합니다.

• AUTO : 커밋 또는 쿼리 실행 시, 플러시
• COMMIT : 커밋 시, 플러시"
공통,Java,영속성 컨텍스트란 무엇인가요?,"• Server와 Database 사이에 엔티티를 저장하는 논리적인 영역이라고 할 수 있습니다.
• 예를 들어, 엔티티 매니저로 엔티티를 저장하거나 조회하면 엔티티 매니저가 영속성 컨텍스트에 엔티티를 보관하고 관리합니다."
공통,Java,영속성 컨텍스트의 이점 5가지를 설명해주세요.,"영속성 컨텍스트 사용 시, 얻는 이점으로는 1차 캐시, 동일성 보장, 쓰기 지연, 변경 감지, 지연로딩이 있습니다.

• 1차 캐시
  • Map 객체로 저장됩니다. 이때, key 값이 @Id 값이 되고 Value는 엔티티가 됩니다. 즉, 영속 상태의 엔티티는 식별자 값이 반드시 있어야 합니다.
  • 엔티티 조회 시, 1차 캐시에 있다면 1차 캐시에서 조회하고 없다면 Database에서 조회 후 1차 캐시에 올립니다.
  • 1차 캐시로 인해, REPEATABLE READ 격리 수준을 데이터베이스가 아닌 애플리케이션 차원에서 제공합니다.
• 동일성(Identity, '') 보장 
  • 동일한 트랜잭션 내에서 동일성 비교가 가능합니다.
  • 영속성 컨텍스트는 특정 엔티티를 여러번 조회해도, 1차 캐시에 있는 동일한 엔티티를 반환하기 때문에 동일성이 보장됩니다.
• 쓰기 지연:
  • SQL을 바로 보내지 않고 쓰기 지연 SQL 저장소에서 관리되다가 Flush 발생 시, 전송합니다.
• 변경 감지(Dirty checking): 
  • 플러시가 일어날 때, 1차 캐시에 들어있는 엔티티와 스냅샵을 비교해서 값이 다르면 쓰기 지연 저장소에 업데이트 쿼리를 저장합니다. 
    마지막으로 쓰기 지연 저장소 SQL을 데이터베이스에 전송하고 커밋이 완료됩니다.
  • 단, 변경 감지는 영속 상태의 엔티티에만 적용됩니다.
  • 스냅샷 : 값을 읽어온 최초 시점
• 지연 로딩(Lazy Loading)
  • 엔티티가 실제 사용될 때까지 데이터베이스 조회를 지연한다.
  • 지연 로딩을 위해 실제 엔티티 대신 프록시 객체를 제공한다.
  • 단, 성능 저하의 원인이 될 수도 있습니다."
공통,Java,엔티티 생명주기를 설명해주세요.,"• 비영속(new/transient)
  • 영속성 컨텍스트와 전혀 관계가 없는 상태
  • 즉, 순수한 객체 상태를 말한다.
• 영속(managed)
  • 영속성 컨텍스트에 저장된 상태
  • 즉, 영속성 컨텍스트가 관리하는 엔티티를 말한다.
  • `EntityManager.persist(..);`, `EntityManager.find(..);`
• 준영속(detached)
  • 영속성 컨텍스트에 저장됐다가 분리된 상태
  • `EntityManager.detach(..);`, `EntityManager.clear(..);`, `EntityManager.close(..);`
• 삭제(removed)
  • 삭제된 상태.
  • 즉, 엔티티를 영속성 컨텍스트와 데이터베이스에서 삭제된 것을 말한다.
  • EntityManager.remove(..);"
공통,Java,즉시 로딩과 지연 로딩에 대해 설명해주세요.,"• 지연로딩 실제 객체가 사용되는 시점에 쿼리가 나가는 방식입니다. 예를 들어, 특정 엔티티를 불러올 때 영속성 컨텍스트에 없다면, 프록시 객체로 가져오고, 이 프록시 객체를 실제 사용하기 전까지 미루다가 실제 사용 시점에 쿼리를 실행합니다. Ex: Member.getTeam() •> 프록시 객체 / Member.getTeam().getName() •> 쿼리 발생
• 실제 객체가 사용되는 시점에 쿼리가 나가는 방식입니다.
• 예를 들어, 특정 엔티티를 불러올 때 영속성 컨텍스트에 없다면, 프록시 객체로 가져오고, 이 프록시 객체를 실제 사용하기 전까지 미루다가 실제 사용 시점에 쿼리를 실행합니다.
• Ex: Member.getTeam() •> 프록시 객체 / Member.getTeam().getName() •> 쿼리 발생
• 즉시 로딩 조회 시, 조인을 이용해 한 번의 쿼리로 전부 조회해옵니다. 즉, 실행하여 받아오는 객체는 프록시 객체가 아닌 실제 객체가 조회됩니다.
• 조회 시, 조인을 이용해 한 번의 쿼리로 전부 조회해옵니다.
• 즉, 실행하여 받아오는 객체는 프록시 객체가 아닌 실제 객체가 조회됩니다."
공통,Java,플러시란 무엇인가요?,"플러시는 영속성 컨텍스트의 내용을 데이터베이스에 반영하는 것을 말합니다. 즉, 영속성 컨텍스트의 내용을 데이터베이스와 동기화하는 것입니다. 단, 영속성 컨텍스트를 비우지는 않습니다.
• 플러시 방법 EntityManager.flush() : 직접 호출 트랜잭션 커밋 : 자동 호출 JPQL 쿼리 실행 : 자동 호출
• EntityManager.flush() : 직접 호출
• 트랜잭션 커밋 : 자동 호출
• JPQL 쿼리 실행 : 자동 호출"
공통,Java,"플러시 발생 시, 일어나는 일을 설명하세요.","영속성 컨텍스트의 내용을 데이터베이스와 동기화하는 것이기 때문에, 플러시가 발생한다면 가장 먼저, 변경 감지가 일어납니다.
• 그리고 변경된 것이 있다면, 데이터베이스에도 반영하기 위해 쓰기 지연 SQL 저장소에 해당 변경 쿼리를 추가합니다.
• 마지막으로 쓰기 지연 저장소의 쿼리를 데이터베이스에 전송합니다."
BACKEND,네트워크,좋은 네트워크란 어떤 네트워크인가요?,"• 많은 처리량, 짧은 지연시간, 낮은 장애 빈도, 좋은 보안 등을 갖춘 네트워크가 좋은 네트워크라 생각합니다."
BACKEND,네트워크,트래픽이란?,"• 특정 시점에 흐르는 데이터 양을 뜻합니다.
• 예를 들어, 서버에 저장된 파일을 클라이언트가 다운로드하는 요청이 발생했을 때, 발생되는 데이터 누적량을 뜻합니다.
• 단위) BPS(Bits Per Second) : 초당 전송/수신되는 비트 수를 의미 
• Ex) 10MB 동영상 10명이 다운 시 누적 트래픽 량 = 10 * 10 = 100MB"
BACKEND,네트워크,처리량이란?,"• 성공적으로 전달되는 데이터의 양을 말하는 것으로 보통 트래픽 처리량을 뜻합니다.
• 즉, 대용량 트래픽을 처리한다는 것은 높은 처리량을 가진 것입니다.
• 단위) BPS(Bits Per Second) : 초당 전송/수신되는 비트 수를 의미"
BACKEND,네트워크,트래픽과 처리량의 차이는?,"• 트래픽이 많아졌다는 것 = 흐르는 데이터가 많아졌다는 것
• 처리량이 많아졌다는 것 = 처리되는 트래픽이 많아졌다는 것"
BACKEND,네트워크,대역폭이란?,"• 주어진 시간동안 네트워크 연결을 통해 흐를 수 있는 최대 비트 수를 말합니다.
• 즉, 최대 처리할 수 있는 트래픽을 뜻하는 것으로 최대 동시 접속자 수를 유추하는 데 척도가 됩니다.
• 때문에, 대역폭이 클수록 사용자에게 빠른 서비스를 제공할 수 있습니다.
• 단위) BPS(Bits Per Second) : 초당 전송/수신되는 비트 수를 의미"
BACKEND,네트워크,RTT(Round Trip Time; 왕복 지연 시간)란?,"• 신호를 전송하고 해당 신호의 수신 확인에 걸린 시간을 더한 값입니다.
• 예를 들어, 어떤 메시지가 두 장치 사이를 왕복하는 데 걸린 시간이 RTT라 할 수 있습니다.
• 지연시간: 매체타입(무선, 유선), 패킷 크기, 라우터의 패킷 처리 시간에 영향을 받습니다."
BACKEND,네트워크,병목 현상이란 무엇인가요?,"• 일반적으로 전체 시스템의 성능이나 용량이 하나의 구성요소로 인해 제한을 받는 현상을 말합니다. 즉, 네트워크에서는 트래픽에 의해 데이터 흐름이 제한되는 상황을 말합니다.
• 예를 들어, 병의 몸통보다 병의 목 부분의 내부 지름이 좁아 물이 상대적으로 천천히 쏟아지는 것에 비유할 수 있습니다.
• 만약, 서비스에서 이벤트를 열었을 때 트래픽이 많이 생기고 그 트래픽을 잘 관리하지 못하면 병목 현상이 생겨 사용자는 웹 사이트로 들어가지 못하게 됩니다."
BACKEND,네트워크,네트워크 성능 분석 명령어에 대해 아시는 게 있나요?,"• ping
  • 네트워크 상태를 확인하려는 대상 노드를 향해 일정 크기의 패킷을 전송하는 명령어
  • 이를 통해 해당 노드의 패킷 수신 상태와 도달하기까지 시간, 네트워크 연결 상태 등을 확인할 수 있다.
  • TCP/IP 프로토콜 중 ICMP 프로토콜을 통해 동작한다.
• netstat
  • 접속되어 있는 서비스들의 네트워크 상태를 표시하는 데 사용된다.
  • 이는 네트워크 접속, 라우팅 테이블, 네트워크 프로토콜 등의 리스트를 보여준다.
  • 주로 서비스의 포트가 열려 있는 지 확인하기 위해 사용된다.
• nslookup
  • DNS에 관련된 내용을 확인하기 위해 쓰는 명령어로 특정 도메인에 매핑된 IP를 확인하기 위해 사용된다.
• tracert(윈도우) 혹은 traceroute(리눅스)
  • 목적지 노드까지 네트워크 경로를 확인할 때 사용하는 명령어
  • 목적지 노드까지의 구간들 중 어느 구간에서 응답 시간이 느려지는 지 등을 확인할 수 있습니다."
BACKEND,네트워크,"유니캐스트, 멀티캐스트, 브로드캐스트에 대해 설명해주세요.","• 유니캐스트 1 : 1 통신이다. 대표적으로 HTTP 통신이 있다.
• 1 : 1 통신이다. 대표적으로 HTTP 통신이 있다.
• 멀티캐스트 1 : N 통신이다. 이때 N은 연결된 모든 노드들이 아닌 특정 그룹의 노드들에게만 데이터를 전달한다.
• 1 : N 통신이다. 이때 N은 연결된 모든 노드들이 아닌 특정 그룹의 노드들에게만 데이터를 전달한다.
• 브로드캐스트 1 : N 통신이다. 이때 N은 그룹이 아닌 연결된 모든 노드들을 말한다. 대표적으로 ARP가 있다.
• 1 : N 통신이다. 이때 N은 그룹이 아닌 연결된 모든 노드들을 말한다. 대표적으로 ARP가 있다."
BACKEND,네트워크,"LAN, MAN, WAN에 대해 설명해주세요.","• LAN MAN, WAN보다 높은 안정성, 전송 속도를 가진다. 일반적으로 허브, 스위치로 연결된 소규모 네트워크를 말한다. (집, 사무실 등) 하나의 IP 주소(논리적)를 기반으로 여러 개의 MAC 주소(물리적)로 구별하는 네트워크라 볼 수 있다. 내부적으로는 하나의 IP 주소를 받았지만 NAT(라우터) 기술을 통해 여러 IP인 것처럼 가상의 IP를 부여하고 각 컴퓨터 고유 번호인 MAC 주소를 기반으로 구별한다. 외부적으로는 논리적 주소인 IP 주소를 기반으로 통신한다.
• MAN, WAN보다 높은 안정성, 전송 속도를 가진다.
• 일반적으로 허브, 스위치로 연결된 소규모 네트워크를 말한다. (집, 사무실 등)
• 하나의 IP 주소(논리적)를 기반으로 여러 개의 MAC 주소(물리적)로 구별하는 네트워크라 볼 수 있다.
• 내부적으로는 하나의 IP 주소를 받았지만 NAT(라우터) 기술을 통해 여러 IP인 것처럼 가상의 IP를 부여하고 각 컴퓨터 고유 번호인 MAC 주소를 기반으로 구별한다.
• 외부적으로는 논리적 주소인 IP 주소를 기반으로 통신한다.
• MAN 도시와 도시의 통신망을 뜻하는 것으로 2개 이상의 LAN이 연결되어 구성된다. 연결은 라우터, 브리지 등으로 연결된다. (브릿지 = LAN과 LAN을 잇는 네트워크 장치)
• 도시와 도시의 통신망을 뜻하는 것으로 2개 이상의 LAN이 연결되어 구성된다.
• 연결은 라우터, 브리지 등으로 연결된다. (브릿지 = LAN과 LAN을 잇는 네트워크 장치)
• WAN 국가와 국가와의 통신망으로 수많은 라우터를 거쳐 다른 국가와도 연결되는 범위를 말한다.
• 국가와 국가와의 통신망으로 수많은 라우터를 거쳐 다른 국가와도 연결되는 범위를 말한다."
BACKEND,네트워크,OSI 7계층에 대해 설명해 주세요.,"• 네트워크 통신이 일어나는 과정을 7단계로 나눈 네트워크 표준 모델입니다.
• 즉, 네트워크 프로토콜이 통신하는 구조를 7개의 계층으로 분리해 각 계층간 상호 작동하는 방식을 정해놓은 것입니다.
• 이는 응용, 표현, 세션, 전송, 네트워크(패킷), 데이터 링크(프레임), 물리(비트) 계층으로 이루어져 있습니다."
BACKEND,네트워크,각 계층을 간단하게 설명해주세요.,"• 응용 계층 (L7)
  • 최종 목적지로 응용 프로세스와 직접 관계하여 일반적인 응용 서비스를 수행합니다.
  • 사용자 인터페이스(UI), 전자우편, DB 관리 등의 서비스를 제공합니다.
  • Ex: HTTP, FTP, DNS 등
• 표현 (L6)
  • 데이터 표현에 대한 독립성을 제공하고 암호화하는 역할을 담당하는 계층입니다. 즉, 파일 인코딩, 명령어 포장, 압축, 암호화 등을 합니다.
  • Ex: JPEG, MPEG 등
• 세션 계층 (L5)
  • 데이터가 통신하기 위한 논리적 연결을 담당하는 계층입니다. 즉, TCP/IP 세션을 관리하는 책임을 갖습니다.
  • Ex: API, Socket 등
• 전송 계층 (L4)
  • TCP/UDP 프로토콜을 통해 통신을 활성화하는 계층입니다. 즉, 포트를 열어서 프로그램들이 데이터를 주고 받을 수 있도록 합니다.
  • TCP: 신뢰성, 연결형, 패킷 교환 방식, 느림, 순서 보장 O, 1:1 통신, 수신 여부 확인 O
  • UDP: 비신뢰성, 비연결형, 데이터그램 방식, 빠름, 순서 보장 X, N:N 통신, 수신 여부 확인 X, 실시간
• 네트워크 계층 (L3)
  • 데이터를 목적지까지 가장 안전하고 빠르게 전달하는 기능을 담당하는 계층으로 라우팅, 흐름 제어, 세크멘테이션, 오류 제어 등을 수행합니다.
  • 이 계층은 라우터를 통해 이동할 경로를 선택하여 IP 주소를 지정하고 해당 경로에 패킷을 전달합니다.
  • 전송 단위: 패킷
  • Ex: 라우터, IP 
• 데이터 링크 계층 (L2)
  • 물리 계층으로 송/수신되는 정보를 관리하여 안전하게 전달되도록 도와주는 계층입니다.
  • 이 계층은 MAC 주소를 기반으로 통신합니다. 즉, 프레임에 물리적 주소인 MAC 주소를 부여해 오류 제어, 흐름 제어를 수행합니다. 
  • 전송 단위: 프레임
  • Ex: 브리지, 스위치, 이더넷 등
• 물리 계층 (L1)
  • 데이터를 전기적 신호로 변환해 주고 받는 기능을 수행하는 계층입니다. 즉, 데이터를 전송하는 역할만 수행합니다.
  • 전송 단위: 비트 (전기적 신호, 0/1)
  • Ex: 통신 케이블, 리피터, 허브 등"
BACKEND,네트워크,TCP/IP 4계층에 대해 설명해주세요.,"• OSI 7 계층 모델은 실무적으로 이용하기에 다소 복잡하여 TCP/IP 프로토콜 통신 과정에 초점을 맞추어 더 단순화한 계층이다.
• 이는 응용, 전송, 인터넷, 네트워크 엑세스 계층으로 구성된다."
BACKEND,네트워크,각 계층을 간단하게 설명해주세요.,"• 응용 계층 (OSI 7 계층의 응용 계층 + 표현 계층 + 세션 계층) 
  • 사용자에게 서비스를 제공하는 계층이다.
  • Ex: HTTP, SMTP, SSH, FTP 등
• 전송 계층
  • 응용 계층과 인터넷 계층 사이에서 데이터가 전달될 때 중계 역할을 하는 계층입니다.
  • 즉, 응용 계층에서 받은 메시지를 기반으로 세그먼트 혹은 데이터그램으로 데이터를 쪼개 전달합니다.
  • Ex: TCP(세그먼트), UDP(데이터그램)
• 인터넷 계층 (OSI 7계층의 네트워크 계층)
  • 전송 계층에서 받은 세그먼트 혹은 데이터그램을 패킷화하여 IP 주소로 지정된 목적지로 전송하는 역할을 담당하는 계층이다.
  • 전송 계층과 다르게 수신 쪽에서 패킷을 잘 받았는 지에 대해 보장하지 않는 비연결형 특징을 가지고 있는 데이터그램 방식이다.
  • Ex: IP, ARP, ICMP
• 네트워크 엑세스 계층 (OSI 7 계층의 데이터 링크 계층 + 물리 계층)
  • 실질적으로 데이터가 네트워크를 통해 물리적으로 전달되며 장치 간 신호를 주고 받는 계층이다.
  • Ex: 전선, 광섬유, 무선 등"
BACKEND,네트워크,계층 간 송/수신 흐름을 말해보세요.,"• 캡슐화 송신측의 응용 계층 데이터가 전송 계층으로 전달되며 TCP(L4) 헤더가 붙고 세그먼트 또는 데이터그램화 됩니다. 인터넷 계층으로 전달되며 IP(L3) 헤더가 붙고 패킷화 됩니다. 네트워크 엑세스 계층으로 전달되며 프레임 헤더와 프레임 트레일러가 붙고 프레임화 됩니다.
• 송신측의 응용 계층 데이터가 전송 계층으로 전달되며 TCP(L4) 헤더가 붙고 세그먼트 또는 데이터그램화 됩니다.
• 인터넷 계층으로 전달되며 IP(L3) 헤더가 붙고 패킷화 됩니다.
• 네트워크 엑세스 계층으로 전달되며 프레임 헤더와 프레임 트레일러가 붙고 프레임화 됩니다.
• 비캡슐화
4. 수신 측에서 캡슐화된 데이터를 받습니다.
5. 네트워크 엑세스 계층에서 인터넷 계층으로 전달되면서 프레임화된 데이터가 다시 패킷화됩니다.
6. 전송 계층으로 전달되면서 패킷화된 데이터가 세그먼트 혹은 데이터그램화 됩니다.
7. 응용 계층으로 전달되면서 메시지화 됩니다.
8. 최종적으로 사용자에게 애플리케이션의 PDU만 받습니다."
BACKEND,네트워크,캡슐화와 비캡슐화에 대해 설명해주세요.,"• 캡슐화 과정
  • 상위 계층의 헤더와 데이터를 하위 계층의 데이터 부분에 포함시키고 해당 계층의 헤더를 삽입하는 과정을 말한다.
  • 즉, 송신자가 수신자에게 데이터를 보낼 때 데이터가 각 계층을 지나면서 각 계층의 특징들이 담긴 헤더들이 붙여지는 과정이다.
  • 예를 들어, 전송 계층은 TCP 헤더, 네트워크 계층은 IP 주소 헤더를 추가한다.
• 비캡슐화 과정
  • 하위 계층에서 상위 계층으로 이동하며 각 계층의 헤더 부분을 제거하는 과정이다.
  • 즉, 캡슐화의 역과정으로 수신자 측에서 캡슐화된 데이터를 역순으로 제거하며 응용 계층까지 도달한다."
BACKEND,네트워크,PDU(Protocol Data Unit)란?,"• 네트워크의 어떠한 계층에서 계층으로 데이터가 전달될 때 한 덩어리의 단위를 말하는 것으로 각 계층마다 부르는 명칭이 다르다. 
• 즉, TCP/IP 4계층을 기반으로 설명했을 때 각 계층의 데이터 단위를 의미하는 것으로 헤더, 데이터를 의미하는 페이로드로 구성되어 있다. 
• PDU는 아래 계층인 비트로 송수신하는 것이 가장 빠르고 효율성이 좋지만 확장성 등의 이유로 응용 계층에서는 문자열 기반으로 송수신을 한다."
BACKEND,네트워크,각 계층의 PDU(Protocol Data Unit)를 말해주세요.,"• 응용 계층: 메시지
• 전송 계층
  • TCP: 세그먼트
  • UDP: 데이터그램
• 인터넷 계층: 패킷 (세그먼트 혹은 데이터그램에 IP 헤더가 붙은 형태의 조각)
• 네트워크 엑세스
  • 데이터 링크 계층: 프레임 (MAC 주소 헤더와 CRC/Checksum 트레일러가 붙은 조각)
  • 물리 계층: 비트"
BACKEND,네트워크,TCP와 UDP의 차이에 대해 설명해 주세요.,"• Checksum이 무엇인가요?
Checksum이 무엇인가요?
• TCP와 UDP 중 어느 프로토콜이 Checksum을 수행할까요?
TCP와 UDP 중 어느 프로토콜이 Checksum을 수행할까요?
• 그렇다면, Checksum을 통해 오류를 정정할 수 있나요?
그렇다면, Checksum을 통해 오류를 정정할 수 있나요?
• TCP가 신뢰성을 보장하는 방법에 대해 설명해 주세요.
TCP가 신뢰성을 보장하는 방법에 대해 설명해 주세요.
• TCP의 혼잡 제어 처리 방법에 대해 설명해 주세요.
TCP의 혼잡 제어 처리 방법에 대해 설명해 주세요.
• 왜 HTTP는 TCP를 사용하나요?
왜 HTTP는 TCP를 사용하나요?
• 그렇다면, 왜 HTTP/3 에서는 UDP를 사용하나요? 위에서 언급한 UDP의 문제가 해결되었나요?
그렇다면, 왜 HTTP/3 에서는 UDP를 사용하나요? 위에서 언급한 UDP의 문제가 해결되었나요?
• 그런데, 브라우저는 어떤 서버가 TCP를 쓰는지 UDP를 쓰는지 어떻게 알 수 있나요?
그런데, 브라우저는 어떤 서버가 TCP를 쓰는지 UDP를 쓰는지 어떻게 알 수 있나요?
• 본인이 새로운 통신 프로토콜을 TCP나 UDP를 사용해서 구현한다고 하면, 어떤 기준으로 프로토콜을 선택하시겠어요?
본인이 새로운 통신 프로토콜을 TCP나 UDP를 사용해서 구현한다고 하면, 어떤 기준으로 프로토콜을 선택하시겠어요?"
BACKEND,네트워크,3-Way Handshake에 대해 설명해 주세요.,"• ACK, SYN 같은 정보는 어떻게 전달하는 것 일까요?
ACK, SYN 같은 정보는 어떻게 전달하는 것 일까요?
• 2•Way Handshaking 를 하지않는 이유에 대해 설명해 주세요.
2•Way Handshaking 를 하지않는 이유에 대해 설명해 주세요.
• 두 호스트가 동시에 연결을 시도하면, 연결이 가능한가요? 가능하다면 어떻게 통신 연결을 수행하나요?
두 호스트가 동시에 연결을 시도하면, 연결이 가능한가요? 가능하다면 어떻게 통신 연결을 수행하나요?
• SYN Flooding 에 대해 설명해 주세요.
SYN Flooding 에 대해 설명해 주세요.
• 위 질문과 모순될 수 있지만, 3•Way Handshake의 속도 문제 때문에 이동 수를 줄이는 0•RTT 기법을 많이 적용하고 있습니다. 어떤 방식으로 가능한 걸까요?
위 질문과 모순될 수 있지만, 3•Way Handshake의 속도 문제 때문에 이동 수를 줄이는 0•RTT 기법을 많이 적용하고 있습니다. 어떤 방식으로 가능한 걸까요?"
BACKEND,네트워크,4-Way Handshake에 대해 설명해 주세요.,"• 패킷이 4•way handshake 목적인지 어떻게 파악할 수 있을까요?
패킷이 4•way handshake 목적인지 어떻게 파악할 수 있을까요?
• 빨리 끊어야 할 경우엔, (즉, 4•way Handshake를 할 여유가 없다면) 어떻게 종료할 수 있을까요?
빨리 끊어야 할 경우엔, (즉, 4•way Handshake를 할 여유가 없다면) 어떻게 종료할 수 있을까요?
• 4•Way Handshake 과정에서 중간에 한쪽 네트워크가 강제로 종료된다면, 반대쪽은 이를 어떻게 인식할 수 있을까요?
4•Way Handshake 과정에서 중간에 한쪽 네트워크가 강제로 종료된다면, 반대쪽은 이를 어떻게 인식할 수 있을까요?
• 왜 종료 후에 바로 끝나지 않고, TIME_WAIT 상태로 대기하는 것 일까요?
왜 종료 후에 바로 끝나지 않고, TIME_WAIT 상태로 대기하는 것 일까요?"
BACKEND,네트워크,"IP 주소는 무엇이며, 어떤 기능을 하고 있나요?","• IPv6는 IPv4의 주소 고갈 문제를 해결하기 위해 만들어졌지만, 아직도 수많은 기기가 IPv4를 사용하고 있습니다. 고갈 문제를 어떻게 해결할 수 있을까요?
• IPv4와 IPv6의 차이에 대해 설명해 주세요.
• 수많은 사람들이 유동 IP를 사용하고 있지만, 수많은 공유기에서는 고정 주소를 제공하는 기능이 이미 존재합니다. 어떻게 가능한 걸까요?
• IPv4를 사용하는 장비와 IPv6를 사용하는 같은 네트워크 내에서 통신이 가능한가요? 가능하다면 어떤 방법을 사용하나요?
• IP가 송신자와 수신자를 정확하게 전송되는 것을 보장해 주나요?
• IPv4에서 수행하는 Checksum과 TCP에서 수행하는 Checksum은 어떤 차이가 있나요?
• TTL(Hop Limit)이란 무엇인가요?
• IP 주소와 MAC 주소의 차이에 대해 설명해 주세요."
BACKEND,네트워크,"서브넷 마스크와, 게이트웨이에 대해 설명해 주세요.","• NAT에 대해 설명해 주세요.
• 서브넷 마스크의 표현 방식에 대해 설명해 주세요.
• 그렇다면, 255.0.255.0 같은 꼴의 서브넷 마스크도 가능한가요?"
BACKEND,네트워크,HTTP에 대해 설명해 주세요.,"• 공개키와 대칭키에 대해 설명해 주세요.
• 왜 HTTPS Handshake 과정에서는 인증서를 사용하는 것 일까요?
• SSL과 TLS의 차이는 무엇인가요?"
BACKEND,네트워크,Stateless와 Connectionless에 대해 설명해 주세요.,"• 왜 HTTP는 Stateless 구조를 채택하고 있을까요?
왜 HTTP는 Stateless 구조를 채택하고 있을까요?
• Connectionless의 논리대로면 성능이 되게 좋지 않을 것으로 보이는데, 해결 방법이 있을까요?
Connectionless의 논리대로면 성능이 되게 좋지 않을 것으로 보이는데, 해결 방법이 있을까요?
• TCP의 keep•alive와 HTTP의 keep•alive의 차이는 무엇인가요?
TCP의 keep•alive와 HTTP의 keep•alive의 차이는 무엇인가요?"
BACKEND,네트워크,HTTP 응답코드에 대해 설명해 주세요.,"• 401 (Unauthorized) 와 403 (Forbidden)은 의미적으로 어떤 차이가 있나요?
• 200 (ok) 와 201 (created) 의 차이에 대해 설명해 주세요.
• 필요하다면 저희가 직접 응답코드를 정의해서 사용할 수 있을까요? 예를 들어 285번 처럼요."
BACKEND,네트워크,HTTP Method 에 대해 설명해 주세요.,"• HTTP Method의 멱등성에 대해 설명해 주세요.
• GET과 POST의 차이는 무엇인가요?
• POST와 PUT, PATCH의 차이는 무엇인가요?
• HTTP 1.1 이후로, GET에도 Body에 데이터를 실을 수 있게 되었습니다. 그럼에도 불구하고 왜 아직도 이런 방식을 지양하는 것일까요?"
BACKEND,네트워크,HTTP/1.1과 HTTP/2의 차이점은 무엇인가요?,"• HOL Blocking 에 대해 설명해 주세요.
• HTTP/3.0의 주요 특징에 대해 설명해 주세요."
BACKEND,네트워크,쿠키와 세션의 차이에 대해 설명해 주세요.,"• 세션 방식의 로그인 과정에 대해 설명해 주세요.
• HTTP의 특성인 Stateless에 대해 설명해 주세요.
• Stateless의 의미를 살펴보면, 세션은 적절하지 않은 인증 방법 아닌가요?
• 규모가 커져 서버가 여러 개가 된다면, 세션을 어떻게 관리할 수 있을까요?"
BACKEND,네트워크,XSS에 대해서 설명해 주세요.,"• CSRF랑 XSS는 어떤 차이가 있나요?
• XSS는 프론트엔드에서만 막을 수 있나요?"
BACKEND,네트워크,DNS에 대해 설명해 주세요.,"• DNS는 몇 계층 프로토콜인가요?
• UDP와 TCP 중 어떤 것을 사용하나요?
• DNS Recursive Query, Iterative Query가 무엇인가요?
• DNS 쿼리 과정에서 손실이 발생한다면, 어떻게 처리하나요?
• 캐싱된 DNS 쿼리가 잘못 될 수도 있습니다. 이 경우, 어떻게 에러를 보정할 수 있나요?
• DNS 레코드 타입 중 A, CNAME, AAAA의 차이에 대해서 설명해주세요.
• hosts 파일은 어떤 역할을 하나요? DNS와 비교하였을 때 어떤 것이 우선순위가 더 높나요?"
BACKEND,네트워크,"www.github.com을 브라우저에 입력하고 엔터를 쳤을 때, 네트워크 상 어떤 일이 일어나는지 최대한 자세하게 설명해 주세요.","• DNS 쿼리를 통해 얻어진 IP는 어디를 가리키고 있나요?
• Web Server와 Web Application Server의 차이에 대해 설명해 주세요.
• URL, URI, URN은 어떤 차이가 있나요?"
BACKEND,네트워크,SOP 정책에 대해 설명해 주세요.,"• CORS 정책이 무엇인가요?
• Preflight에 대해 설명해 주세요."
BACKEND,네트워크,웹소켓과 소켓 통신의 차이에 대해 설명해 주세요.,"• 소켓과 포트의 차이가 무엇인가요?
소켓과 포트의 차이가 무엇인가요?
• 여러 소켓이 있다고 할 때, 그 소켓의 포트 번호는 모두 다른가요?
여러 소켓이 있다고 할 때, 그 소켓의 포트 번호는 모두 다른가요?
• 사용자의 요청이 무수히 많아지면, 소켓도 무수히 생성되나요?
사용자의 요청이 무수히 많아지면, 소켓도 무수히 생성되나요?"
BACKEND,네트워크,DHCP가 무엇인지 설명해 주세요.,"• DHCP는 몇 계층 프로토콜인가요?
DHCP는 몇 계층 프로토콜인가요?
• DHCP는 어떻게 동작하나요?
DHCP는 어떻게 동작하나요?
• DHCP에서 UDP를 사용하는 이유가 무엇인가요?
DHCP에서 UDP를 사용하는 이유가 무엇인가요?
• DHCP에서, IP 주소 말고 추가로 제공해주는 정보가 있나요?
DHCP에서, IP 주소 말고 추가로 제공해주는 정보가 있나요?
• DHCP의 유효기간은 얼마나 긴가요?
DHCP의 유효기간은 얼마나 긴가요?"
BACKEND,네트워크,라우터 내의 포워딩 과정에 대해 설명해 주세요.,"• 라우팅과 포워딩의 차이는 무엇인가요?
라우팅과 포워딩의 차이는 무엇인가요?
• 라우팅 알고리즘에 대해 설명해 주세요.
라우팅 알고리즘에 대해 설명해 주세요.
• 포워딩 테이블의 구조에 대해 설명해 주세요.
포워딩 테이블의 구조에 대해 설명해 주세요."
BACKEND,네트워크,로드밸런서가 무엇인가요?,"• L4 로드밸런서와, L7 로드밸런서의 차이에 대해 설명해 주세요.
L4 로드밸런서와, L7 로드밸런서의 차이에 대해 설명해 주세요.
• 로드밸런서 알고리즘에 대해 설명해 주세요.
로드밸런서 알고리즘에 대해 설명해 주세요.
• 로드밸런싱 대상이 되는 장치중 일부 장치가 문제가 생겨 접속이 불가능하다고 가정해 봅시다. 이 경우, 로드밸런서가 해당 장비로 요청을 보내지 않도록 하려면 어떻게 해야 할까요?
로드밸런싱 대상이 되는 장치중 일부 장치가 문제가 생겨 접속이 불가능하다고 가정해 봅시다. 이 경우, 로드밸런서가 해당 장비로 요청을 보내지 않도록 하려면 어떻게 해야 할까요?
• 로드밸런서 장치를 사용하지 않고, DNS를 활용해서 유사하게 로드밸런싱을 하는 방법에 대해 설명해 주세요.
로드밸런서 장치를 사용하지 않고, DNS를 활용해서 유사하게 로드밸런싱을 하는 방법에 대해 설명해 주세요."
BACKEND,네트워크,멀티플렉싱과 디멀티플렉싱에 대해 설명해 주세요.,"• 디멀티플렉싱의 과정에 대해 설명해 주세요.
디멀티플렉싱의 과정에 대해 설명해 주세요."
공통,Java,얕은 복사와 깊은 복사에 대해서 설명해주세요.,"자바에서 객체를 복사할 때 얕은 복사 와 깊은 복사 라는 두 가지 방식이 있습니다.
먼저 Book과 Author라는 두 클래스를 사용해서 예제를 살펴볼게요. Book은 책의 이름(name)과 저자(author) 정보를 가지고 있고, Author는 저자의 이름을 가지고 있습니다.
shallowCopy() 메서드는 새로운 Book 객체를 만들지만, 내부의 Author 객체는 원본과 동일한 객체를 참조합니다. 즉, Book 객체는 새로 만들었지만, Author 객체는 새로 만들지 않고 기존의 것을 그대로 사용합니다. 예를 들어, book1에서 shallowCopyBook을 만든 후, shallowCopyBook의 저자 이름을 “Joshua Bloch”로 바꾸면 book1의 저자 이름도 “Joshua Bloch”로 바뀝니다. 둘이 같은 Author 객체를 공유하고 있기 때문에 두 Book 객체의 Author가 동시에 변경되는 거죠.
반면 deepCopy() 메서드는 Book 객체와 Author 객체 모두 새로운 객체로 만들어줘요. 그래서 book2에서 deepCopyBook을 만들고 deepCopyBook의 저자 이름을 “Martin Fowler”로 바꾸어도, book2의 저자 이름은 여전히 “마틴 파울러”로 남아 있어요. deepCopyBook과 book2가 서로 다른 Author 객체를 참조하고 있기 때문이에요.
출력 결과를 보면,
얕은 복사에서 shallowCopyBook과 book1이 같은 Author를 공유하니까, shallowCopyBook의 저자 이름을 바꾸면 book1의 저자 이름도 바뀐 거예요.
깊은 복사한 deepCopyBook과 book2는 서로 다른 Author 객체를 참조하니까, deepCopyBook의 저자 이름을 바꿔도 book2는 영향을 받지 않습니다."
공통,네트워크,로그와 메트릭을 설명해주세요.,"로그는 서버가 동작할 때 서버의 상태와 동작 정보를 시간 경과에 따라 기록된 결과입니다. 로그는 시스템의 오류와 문제들을 쉽게 찾아낼 수 있도록 도와줍니다. 반면, 메트릭은 시스템의 성능과 상태에 대한 통계적인 정보를 의미합니다. 메트릭을 잘 수집하면 시스템의 현재 상태를 손쉽게 파악할 수 있고, 사업 현황에 관한 유용한 정보를 얻을 수 있습니다. 가령, 메트릭은 DAU, Retension, CPU 사용량, 메모리 사용량 등이 있습니다.
아래부터는 예시로 생각해주세요! 각자 진행하신 프로젝트 상황에 맞는 답변을 생각해 주세요. 😀
스프링 부트 액추에이터를 사용해 메트릭을 생성하고 프로메테우스에 저장한 다음 그라파나로 시각화한 경험이 있습니다. 수집한 지표는 다음과 같습니다.
로깅은 LogBack을 이용했습니다. 그리고, Loki에 7일동안 보관하도록 설정했으며 로그 추적을 위해 MDC를 사용했습니다.
CPU, 메모리, JVM 사용량 지표를 수집한 이유는 서비스가 현재 안정적으로 동작하고 있는지 파악하기 위함입니다. 또한, 톰캣 스레드 풀과 커넥션 풀의 상태와 error 레벨 로그를 수집한 이유는 서버 프로그램 내부에 비정상적인 상황이 생기는 것을 신속히 대응하기 위함입니다.
로그를 출력하는 경우 대기 시간이 발생합니다. 그리고, 로그 또한 데이터이기 때문에 저장 공간을 요구합니다. 따라서, 정말로 필요한 경우에만 로깅을 수행하는 것이 비용 효율적입니다. 하지만, System.out.println은 로그 레벨 설정과 환경 별 필터링을 적용하기 까다롭습니다. 반면, 로깅 프레임워크는 로그 레벨 설정, 필터링 등 로그의 양 조절을 하기 위한 기능을 제공하기 때문에 이를 사용하는 것이 서비스 운영에 유리합니다.

"
공통,Java,JPA에서 ID 생성 전략에 대해 설명해주세요.,"JPA에서 ID를 생성하기 위해서는 직접 할당과 자동 할당을 사용할 수 있습니다. 직접 할당은 @Id 어노테이션만을 사용하여 Id값을 직접 할당하는 방식입니다. 반면, 자동 할당은 @Id 와 @GeneratedValue 를 함께 사용해서 원하는 키 생성 전략을 선택하는 방식입니다. @GeneratedValue 의 stretagy 옵션을 통해 생성 전략을 설정할 수 있는데, 여기에 올 수 있는 값인 GenerationType는 다음과 같습니다.
IDENTITY 전략 은 기본 키 생성을 DB에 위임하는 전략입니다. 주로 MySQL, PostgreSQL, SQL Server, DB2에서 사용됩니다. 해당 전략을 사용하면 엔티티를 생성할 때 쓰기 지연이 적용되지 않습니다. 왜냐하면 JPA에서 엔티티를 영속하기 위해선 식별자가 필요한데, IDENTITY 전략에서는 이 식별자가 DB에 저장되어야 할당되기 때문입니다. 따라서 엔티티를 생성할 때 즉시 INSERT 쿼리가 실행되어야 합니다. 이때 하이버네이트를 사용하는 경우에는 INSERT 쿼리의 결과를 다시 조회하지 않기 위해서 내부적으로 Statement.getGeneratedKeys를 사용합니다. 추가로 IDENTITY 전략을 사용하면 배치 인서트가 불가하다는 점을 주의해야합니다.
SEQUENCE 전략 은 시퀀스 키 생성 전략을 지원하는 DB에서 사용할 수 있습니다. 데이터베이스 시퀀스란, 유일한 값을 자동으로 생성하게 하는 객체입니다. auto_increment와 달리 초기 값과 한번에 증가할 크기를 설정할 수 있습니다. 해당 시퀀스를 키 생성 전략으로 갖는 DB에 대해 SEQUENCE 전략을 사용할 수 있습니다. 어떤 시퀀스를 사용할 것인지를 @SequenceGenerator 로 설정할 수 있습니다. SEQUENCE 전략은 em.persist()를 호출하는 경우 먼저 데이터베이스 시퀀스를 이용하여 식별자를 조회합니다. 이후 조회한 식별자를 엔티티에 할당한 후에 엔티티를 영속성 컨텍스트에 저장합니다. 트랜잭션을 커밋하여 플러시가 일어나면 엔티티를 저장한다는 점에서 IDENTITY 전략과 차이가 있습니다.
TABLE 전략 은 키 생성 전용 테이블을 만들어 시퀀스를 흉내내는 전략입니다. 어떤 테이블을 사용할 것인지를 @TableGenerator 로 설정할 수 있습니다. TABLE 전략은 값을 조회하면서 SELECT 쿼리를 사용하며 증가를 위해 UPDATE 쿼리를 사용합니다. SEQUENCE 전략보다 DB와 한번 더 통신한다는 점에서 성능이 안좋다는 단점이 있지만, 모든 DB에 적용할 수 있다는 장점이 있습니다.
AUTO 전략 은 데이터베이스 방언에 따라서 IDENTITY, SEQUENCE, TABLE 중 하나를 자동으로 선택합니다. 데이터베이스를 변경해도 코드를 수정할 필요가 없다는 장점이 있습니다.

"
공통,Java,equals와 hashCode는 왜 함께 재정의해야 할까요?,"equals와 hashCode 메서드는 객체의 동등성 비교와 해시값 생성을 위해서 사용할 수 있습니다. 하지만, 함께 재정의하지 않는다면 예상치 못한 결과를 만들 수 있습니다. 가령, 해시값을 사용하는 자료구조(HashSet, HashMap..)을 사용할 때 문제가 발생할 수 있습니다.
해시값을 사용하는 자료구조는 hashCode 메서드의 반환값을 사용하는데요. hashCode 메서드의 반환 값이 일치한 이후 equals 메서드의 반환값 참일 때만 논리적으로 같은 객체라고 판단합니다. 위 예제에서 Subscribe 클래스는 hashCode 메서드를 재정의하지 않았기 때문에 Object 클래스의 기본 hashCode 메서드를 사용합니다. Object 클래스의 기본 hashCode 메서드는 객체의 고유한 주소를 사용하기 때문에 객체마다 다른 값을 반환합니다. 따라서 2개의 Subscribe 객체는 다른 객체로 판단되었고 HashSet에서 중복 처리가 되지 않았습니다.

"
공통,Java,동일성과 동등성에 대해서 설명해주세요.,"동일성과 동등성은 객체를 비교할 때 중요한 개념입니다. 자바에서는 이 두 개념을 equals() 메서드와 == 연산자를 통해 구분할 수 있습니다.
equals()는 객체의 내용을 비교 하는 반면, ==는 객체의 참조(레퍼런스)를 비교 합니다. 따라서 두 객체의 내용이 같더라도 서로 다른 객체라면 equals()는 true를 반환할 수 있지만, ==는 false를 반환합니다.
동등성은 논리적으로 객체의 내용이 같은지를 비교하는 개념입니다. 자바에서는 equals() 메서드를 사용하여 객체의 동등성을 비교합니다. Apple 클래스를 예시로 보면, Object.equals 메서드를 오버라이딩하여 객체의 실제 데이터를 비교하도록 했습니다. 그래서 apple과 anotherApple은 다른 객체이지만, 무게가 같기 때문에 동등성 비교 결과 true가 반환됩니다.
Object 클래스의 equals() 메서드는 == 연산자를 사용하여 동일성을 비교합니다. 그리고 모든 클래스는 Object 클래스를 상속하여 동일성 비교를 기본으로 동작하기 때문에, 동등성 비교가 필요한 클래스에서 필요에 맞게 equals & hashCode 메서드를 오버라이딩해야 합니다.
동일성은 두 객체가 메모리 상에서 같은 객체인지 비교하는 개념입니다. 자바에서는 == 연산자를 사용하여 객체의 동일성을 비교합니다. == 연산자는 객체의 레퍼런스(참조)를 비교하므로, 두 변수가 동일한 객체를 가리키고 있는지를 확인합니다.
apple1과 apple2는 참조가 다르기 때문에 == 연산 결과 false가 반환되지만, apple1의 참조를 가지는 apple3은 == 연산 결과 true를 반환합니다.
문자열 리터럴은 문자열 상수 풀(String Constant Pool) 에 저장되기 때문에, 동일한 문자열 리터럴을 참조하면 == 연산자가 true를 반환할 수 있습니다. 하지만 new 키워드를 사용하여 문자열을 생성하면 새로운 객체가 생성되므로 == 연산자가 false를 반환할 수 있습니다. 따라서 문자열 비교 시 항상 equals() 메서드를 사용한 동등성 비교를 하는 것이 좋습니다.
래퍼 클래스도 객체이기 때문에 == 연산자는 참조를 비교합니다. 값 비교를 원할 경우 equals() 메서드를 사용해야 합니다. 다만, 자바는 특정 범위의 래퍼 객체를 캐싱하므로 같은 값의 Integer 객체가 같은 참조를 가질 수 있습니다(•128 ~ 127). 하지만 일반적으로 equals()를 사용하는 것이 안전합니다.

"
공통,Spring,"@Component, @Controller, @Service, @Repository의 차이점에 대해서 설명해주세요.","@Component, @Service, @Controller, @Repository는 각각의 클래스를 특정 역할을 수행하는 Spring Bean으로 등록할 때 사용됩니다. 각 애너테이션은 클래스가 어떤 역할을 하는지를 명시적으로 나타내며, Spring의 @ComponentScan 기능을 통해 자동으로 Bean으로 등록됩니다. @Service, @Controller, @Repository 어노테이션은 내부적으로 @Component 어노테이션을 사용하고 있으며, 각 특징과 용도는 아래와 같습니다.
@Component 는 가장 일반적인 형태의 어노테이션으로, 특정 역할에 종속되지 않는 일반적인 Spring Bean을 나타냅니다.
공통 기능을 제공하는 유틸리티 클래스나, 특정 계층에 속하지 않는 일반적인 컴포넌트를 정의할 때 사용됩니다.
@Service 는 비즈니스 로직을 수행하는 클래스에 사용되며 서비스 레이어의 Bean을 나타냅니다.
@Controller 는 Spring MVC에서 웹 요청을 처리하는 컨트롤러 클래스에 사용되며 프레젠테이션 레이어의 Bean을 나타냅니다.
@Repository 는 데이터베이스와의 상호작용을 수행하는 클래스에 사용되며. 데이터 액세스 레이어의 Bean을 나타냅니다.
Spring 6(Spring Boot 3) 이전 버전에서는 @Component + @RequestMapping으로도 Bean 및 핸들러로 등록되었습니다. 하지만 Spring 6 이후 부터 @Controller 외에는 핸들러로 등록하지 않아 웹 요청을 정상적으로 수행할 수 없습니다.
@Repository를 @Component로 대체할 경우, PersistenceExceptionTranslationPostProcessor에 의해 예외가 DataAccessException으로 변환되지 않습니다. 이 경우 데이터 액세스 계층에서 발생하는 예외 처리에 영향을 미칠 수 있습니다.
또 @Service, @Controller, @Repository는 각각 특정 계층을 나타내므로, AOP의 포인트컷을 정의할 때 유용하게 사용될 수 있습니다. @Component를 사용하면 이러한 계층 구분이 불분명해져 AOP 적용이 어려울 수 있습니다.

"
공통,네트워크,동기 방식으로 외부 서비스를 호출할 때 외부 서비스 장애가 나면 어떻게 조치할 수 있나요?,"외부 서비스 장애로 인해 응답이 오래 걸린다고 했을 때 외부 API 응답으로 대기하는 자원들이 운영 서버 내부에 쌓이면서 성능에 악영향을 줄 수 있습니다. 이를 해결하기 위한 가장 기본적인 방법은 타임아웃을 설정하는 것입니다. 크게 타임아웃에는 커넥션 타임아웃과 리드 타임아웃, HTTP 커넥션 풀 타임아웃을 설정해 볼 수 있습니다.
이 경우는 벌크헤드 패턴을 적용해 볼 수 있습니다. 벌크헤드 패턴은 기능의 종류마다 자원 사용을 분리하는 것을 의미하는데요. 자원을 격리하여 서비스 일부에 장애가 발생해도 전체로 전파되지 않도록 보장해 주는 패턴입니다. 위 예시에서는 외부 서비스마다 다른 HTTP 커넥션 풀을 사용하도록 벌크헤드 패턴을 적용할 수 있습니다. 서로 다른 커넥션 풀을 사용하기 때문에 A 서비스에 문제가 발생해도 B,C의 영향을 최소화할 수 있습니다.
지속되는 외부 서비스 장애로 타임아웃에 의한 서비스 에러가 발생할 수 있습니다. 외부 서비스가 장애가 발생했는데도 불구하고 운영 서버는 계속 요청을 보내게 되니, 불필요하게 응답 시간이 저해되고, 처리량도 감소하게 됩니다. 이 문제를 해결하기 위해서는 서킷 브레이커를 적용할 수 있는데요. 서킷 브레이커는 오류가 지속되는 경우 일정 시간 동안 기능 실행을 차단할 수 있습니다. 서킷 브레이커가 빠른 실패를 도와주기 때문에 외부 서비스 장애에 의한 응답 시간 증가를 예방할 수 있습니다.

"
공통,네트워크,TCP 3-way handshake에 대해서 설명해주세요.,"TCP 3•way handshake는 TCP/IP 네트워크에서 안정적이고 연결 지향적인 통신을 설정하기 위해 사용되는 절차입니다. 이 절차는 클라이언트와 서버 간에 신뢰할 수 있는 연결을 설정하기 위해 세 개의 메시지(세그먼트)를 교환하는 과정을 포함합니다.
우선 클라이언트는 서버에 연결을 요청하는 SYN 세그먼트를 보내는데요. 이 세그먼트에는 초기 순서 번호(Sequence Number)와 윈도우 크기(Window Size) 정보가 포함되어 있습니다.
이후 서버는 클라이언트의 요청을 수락하고, SYN과 ACK 플래그가 설정된 세그먼트를 클라이언트에 보냅니다. 이 세그먼트는 서버의 초기 순서 번호와 클라이언트의 초기 순서 번호에 대한 응답(ACK=클라이언트의 초기 순서 번호 + 1)을 포함합니다.
클라이언트는 서버의 응답을 확인하고, ACK 플래그가 설정된 세그먼트를 서버에 보냅니다.
이 세그먼트는 서버의 순서 번호에 대한 응답(ACK=서버의 초기 순서 번호 + 1)을 포함합니다.
이 절차가 완료되면 클라이언트와 서버 간에 신뢰할 수 있는 연결이 설정되고, 데이터 전송이 시작될 수 있습니다.

"
공통,Spring,Spring Data JPA에서 새로운 Entity인지 판단하는 방법은 무엇일까요?,"새로운 Entity인지 여부는 JpaEntityInformation의 isNew(T entity) 에 의해 판단됩니다. 다른 설정이 없으면 JpaEntityInformation의 구현체 중 JpaMetamodelEntityInformation 클래스가 동작합니다. @Version 이 사용된 필드가 없거나 @Version 이 사용된 필드가 primitive 타입이면 AbstractEntityInformation의 isNew() 를 호출합니다. @Version 이 사용된 필드가 wrapper class이면 null여부를 확인합니다.
@Version 이 사용된 필드가 없어서 AbstractEntityInformation 클래스가 동작하면 @Id 어노테이션을 사용한 필드를 확인해서 primitive 타입이 아니라면 null 여부, Number의 하위 타입이면 0인지 여부를 확인합니다. @GeneratedValue 어노테이션으로 키 생성 전략을 사용하면 데이터베이스에 저장될 때 id가 할당됩니다. 따라서 데이터베이스에 저장되기 전에 메모리에서 생성된 객체는 id가 비어있기 때문에 isNew() 는 true가 되어 새로운 entity로 판단합니다.
키 생성 전략을 사용하지 않고 직접 ID를 할당하는 경우 새로운 entity로 간주되지 않습니다.
이 때는 엔티티에서 Persistable<T> 인터페이스를 구현해서 JpaMetamodelEntityInformation 클래스가 아닌 JpaPersistableEntityInformation의 isNew() 가 동작하도록 해야 합니다.
SimpleJpaRepository의 save() 메서드에서 isNew() 를 사용하여 persist를 수행할지 merge를 수행할지 결정합니다. 만약 ID를 직접 지정해주는 경우에는 신규 entity라고 판단하지 않기 때문에 merge를 수행합니다. 이때 해당 entity는 신규임에도 불구하고 DB를 조회하기 때문에 비효율적입니다. 따라서, 새로운 entity인지 판단하는 것은 중요한 부분입니다.

"
공통,Java,동기와 비동기의 차이점은 무엇인가요?,"동기와 비동기는 호출하는 함수의 작업 완료를 기다리는지 여부의 차이가 있습니다. 함수 A가 동기로 함수 B를 호출하면 A는 B의 작업이 완료될 때까지 기다려야 합니다. 따라서 작업이 순차적으로 진행됩니다. 반면, 함수 A가 비동기로 함수 B를 호출하면 A는 B의 작업 완료를 신경 쓰지 않고 따로 동작합니다. 따라서 작업이 순차적으로 진행되지 않습니다.

블로킹과 동기는 어떤 차이가 있나요? 🤔
두 개념은 유사하면서도 다른데요. 동기 호출에서는 호출된 함수가 작업을 완료할 때까지 호출한 함수가 기다립니다. 즉, 작업이 순차적으로 진행되는 것을 의미합니다. 반면, 블로킹은 함수가 호출된 후, 호출한 함수의 결과를 기다리기 위해 실행을 멈추는 상태를 의미합니다. 즉, 제어권이 반환되지 않고 대기하는 상황입니다.

스프링에서 비동기 처리는 어떻게 하며 무엇을 주의해야 하나요?
스프링에서는 @Async 어노테이션을 사용하여 비동기 처리를 수행할 수 있습니다. 해당 어노테이션을 사용하기 위해서는 몇 가지 주의할 부분이 있는데요. 기본적으로 @Async 가 적용된 메서드에서 발생하는 예외는 호출자에게 전파되지 않습니다. 비동기 메서드에서 예외를 정상적으로 처리하기 위해서는 별도의 비동기 예외 처리기를 사용해야 합니다. 또한, @Async 어노테이션은 프록시 기반으로 동작하기 때문에 같은 클래스 내부에서 직접 호출하는 경우 별도의 스레드에서 메서드가 실행되지 않습니다. 그리고, 비동기 메서드 내에서 생성한 트랜잭션은 상위 트랜잭션과 무관한 생명주기를 가집니다."
공통,Java,JPA의 ddl-auto 옵션은 각각 어떤 동작을 하고 어떤 상황에서 사용해야 할까요?,"ddl•auto 옵션은 스프링 부트 애플리케이션에서 Hibernate와 같은 JPA 구현체를 사용할 때 데이터베이스 스키마 관리를 제어하는 설정입니다. 이 옵션은 application.properties 또는 application.yml 파일에서 설정할 수 있으며, 다양한 값에 따라 데이터베이스 스키마에 대해 다른 동작을 수행합니다. ddl•auto 옵션에는 none, validate, update, create, create•drop 등이 존재합니다.
none 으로 설정하면 데이터베이스 스키마와 관련된 어떠한 작업도 수행하지 않습니다. 데이터베이스 스키마를 수동으로 관리하고 싶을 때 유용하며, 프로덕션 환경에서 주로 사용됩니다.
validate 는 애플리케이션이 시작될 때, 엔티티 매핑이 데이터베이스 스키마와 일치하는지 검증하며 스키마 변경은 따로 수행하지 않습니다. 프로덕션 환경에서 엔티티와 데이터베이스 스키마가 일치하는지 확인하고 싶을 때 사용합니다.
update 는 엔티티 매핑과 데이터베이스 스키마를 비교하여 필요한 경우 스키마를 업데이트합니다. 기존 데이터는 유지되지만, 새로운 엔티티나 변경된 엔티티 필드는 스키마에 반영됩니다. 해당 옵션은 엔티티에 변경이 발생할 때 자동으로 스키마를 업데이트하고 싶을 때 유용합니다. 프로덕션 환경에서는 예기치 않은 스키마 변경을 방지하기 위해 주의가 필요합니다.
create 는 애플리케이션이 시작될 때 기존 스키마를 삭제하고 새로 생성합니다. 데이터가 모두 삭제되며 엔티티 매핑을 기반으로 새로운 스키마가 생성됩니다. 개발 초기에 빈 데이터베이스 스키마를 반복적으로 생성해야 할 때 유용합니다. 기존 데이터가 모두 삭제되므로 프로덕션 환경에서는 사용하지 않습니다.
create•drop 은 create 와 유사하지만, 애플리케이션이 종료될 때 스키마를 삭제한다는 점이 다릅니다. 해당 옵션은 테스트 환경에서 일시적인 데이터베이스 스키마가 필요한 경우 유용하며, 매 테스트 실행 시마다 깨끗한 데이터베이스 상태를 유지하고자 할 때 사용됩니다. 프로덕션 환경에서는 사용하지 않습니다.
스키마 변경이 필요할 때는 적절한 데이터베이스 마이그레이션 도구(Flyway, Liquibase 등)를 사용하여 제어된 방식으로 스키마를 관리하거나, 사용자가 없는 새벽에 스키마 변경 작업을 수동으로 진행하는 것이 더욱 안전할 수 있습니다.

"
BACKEND,데이터베이스,엔티티 매니저에 대해 설명해주세요.,"엔티티 매니저에 대해 알기 위해선 영속성 컨텍스트에 대해 알아야 합니다. 영속성 컨텍스트는 엔티티를 영구 저장하는 환경으로 1차 캐싱, 쓰기 지연, 변경 감지를 통해
영속 로직을 효율적으로 할 수 있게 해줍니다. 이러한 효율적인 영속 로직 수행을 위해서 엔티티는 영속성 컨텍스트에 관리되어야 합니다.
이런 작업을 도와주는 것이 바로 엔티티 매니저입니다. 엔티티 매니저는 엔티티의 상태를 변경하고, 영속성 컨텍스트와 상호작용함으로써 영속 로직을 수행하는 역할을 가지고 있습니다.
엔티티는 영속성 컨텍스트와 관련하여 4가지 상태(비영속, 영속, 준영속, 삭제)를 가질 수 있는데요. 엔티티 매니저는 persist, merge, remove, close 메서드를 이용하여 엔티티의 상태를 변경할 수 있습니다. 또한, 엔티티 매니저는 영속성 컨텍스트의 1차 캐시로부터 엔티티를 조회할 수 있으며, 쓰기 지연 저장소에 있는 쿼리들을 flush하여 DB와 동기화시킬 수 있습니다. 또한 JPQL이나 Native Query를 이용해 직접 DB로부터 데이터를 불러올 수도 있습니다.
비영속 상태는 엔티티 객체가 새로 생성되었지만, 아직 영속성 컨텍스트와 연관되지 않은 상태입니다. 이 상태에서는 데이터베이스와 전혀 관련이 없으며, 엔티티 객체는 메모리 상에만 존재합니다.
영속 상태는 엔티티 객체가 영속성 컨텍스트에 관리되고 있는 상태입니다. 이 상태에서는 엔티티의 변경 사항이 자동으로 데이터베이스에 반영됩니다.
준영속 상태는 엔티티 객체가 한 번 영속성 컨텍스트에 의해 관리되었지만, 현재는 영속성 컨텍스트와 분리된 상태입니다. 이 상태에서는 엔티티 객체의 변경 사항이 더 이상 데이터베이스에 반영되지 않습니다.
영속성 컨텍스트 종료, 트랜잭션 종료 등으로도 준영속 상태로 전환됩니다.
삭제 상태는 엔티티 객체가 영속성 컨텍스트에서 제거된 상태입니다. 이 상태에서는 엔티티 객체가 데이터베이스에서 삭제됩니다.

"
공통,Java,JPA의 N + 1 문제에 대해서 설명해주세요.,"JPA N + 1 문제는 연관 관계가 설정된 엔티티를 조회할 경우에, 조회된 데이터 개수(N)만큼 연관관계의 조회 쿼리가 추가로 발생하는 현상입니다. 예를 들어, 블로그 게시글과 댓글이 있는 경우, 게시글을 조회한 후 각 게시글마다 댓글을 조회하기 위한 추가 쿼리가 발생할 수 있습니다. 이를 N + 1 문제라고 합니다.
spring data jpa에서 제공하는 repository의 findAll 메서드입니다!
글로벌 패치 전략을 즉시로딩으로 설정하고 findAll()을 실행하면 N + 1 문제가 발생합니다. 이는 findAll()은 select u from User u 라는 JPQL 구문을 생성해서 실행하기 때문입니다. JPQL은 글로벌 패치 전략을 고려하지 않고 쿼리를 실행합니다. 모든 User를 조회하는 쿼리 실행 후, 즉시로딩 설정을 보고 연관관계에 있는 모든 엔티티를 조회하는 쿼리를 실행합니다.
글로벌 패치 전략을 지연 로딩으로 설정하고 findAll()을 실행하면 N + 1 문제가 발생하지 않습니다. 이는 연관관계에 있는 엔티티를 실제 객체 대신에 프록시 객체로 생성하여 주입하기 때문입니다. 하지만 프록시 객체를 사용할 경우에 실제 데이터가 필요하여 조회하는 쿼리가 발생하고 N + 1 문제가 발생할 수 있습니다.
N + 1 문제를 해결하기 위해서는 fh join , @EntityGraph 를 사용해 볼 수 있습니다. fh join 은 연관 관계에 있는 엔티티를 한번에 즉시 로딩하는 구문입니다. @EntityGraph 도 비슷한 효과를 만들어내며, 쿼리 메서드에 해당 어노테이션을 추가해 사용할 수 있습니다."
공통,Java,자바에서 Checked Exception과 Unchecked Exception에 대해서 설명해주세요.,"Checked Exception은 컴파일 시점에 확인 되며, 반드시 처리해야 하는 예외 입니다. 자바에서는 IOException , SQLException 등이 이에 속합니다. Checked Exception을 유발하는 메서드를 호출하는 경우, 메서드 시그니처에 throws 를 사용하여 호출자에게 예외를 위임하거나 메서드 내에서 try•catch를 사용하여 해당 예외를 반드시 처리해야합니다.
Unchecked Exception은 런타임 시점에 발생 하는 예외로, 컴파일러가 처리 여부를 강제하지 않습니다. 자바에서는 RuntimeException 을 상속한 예외들이 해당됩니다. 일반적으로 프로그래머의 실수나 코드 오류로 인해 발생합니다.
정답이 없는 영역이라고 생각해요. 자신의 주관을 만들면서 학습해봐도 좋을 것 같아요!
Checked Exception은 외부 환경과의 상호작용에서 발생할 가능성이 높은 예외에 적합합니다. 예를 들어, 파일 입출력, 네트워크 통신 등에서 발생할 수 있는 예외는 Checked Exception으로 처리하는 것이 좋습니다. 이러한 예외는 예측 가능하며, 호출하는 쪽에서 적절히 처리할 수 있는 여지가 있습니다.
Uncheked Exception은 코드 오류, 논리적 결함 등 프로그래머의 실수로 인해 발생할 수 있는 예외에 적합합니다. 예를 들어, null 참조 또는 잘못된 인덱스 접근 등은 호출자가 미리 예측하거나 처리할 수 없기 때문에 Unchecked Exception으로 두는 것이 좋습니다.
Error는 주로 JVM에서 발생하는 심각한 문제로, OutOfMemoryError , StackOverflowError 등 시스템 레벨에서 발생하는 오류입니다. 이는 일반적으로 프로그램에서 처리하지 않으며, 회복이 어려운 오류 에 속하며, 애플리케이션 코드에서 복구할 수 없는 심각한 문제를 나타냅니다.
반면, Exception은 프로그램 실행 중 발생할 수 있는 오류 상황을 나타냅니다. 대부분의 경우 회복 가능성 이 있으며, 프로그램 내에서 예외 처리를 통해 오류 상황을 제어할 수 있습니다. Exception은 다시 Checked Exception 과 Unchecked Exception 으로 나눌 수 있습니다."
공통,Java,일급 컬렉션이 무엇인가요?,"일급 컬렉션(First•Class Collection)은 하나의 컬렉션을 감싸는 클래스를 만들고, 해당 클래스에서 컬렉션과 관련된 비즈니스 로직을 관리하는 패턴을 말합니다. 아래 코드 중에서 Order의 List 자료구조를 감싼 Orders가 일급 컬렉션의 예시입니다.
일급 컬렉션 클래스에 로직을 포함하거나 비즈니스에 특화된 명확한 이름을 부여할 수 있습니다. 또한, 불필요한 컬렉션 API를 외부로 노출하지 않도록 할 수 있으며, 컬렉션을 변경할 수 없도록 만든다면 예기치 않은 변경으로부터 데이터를 보호할 수 있습니다."
BACKEND,데이터베이스,데이터베이스 인덱스에 대해서 설명해주세요.,"인덱스는 데이터베이스 테이블의 검색 속도를 향상시키기 위한 자료구조로 백과사전의 색인과 같습니다.
저장되는 컬럼의 값을 사용하여 항상 정렬된 상태를 유지하는 것이 특징입니다.
이러한 특징으로 인해 인덱스는 INSERT, UPDATE, DELETE의 성능이 희생된다는 것이 단점입니다.
MySQL InnoDB를 기준으로 설명드리자면, B+Tree와 같은 변형 B•Tree 자료구조를 이용해서 인덱스를 구현합니다.
기본 토대는 B•Tree 인덱스이기 때문에 이를 기준으로 설명합니다.
B•Tree 인덱스는 컬럼의 값을 변형하지 않고 인덱스 구조체 내에서 항상 정렬된 상태로 유지합니다.
B•Tree(Balanced•Tree)에서는 크게 3가지 노드가 존재합니다.
최상위에 하나의 루트 노드가 존재하며, 가장 하위 노드인 리프 노드가 존재합니다.
이 두 노드의 중간에 존재하는 브랜치 노드가 존재합니다.
최하위 노드인 리프 노드에는 실제 데이터 레코드를 찾아가기 위한 주소값을 가지고 있습니다.
InnoDB 스토리지 엔진에서는 세컨더리 인덱스(프라이머리 인덱스를 제외한 모든 인덱스)의 리프 노드에는 레코드의 PK가 저장됩니다. 따라서 세컨더리 인덱스 검색에서는 레코드를 읽기 위해 PK를 가지고 있는 B•Tree를 다시 한번 검색해야합니다.
MySQL에는 크게 인덱스 레인지 스캔, 인덱스 풀 스캔, 루스 인덱스 스캔 방식이 있습니다.
인덱스 레인지 스캔 은 검색할 인덱스 범위가 결정되었을 경우 사용하며 가장 빠릅니다.
레코드를 읽어오는 과정에서 랜덤 IO가 발생할 수 있습니다.
읽어야할 데이터 레코드가 전체 20•25%의 경우에는 풀 테이블 스캔(순차 IO를 이용)이 더욱 좋을 수 있습니다.
인덱스 풀 스캔 은 인덱스를 사용하지만 인덱스를 처음부터 끝까지 모두 읽는 방식입니다.
루스 인덱스 스캔 은 듬성듬성하게 인덱스를 읽는 것을 의미합니다. (앞서 언급한 인덱스 레인지, 인덱스 풀 스캔은 타이트 인덱스 스캔 으로 분류됩니다.)"
BACKEND,데이터베이스,트랜잭션 격리수준은 무엇인가요?,"트랜잭션의 격리 수준은 동시에 여러 트랜잭션이 실행될 때 한 트랜잭션이 다른 트랜잭션의 연산에 영향을 받지 않도록 하는 정도를 말합니다. 낮은 격리 수준은 동시 처리 능력을 높이지만, 데이터의 일관성 문제를 발생시킬 수 있습니다. 반면, 높은 격리 수준은 데이터의 일관성을 보장하지만, 동시 처리 능력이 떨어질 수 있습니다. 즉, 데이터 정합성과 성능은 반비례합니다. 트랜잭션 격리 수준은 개발자가 트랜잭션 격리 수준을 설정할 수 있는 기능을 제공하는 기능입니다.
트랜잭션 격리 수준은 READ UNCOMMITTED, READ COMMITTED, REPEATABLE READ가 존재합니다.
READ UNCOMMITTED는 커밋이 되지 않은 트랜잭션의 데이터 변경 내용을 다른 트랜잭션이 조회하는 것을 허용합니다. 또한 해당 격리 수준에서는 Dirty Read, Phantom Read, Non•Repeatable Read 문제가 발생할 수 있습니다.
READ COMMITTED는 커밋이 완료된 트랜잭션의 변경사항만 다른 트랜잭션에서 조회할 수 있도록 허용합니다. 특정 트랜잭션이 이루어지는 동안, 다른 트랜잭션은 해당 데이터에 접근할 수 없습니다. Dirty Read는 발생하지 않지만, Phantom Read, Non•Repeatable Read 문제가 발생할 수 있습니다.
REPEATABLE READ는 한 트랜잭션에서 특정 레코드를 조회할 때 항상 같은 데이터를 응답하는 것을 보장합니다. 하지만, SERIALIZABLE과 다르게 행이 추가되는 것을 막지는 않습니다. Non•Repeatable Read 문제가 발생하지 않지만, Phantom Read 문제가 발생할 수 있습니다.
SERIALIZABLE은 특정 트랜잭션이 사용중인 테이블의 모든 행을 다른 트랜잭션이 접근할 수 없도록 잠급니다. 가장 높은 데이터 정합성을 가지지만 성능이 가장 낮습니다. MySQL의 경우 단순한 SELECT 쿼리가 실행되더라도 데이터베이스 잠금이 걸려 다른 트랜잭션에서 데이터에 접근할 수 없습니다.
Dirty Read는 한 트랜잭션이 다른 트랜잭션이 변경 중인 데이터를 읽는 경우 발생합니다. 다른 트랜잭션이 아직 커밋되지 않은 (즉, 롤백할 가능성이 있는) 데이터를 읽어서, 그 데이터가 나중에 롤백될 경우 트랜잭션의 결과가 변경될 수 있습니다. 이는 데이터의 일관성을 깨뜨릴 수 있습니다.
Phantom Read는 한 트랜잭션이 동일한 쿼리를 두 번 실행했을 때, 두 번의 쿼리 사이에 다른 트랜잭션이 삽입, 갱신, 삭제 등의 작업을 수행하여 결과 집합이 달라지는 경우를 말합니다. 이로 인해 한 트랜잭션 내에서 일관성 없는 결과를 가져올 수 있습니다.
Non•Repeatable Read는 같은 트랜잭션 안에서 동일한 쿼리를 실행했을 때, 다른 결과를 얻는 경우를 의미합니다. 예를 들어, 한 트랜잭션이 같은 데이터를 두 번 읽을 때, 첫 번째 읽기와 두 번째 읽기 사이에 다른 트랜잭션이 해당 데이터를 변경했을 경우 발생할 수 있습니다.
"
BACKEND,운영체제,운영체제란?,"• 사용자에게 편리한 인터페이스 환경을 제공하고 컴퓨터 시스템의 자원을 효율적으로 관리하는 일종의 소프트웨어입니다.
• 예를 들어, 관리자 역할을 하는 운영체제의 커널이 프로그램을 메모리에 올려 프로세스로 만들면 일꾼인 CPU가 이를 처리합니다."
BACKEND,운영체제,운영체제가 왜 필요할까요?,"• 컴퓨터 자원을 보호하기 위해 필요합니다.
  • 운영체제를 통해 자원을 관리하고 접근합니다. 즉, 사용자가 자원에 직접적으로 접근하는 것을 막음으로써 보호합니다.
• 기능 추가 및 성능 향상을 위해 필요합니다.
  • 운영체제가 있으면 다양한 응용 프로그램을 사용할 수 있습니다. 예를 들어, 운영체제로 성능 향상을 위해 새로운 기능을 쉽게 추가할 수 있습니다.
• 편리한 인터페이스 환경을 제공받기 위해 필요합니다.
• 사용 규칙의 역할을 수행하기 위해 필요합니다.
• 컴퓨터가 발전하면서 여러 작업을 동시에 할 수 있는 컴퓨팅 환경이 조성되어 사용 규칙이 필요해졌습니다."
BACKEND,운영체제,운영체제의 역할이 무엇인가요?,"• 자원 관리 : 효율성
  • 여러 응용 프로그램이 자원을 요청하면 적절한 순서로 배분하고 회수하여 자원을 효율적으로 관리합니다.
  • 예시 : 리소스 관리, I/O 시스템 관리, CPU 관리(스레드에 CPU를 시분할로 할당), 메모리 관리(모든 프로세스에 공평하게 메모리를 할당)
• 자원 보호 : 안정성
  • 사용자 및 응용 프로그램이 CPU, 메모리 등에 대해 직접 접근하는 것을 막습니다.
• HW 인터페이스 제공 : 확장성
  • 마우스, 키보드 등을 복잡한 과정없이 사용할 수 있도록 합니다.
• SW 인터페이스 제공 : 편리성
  • OS를 편리하게 사용하기 위해 제공됩니다.
  • Ex) Window GUI 등"
BACKEND,운영체제,운영체제 종류는 무엇이 있을까요?,"• 운영체제는 앞단에 어떤 인터페이스를 두냐에 따라 GUI, CUI로 나뉠 수 있습니다.

• GUI (Graphical User Interface)
  • 그래픽을 사용하여 컴퓨터와 상호 작용하는 인터페이스입니다.
  • 즉, 사용자가 전자 장치와 상호 작용할 수 있도록 하는 사용자 인터페이스의 한 형태입니다.
  • 단순 명령어 창이 아닌 아이콘을 마우스로 클릭하는 등의 단순한 동작으로 컴퓨터와 상호 작용할 수 있도록 해줍니다.
  • Ex) windowOS, macOS 등의 현대의 OS
• CUI (Character Use Interface)
  • 사용자가 키보드만을 사용하여 문자를 기반으로 컴퓨터와 상호 작용하는 인터페이스입니다.
  • 즉, 그래픽이 아닌 명령어로 처리하는 인터페이스입니다.
  • Ex) MS•DOS (1994년 단종), chatGPT도 CUI라 할 수 있습니다."
BACKEND,운영체제,커널이란 무엇인가요?,"• 운영체제의 핵심 부분이자 시스템 콜 인터페이스를 제공합니다.
• 예를 들어, 보안, 메모리, 프로세스, 파일 시스템, I/O 디바이스, I/O 요청 관리 등 운영체제의 중추적인 역할을 합니다."
BACKEND,운영체제,커널의 역할은 무엇이 있을까요?,"• OS의 역할은 OS의 커널이 담당합니다. 즉, OS 역할이 커널 역할이라 할 수 있습니다.
  • CPU 스케줄링 및 프로세스 관리 : CPU를 어떤 프로세스 할당할 지, 혹은 프로세스 생성/삭제/자원 할당/반환을 관리합니다.
  • 메모리 관리 : 한정된 메모리를 어떤 프로세스에 얼만큼 할당할 지 관리합니다.
  • 디스크 파일 관리 : 디스크 파일을 어떤 방법으로 보관할 지 관리합니다.
  • I/O 디바이스 관리 : 마우스, 키보드 등과 같은 I/O 디바이스들과 컴퓨터 간에 데이터를 주고 받는 것을 관리합니다."
BACKEND,운영체제,운영체제와 커널의 차이점은 무엇인가요?,"• 운영체제는 시스템 전체를 관리하고 사용자와 응용 프로그램에 다양한 서비스를 제공합니다.
• 커널은 운영체제의 핵심 부분으로 하드웨어와 직접적으로 상호 작용하여 시스템 기능을 제공하고 관리합니다.
• 즉, 운영체제 전체가 컴퓨터 부팅 시 반드시 실행되어야 하는 것은 아니지만, 커널은 반드시 실행되어야합니다."
BACKEND,운영체제,커널 함수란?,"• 커널 내부에 있는 여러 함수들을 뜻하는 것으로 네이티브 함수를 말합니다.
• 이 커널 함수들은 System Call(호출)을 통해 사용자 프로그램이 커널 함수를 호출할 수 있습니다. 
• 예를 들어, 프로세스를 종료하는 kill() 함수를 호출 시, 시스템 콜을 거쳐 커널 함수가 호출되고 프로세스가 종료됩니다.
• 이처럼, 커널 함수는 운영 체제의 안정성과 기능에 큰 영향을 미칩니다."
BACKEND,운영체제,커널 유형은 무엇이 있을까요?,"• 단일형 구조 커널(모놀리식)
  • 초창기 OS 구조로 기능들이 단일의 모듈로 구성되어 있습니다.
  • 즉, 모든 시스템 서비스를 하나의 큰 프로세스 내에서 실행합니다.
  • Ex) MS•DOS, VMS, 초기 UNIX
  • 장점
    • 모듈 간의 통신 비용이 줄어 효율적인 운영이 가능합니다.
  • 단점
    • 버그나 오류를 처리하기 어렵습니다.
    • 기능 간 상호 의존성이 높아 작은 결함이 시스템 전체로 확산될 수 있습니다.
    • 수정이 어려워 이식성이 낮습니다.
    • 현대의 OS는 크고 복잡해 단일형으로 구현하기 어렵습니다.
• 계층형 구조 커널
  • 단일형 구조 커널의 발전된 형태로 비슷한 기능의 모듈을 하나의 계층으로 묶어 계층 간의 통신을 통해 OS를 구현한 커널입니다.
  • 장점
    • 버그나 오류가 생길 경우 해당 계층만 수정하면 되기 때문에, 디버깅이 쉽습니다.
    • Window를 비롯한 현대 OS는 이 구조로 구현되어 있습니다.
• 마이크로 구조 커널
  • 계층형 구조의 접근 방식과 반대로 개발된 커널로 가장 기본적인 기능만 제공합니다.
  • 즉, 최소한의 기능만을 제공하며 대부분 서비스가 사용자 영역에 구현되어 있으며, 
    각 모듈 간의 정보 교환은 프로세스 간 통신을 통해 이루어집니다.
  • 장점
    • 각 모듈이 독립적으로 작동하기 때문에, 하나의 모듈에 문제가 있어도 전체 OS가 멈추지 않습니다.
    • 커널이 가벼워 CPU 용량이 작은 시스템에도 적용이 가능합니다."
BACKEND,운영체제,시스템 호출(System Call)이 무엇인지 설명해 주세요.,"• 시스템 콜은 OS가 커널에 접근하기 위한 인터페이스로 소프트웨어 인터럽트인 Trap의 한 종류입니다.
• 예를 들어, 사용자 프로그램이 OS의 서비스를 받기 위해 커널 함수를 호출할 때, 시스템 콜을 거쳐 호출하도록 설계되어 있습니다. 시스템 콜은 커널 영역의 기능을 사용자 모드가 사용 가능하게 해줍니다. 프로세스가 하드웨어에 접근해서 필요한 기능을 할 수 있게 해줍니다. Ex) 프로세스 관리(생성/삭제 등), 파일 관리, 디바이스 관리, 시간/날짜 관련 시스템, 프로세스 간 통신 등을 위해 시스템 콜을 거쳐 커널 함수 호출합니다.
• 시스템 콜은 커널 영역의 기능을 사용자 모드가 사용 가능하게 해줍니다.
• 프로세스가 하드웨어에 접근해서 필요한 기능을 할 수 있게 해줍니다.
• Ex) 프로세스 관리(생성/삭제 등), 파일 관리, 디바이스 관리, 시간/날짜 관련 시스템, 프로세스 간 통신 등을 위해 시스템 콜을 거쳐 커널 함수 호출합니다.
• 즉, OS는 다양한 서비스들을 수행하기 위해 하드웨어를 직접 관리하고 응용 프로그램은 OS가 제공하는 인터페이스인 시스템 콜을 통해서만 자원을 사용할 수 있습니다."
BACKEND,운영체제,우리가 사용하는 시스템 콜의 예시를 들어주세요.,"• 'open', 'close' : 파일을 열거나 닫는 시스템 콜입니다.
• 'fork', 'exit' : 프로세스를 생성하거나 종료하는 시스템 콜입니다.
• 'malloc', 'free' : 메모리를 할당하거나 해제하는 시스템 콜입니다."
BACKEND,운영체제,시스템 콜의 장점은 ?,"• 유저 프로그램이 복잡한 파일 시스템, 프로세스 관리 등의 내부 동작을 몰라도 됩니다.
  • 시스템 콜은 하나의 추상화 계층이기 때문에, 네트워크 통신이나, DB와 같은 낮은 단계의 영역 처리에 대한 부분을 많이 신경쓰지 않고 프로그램을 구현할 수 있습니다.
  • 즉, 유저 프로그램은 시스템 콜을 기반으로 커널과 분리 됩니다.
• 운영체제의 관리 하에 프로그램이 운영되므로 시스템의 안정성과 보안이 강화됩니다.
  • 예를 들어, 공격자가 만든 카메라 앱 프로그램이 아무런 제약 없이 접근 가능할 때, 카메라에 관련한 메모리 등이 오염되어 의도와는 상관없이 사생활이 노출될 수 있습니다.
  • 반대로, 시스템 콜은 유저 모드에서 시스템 콜로만 커널 모드에 진입할 수 있는 단 하나의 통로 역할을 하기 때문에, 컴퓨터 자원에 대한 직접적인 접근을 차단하여 보호할 수 있습니다."
BACKEND,운영체제,"시스템 콜이, 운영체제에서 어떤 과정으로 실행되는지 설명해 주세요.","1. 사용자 프로세스가 시스템 콜을 호출하면, trap이 걸리면서 mode bit 값이 1에서 0으로 바뀝니다. 즉, 유저모드에서 커널모드가 됩니다.
2. 이때, 커널은 내부적으로 시스템 콜을 구분하기 위해 기능별로 고유 번호를 할당하고 해당 번호에 제어 루틴의 정의하고 있기 때문에,
   커널은 요청받은 시스템 콜에 대응하는 고유 번호를 확인하고 그에 맞는 서비스 루틴을 호출합니다.
3. 작업 완료 후 다시 사용자 모드로 전환됩니다. 즉, mode bit도 0에서 1로 바뀝니다."
BACKEND,운영체제,운영체제의 Dual Mode에 대해 설명해 주세요.,"• 운영체제를 보호하기 위한 기법입니다. 예를 들어, 사용자에게 시스템 자원에 대한 제한을 걸지 않을 경우 사용자가 중요한 HW 자원을 망가뜨리 위험이 생기는데, 이를 보호하기 위한 기법입니다.
• 이는 `mode bit`를 참고해서 유저 모드와 커널 모드로 구분합니다. 이때, mode bit가 1이면 유저 모드이고 0이면 커널 모드입니다.
  • 유저 모드(mode bit 1) : 유저가 접근할 수 있는 영역을 제한적으로 둬서 컴퓨터 자원에 함수로 침범하지 못하는 모드입니다.
  • 커널 모드(mode bit 0) : 모든 컴퓨터 자원에 접근할 수 있는 모드입니다."
BACKEND,운영체제,"시스템 콜 혹은 인터럽트가 발생했을 때, Dual Mode 흐름을 말해보세요.","1. 유저 모드에서 프로세스가 실행됩니다.
2. 실행 중 프로세스가 시스템 콜을 호출합니다.
3. 커널 모드로 전환됩니다.
4. 작업을 수행합니다.
5. 작업 완료 후 다시 유저 모드로 전환됩니다."
BACKEND,운영체제,왜 유저모드와 커널모드를 구분해는 이유가 무엇일까요?,"시스템을 보호하기 위해 구분합니다. 즉, 의도치 않거나 악의적으로 호출을 막아 시스템 내부 데이터를 보호하기 위해 구분합니다."
BACKEND,운영체제,서로 다른 시스템 콜을 어떻게 구분할 수 있을까요?,"• 커널은 내부적으로 각각의 시스템 콜을 구분하기 위해 고유한 이름, 매개변수, 시스템 콜 번호, 시스템 콜 번호에 해당하는 서비스 루틴 등을 가집니다.
  • 시스템 콜 이름(고유) : open, read, write와 같이 고유한 이름
  • 매개변수 : 매개변수의 종류와 값에 따라 시스템 콜이 어떤 동작을 수행하는 지 구분 가능합니다. (Ex) open: 파일 경로와 옵션을 매개변수로 전달, fork: 새로운 프로세스를 생성하는데 필요한 정보를 매개변수로 전달"
BACKEND,운영체제,우리가 사용하는 Java에서 시스템 콜을 어떻게 사용하는지 자유롭게 설명해주세요.,• Java는 시스템 콜을 사용하기 위해 JNI를 통하여 네이티브 메서드를 활용하는 것으로 알고 있습니다.
BACKEND,운영체제,인터럽트가 무엇인지 설명해 주세요.,"• 즉각적인 주의가 필요한 이벤트를 나타내는 외부 장치 혹은 SW 내부에서 CPU로 전송하는 신호를 말합니다. 신호를 받은 CPU에서 실행 중인 프로세스를 중단하고 임시로 미리 결정된 위치로 제어권을 전달합니다. 즉, 이벤트가 발생했을 때 CPU가 이에 응답할 수 있도록 합니다. 이는 폴링으로 주변 장치를 주기적으로 확인할 필요가 없어져서 프로세서의 효율성도 향상시킵니다.
• 쉽게 말해, 인터럽트는 프로그램 실행 도중에 예기치 않은 상황이나 급한 작업이 발생할 경우, 현재 실행 중인 작업을 일시 중단 후, 발생된 상황을 우선처리한 후 실행 중이던 작업으로 복귀해 계속 처리하는 것을 말합니다. 즉, 현재 실행 중인 작업을 즉시 중단하고 발생한 상황에 대한 우선처리가 필요함을 CPU에 알리는 것입니다."
BACKEND,운영체제,인터럽트가 왜 필요할까요?,"• 대부분의 컴퓨터는 한 개의 CPU를 사용하므로 한 순간에는 하나의 일 밖에 처리할 수 없습니다.
• 때문에, 어떤 일을 처리하는 도중 우선 순위가 급한 일을 처리할 필요가 있을 때, 대처하기 위해 필요합니다."
BACKEND,운영체제,트랩(Trap)이란?,"• 트랩은 SW 인터럽트(=내부 인터럽트, 동기적 인터럽트)를 말합니다.    
• 이때 SW 인터럽트는 비자발적과 자발적인 System Call로 나뉩니다.
  • Exception(비자발적) : 오버플로, 언더플로, I/O 장치에 의한 인터럽트, 0으로 나눗셈한 경우 등
  • System Call(자발적) : 프로그램이 커널 함수를 호출하는 경우"
BACKEND,운영체제,인터럽트 핸들러 함수(ISR; Interrupt Service Routine)란?,"• 인터럽트 발생 시, 이를 핸들링하기 위함 함수를 말합니다.
• 이는 리눅스에서 `request_irq()`를 통해 인터럽트 핸들러 함수로 등록할 수 있습니다."
BACKEND,운영체제,인터럽트는 어떻게 처리하나요?,"1. 프로세스 실행 : CPU가 메모리에 있는 명령어를 순차적으로 실행하다가, 
2. 인터럽트 요청 : 중간에 HW 혹은 SW 이벤트에 의해 인터럽트 요청 시, 
3. 프로세스 중단 : CPU가 현재 실행 중인 프로세스를 중단하고 
4. 상태 보존 : PCB에 해당 작업 상태를 저장합니다.
5. 서비스 루틴 : Interrupt Vector에서 ISR(Intterrupt Handler)를 찾습니다.
6. 프로세스 인터럽트 : 찾은 ISR을 수행해 특정 명령어를 실행합니다.
7. 상태 복원 : 실행 완료 후 상태 복구 명령어가 실행되어 저장해둔 PCB 등을 복원하고 
8. 실행 재개 : CPU는 다시 메모리에 있는 명령어를 순차적으로 실행합니다. 이때, 이전에 실행 중이던 프로그램이 실행될 수도 있지만, Ready Queue의 가장 앞에 있던 프로그램이 다시 올라갈 수도 있습니다.
  
• PCB(Process Control Block) : 수행 중이던 PC, 메모리 주소, 레지스터, HW 상태 등이 저장됩니다.
• PC(Program Counter) : 다음에 실행할 명령어의 주소
• Interrupt Vector : 인터럽트 유발한 장치를 위한 ISR의 주소 배열. 즉, 인터럽트 핸들러 함수가 모여 있는 곳.
• ISR(Interrupt Handler Function) : 해당 인터럽트를 처리하기 위한 코드 집합. 즉, 인터럽트를 핸들링하기 위한 함수
  • 만약, ISR을 수행할 때, 우선순위가 더 높은 인터럽트 발생 시, 재귀적으로 과정을 수행합니다.
  • ISR 내에서는 다른 인터럽트가 발생하지 않도록 인터럽트 플래그를 사용해 중첩된 인터럽트를 방지합니다.
• Context : 프로세스와 관련된 정보의 집합
  • CPU Register Context : CPU(프로세서) 내부에 위치
  • Code & Data, Stack, PCB : 메모리에 위치."
BACKEND,운영체제,Polling 방식에 대해 설명해 주세요.,"• 폴링은 특정 주기를 갖고 해당 주기마다 처리를 위한 시그널이 들어왔는지 체크합니다. 따라서 커널과 같은 인터럽트 핸들러가 필요하지 않습니다.
• 단, 시스템 리소스를 많이 소비하기 때문에 구현 시, 시스템의 성능 저하 원인이 되기도 합니다. 따라서 오늘날의 다양한 프로세스를 처리하기에는 적합하지 않습니다.

• 인터럽트
  • CPU가 아닌 주변의 I/O 장치가 대신 I/O 해주는 방식입니다. 때문에 데이터의 I/O 이루어지는 동안 CPU는 다른 작업을 할 수 있습니다.
  • CPU의 작업과 저장장치의 데이터 이동을 독립적으로 운영할 수 있어서 시스템 효율을 높입니다.
  • 현대 운영체제는 인터럽트 기반의 시스템을 사용합니다."
BACKEND,운영체제,HW/SW 인터럽트 혹은 외부/내부 혹은 비동기적/동기적 인터럽트에 대해 설명해 주세요.,"• 인터럽트에는 HW 인터럽트와 SW 인터럽트가 있고 SW 인터럽트는 비자발적인 예외와 자발적인 System Call로 나뉩니다.

• HW 인터럽트 (=외부 인터럽트, 비동기적 인터럽트)
  • 일반적으로 인터럽트를 부르는 것으로 CPU 외부로부터 인터럽트 요구신호에 의해 발생되는 인터럽트를 말합니다. 때문에 외부 인터럽트라고도 합니다.
  • 다른 하드웨어 장치가 실행 중인 명령어와는 무관하게 생성하는 인터럽트이기 때문에 비동기적 인터럽트라고도 합니다.
  • Ex) 정전/전원의 이상, CPU의 기능 오류 및 기계의 착오, I/O 인터럽트(입출력 오류, I/O 디바이스의 데이터 전송 등), 외부 신호 인터럽트(I/O 장치가 아닌 오퍼레이터나 타이머에 의한 인터럽트)          
• SW 인터럽트 (=내부 인터럽트, 동기적 인터럽트, Trap)
  • 프로그램 내부에서 발생하는 것을 말합니다. 때문에 내부 인터럽트라고도 합니다.
  • 프로세스 오류/종료/시작 등을 기반으로 프로세스에서 발생하는 인터럽트를 말합니다. 즉, 프로세스가 실행 중인 명령어로 인해 발생하기 때문에 동기적 인터럽트라고도 부릅니다.
  • Ex) 잘못된 명령 및 잘못된 데이터 사용, Division By Zero, 오버플로우/언더플로우, 기타 프로그램 Exception 등"
BACKEND,운영체제,"동시에 두 개 이상의 인터럽트가 발생하면, 어떻게 처리해야 하나요?","• 운영체제에서 사용되는 인터럽트 처리 메커니즘에 따라 정확한 동작이 달라질 수 있지만 주로 아래와 같은 동작으로 처리합니다.
  • 인터럽트 우선순위 할당 : 가장 높은 우선순위를 가진 인터럽트를 처리합니다.
  • 인터럽트 마스킹 : 인터럽트 처리 중 다른 인터럽트를 일시적으로 비활성화하여 우선순위를 선점하지 못하도록 방지할 수 있습니다.
  • 인터럽트 큐, 버터 : 받은 순서대로 대기 중인 인터럽트를 처리하고 처리 순서를 관리합니다."
BACKEND,운영체제,HW 인터럽트와 SW 인터럽트 중 어떤 것이 우선순위가 높나요?,"• 보통 HW 인터럽트가 높은 것으로 알고 있습니다.

1. 전원 이상
2. 기계 착오
3. 외부 신호
4. I/O
5. 명령어 에러
6. 프로그램 검사
7. SuperVisor Call"
BACKEND,운영체제,프로세스와 스레드가 무엇인가요?,"• 프로세스 컴퓨터의 메모리에 올라가 실행 중인 프로그램을 의미합니다. 즉, 프로그램이 메모리에 올라가면 프로세스가 되는 인스턴스화가 일어나고 이후 OS의 CPU 스케줄링에 따라 CPU가 프로세스를 실행합니다.
• 컴퓨터의 메모리에 올라가 실행 중인 프로그램을 의미합니다.
• 즉, 프로그램이 메모리에 올라가면 프로세스가 되는 인스턴스화가 일어나고 이후 OS의 CPU 스케줄링에 따라 CPU가 프로세스를 실행합니다.
• 스레드 스레드는 프로세스 내 작업의 실행 흐름 단위입니다. 즉, 프로세스의 실행 가능한 가장 작은 단위입니다. 즉, 프로세스는 여러 스레드를 가질 수 있습니다.
• 스레드는 프로세스 내 작업의 실행 흐름 단위입니다. 즉, 프로세스의 실행 가능한 가장 작은 단위입니다.
• 즉, 프로세스는 여러 스레드를 가질 수 있습니다."
BACKEND,운영체제,"프로그램과 프로세스, 스레드의 차이에 대해 설명해 주세요.","• 프로그램
  • 사용자가 원하는 일을 처리할 수 있도록 프로그래밍 언어를 사용해 올바른 수행절차를 표현해놓은 명령어들의 집합입니다.
  • 컴퓨터에서 어떤 작업을 위해 실행할 수 있는 정적인 상태의 파일로 메모리에 적재되기 전 상태의 파일입니다.
• 프로세스
  • 각 프로세스는 OS로부터 필요한 자원을 할당 받습니다. 즉, 운영체제가 메모리 등의 필요한 자원을 할당해준 실행 중인 프로그램을 말합니다.
  • 각 프로세스는 독립적으로 Code/Text, Data, Stack, Heap 영역을 관리합니다.
  • 독립적으로 관리하기 때문에, 동기화 문제 등은 발생하지 않지만, 다른 프로세스의 자원에 접근하기 위해 프로세스간 통신(IPC)을 사용해야 합니다.
• 스레드
  • 각 스레드는 프로세스가 할당받는 자원을 이용합니다. 즉 프로세스 내에서 작업을 수행하는 실행 단위로 하나의 프로세스에 여러 스레드가 있습니다.
  • 각 스레드는 Code/Text, Data(전역 변수 등), Heap 영역을 공유하고 Stack(지역 변수 등) 영역, 스레드 실행 환경 정보를 독립적으로 관리합니다.
  • 각 스레드는 메모리를 공유하지만, 이로 인해 동기화, 데드락 등의 문제가 발생할 수 있습니다."
BACKEND,운영체제,PCB(Process Control Block)가 무엇인가요?,"• CPU가 프로세스를 실행할 때 필요한 중요 정보들을 보관하는 자료구조입니다. 즉, 프로세스에 대한 메타데이터를 저장하는 블록입니다.
• 모든 프로세스는 고유한 PCB를 갖는데, 프로세스 생성 시 PCB도 함께 생성되고 프로세스 완료 시, PCB도 함께 삭제됩니다.

• PCB에 저장되는 정보 (구조)
  • 프로세스 상태 : new, Ready, Running, Wait, Terminated 등
  • 프로세스 구분자 (PID) : 각 프로세스의 고유 식별 변호
  • 프로그램 카운터 (PC) : 다음에 실행될 명령어의 위치 값. 예를 들어, Context Switching을 할 때, 어디부터 다시 실행해야하는 지 알려줍니다.
  • CPU 레지스터 및 일반 레지스터 정보 : 프로세스를 실행하기 위해 저장해야 할 레지스터 정보
  • CPU 스케줄링 정보 : 우선 순위, 최종 실행 시간, CPU 점유 시간 등의 정보
  • 메모리 관리 정보 : 프로세스 주소 공간 정보
  • I/O 상태 정보 : 프로세스에 할당된 I/O 장치 목록, 열린 파일 목록 등
  • 프로세스 계정 정보 : Page Table, Scheduling Queue Pointer, 소유자, 부모 등
  • Stack Pointer : 부모/자식 프로세스에 대한 포인터, 프로세스가 위치한 메모리 주소에 대한 포인터, 할당된 자원에 대한 포인터 정보.
                    이는 함수 호출 시 스택의 가장 위쪽 데이터의 위치를 가리킵니다."
BACKEND,운영체제,"그렇다면, 스레드는 PCB를 갖고 있을까요?","• 스레드는 프로세스 내부에 있으므로 PCB를 가지지 않고 TCB(Thread Control Block)를 가집니다.
• TCB는 스레드와 관련된 정보만 가지기 때문에, PCB보다 적은 데이터를 가집니다.
• TCB는 스레드가 생성될 때마다 생성되고 스레드 종료 시, 해제됩니다.
• TCB는 보통 Linked List로 구현되어 있는 것으로 알고 있습니다.

• TCB에 저장되는 정보 (구조)
  • 스레드 ID (TID) : 각 스레드의 고유 식별 번호
  • 스레드 상태 : 순서열 레지스터, 스택 포인터, 프로그램 카운터 (PC)
    • 순서열 레지스터 : 명령의 진행 상태
    • 스택 포인터 : 스레드 함수 호출 시 저장되는 곳이 스택이라 실행 흐름을 저장하는 데 필요
    • 프로그램 카운터 (PC) : 스레드 내에서 실행될 다음 명령어의 주소
  • 스케줄링 정보
  • PCB에 대한 포인터 : 해당 스레드를 포함하는 프로세스에 대한 포인터"
BACKEND,운영체제,프로세스 상태에 대해 설명해주세요.,"• Create/New (생성 상태)
  • 프로세스가 생성 중인 상태를 의미합니다.
  • 이때, 프로세스를 생성하기 위한 여러 작업(Ex: PCB 생성)과 장기 스케줄러 승인 등의 과정을 밟습니다.
  • Ex) `fork()`, `exec()`
• Ready (준비 상태)
  • 생성된 프로세스가 CPU 스케줄러로부터 CPU 소유권을 얻을 때까지 기다리는 상태입니다.
  • CPU가 하나인 경우 컴퓨터는 한 번에 하나의 프로세스만 실행할 수 있어서 기다리는 상태입니다.
  • 실제로 CPU 자원을 어떤 프로세스에게 줄 지에 대한 알고리즘도 다양합니다.
• Running (실행 상태)
  • 프로세스가 CPU를 얻어 실제 작업을 수행하는 상태입니다. (명령어들이 실행되고 있는 상태)
  • 즉, CPU 소유권을 얻고 메모리를 할당받아 수행 중인 상태로 `CPU Burst`가 일어났다고 합니다.
• Wait/Blocked (대기 상태)
  • 어떤 이벤트가 발생한 후 프로세스가 중단된 상태입니다. 즉, 프로세스가 어떤 이벤트가 발생하기를 대기하는 상태입니다.
  • 이는 작업의 효율성을 위해 OS에 추가된 상태로 CPU가 주어져도 당장 작업을 수행할 수 없는 상태입니다.
  • 예를 들어, 프린트 인쇄 버튼으로 인한 I/O 요청 인터럽트가 발생한 경우가 있습니다. 즉, 실행 상태의 프로세스가 I/O을 요구한 경우입니다.
• Terminated/Exit (완료 상태)
  • 프로세스가 작업을 마친 후 해당 프로세스에 대한 자원을 반납하고 PCB가 삭제되는 상태를 말합니다.
  • 종료는 자연스럽게 종료되는 상황도 있지만, 부모 프로세스가 자식 프로세스를 강제적으로 종료시켜 비자발적 종료되는 경우(Abort)도 있습니다. 

[상세]
• Ready Suspended (준비 중단 상태)
  • 메모리 부족으로 일시 중단된 상태입니다.
  • 즉, Ready Queue가 꽉찬 상태입니다.
• Blocked Suspended (일시 중단 상태)
  • 중단 상태에서 프로세스가 실행되려고 했는데, 또 다시 메모리 부족으로 일시 중단된 상태를 말합니다. 

[흐름 예시]
1. New •> Ready : 생성 완료 시, OS 커널에 존재하는 Ready Queue에 올라갑니다.
2. Ready •> Running : Ready Queue에 있는 프로세스들을 OS가 프로세스 스케줄링 알고리즘에 의해 Running 상태로 가야할 프로세스를 CPU로 할당합니다.
3. Running •> Waiting : 현재 Running 상태에 있는 프로세스 A에서 I/O 이벤트가 발생하여 프로세스 A가 대기합니다.
4. Running •> Ready : I/O 이벤트가 종료된 프로세스 A가 다시 Ready Queue에 올라갑니다. (이후 다시 2번으로)
5. Running •> Terminated : 프로세스 A의 작업이 완료됩니다.
6. Ready •> Waiting : 이 모든 과정에서 하나의 작업을 매우 짧은 시간 동안 처리 후 다른 작업으로 넘어가는 것을 반복합니다. 겉으로 보기엔 동시에 실행되는 것처럼 보입니다. (Cuncurrency)"
BACKEND,운영체제,리눅스에서 프로세스와 스레드는 각각 어떻게 생성될까요?,"• 부모 프로세스 리눅스는 부팅될 때 부트로더에서 커널을 작동합니다. 부트로더: OS가 시동되기 전에 미리 실행되면서 커널이 올바르게 시동되기 위해 필요한 관련 작업을 마무리하고 최종적으로 OS를 시동시키기 위한 목적을 가진 프로그램. 작동된 커널이 init 프로세스를 실행합니다. init 프로세스: 모든 프로세스의 부모 프로세스입니다.
• 리눅스는 부팅될 때 부트로더에서 커널을 작동합니다. 부트로더: OS가 시동되기 전에 미리 실행되면서 커널이 올바르게 시동되기 위해 필요한 관련 작업을 마무리하고 최종적으로 OS를 시동시키기 위한 목적을 가진 프로그램.
• 부트로더: OS가 시동되기 전에 미리 실행되면서 커널이 올바르게 시동되기 위해 필요한 관련 작업을 마무리하고 최종적으로 OS를 시동시키기 위한 목적을 가진 프로그램.
• 작동된 커널이 init 프로세스를 실행합니다. init 프로세스: 모든 프로세스의 부모 프로세스입니다.
• init 프로세스: 모든 프로세스의 부모 프로세스입니다.
• 자식 프로세스 대부분 fork() 혹은 exec() 시스템 콜 함수를 사용해 자식 프로세스를 생성합니다. fork() : 부모 프로세스와 동일한 정보(PCB)를 갖는 자식 프로세스를 만드는 시스템 콜입니다. exec() : 해당 함수로 호출된 부모 프로세스를 새로운 정보로 덮어버려 다른 작업을 하는 자식 프로세스를 만드는 시스템 콜입니다.
• 대부분 fork() 혹은 exec() 시스템 콜 함수를 사용해 자식 프로세스를 생성합니다. fork() : 부모 프로세스와 동일한 정보(PCB)를 갖는 자식 프로세스를 만드는 시스템 콜입니다. exec() : 해당 함수로 호출된 부모 프로세스를 새로운 정보로 덮어버려 다른 작업을 하는 자식 프로세스를 만드는 시스템 콜입니다.
• fork() : 부모 프로세스와 동일한 정보(PCB)를 갖는 자식 프로세스를 만드는 시스템 콜입니다.
• exec() : 해당 함수로 호출된 부모 프로세스를 새로운 정보로 덮어버려 다른 작업을 하는 자식 프로세스를 만드는 시스템 콜입니다.
• 스레드 pthread_create() 시스템 콜 함수를 사용해 생성합니다. 같은 프로그램 내에서 작은 작업을 처리하는 데 fork()를 통해 부모와 동일한 자식 프로세스를 생성하는 것은 비용이 많이 발생합니다. 반면, 스레드는 부모 프로세스의 PCB 정보를 가지고 있기 때문에, 해당 시스템 콜 함수로 부모 프로세스와 같은 정보에 적은 비용으로 접근해 필요한 작업만 처리가 가능합니다.
• pthread_create() 시스템 콜 함수를 사용해 생성합니다. 같은 프로그램 내에서 작은 작업을 처리하는 데 fork()를 통해 부모와 동일한 자식 프로세스를 생성하는 것은 비용이 많이 발생합니다. 반면, 스레드는 부모 프로세스의 PCB 정보를 가지고 있기 때문에, 해당 시스템 콜 함수로 부모 프로세스와 같은 정보에 적은 비용으로 접근해 필요한 작업만 처리가 가능합니다.
• 같은 프로그램 내에서 작은 작업을 처리하는 데 fork()를 통해 부모와 동일한 자식 프로세스를 생성하는 것은 비용이 많이 발생합니다.
• 반면, 스레드는 부모 프로세스의 PCB 정보를 가지고 있기 때문에, 해당 시스템 콜 함수로 부모 프로세스와 같은 정보에 적은 비용으로 접근해 필요한 작업만 처리가 가능합니다."
BACKEND,운영체제,"자식 프로세스가 상태를 알리지 않고 죽거나, 부모 프로세스가 먼저 죽게 되면 어떻게 처리하나요?","• 좀비 프로세스 (Zombie Process)
  • 자식 프로세스가 부모 프로세스에게 상태를 알리지 못하고 죽으면, 자식 프로세스는 좀비 프로세스가 됩니다. 
  • 이를 위해 커널은 자식 프로세스가 종료되어도 최소한의 정보(PID, 종료 상태 등)을 남겨두기 때문에, wait() 함수를 통해서 좀비 프로세스들을 회수할 수 있습니다.
  • 즉, 좀비 프로세스는 다른 말로 부모 프로세스가 wait()를 호출하지 못한 상태로 자식 프로세스가 먼저 죽은 상황이라고 할 수 있습니다.
  • 만약 부모 프로세스가 wait()를 오랫동안 호출하지 않아 메모리가 남아있는 경우 결국 자원 낭비를 야기하고 최악에는 리소스의 유출을 야기할 수 있으니 꼭 처리해야 합니다.
• 고아 프로세스 (Orphan Process)
  • 부모 프로세스가 자식 프로세스보다 먼저 죽은 경우 자식 프로세스들은 고아 프로세스가 됩니다. 즉, 고아 프로세스들은 종료 상태를 확인하거나 회수할 수 없습니다.
  • 하지만 다행히 OS는 고아 프로세스를 허용하지 않기 때문에, 부모 프로세스가 먼저 종료되면 자식 프로세스들은 새로운 부모 프로세스로 init이 설정됩니다.
  • 이 init 프로세스는 자식 프로세스가 종료될 때까지 기다린 후 wait 함수를 호출합니다. 즉, 고아 프로세스들이 좀비 프로세스가 되는 것을 방지합니다.
  • 고아 프로세스는 시스템이 프로세스가 종료될 때까지 추적해야해서 시스템 자원을 낭비할 수 있습니다. 즉, 성능 저하의 원인이 됩니다."
BACKEND,운영체제,리눅스에서 데몬 프로세스(Daemon Process)에 대해 설명해 주세요.,"• 서비스 요청에 대해 응답하기 위해 오랫동안 실행 중인 백그라운드 프로세스를 말하는 것으로 부팅 시 자동으로 생성됩니다.
• 즉, 백그라운드 프로세스 중 부모 프로세스의 고유 번호 즉, PPID가 1인 프로세스를 말합니다.
• 데몬 프로세스는 사용자와 상호작용하지 않고 주로 시스템의 특정 기능을 지속해서 실행하거나 관리하는 데 사용됩니다.

• 예시
  • 웹 서버, 네트워크 서비스, 로깅 서비스 등
  • 웹 서버: 서버에서 터미널을 통해 실행될 수 있지만 터미널을 통해 사용자와 대화할 필요는 없어서 백그라운드 프로세스로 만들어집니다.
• 특징
  • 백그라운드에서 실행됩니다.
  • 주기적으로 시스템 작업(백업, 로깅, 네트워크 통신 등)을 수행하거나 관리하고 특정 서비스를 제공합니다.
  • 무한 루프 실행하여 지속적으로 요청을 처리하거나 시스템을 모니터링합니다.
  • init 프로세스의 자식 프로세스로 시작됩니다. 즉, 시스템 부팅 시 init 프로세스에 의해 시작되고 관리됩니다."
BACKEND,운영체제,포그라운드 프로세스와 백그라운드 프로세스 개념을 설명해주세요.,"• 포그라운드 프로세스
  • 표준 I/O 장치를 통해 대화하는 프로세스를 말합니다.
  • 표준 I/O 장치 예시: 터미널, 키보드
• 백그라운드 프로세스
  • 입력 장치에 대해 터미널과의 관계를 끊은 모든 프로세스를 말합니다.
  • 즉, 키보드를 통해 사용자에게 입력받지 않고 스스로 동작하는 프로세스입니다."
BACKEND,운영체제,리눅스는 프로세스가 일종의 트리를 형성하고 있습니다. 이 트리의 루트 노드에 위치하는 프로세스에 대해 설명해 주세요.,"• 루트 노드에 위치한 프로세스는 init 프로세스입니다. 즉, 모든 프로세스의 부모 프로세스로 PID는 항상 1입니다. 최근에는 systemd라고도 부릅니다.
• 이 init 프로세스는 리눅스가 부팅될 때 부트로더에서 작동된 커널이 실행시킵니다. 즉, 부팅 시 첫 번째로 생성되고 보통 종료될 때까지 Running 상태입니다.
• init 프로세스는 시스템의 초기화 및 관리를 담당합니다. 예를 들어, 시스템 서비스의 시작/중지, 사용자 로그인/로그아웃 등의 작업을 말합니다.
• 이 프로세스로부터 모든 시스템/사용자 프로세스가 파생됩니다.

• 부트로더
  • OS가 시동되기 전에 미리 실행되어 커널이 올바르게 시동되도록 필요한 모든 작업을 마무리합니다.
  • 최종적으로 OS를 시동시키기 위한 목적을 가진 프로그램입니다."
BACKEND,운영체제,프로세스 주소 공간(프로세스 메모리 구조)에 대해 설명해 주세요.,"• 실행 중인 각 프로세스에 할당된 메모리 공간을 의미하는 것으로 각각 고유한 주소 공간을 가집니다.
• 이 메모리 공간은 한정적이라 프로세스는 이 공간을 절약하기 위해 Stack, Heap, Data, Code(Text) 영역으로 할당합니다.
• 반면, 스레드 같은 경우엔 프로세스 내에서 독립된 Stack 영역을 할당받고 나머지 영역은 공유합니다. 때문에, Data 영역(전역 변수)은 동시에 여러 스레드가 접근할 수 있어서 동기화가 필요합니다."
BACKEND,운영체제,스레드의 주소 공간은 어떻게 구성되어 있을까요?,"• 스레드는 프로세스 내에서 스택만 독립적으로 할당받고 나머지 영역은 공유합니다.
• 때문에, Data 영역의 자원은 동시에 여러 스레드가 접근할 수 있어서 동기화 처리가 필요합니다.
• 예를 들어, 한 스레드가 공유 데이터에 대한 접근을 마칠 때까지 다른 스레드가 공유 데이터에 접근하지 못하도록 제어해야 합니다."
BACKEND,운영체제,프로세스의 각 영역을 설명해주세요.,"• Stack 영역
  • 함수 호출 정보와 관계되는 지역 변수, 매개변수가 저장되는 영역으로 함수의 호출과 함께 할당되고 함수 완료 시, 소멸합니다.
  • 즉, 재귀 함수가 너무 깊게 호출되거나 함수가 지역변수를 너무 많이 가지고 있으면 스택 영역을 초과해 Stack Overflow 에러가 발생할 수 있습니다.
  • 메모리의 높은 주소에서 낮은 주소 방향으로 할당됩니다.
  • 이 영역은 대부분 컴파일 시 크기가 결정됩니다.(정적) 다만 재귀 함수 등에 의해 런타임 시 결정되기도 합니다.(동적)
• Heap 영역
  • 주로 클래스 등의 참조형 데이터가 할당되는 영역으로 사용자에 의해 공간이 동적으로 할당 및 해제됩니다. 즉, 런타임에 크기가 결정됩니다.
  • 메모리의 낮은 주소에서 높은 주소 방향으로 할당됩니다.
  • 대표적으로 C언어에서는 malloc()와 free() 함수로 메모리를 할당 및 해제합니다.
• Data 영역 (Data & BSS)
  • 전역 변수나 Static 변수 등 프로그램이 사용할 수 있는 데이터를 저장하는 영역으로 프로그램 시작과 함께 할당되며 프로그램 종료 시 소멸합니다.
  • 즉, 어떤 프로그램이 전역 혹은 Static 변수를 참조하는 코드가 존재하면 이 프로그램은 컴파일된 후 실행 시점에 Data 영역을 참조하게 됩니다.
  • 만약, 초기화 되지 않은 변수가 존재한다면 BSS 영역에 초기화되어 저장됩니다.
    • Data : 특정 값으로 할당된 변수들이 저장되는 곳
    • BSS : 초기화되지 않은 변수들이 저장되는 곳
• Code 영역 (Text 영역)
  • 프로그램 명령어가 저장되는 영역입니다. 즉, 프로그램이 실행될 수 있도록 CPU가 해석 가능한 기계어 코드가 저장되어 있는 영역입니다.
  • 이는 수정되면 안되므로 ReadOnly 상태로 저장되어 있습니다."
BACKEND,운영체제,전역 변수 중 초기화 하지 않은 변수들은 어디에 저장될까요?,"• 컴파일 시점에 데이터 영역의 BSS(Block Started by Symbol) 영역에 저장됩니다. 즉, 크기는 컴파일 단계에서 정해지고 변하지 않습니다.
• 참고로 초기화되지 않은 변수에 대해 메모리를 할당하지만, OS에 따라 정해진 기본값(보통 0)으로 변수를 초기화해주는 경우도 있습니다."
BACKEND,운영체제,Stack과 Heap의 크기는 정해져 있나요? 그렇지 않다면 언제 결정되나요?,"• 클래스 등과 같은 참조형 데이터들은 Stack이 아닌 Heap에서 관리됩니다. 예를 들어, Stack 영역에 등장하는 각 변수들은
  Heap 영역에 위치한 객체의 참조를 가질 뿐 실제 객체 값은 Heap 영역에서 관리됩니다. 때문에, Stack 매우 클 필요는 없어서 크기에 제한을 가질 것이라 생각합니다.
  반면, Heap 실제 객체를 관리하는 만큼 Stack 영역과는 다르게 크기 정해져 있지 않고 동적으로 정해질 것 같습니다.

• Stack
  • 생성과 동시에 크기가 결정되고 웬만하면 바뀌지 않습니다. 물론 런타임 시에 변경될 수도 있습니다.
  • Heap 영여과 상관없이 크기의 제한을 가집니다.
• Heap
  • 런타임에 크기가 결정되고 동적으로 바뀝니다. 즉, 가변적 크기입니다."
BACKEND,운영체제,Stack과 Heap 영역 중 접근 속도가 더 빠른 공간은 어디일까요?,"• 접근 속도가 더 빠른 공간은 일반적으로 Stack 영역이라 생각합니다.

• Stack
  • 스택은 이미 생성되어 있는 영역의 값들에 대해 포인터의 위치만 바꿔주는 단순한 CPU instruction이라 생각합니다.
• Heap
  • 힙은 메모리 블록들이 흩어져 있을 수 있어 단편화 문제가 발생하는 등을 고려해야 하기 때문에 더 복잡한 CPU instruction이 필요하다 생각합니다."
BACKEND,운영체제,스택과 힙 영역을 개발자가 아닌 사용자가 크기를 수정할 수 있나요?,"• 스택과 힙 영역의 크기는 런타임에 결정됩니다. 즉, 실행 중 동적으로 크기가 필요에 따라 변합니다.
• 때문에, 프로그램 개발자가 아닌 사용자가 이 공간의 크기를 수정하는 것은 어렵다고 생각합니다.

• 웹 애플리케이션의 사용자 : 수정 불가능
• OS 개발자 혹은 JVM 개발자 : 수정 가능"
BACKEND,운영체제,"""스택""영역과 ""힙""영역은 정말 자료구조의 스택/힙과 연관이 있을까요?","• 결론부터 말씀드리면 관련이 있다고 생각합니다. 추가로 OS의 스택/힙은 특정 개념을 가리킵니다.

• Stack
  • 자료구조 : 후입선출(LIFO) 원칙을 따르는 선형 데이터 구조로 Push/Pop이 주요 작업입니다.
  • 운영체제 : 함수호출/지역 변수를 관리하는 영역으로 함수 호출 시, 새로운 스택 프레임에서 Push 되고 반환 시, Pop 됩니다.
• Heap
  • 자료구조 : 트리와 유사한 구조로 구현되어 있고 삽입/삭제 등의 작업을 지원하며 메모리를 효율적으로 관리합니다.
  • 운영체제 : 동적 할당에 사용되는 메모리 영역을 의미하고 malloc(), new 등과 같은 명령어를 사용해 런타임에 메모리를 요청합니다."
BACKEND,운영체제,다음과 같이 공간을 분할하는 이유가 있을까요?,"• 결론 : 각 역할을 분배하고 필요에 따라 데이터를 공유하여 메모리 사용량을 줄이기 위함이라 생각합니다.

• 스택 영역 분리 이유
  • LIFO(후입선출) 구조를 이용해 함수 호출과 지역변수 관리가 쉽도록 설계되어 빠른 호출과 반환 작업이 가능합니다.
  • 또한 구조화된 형태와 고정된 할당 패턴은 메모리 조각화와 할당 관련 문제를 예방하는 데 도움됩니다.
  • 스택은 작고 메모리 엑세스 패턴이 예측 가능하기 때문에, 캐시에 저장해두고 쓰기 좋습니다.
• 힙 영역 분리 이유
  • 한 번의 함수 호출 범위를 넘어 지속되어야 하는 경우 동적 수명을 갖는 데이터를 관리하기 위해 필요합니다.
  • 예를 들어, 힙을 사용하면 데이터를 구조화되지 않은 방식으로 할당/해제할 수 있으므로 다양한 크기의 데이터 구조를 관리하는 데, 유연성을 제공합니다.
• 코드(텍스트) 영역 분리 이유
  • 같은 프로그램에선 모두 같은 내용이기 때문에, 따로 관리하여 공유합니다. 그리고 애초에 기계어만 들어있기 때문에, 다른 영역과 분리하는게 당연하다고 생각합니다.
• 스택 영역과 데이터 영역 분리 이유
  • 스택 구조의 특성과 전역변수의 활용성을 위해 분리되었다고 생각합니다. 예를 들어, 스택은 함수의 흐름을 관리하지만, 데이터는 전역 혹은 Static 변수를 관리합니다.
  • 또한 각 스레드는 독립된 Stack 영역을 갖지만 Data 영역은 공유합니다. 즉, 각 스레드가 동일한 Data 공유함으로써 메모리를 절약할 수 있습니다.
• Data 영역의 Data, BSS 분리 이유
  • 초기화된 변수는 영역과 값 모두 프로그램에 저장하고 있어야 하지만 초기화되지 않은 변수는 프로그램이 실행될 때 영역만 정해주면 됩니다.
  • 즉, BSS 영역은 변수들이 많아져도 프로그램의 실행 코드 사이즈를 늘리지는 않는 것으로 알고 있습니다."
BACKEND,운영체제,정적 할당과 동적 할당에 대해 설명해주세요.,"• 정적 할당
  • 정적 할당은 컴파일 단계에서 메모리가 할당되는 것을 말합니다.
  • 보통 정적 할당은 Data 영역의 Data/BSS와 Code(Text) 영역으로 나뉘어집니다.
• 동적 할당
  • 동적 할당은 런타임 단계에서 메모리가 할당되는 것을 말합니다.
  • 보통 동적 할당은 Stack 영역과 Heap 영역으로 나뉘어집니다."
BACKEND,운영체제,프로세스 문맥 교환(Context Switching)이란 무엇인가요?,"• CPU에서 실행 중이던 프로세스/스레드가 다른 프로세스/스레드로 교체되는 것을 말합니다. 즉, PCB/TCB 교체 과정이라 할 수 있습니다.
• 다시 말해, PCB/TCB를 기반으로 프로세스/스레드를 저장하고 다시 복원하는 과정을 말합니다.
• 이는 한 프로세스에 할당된 시간이 끝났을 때, 프로세스가 종료될 때, I/O 요청에 의한 시스템 콜, 인터럽트 등에 의해 발생합니다."
BACKEND,운영체제,"Context Switching(문맥 교환) 시, 어떤 일들이 일어나나요? 흐름을 설명해주세요.","1. PCB/TCB에 현재 수행 중인 프로세스/스레드 상태를 저장 후 커널 모드로 전환됩니다.
2. 스케줄링 알고리즘을 통해 다음 실행할 프로세스/스레드를 결정합니다.
3. 결정된 프로세스/스레드의 PCB/TCB를 새로 생성하거나 불러옵니다.
4. 불러온 PCB/TCB에 해당하는 프로세스/스레드를 실행하기 위해 사용자 모드로 전환됩니다."
BACKEND,운영체제,프로세스와 스레드는 컨텍스트 스위칭이 발생했을 때 어떤 차이가 있을까요?,"• 결론적으로는 컨텍스트 스위칭은 스레드가 프로세스에 비해 오버헤드와 비용이 적어 더 빠르고 효율적입니다.

• 이유
  • 스레드는 스택 영역을 제외한 모든 영역을 공유하기 때문에 스택 및 PC 등 일부만 교환하면 됩니다. 즉, TCB가 PCB보다 가볍습니다.
  • 프로세스는 서로 다른 메모리 주소 공간을 가집니다. 때문에 새로 실행되는 프로세스가 기존 프로세스의 메모리 주소 공간을 침범하면 안됩니다.
    따라서, Page Table 교체와 TLB를 완전히 비워주는 작업, MMU 변경 등이 추가적으로 발생하여 더 많은 비용이 발생하게 되는 것입니다.

• PC (Program Counter)
  • 다음에 실행될 명령어의 위치 값입니다.
  • 예를 들어, Context Switching을 할 때, 어디부터 다시 실행해야하는 지 알려줍니다.
• Page Table
  • 가상 메모리 주소와 물리 메모리 주소 간의 매핑을 저장하는 자료구조입니다.
• TLB (Table Lookaside Buffer)
  • 가상 메모리 주소를 물리적 주소로 변환하는 속도를 높이기 위해 사용하는 것으로 MMU에 위치한 캐시입니다.
  • CPU가 가상 주소로 메모리에 접근하려고 할 때, 먼저 TLB에 접근하고 없으면 Page Table에서 찾습니다.
• MMU (Memory Management Unit)
  • 가상 메모리 주소를 물리 메모리 주소로 매핑 시켜주는 역할을 수행하는 HW입니다.
  • 뿐만 아니라, 잘못된 주소에 접근하지 않도록 보호하는 역할도 합니다."
BACKEND,운영체제,컨텍스트 스위칭은 언제 일어날까요?,"• 주어진 할당 시간(Time Slice)을 다 사용했을 때, I/O 작업을 해야할 때, 다른 리소스를 기다려야 할 때, 인터럽트 등 여러 이유로 발생합니다."
BACKEND,운영체제,"A 프로세스에서 인터럽트 혹은 시스템 콜로 인해 유저모드에서 커널모드로 넘어간 뒤, 다시 A로 돌아온 경우도 컨텍스트 스위칭인가요?","• 특정 프로세스가 특정 이벤트에 의해 커널 모드로 넘어간 뒤 다시 원래 프로세스로 복귀한다면 다른 프로세스로 복귀한 것이 아니기 때문에, Context Switching이라 할 수 없습니다."
BACKEND,운영체제,"단일 프로세스, 멀티 프로세스와 멀티 스레드의 차이점을 설명해주세요.","• 단일 프로세스 말 그대로 하나의 프로세스로 사용하는 것을 말합니다. 때문에, CPU 사용률이 떨어집니다. 예를 들어, 한 프로세스가 실행되고 있을 때 CPU를 사용하다가 I/O 작업을 만나면 I/O 작업으로 인해 CPU는 놀고 있기 때문입니다.
• 말 그대로 하나의 프로세스로 사용하는 것을 말합니다. 때문에, CPU 사용률이 떨어집니다.
• 예를 들어, 한 프로세스가 실행되고 있을 때 CPU를 사용하다가 I/O 작업을 만나면 I/O 작업으로 인해 CPU는 놀고 있기 때문입니다.
• 멀티 프로세스 하나의 프로그램을 여러 개의 프로세스로 나눠 사용하는 것을 말합니다. 각 프로세스가 OS에게 독립적으로 자원을 할당받아 서로의 메모리에 침범하지 않습니다. 독립적인 영역을 가져 안정적입니다. 즉, 각 프로세스에 문제가 발생해도 다른 프로세스에 영향을 주지 않습니다. 서로 독립된 메모리를 가지기 때문에, 서로 메모리를 공유하기 위해 IPC(Inter Process Communication) 기법을 사용해야 합니다. 이 과정에서 추가적인 설비가 필요하고 다소 비효율적입니다. 서로 독립된 메모리를 가져 Context Switching(문맥 교환) 발생 시, 시간이 오래 걸립니다.
• 하나의 프로그램을 여러 개의 프로세스로 나눠 사용하는 것을 말합니다.
• 각 프로세스가 OS에게 독립적으로 자원을 할당받아 서로의 메모리에 침범하지 않습니다.
• 독립적인 영역을 가져 안정적입니다. 즉, 각 프로세스에 문제가 발생해도 다른 프로세스에 영향을 주지 않습니다.
• 서로 독립된 메모리를 가지기 때문에, 서로 메모리를 공유하기 위해 IPC(Inter Process Communication) 기법을 사용해야 합니다. 이 과정에서 추가적인 설비가 필요하고 다소 비효율적입니다.
• 서로 독립된 메모리를 가져 Context Switching(문맥 교환) 발생 시, 시간이 오래 걸립니다.
• 멀티 스레드 하나의 프로세스가 여러 스레드를 갖고, 각 스레드가 서로 다른 작업들을 수행하는 것을 말합니다. 프로세스를 추가적으로 생성하지 않기 때문에, 비용 측면에서 효율적입니다. 스레드는 동일한 프로세스 내 자원을 공유하기 때문에 프로세스에 비해 효율적입니다. 단, 동기화 처리가 필요한 상황이 생길 수 있습니다. 하나의 스레드에 문제가 생기면 프로세스 전체에 문제가 발생할 수 있습니다.
• 하나의 프로세스가 여러 스레드를 갖고, 각 스레드가 서로 다른 작업들을 수행하는 것을 말합니다.
• 프로세스를 추가적으로 생성하지 않기 때문에, 비용 측면에서 효율적입니다.
• 스레드는 동일한 프로세스 내 자원을 공유하기 때문에 프로세스에 비해 효율적입니다. 단, 동기화 처리가 필요한 상황이 생길 수 있습니다.
• 하나의 스레드에 문제가 생기면 프로세스 전체에 문제가 발생할 수 있습니다."
BACKEND,운영체제,"멀티 프로세스, 멀티 스레드 중 어떤 것을 선택하는 게 좋을까요?","• 대부분의 경우 멀티 스레드를 선택할 것 같습니다.
• 멀티 프로세스의 경우 멀티 프로세스를 시작하기 위해 여러 프로세스를 생성해야 하기 때문에 비용이 많이 발생합니다.
• 또한 각 프로세스가 독립적이기 때문에 스레드의 Context Switching 과정보다 프로세스의 Context Switching 과정에서 비교적 많은 비용이 발생할 것입니다.
• 그리고 스레드의 자원 공유 방식이 프로세스의 IPC 기법보다 더 빠르고 효율적이기 때문에 멀티 스레드를 선택할 것 같습니다."
BACKEND,운영체제,"크롬의 경우 멀티 프로세스 구조를 택했는데, 그 이유는 무엇일까요?","• 멀티 스레드라면 각각의 크롬 탭에서 문제가 발생하거나 확장 중에 문제가 발생하면 전체 브라우저에 영향이 갈 수 있습니다.
• 크롬은 특정 탭이 전체 브라우저에 영향이 가지 않도록 하기 위해 서로 다른 프로세스로 분리시켜 관리한다고 생각합니다."
BACKEND,운영체제,동시성과 병렬성의 차이에 대해 설명해 주세요.,"많은 프로세스가 동시에 실행되는 것처럼 보이는 이유는 무엇일까요? (답변 부족)
• 싱글 코어 기준
  • 컴퓨터는 많은 프로그램을 동시에 실행되는 것처럼 보이지만, 사실 특정 시점에 실행되는 프로세스는 단 1개입니다.
  • 이는 프로세스들 간에 컨텍스트 스위칭이 매우 빠르게 발생하여 동시에 실행되는 것처럼 보이는 것입니다.
• 멀티 코어 기준
  • 현대 컴퓨터는 멀티 코어 CPU를 가지기 때문에, 특정 시점에 단 1개의 프로세스가 실행된다는 말은 틀린말입니다."
BACKEND,운영체제,많은 프로세스가 동시에 실행되는 것처럼 보이는 이유는 무엇일까요? (답변 부족),"• 싱글 코어 기준
  • 컴퓨터는 많은 프로그램을 동시에 실행되는 것처럼 보이지만, 사실 특정 시점에 실행되는 프로세스는 단 1개입니다.
  • 이는 프로세스들 간에 컨텍스트 스위칭이 매우 빠르게 발생하여 동시에 실행되는 것처럼 보이는 것입니다.
• 멀티 코어 기준
  • 현대 컴퓨터는 멀티 코어 CPU를 가지기 때문에, 특정 시점에 단 1개의 프로세스가 실행된다는 말은 틀린말입니다."
BACKEND,운영체제,"CPU 혹은 프로세스 스케쥴링이라 부르는 데, 이에 대해서 설명해주세요.","• 스케줄링 알고리즘 종류로는 무엇이 있나요?
• 단기, 중기, 장기 스케줄링에 대해서 설명해주세요.
• 현대 OS에는 단기, 중기, 장기 스케쥴러를 모두 사용하고 있나요?
• 프로세스 스케쥴링 상태에 대해 설명해 주세요.
• 선점형(preemptive) 스케줄링과 비선점형(non•preemptive) 스케줄링의 차이점은 무엇일까요?
• 선점형(preemptive)과 비선점형(non•preemptive)에서 존재할 수 없는 상태가 있을까요?
• RR을 사용할 때, Time Slice에 따른 trade•off를 설명해 주세요.
• Memory가 부족할 경우, Process는 어떠한 상태로 변화할까요?
• 싱글 스레드 CPU 에서 상시로 돌아가야 하는 프로세스가 있다면, 어떤 프로세스 스케쥴링 알고리즘을 사용하는 것이 좋을까요? 근거는?
• 타 스케쥴러와 비교하여, Multi•level Feedback Queue는 어떤 문제점들을 해결한다고 볼 수 있을까요?
• 보통 스케줄링 알고리즘을 ""프로세스"" 스케줄링 알고리즘이라고 부릅니다. 스레드는 다른 방식으로 스케줄링을 하나요?
• 유저 스레드와 커널 스레드의 스케쥴링 알고리즘은 똑같을까요?
• FIFO 스케쥴러는 정말 쓸모가 없는 친구일까요? 어떤 시나리오에 사용하면 좋을까요?"
BACKEND,운영체제,"IPC(Inter-Process Communication)가 무엇이고, 어떤 종류가 있는지 설명해 주세요.","• 서로 다른 프로세스가 데이터를 주고 받고 관리하는 메커니즘입니다.
• 대표적으로 공유 메모리, 메시지 큐 등이 있습니다."
BACKEND,운영체제,"Shared Memory가 무엇이며, 사용할 때 유의해야 할 점에 대해 설명해 주세요.","• 프로세스 주소 공간의 일부를 공유하여 여러 프로세스가 통신할 수 있도록하는 기법으로 알고 있습니다. 즉, 어떤 매개체를 통해 데이터를 주고 받는 것이 아닙니다.
• 이는 메모리 자체를 공유하기 때문에, 불필요한 데이터 복사로 인한 오버헤드가 발생하지 않아 IPC 기법 중 가장 빠른 것으로 알고 있습니다.
• 단, 여러 프로세스가 동일한 메모리 영역을 공유하기 때문에, 동기화 처리가 필요합니다. 따라서 쓰기 및 읽기 빈도가 높으면 동기화 처리를 꼭 해줘야 해서 복잡해집니다."
BACKEND,운영체제,IPC의 Shared-Memory 기법은 프로세스 주소공간의 어디에 들어갈까요? 그 이유는? (답변 부족),"• 공유 메모리 기법 자체가 세그먼트를 생성하고 이 세그먼트를 공유하는 기술입니다.
• 즉, 물리적인 공간에 공유 메모리 영역이 구축되고 이 세그먼트가 물리적인 메모리 주소 공간에 할당된다고 이해하고 있습니다.
• 결론적으로 프로세스 주소 공간에서는 해당 공유 메모리 영역과 매핑해주고 각 프로세스에 이를 통해 세그먼트에 접근하여 데이터를 읽고 쓰는 것 같은데, 
• 그렇다면 ""이 프로세스 주소 공간 어디에 들어갈까?""가 궁금한데, 아마 ""Data 영역에서 공유 메모리를 가리키는 게 있지 않을까?"" 추측해봅니다."
BACKEND,운영체제,메시지 큐에 대해 설명하고 흐름도 간단하게 말씀해주세요.,"• 큐 형태로 관리하는 버퍼를 만들어 통신하는 기법으로 알고 있습니다.
• 이는 커널에서 전역적으로 관리되며 다른 IPC에 비해 사용 방법이 직관적이며 간단합니다.
• 대표적인 예시로 RabbitMQ, Kafka가 있습니다.

• 흐름
  1. 프로세스가 메시지를 보내거나 받기 전에 큐를 초기화합니다.
  2. 프로세스의 메시지는 큐에 복사되어 다른 프로세스에게 전달됩니다."
BACKEND,운영체제,메시지 큐는 단방향이라고 할 수 있나요?,"• 상황마다 다르지만 일반적으로는 단방향이라 생각합니다.
• 예를 들어, 메시지 큐 구현 시 파이프가 쓰이기도 하는데, 익명 파이프에는 단방향이고 명명 파이프를 사용할 경우에는 양방향인 것으로 알고 있습니다.

• 익명 파이프 (Anonymous/Unnamed Pipe)
  • 단방향 방식의 읽기/쓰기 전용 파이프를 만들어 작동하는 방식입니다.
  • 이는 부모•자식 프로세스 간에서만 사용할 수 있고 다른 네트워크 상에서는 사용이 불가능합니다.
  • 파이프의 데이터 용량은 제한되어 있기 때문에 쓰기 프로세스가 읽기 프로세스보다 더 빠르게 사용될 수 없습니다.
• 명명 파이프 (Named Pipe)
  • 양방향 방식의 읽기/쓰기 전용 파이프를 만들어 작동하는 방식입니다.
  • 이는 부모•자식 뿐만 아니라 다른 네트워크 상에서도 통신이 가능합니다."
BACKEND,운영체제,뮤텍스와 세마포어의 차이점은 무엇인가요?,"• 이진 세마포어와 뮤텍스의 차이에 대해 설명해 주세요.
• Lock을 얻기 위해 대기하는 프로세스들은 Spin Lock 기법을 사용할 수 있습니다. 이 방법의 장단점은 무엇인가요? 단점을 해결할 방법은 없을까요?
• 뮤텍스와 세마포어 모두 커널이 관리하기 때문에, Lock을 얻고 방출하는 과정에서 시스템 콜을 호출해야 합니다. 이 방법의 장단점이 있을까요? 단점을 해결할 수 있는 방법은 없을까요?"
BACKEND,운영체제,Deadlock 에 대해 설명해 주세요.,"• Deadlock 이 동작하기 위한 4가지 조건에 대해 설명해 주세요.
• 그렇다면 3가지만 충족하면 왜 Deadlock 이 발생하지 않을까요?
• 어떤 방식으로 예방할 수 있을까요?
• 왜 현대 OS는 Deadlock을 처리하지 않을까요?
• Wait Free와 Lock Free를 비교해 주세요."
BACKEND,운영체제,Thread Safe 하다는 것은 어떤 의미인가요?,"• Thread Safe 를 보장하기 위해 어떤 방법을 사용할 수 있나요?
• Peterson's Algorithm 이 무엇이며, 한계점에 대해 설명해 주세요.
• Race Condition 이 무엇인가요?
• Thread Safe를 구현하기 위해 반드시 락을 사용해야 할까요? 그렇지 않다면, 어떤 다른 방법이 있을까요?"
BACKEND,운영체제,"Thread Pool, Monitor, Fork-Join에 대해 설명해 주세요.","• Thread Pool을 사용한다고 가정하면, 어떤 기준으로 스레드의 수를 결정할 것인가요?
• 어떤 데이터를 정렬 하려고 합니다. 어떤 방식의 전략을 사용하는 것이 가장 안전하면서도 좋은 성능을 낼 수 있을까요?"
BACKEND,운영체제,"동기와 비동기, 블로킹과 논블로킹의 차이에 대해 설명해 주세요.","• 그렇다면, 동기이면서 논블로킹이고, 비동기이면서 블로킹인 경우는 의미가 있다고 할 수 있나요?
• I/O 멀티플렉싱에 대해 설명해 주세요.
• 논블로킹 I/O를 수행한다고 하면, 그 결과를 어떻게 수신할 수 있나요?"
BACKEND,운영체제,동기화를 구현하기 위한 하드웨어적인 해결 방법에 대해 설명해 주세요.,"• volatile 키워드는 어떤 의미가 있나요?
• 싱글코어가 아니라 멀티코어라면, 어떻게 동기화가 이뤄질까요?"
BACKEND,운영체제,캐시 메모리 및 메모리 계층성에 대해 설명해 주세요.,"• 캐시 메모리는 어디에 위치해 있나요?
• L1, L2 캐시에 대해 설명해 주세요.
• 캐시에 올라오는 데이터는 어떻게 관리되나요?
• 캐시간의 동기화는 어떻게 이루어지나요?
• 캐시 메모리의 Mapping 방식에 대해 설명해 주세요.
• 캐시의 지역성에 대해 설명해 주세요.
• 캐시의 지역성을 기반으로, 이차원 배열을 가로/세로로 탐색했을 때의 성능 차이에 대해 설명해 주세요.
• 캐시의 공간 지역성은 어떻게 구현될 수 있을까요? (힌트: 캐시는 어떤 단위로 저장되고 관리될까요?)"
BACKEND,운영체제,"메모리의 연속할당 방식 세 가지를 설명해주세요. (first-fit, best-fit, worst-fit)","• worst•fit 은 언제 사용할 수 있을까요?
• 성능이 가장 좋은 알고리즘은 무엇일까요?"
BACKEND,운영체제,Thrashing 이란 무엇인가요?,"• Thrashing 발생 시, 어떻게 완화할 수 있을까요?"
BACKEND,운영체제,가상 메모리란 무엇인가요?,"• 가상 메모리가 가능한 이유가 무엇일까요?
• Page Fault가 발생했을 때, 어떻게 처리하는지 설명해 주세요.
• 페이지 크기에 대한 Trade•Off를 설명해 주세요.
• 페이지 크기가 커지면, 페이지 폴트가 더 많이 발생한다고 할 수 있나요?
• 세그멘테이션 방식을 사용하고 있다면, 가상 메모리를 사용할 수 없을까요?"
BACKEND,운영체제,세그멘테이션과 페이징의 차이점은 무엇인가요?,"• 페이지와 프레임의 차이에 대해 설명해 주세요.
• 내부 단편화와, 외부 단편화에 대해 설명해 주세요.
• 페이지에서 실제 주소를 어떻게 가져올 수 있는지 설명해 주세요.
• 어떤 주소공간이 있을 때, 이 공간이 수정 가능한지 확인할 수 있는 방법이 있나요?
• 32비트에서, 페이지의 크기가 1kb 이라면 페이지 테이블의 최대 크기는 몇 개일까요?
• 32비트 운영체제는 램을 최대 4G 까지 사용할 수 있습니다. 이 이유를 페이징과 연관 지어서 설명해 주세요.
• C/C++ 개발을 하게 되면 Segmentation Fault 라는 에러를 접할 수 있을텐데, 이 에러는 세그멘테이션/페이징과 어떤 관계가 있을까요?"
BACKEND,운영체제,TLB는 무엇인가요?,"• TLB를 쓰면 왜 빨라지나요?
• MMU가 무엇인가요?
• TLB와 MMU는 어디에 위치해 있나요?
• 코어가 여러개라면, TLB는 어떻게 동기화 할 수 있을까요?
• TLB 관점에서, Context Switching 발생 시 어떤 변화가 발생하는지 설명해 주세요."
BACKEND,운영체제,페이지 교체 알고리즘에 대해 설명해 주세요.,"• LRU 알고리즘은 어떤 특성을 이용한 알고리즘이라고 할 수 있을까요?
• LRU 알고리즘을 구현한다면, 어떻게 구현할 수 있을까요?
• LRU 알고리즘의 단점을 설명해 주세요. 이를 해결할 수 있는 대안에 대해서도 설명해 주세요."
BACKEND,운영체제,"프로그램이 컴파일 되어, 실행되는 과정을 간략하게 설명해 주세요.","• 링커와, 로더의 차이에 대해 설명해 주세요.
• 컴파일 언어와 인터프리터 언어의 차이에 대해 설명해 주세요.
• JIT에 대해 설명해 주세요.
• 본인이 사용하는 언어는, 어떤식으로 컴파일 및 실행되는지 설명해 주세요."
BACKEND,운영체제,"File Descriptor와, File System에 에 대해 설명해 주세요.","• I•Node가 무엇인가요?
• 프로그래밍 언어 상에서 제공하는 파일 관련 함수 (Java • BufferedReader/Writer 등)은, 파일을 어떤 방식으로 읽어들이나요?"
공통,Spring,서블릿(Servlet)에 대해 설명하세요.,"• 클라이언트의 요청을 처리하고, 그 결과를 반환하는 Servlet 클래스의 구현 규칙을 지킨 자바 웹 프로그래밍 기술입니다. 클라이언트의 요청에 대해 동적으로 작동하는 웹 어플리케이션 컴포넌트입니다. 요청/응답을 일일히 처리하지 않고 서블릿을 통해 웹 요청과 응답의 흐름을 간단한 메서드 호출만으로 다룰 수 있게 합니다. MVC 패턴에서 Controller로 이용됩니다.
• 클라이언트의 요청에 대해 동적으로 작동하는 웹 어플리케이션 컴포넌트입니다.
• 요청/응답을 일일히 처리하지 않고 서블릿을 통해 웹 요청과 응답의 흐름을 간단한 메서드 호출만으로 다룰 수 있게 합니다.
• MVC 패턴에서 Controller로 이용됩니다."
공통,Spring,서블릿 생명주기에 대해 설명해주세요.,"• init():
  • 클라이언트의 요청이 들어오면 컨테이너는 해당 서블릿이 메모리에 올라와있는지 확인하고, 없을 경우 init() 메서드를 통해 메모리에 적재합니다.
  • 처음 한 번만 실행되고 서블릿의 모든 쓰레드에서 공통적으로 사용해야 한다면 오버라이딩해서 구현하면 됩니다.
• service():
  • 클라이언트의 요청이 들어왔을 때, service() 메서드를 통해 요청에 대한 응답이 doGet()과 doPost()로 나뉘며 
    HttpServletRequest와 HttpServletResponse 객체가 제공됩니다.
  • 실질적으로 요청에 대한 처리를 수행하는 곳입니다.
• destroy():
  • 컨테이너가 서블릿에 종료 요청을 하면 발생되는 메서드로, 서블릿의 처리가 모두 끝났을 때 발생합니다."
공통,Spring,서블릿의 경우 멀티 쓰레드 환경에서 어떻게 동작하는지 알려주세요.,"• 우선 서블릿은 WAS가 실행되면 싱글톤으로 1개만 생성됩니다.
• 싱글톤으로 생성된 특정 서블릿에 대한 요청이 한 번에 10개가 발생했다고 가정한다면,
  요청 하나당 쓰레드 하나가 쓰레드 풀에서 할당되고 10개의 요청은 모두 쓰레드를 할당받아 특정 서블릿의 service()를 요청합니다.
• 결국 동시에 여러 클라이언트의 요청을 처리할 수 있기 때문에, 서블릿에서 전역 변수를 사용하거나, 상태를 변경하는 등의
  작업을 여러 쓰레드에서 동시에 처리하면, 데이터 불일치나 에기치 않은 결과를 초래할 수 있습니다.
• 따라서, 가급적이면 인스턴스 변수를 사용하지 않고 쓰레드마다 지역변수를 이용하거나, synchronized 키워드를 이용해
  특정 코드 블록이 한 번에 하나의 쓰레드만 실행할 수 있도록 제한해야 합니다."
공통,Spring,서블릿 컨테이너(Servlet Container)란?,"• 서블릿을 관리해주는 컨테이너로 클라이언트의 요청을 받고 응답할 수 있게, 웹 서버와 소켓으로 통신하는 역할을 합니다.
• 즉, Tomcat처럼 서블릿을 지원하는 WAS입니다."
공통,Spring,서블릿 컨테이너의 역할에 대해 설명해주세요.,"1. 웹서버와 통신지원을 합니다.
  • 서블릿과 웹서버가 손쉽게 통신할 수 있게 합니다.
  • 보통 소켓을 만들고 listen, accept를 해야하는데, 서블릿 컨테이너는 이런 기능을 API로 제공하여 복잡한 과정이 생략됩니다.
2. 서블릿 생명주기를 관리합니다.
  • 서블릿의 탄생부터 죽음을 관리합니다.
  • 서블릿 클래스를 로딩하여 인스턴스화하고 초기화 메서드를 호출하고 요청이 들어오면 적절한 서블릿 메서드를 호출합니다.
3. 멀티 쓰레드를 지원 및 관리합니다. 
  • 서블릿 컨테이너는 요청이 들어올 때마다 새로운 자바 쓰레드를 생성합니다.
  • 이를 통해 여러 사용자의 요청을 동시에 처리할 수 있습니다."
공통,Spring,Tomcat이란 무엇인가요?,"• 웹 서버(WS)와 웹 컨테이너(=서블릿 컨테이너)의 결합인 웹 애플리케이션 서버(WAS)입니다. 보통 Apache Tomcat이라 하는데, Tomcat에서 편의를 위해 Apache 기능을 포함해 Tomcat이라 부릅니다. Apache : 정적인 데이터를 처리하는 웹 서버 Tomcat : 동적인 데이터를 처리하는 웹 애플리케이션 서버 WS : 정적 콘텐츠를 제공하는 서버입니다. (HTML, CSS, 이미지 등) WAS : 동적인 데이터를 처리하는 서버입니다. (DB 연결 및 데이터 조작 등의 처리를 담당)
• 보통 Apache Tomcat이라 하는데, Tomcat에서 편의를 위해 Apache 기능을 포함해 Tomcat이라 부릅니다.
• Apache : 정적인 데이터를 처리하는 웹 서버
• Tomcat : 동적인 데이터를 처리하는 웹 애플리케이션 서버
• WS : 정적 콘텐츠를 제공하는 서버입니다. (HTML, CSS, 이미지 등)
• WAS : 동적인 데이터를 처리하는 서버입니다. (DB 연결 및 데이터 조작 등의 처리를 담당)"
공통,Spring,"내장 톰캣과 외장 톰캣이 어떤 식으로 활용되는 지, 차이점에 대해서 아는대로 설명해주세요.","주로 톰캣은 스프링 프레임워크를 사용할 때 이용합니다.
예를 들어, 기본 스프링을 이용할 땐 외장 톰캣을 이용하고 스프링부트를 사용할 때는 내장 톰캣을 이용합니다.
즉, 프레임워크 밖에서 동작하면, 외장 톰캣, 프레임워크 안에서 동작하면 내장 톰캣을 이용한다고 보면 됩니다.
내장 톰캣은 웹 어플리케이션을 빌드하고 실행하는 것만으로 웹 애플리케이션을 실행할 수 있습니다. 즉, Jar 파일 형태로 손쉽게 배포가 가능합니다.
반면 외장 톰캣은 톰캣을 직접 설치하여 스프링과 통신할 수 있도록 복잡한 설정을 해야 합니다.

1. 내장 톰캣
  • Springboot 안에는 Tomcat이 내장
  • 애플리케이션을 빌드하고 실행하는 것만으로 웹 애플리케이션을 서비스할 수 있다.
2. 외장 톰캣
  • Spring을 사용하는 경우 Tomcat을 설치하여 스프링과 통신할 수 있도록 설정해야 한다.
  • 복잡한 대신 Virtual Host라는 기능을 사용할 수 있다.
    • 도메인 호스트에 따라 다른 Root Context를 적용해 하나의 웹 어플리케이션에서도 마치 여러 애플리케이션을 사용하는 것처럼 주소 설정 가능
    • 내장 톰캣도 가능하긴 하지만 매우 복잡하기 때문에, 웹 서버를 별도로 두고 하나의 웹 애플리케이션은 하나의 내장 WAS를 갖는 것이 더 효율적"
공통,Spring,Tomcat 동작과정에 대해 설명해주세요.,"1. 클라이언트가 요청을 하면 웹 서버에서 톰캣과 같은 WAS에 위임합니다.
2. 서블릿 컨테이너가 HttpServletRequest, HttpServletResponse(빈객체) 객체를 생성합니다.
3. web.xml을 기반으로 해당 URL이 어떤 서블릿에 대한 요청인지 찾습니다.
4. 해당 서블릿이 최초 요청이면 init()를 통해 메모리에 로드하고 아니라면 기존 서블릿 인스턴스를 가져옵니다.
5. 가져온 서블릿에서 service()를 호출 후 doGet() 또는 doPost()를 호출합니다.
6. doGet() 혹은 doPost()가 동적 페이지를 생성해 HttpServletResponse 객체에 응답을 보냅니다.
7. 응답이 끝나면 HttpServletRequest와 HttpServletResponse 객체를 소멸시킵니다."
공통,Spring,Spring 환경에서 tomcat 에 request 가 들어왔을 때 RequestMapping 에 도달하기까지 과정을 설명해주세요.,"1) 톰캣이 HttpServletRequest와 HttpServletResponse 객체를 생성합니다.
2) 스프링이 DispatcherServlet에 이 두 객체를 전달합니다. 
3) DispatcherServlet은 HandlerMapping에게 이 요청을 처리할 Handler(컨트롤러)를 물어봅니다. 
4) HandlerMapping은 요청의 URI, HTTP 메서드 등을 기준으로 Handler를 찾아 DispatcherServlet에 반환합니다.
5) DispatcherServlet은 반환받은 Handler(@RequestMapping이 붙은 컨트롤러의 메서드)를 실행합니다."
공통,Spring,필터(Filter)란?,• 서블릿으로 전달되는 클라이언트의 요청 혹은 서블릿에서 클라이언트로 전달되는 응답을 중간에 가로채 필터링을 위한 객체와 메서드를 정의해둔 인터페이스입니다.
공통,Spring,Filter 메서드에 대해 설명해주세요.,"• init(FilterConfig): 
  • 필터 인스턴스 초기화를 위해 호출하는 메서드
  • 필터가 생성되고 난 후 한 번만 호출됩니다. 
• doFilter(ServletRequest, ServletResponse, FilterChain):
  • 실제 필터의 로직을 수행하는 메서드입니다.
  • 클라이언트의 요청이 있을 때마다 호출됩니다.
  • 작업이 끝나면 FilterChain의 doFilter 메서드를 호출하여 다음 필터나 서블릿에게 요청과 응답을 전달합니다.
• destroy():
  • 필터 인스턴스를 종료시키기 전에 호출하는 메서드입니다.
  • 이 메서드에서는 필터의 리소스를 해제하거나 종료에 필요한 작업을 수행합니다.

이처럼 필터는 요청과 응답을 가공하거나 특정 작업을 수행하는 데 사용되며, 
init, doFilter, destroy 세 가지 메서드를 통해 필터의 생명 주기를 관리합니다."
공통,Spring,필터에서 사용되는 요청과 서블릿에서 사용되는 요청의 차이를 설명하세요.,"• 필터는 ServletRequest 사용되고 서블릿은 HttpServletRequest가 사용됩니다.
• 서블릿의 HttpServletRequest는 필터의 ServletRequest의 기능을 상속받아
  추가적으로 HTTP 프로토콜 관련 기능들을 추가적으로 제공하는 인터페이스입니다."
공통,Spring,필터를 사용해본 경험이 있나요? 있다면 필터에서 예외 처리를 해봤나요? 없다면 어떻게 할 것 같은가요?,이 답변은 개인적으로 준비하는 것이 좋을 것 같습니다.
공통,Spring,Spring과 SpringBoot 차이에 대해 설명하세요.,"• Spring Boot는 WAS 서버를 내장하고 있어, Jar 파일로 배포가 용이합니다. 또한 의존성을 관리해주기 때문에 손쉽게 사용이 가능합니다.
예를 들어, Spring MVC, Spring Data JPA, Spring Security 등을 자동으로 설정해 개발자가 별도로 설정 파일을 작성하지 않아도 됩니다.
• 반면 Spring은 굉장히 많은 설정을 해줘야 합니다. 예를 들어, 웹 서버로 만들 때는 외부의 WAS 서버를 이용해 처리해야 합니다."
공통,Spring,본인이 생각할 때 스프링과 스프링부트는 각각 언제 사용할 것 같나요?,"우선 스프링은 많은 설정을 개발자가 직접해야 해서 복잡하지만, 오히려 섬세한 설정을 할 수 있기 때문에,
스프링 프레임워크에 대한 이해가 깊다면, 세밀한 설정이 필요할 때 사용할 것 같습니다.
반대로 스프링부트는 개발 시간을 최소화해야하는 경우 사용할 것 같습니다."
공통,Spring,Spring MVC(Model-View-Controller) 란?,"• Spring MVC는 Dispatcher Servlet, ModelAndVidew, View Resolver와 같은 간단한 개념으로 웹 애플리케이션을 개발할 수 있도록 돕는 프레임워크입니다."
공통,Spring,MVC 패턴이란?,"MVC 패턴은 애플리케이션을 세 가지 역할로 구분한 개발 방법론입니다. 
  • Model: 애플리케이션의 정보, 데이터를 나타내며, 비즈니스 로직을 처리합니다.
  • View: 사용자에게 보여지는 화면입니다. Model이 처리한 데이터를 사용자에게 보여주는 역할을 합니다.
  • Controller: 사용자의 입력을 받아 Model에 작업을 지시하고, 그 결과를 View에 반영하여 사용자에게 전달하는 역할을 합니다."
공통,Spring,"Spring MVC1, Spring MVC2 패턴 차이에 대해 설명해주세요.","• Spring MVC1: 
  • View와 Controller를 JSP가 모두 담당하는 형태를 의미합니다.
  • JSP에 모든 정보가 담겨 있기 때문에, 읽기가 힘들고 유지보수성이 떨어집니다.
• Spring MVC2: 
  • 요청을 하나의 Controller(Servlet)가 먼저 받아 View와 Model의 중간 역할을 하는 형태입니다.
  • 예를 들어, 스프링에서는 Dispatcher Servlet이 프론트 컨트롤러 역할을 맡아 요청에 맞는 컨트롤러를 찾아 요청을 위임합니다.
  • 때문에 Spring MVC1보다 역할이 명확하게 분리되어, 유지보수성 및 확장성이 용이합니다."
공통,Spring,DispatcherServlet 이란?,"• Http 프로토콜로 들어오는 모든 클라이언트 요청을 최초로 받아 적합한 컨트롤러에 위임해주는 프론트 컨트롤러입니다. 프론트 컨트롤러란 서블릿 컨테이너의 제일 앞에서 서버로 들어오는 클라이언트의 모든 요청을 받아 처리해주는 컨트롤러입니다. web.xml에 맵핑되는 컨트롤러를 모두 등록해야 하던 것을, Dispatcher Servlet을 통해 모든 요청을 핸들링하고 공통 작업을 처리해주면서 web.xml의 역할이 축소되었습니다.
• 프론트 컨트롤러란 서블릿 컨테이너의 제일 앞에서 서버로 들어오는 클라이언트의 모든 요청을 받아 처리해주는 컨트롤러입니다.
• web.xml에 맵핑되는 컨트롤러를 모두 등록해야 하던 것을, Dispatcher Servlet을 통해 모든 요청을 핸들링하고 공통 작업을 처리해주면서 web.xml의 역할이 축소되었습니다."
공통,Spring,Dispatcher Servlet의 동작 과정에 대해서 설명해주세요.,"1. 첫 번째로, 클라이언트 요청이 들어오면 웹 컨텍스트를 지나 스프링 컨텍스트에 있는 Dispatcher Servlet이 가장 먼저 요청을 받습니다.
2. Dispatcher Servlet은 사용자가 요청한 URL을 기반으로 HandlerMapping을 통해 어떤 컨트롤러로 요청을 위임할 지 찾습니다.
3. 찾았다면 HandlerExecutionChain으로 감싸서 반환합니다.
  • 컨트롤러로 요청을 넘기기 전 처리해야하는 인터셉터 등을 포함하기 위해 감싸서 반환합니다.
4. 반환된 값을 기반으로 HandlerAdapter를 통해 컨트롤러로 요청을 위임합니다.
  • HandlerAdapter에서는 컨트롤러로 요청을 위임하기 전/후에 Interceptor와 @RequestParam, @RequestBody 등을 처리하기 위한
    ArgumentResolver들과 직렬화와 같은 기능을 처리하게 됩니다.
5. 요청을 위임받은 컨트롤러가 비지니스 로직을 수행 후 응답합니다.
  • 웹 페이지를 사용할 경우 View Name을 String으로 반환합니다.
  • 응답 데이터를 JSON으로 반환할 경우 주로 ResponseEntity를 반환하게 됩니다.
  • HandlerAdapter에서 반환된 값을 파악해 해당하는 것에 맞는 Converter를 이용하여 클라이언트로 반환합니다."
공통,Spring,"여러 요청이 들어온다고 가정할 때, DispatcherServlet은 한번에 여러 요청을 모두 받을 수 있나요?","• DispatcherServlet은 멀티스레드 환경에서 동작하므로 한 번에 여러 요청을 받아 처리할 수 있습니다.
• 각 요청은 별도의 스레드에서 처리되며, 이를 통해 동시에 여러 사용자의 요청을 처리할 수 있습니다."
공통,Spring,수많은 Controller 를 DispatcherServlet은 어떻게 구분 할까요?,"• DispatcherServlet은 요청 URL을 분석하여 해당 요청을 처리할 Controller를 결정합니다.
• 스프링에서는 HandlerMapping이 @Controller 어노테이션이 적용된 모든 컨트롤러를 찾아 파싱하여 HashMap<요청 정보, 처리할 대상>으로 관리합니다."
공통,Spring,"HandlerMapping, HandlerAdapter, HandlerInterceptor, ViewResolver 용어에 대해 설명해주세요.","HandlerMapping
  • 요청을 처리할 컨트롤러를 찾아주는 역할을 합니다.
  • 요청 URL, HTTP Method 등을 기준으로 적절한 핸들러를 찾아 DispatcherServlet에게 반환합니다.
HandlerAdapter
  • 요청을 컨트롤러로 위임하기 위한 어댑터입니다.
  • DispatcherServlet은 이를 이용해 각각의 핸들러 타입에 맞는 방식으로 요청을 처리합니다.
HandlerInterceptor
  • 핸들러의 처리 전/후에 특정 작업을 수행할 수 있게 해주는 역할을 합니다.
ViewResolver
  • 뷰를 반환하기 위한 리졸버입니다."
공통,Spring,IoC(Inversion of Control)에 대해 설명해 주세요.,"• IoC는 제어의 역전이라해서, 개발자가 아닌 다른 곳, 프레임워크 같은 곳에 제어권을 맡기는 것을 의미합니다.
• 예를 들어, 스프링의 경우 빈의 생성과 의존성 주입 등 여러가지 일을 스프링 컨테이너에서 하게 되는데, 이것을 개발자가 관리하지 않고 프레임워크에서 한다고 하여 제어의 역전이라고 부릅니다."
공통,Spring,IoC 컨테이너(Spring 컨테이너)란 무엇인가요?,"• 빈의 생명주기를 관리하고 의존성 주입과 같은 DI 역할을 도와주는 컨테이너입니다.
• 즉, Bean 객체를 담는 공간이라 볼 수 있는 곳으로 Bean 객체의 생명주기를 관리하고 생성된 객체에게 추가적인 기능을 제공합니다.
• 스프링에서는 BeanFactory, ApplicationContext, DI Container라고도 불립니다."
공통,Spring,IoC 컨테이너 동작과정에 대해 설명해주세요.,• XML 혹은 어노테이션 등의 Bean 설정을 읽어 Bean을 생성하고 Bean 간의 의존성을 주입합니다.
공통,Spring,BeanFactory과 ApplicationContext 차이에 대해 설명해주세요.,"BeanFactory와 ApplicationContext는 스프링에서 제공하는 IoC Container입니다.
이들은 빈의 생명주기를 관리하고 의존성 주입과 같은 DI 역할을 도와주는 컨테이너입니다.

그 중 BeanFactory는 컨테이너의 최상위 인터페이스로 스프링 빈을 관리하고 조회하는 역할을 합니다. 
그리고 ApplicationContext는 BeanFactory를 상속받은 인터페이스로 
빈 팩토리의 기능을 모두 수행하며 메시지 국제화, 이벤트 발행, 환경 변수와 같은 추가적인 기능을 수행합니다.

• BeanFactory
  • Spring 컨테이너의 최상위 인터페이스로 getBean() 메서드를 제공합니다.
  • 이는 Spring Bean을 관리하고 조회하는 역할을 담당합니다.
• ApplicationContext
  • BeanFactory의 자식 컨테이너로 BeanFactory보다 더 많은 기능을 수행합니다.
  • 예를 들어, 국제화 기능, 이벤트 발행, 환경 변수와 같은 추가적인 기능을 수행합니다."
공통,Spring,DI(Dependency Injection)에 대해 설명해 주세요.,"• 의존 관계를 외부에서 결정하는 것을 의존 관계 주입이라 합니다. 예를 들어, 자바에서 클래스 내 new 키워드로 직접 생성하는 것이 아닌, 외부에서 클래스를 생성할 때 생성자 매개변수로 넣어주는 것을 의미합니다.
• 예를 들어, 자바에서 클래스 내 new 키워드로 직접 생성하는 것이 아닌, 외부에서 클래스를 생성할 때 생성자 매개변수로 넣어주는 것을 의미합니다."
공통,Spring,주입 방식에 대해 설명해주세요.,"1. 필드 주입
  • 장점
    • 사용하기 편리 합니다.
  • 단점
    • 의존성이 외부에서 보이지 않아 의존 관계를 한 눈에 파악하기 힘듭니다.
    • 필드에 직접 주입되기 때문에, 테스트 시 어려움이 있습니다.
2. 세터 주입 (수정자 주입)
  • 장점
    • 선택적인 의존성을 가질 수 있습니다. 즉, 중간에 수정이 가능합니다.
  • 단점
    • 주입받지 않은 구현체를 사용할 가능성이 있어 NPE 문제가 발생할 수 있습니다.
3. 생성자 주입 (권장)
  • 장점
    • 의존 관계를 모두 주입해야만 객체 생성이 가능하기 때문에, NPE 문제가 방지됩니다.
    • 객체 생성 시, 모든 의존성이 주입되므로 객체의 불변성을 보장합니다.
    • 순환 참조를 컴파일 단계에서 찾아낼 수 있습니다."
공통,Spring,생성자 주입 방식을 사용하는 이유가 있나요?,"• 생성자 주입 방식을 사용하면, 객체가 생성될 때 모든 의존성이 주입되므로 객체의 불변성을 보장할 수 있습니다.
• 또한, 컴파일 단계에서 순환 참조를 방지할 수 있으며, 테스트에도 유리합니다. 이런 이유로 Spring에서는 생성자 주입 방식을 권장하고 있습니다."
공통,Spring,"DI를 진행할 때, @Autowired를 사용하는데, 어떤 식으로 의존 관계를 주입하는지 설명하세요.","1. 스프링 서버가 실행되면 ApplicationContext가 @Bean 혹은 그 외 어노테이션을 이용해 등록된 스프링 빈을 생성합니다.
2. 스프링 빈 생성 후, AutowiredAnnotationBeanPostProcessor 클래스의 processInjection() 메서드에서 @Autowired 어노테이션이 붙은 빈을 찾습니다.
3. 찾은 빈을 객체에 주입할 때 reflection을 이용해 의존성을 주입합니다.
  • reflection : 구체적인 클래스 타입을 몰라도, 해당 클래스의 메서드, 타입, 변수들에 접근할 수 있도록 해주는 자바 API"
공통,Spring,@Bean과 @Component 어노테이션 차이에 대해 설명해주세요.,"• @Bean: 개발자가 컨트롤이 불가능한 외부 라이브러리들을 Bean으로 등록하고 싶을 때, 메서드에 해당 어노테이션을 붙여 사용할 수 있습니다. 단, 클래스에 @Configuration을 붙어야 합니다. 예를 들어, ObjectMapper 클래스는 JSON 처리를 담당하는 외부 라이브러리 클래스이기 때문에, @Component 어노테이션을 붙여 개발자가 직접 수정할 수 없습니다. 하지만, @Bean 어노테이션을 이용해 메서드에서 new 키워드로 ObjectMapper를 생성하고 커스텀하여 반환하면 빈으로 등록할 수 있습니다.
• 개발자가 컨트롤이 불가능한 외부 라이브러리들을 Bean으로 등록하고 싶을 때, 메서드에 해당 어노테이션을 붙여 사용할 수 있습니다. 단, 클래스에 @Configuration을 붙어야 합니다.
• 예를 들어, ObjectMapper 클래스는 JSON 처리를 담당하는 외부 라이브러리 클래스이기 때문에, @Component 어노테이션을 붙여 개발자가 직접 수정할 수 없습니다.
• 하지만, @Bean 어노테이션을 이용해 메서드에서 new 키워드로 ObjectMapper를 생성하고 커스텀하여 반환하면 빈으로 등록할 수 있습니다.
• @Component: @Bean과 반대로 직접 컨트롤이 가능한 Bean들을 Spring에서 관리하기 위해 사용하는 어노테이션입니다.
• @Bean과 반대로 직접 컨트롤이 가능한 Bean들을 Spring에서 관리하기 위해 사용하는 어노테이션입니다."
공통,Spring,"@Repository, @Service, @Rest/Controller, @Rest/ControllerAdvice 어노테이션 등에 대해 설명하세요.","• @Repository
  • 데이터베이스에 접근하는 로직에 사용되는 어노테이션입니다.
  • Hibernate와 같은 영속성 프레임워크를 사용할 경우, 선언된 클래스에서 발생하는 영속성 예외를 스프링의 예외로 자동 전환합니다.
• @Service
  • 비즈니스 로직이나 Repository를 호출하는 클래스를 컴포넌트로 등록할 때 사용됩니다.
• @Controller
  • 일반적으로 웹 페이지 요청을 처리하는 클래스를 컴포넌트로 등록할 때 사용됩니다.
  • 보통 메서드가 View 이름을 반환하고 View 이름과 실제 뷰를 연결하는 작업이 필요합니다.
  • @Controller로 작성된 컨트롤러에서 JSON을 반환하려면 메서드에 @ResponseBody를 추가하면 됩니다.
• @RestController
  • RESTFul 웹 서비스 요청을 처리하는 클래스를 컴포넌트로 등록할 때 사용됩니다.
  • @Controller와 다르게 메서드가 데이터를 반환하고 이 데이터는 HTTP 응답 본문에 직접 쓰여집니다.
  • @RestController는 사실상 @Controller와 @ResponseBody가 결합된 형태입니다.
• @ControllerAdvice
  • ?
• @RestControllerAdvice
  • ?"
공통,Spring,@Component 을 메서드 레벨에 선언할 수 있을까요? 혹은 @Bean 을 클래스 레벨에 선언할 수 있을까요?,"• 결론부터 말씀드리자면, 둘 경우 모두 선언할 수 없습니다. 
• @Bean과 @Component 어노테이션은 각각 선언할 수 있는 타입이 정해져 있기 때문에, 해당 용도 외에 사용할 시 컴파일 에러가 발생합니다.
• 예를 들어 @Bean 같은 경우에는 @Target이 METHOD로 지정되어 있지만, TYPE은 없고,
• @Component 는 @Target이 TYPE로 지정되어 Class위에서만 선언될수 있음을 알 수 있습니다."
공통,Spring,싱글턴 스코프과 프로토타입 스코프 차이에 대해 설명해 주세요.,"• 싱글톤 스코프 (Default) 싱글턴 스코프의 스프링 빈은 스프링 컨테이너와 생명주기를 같습니다. 예를 들어, 싱글톤 스코프의 스프링 빈은 매번 Spring 컨테이너에서 동일한 인스턴스 참조 주소 값을 반환하고 스프링 컨테이너 종료 시, 소멸 메서드도 자동으로 실행됩니다. 정리: 기본 Scope로, Spring 컨테이너 내에 하나의 Bean 인스턴스만 생성합니다.
• 싱글턴 스코프의 스프링 빈은 스프링 컨테이너와 생명주기를 같습니다.
• 예를 들어, 싱글톤 스코프의 스프링 빈은 매번 Spring 컨테이너에서 동일한 인스턴스 참조 주소 값을 반환하고 스프링 컨테이너 종료 시, 소멸 메서드도 자동으로 실행됩니다.
• 정리: 기본 Scope로, Spring 컨테이너 내에 하나의 Bean 인스턴스만 생성합니다.
• 프로토타입 스코프 프로토타입 스코프의 스프링 빈은 스프링 컨테이너와 생명주기를 달리합니다. 예를 들어, 프로토타입 스코프의 스프링 빈은 Spring 컨테이너에 요청할 때마다 새로운 스프링 빈이 생성되고 의존 관계까지 주입 및 초기화 진행 후 반환합니다. 따라서 프로토타입 빈은 싱글턴 빈과는 다르게 소멸 메서드가 호출되지 않아 클라이언트가 프로토타입 빈을 직접 관리해야 합니다. 정리: 요청할 때마다 새로운 Bean 인스턴스를 생성합니다.
• 프로토타입 스코프의 스프링 빈은 스프링 컨테이너와 생명주기를 달리합니다.
• 예를 들어, 프로토타입 스코프의 스프링 빈은 Spring 컨테이너에 요청할 때마다 새로운 스프링 빈이 생성되고 의존 관계까지 주입 및 초기화 진행 후 반환합니다.
• 따라서 프로토타입 빈은 싱글턴 빈과는 다르게 소멸 메서드가 호출되지 않아 클라이언트가 프로토타입 빈을 직접 관리해야 합니다.
• 정리: 요청할 때마다 새로운 Bean 인스턴스를 생성합니다."
공통,Spring,Bean Scope 에 대해서 아시나요?,"Bean Scope는 Spring Bean이 존재할 수 있는 범위를 뜻합니다. 
기본적으로 Spring 컨테이너에서 스프링 Bean 이 싱글톤 스코프로 생성되기 때문에, Spring 컨테이너와 생명주기가 같아 신경쓸 필요가 없습니다.
하지만, Bean Scope를 어떻게 설정하느냐에 따라 Spring Bean의 생성과 소멸을 클라이언트에서 관리해야하는 경우도 생길 수 있습니다."
공통,Spring,싱글턴 스코프와 프로토타입 스코프 외의 웹 스코프 종류를 말해보세요.,"웹 스코프는 웹 환경에서만 동작하는 스코프로 스프링이 웹 스코프의 종료시점까지 관리하며, 종료 메서드도 호출됩니다.

웹 스코프 종류로는 다음과 같습니다.
• request: HTTP 요청이 들어오고 나갈 때까지 유지되는 스코프로 각각의 요청마다 별도의 빈 인스턴스가 생성 및 관리됩니다.
• session: HTTP Session과 동일한 생명주기를 가집니다.
• application: ServletContext와 동일한 생명주기를 가지는 스코프입니다.
• websocket: 웹소켓과 동일한 생명주기를 가지는 스코프입니다."
공통,Spring,스프링의 디폴트 스코프가 어떤 스코프인지 이유와 함께 설명하세요.,"• Spring의 기본 Bean Scope는 Singleton Scope입니다. 
• 이는 Spring이 객체의 생명 주기를 관리하고, 객체 간의 의존성을 관리하는 DI 컨테이너의 특성상, 
• 대부분의 경우에 하나의 Bean 인스턴스만을 생성하여 재사용하는 것이 효율적이기 때문입니다."
공통,Spring,프로토타입 스코프는 언제 사용할까요?,"• Prototype Scope는 요청할 때마다 새로운 Bean 인스턴스를 생성하므로, 여러 인스턴스를 검색해야 하는 경우 사용할 것 같습니다.
• 예를 들어, 여러 인스턴스 중 특정 인스턴스를 지연하거나 선택적으로 찾아야 하는 경우가 있을 것 같습니다."
공통,Spring,Spring의 Bean 생명 주기(Life Cycle)에 대해 설명해 주세요.,"Spring Bean은 스프링 컨테이너에 의해 관리 받습니다.
흐름은 다음과 같습니다.

1. 생성 : 스프링 컨테이너가 Bean 정의를 읽고 Bean 인스턴스를 생성합니다.
2. 의존 : 생성된 Bean 인스턴스는 생성자 주입 등의 방식으로 의존 설정이 일어납니다.
3. 초기화 : Bean이 InitalizingBean 인터페이스를 구현했거나, @PostConstruct 어노테이션이 붙은 메서드가 있다면 초기화가 수행됩니다.
  • Bean 객체가 InitialzingBean 인터페이스 구현 시, afterPropertiesSet() 메서드가 호출
4. 사용 : 이제 애플리케이션은 해당 Bean을 사용해 비즈니스 로직을 수행합니다.
5. 소멸 : 추가적으로 Bean이 DisposableBean 인터페이스를 구현했거나, @PreDestory 어노테이션이 붙은 메서드가 있으면 Bean이 소멸된다.
  • Bean 객체가 DisposableBean 인터페이스 구현 시, destory() 메서드가 호출된다.
    
이런 식으로 Spring 컨테이너는 Bean의 생명 주기를 관리한다."
공통,Spring,"Spring에서 후보 없이 특정 기능을 하는 클래스가 단 1개일 때에도, 왜 구체 클래스를 사용하지 않고 Spring Bean을 사용 할까요?"," • Spring에서는 Bean을 사용하여 객체의 생명 주기를 관리합니다. 
 • Bean을 사용하면 개발자는 객체 생성, 소멸 등의 생명 주기 관리와 같은 부수적인 작업을 하지 않아도 되며, 객체의 의존성을 자동으로 관리해줍니다. 
 • 또한, Bean을 사용하면 하나의 객체를 여러 컴포넌트에서 공유하여 사용할 수 있어 메모리 사용량을 줄일 수 있습니다."
공통,Spring,"DTO, VO, DAO, ENTITY의 각 정의를 말해주세요.","• DAO Database에 접근하는 역할을 가진 객체입니다. 데이터의 CRUD 작업을 시행하는 클래스입니다. 즉, 데이터에 대한 CRUD 기능을 전담하는 객체입니다.
• Database에 접근하는 역할을 가진 객체입니다.
• 데이터의 CRUD 작업을 시행하는 클래스입니다. 즉, 데이터에 대한 CRUD 기능을 전담하는 객체입니다.
• DTO 데이터를 전달하기 위한 객체입니다. 로직을 가지지 않는 순수한 데이터 객체입니다. 계층 간 데이터를 주고 받을 때 사용합니다.
• 데이터를 전달하기 위한 객체입니다.
• 로직을 가지지 않는 순수한 데이터 객체입니다.
• 계층 간 데이터를 주고 받을 때 사용합니다.
• VO 값 자체를 표현하는 객체입니다. VO는 Getter 메서드만 존재하고 Setter 메서드는 존재하지 않습니다. 단, 비즈니스 로직을 포함할 수 있습니다. VO는 두 객체의 모든 필드 값들이 동일하다면, 두 객체는 같다라는 것이 핵심 정의입니다. 완전히 값 자체 표현 용도로만 사용된다면, equals(), hashCode() 메서드를 오버라이딩 해야할 수도 있습니다.
• 값 자체를 표현하는 객체입니다.
• VO는 Getter 메서드만 존재하고 Setter 메서드는 존재하지 않습니다. 단, 비즈니스 로직을 포함할 수 있습니다.
• VO는 두 객체의 모든 필드 값들이 동일하다면, 두 객체는 같다라는 것이 핵심 정의입니다.
• 완전히 값 자체 표현 용도로만 사용된다면, equals(), hashCode() 메서드를 오버라이딩 해야할 수도 있습니다.
• Entity Database Table과 매핑되는 클래스입니다.
• Database Table과 매핑되는 클래스입니다."
공통,Spring,DAO와 Repository 차이를 아시나요?,"• 이 둘은 거의 같다고 생각합니다. 좀 더 깊이있게 차이를 설명하자면, 
• Repotiroy는 Entity 객체를 보관하고 관리하는 저장소라 생각합니다.
• DAO는 데이터에 접근하도록 Databasae에 접근 관련 로직을 모아둔 객체라 생각합니다.
• 즉, Repository는 객체 중심이고 DAO는 데이터 저장소인 Database 테이블 중심이라 생각합니다.
• 하지만 둘다 개념의 차이일뿐 실제로 개발할 때는 비슷하게 사용되는 것 같습니다."
AI,머신러닝,머신러닝이란 무엇인가?,"머신러닝은 인공지능의 한 분야로, 컴퓨터가 데이터를 통해 스스로 학습하고 예측 및 결정을 내리는 알고리즘과 기술들을 연구하는 분야이다. 머신러닝 모델은 데이터로부터 패턴을 학습하며, 새로운 데이터에 대한 예측이나 분류를 수행할 수 있다. 이를 통해 수동적인 프로그래밍 대신 데이터를 기반으로 한 예측 및 의사결정을 할 수 있다."
AI,딥러닝,머신러닝과 딥러닝의 차이점은 무엇안가?,"머신러닝은 컴퓨터가 데이터를 통해 학습하는 알고리즘과 기술들을 포함하는 분야이다. 딥러닝은 머신런이의 한 부분으로, 인공싱경만(Artificial Neural Networks)을 기반으로 한 방법론입니다. 딥러닝은 복잡한 문제를 해결하기 위해 다양한 계층(layer)으로 구성된 신경망을 사용하여 데이터의 추상적인 표현을 학습한다. 딥러닝은 특히 대용량 데이터를 처리하할 때 높은 성능을 보이며, 이미지 인식, 자연어 처리 등의 복잡한 문제를 해결하는 데 사용되고 있다."
AI,머신러닝,머신러닝 알고리즘의 주요 종류는 무엇인가?,"머신러닝 알고리즘은 크게 지도학습(Supervised Learning), 비지도학습(Unsupervised Learning), 준지도학습(Semi-supervised Learning), 강화학습(Reinforcement Learning)으로 나눌 수 있다. 대표적인 알고리즘으로는 선형 회귀(Linear Regression), 로지스틱회귀(Logistic Regression), 서포트 벡터 머신(SVM), 의사결정 트리(Decision Tree), 랜덤 포레스트(Random Forest), k-최근접 이웃(K-NN), 신경망(Neural Networks)등이 있다."
AI,머신러닝,지도학습이란 무엇이며 언제 사용되는가?,"지도학습은 레이블이 있는 데이터를 사용하여 모델을 학습하는 방법이다. 지도학습 알고리즘은 입력 데이터와 해당 데이터의 정답(레이블)을 이용해 학습하며, 새로운 데이터에 대한 예측이나 분류를 수행할 수 있다. 지도학습은 주로 분류(Classification)와 회귀(Regression)문제를 해결하는 데 사용된다. 분류 문제는 데이터를 미리 정의된 클래스로 분류하는 것으로, 이진 분류(Binary Classification)와 다중 클래스 분류(Multiclass Classification)로 나눌 수 있다. 회귀 문제는 데이터를 통해 연속적인 값을 예측하는 것으로, 주택 가격 예측이나 주식 가격 예측 등과 같은 문제를 해결할 때 사용된다."
AI,머신러닝,"비지도학습이란 무엇이며, 언제 사용되는가?","비지도 학습은 레이블이 없는 데이터를 사용하여 모델을 학습하는 방법이다. 비지도학습 알고리즘은 레이블이 없는 데이터에서 패턴, 구조, 상관곤계 등을 찾아내는 데 사용됩니다. 비지도학습은 주로 군집화(Clustering)와 차원 축소(Dimensionality Reduction)문제를 해결하는 데 사용된다. 군집화는 유사한 특성을 갖는 데이터를 그룹으로 묶는 것이며, 차우너 축소는 데이터의 차원을 줄이면서 중요한 정보를 유지하는 것이다. 이러한 비지도 학습 기법은 데이터 시각화, 데이터 전처리, 특성 추출 등에 활용된다."
AI,머신러닝,"강화학습이란 무엇이며, 어떻게 작동하는가?","강화학습은 에이전트(agent)가 환경(environment)과 상호작용하며, 보상(reward)을 최대화하는 행동(action)을 학습하는 머신러닝의 한 방법이다. 에이전트는 상태(state)를 관찰하고 행동을 취한 후, 그 결과로 보상을 받는다. 보상은 긍정적이거나 부정적일 수 있으며, 에이전트는 누적 보상을 최대화하는 행동을 학습하려고 한다. 강화학습은 게임, 로봇 제어, 자율 주행 차량 등 다양한 분야에서 적용되고 있다."
AI,머신러닝,분류와 회귀의 차이점은 무엇인가?,"분류는 데이터를 미리 정의된 클래스로 나누는 문제이다. 이진 분류는 두 개의 클래스로 나누는 문제이며, 다중 클래스 분류는 세 개 이상의 클래스로 나누는 문제이다. 반면 회귀는 연속적인 값을 예측하는 문제이다. 회귀 문제의 예로는 주택 가격 예측, 주식 가격 예측 등이 있다. 분류와 회귀의 주요 차이점은 출력 변수의 형태이다. 분류에서 범주형 변수를 예측하고, 회귀에서는 연속형 변수를 예측한다."
AI,머신러닝,"k-최근접 이유(k-NN) 알고리즘은 무엇이며, 어떻게 작동하는가?","k-최근접 이유 알고리즘은 분류 및 회귀 문제를 해결하는 데 사용되는 지도학습 방법이다. k-NN 알고리즘은 새로운 데이터 포인트에 대한 예측을 수행하기 위해 주변의 k개의 가장 가까운 이웃 데이터 포인트를 참조한다. 이웃들의 클래스 또는 값을 분석하여 새 데이터 포인트의 클래스 또는 값을 예측한다. 분류에서는 가장 많은 이웃을 가진 클래스를 선택하고, 회귀에서는 이웃 값의 평균을 계산한다. k-NN은 새로운 데이터에 대한 예측이 이웃 데이터 포인트와 유사할 것이라는 가정이 기반한다."
AI,머신러닝,"서포트 벡트 머신(SVM)이란 무엇이며, 언제 사용되는가?","서포트 벡터 머신은 지도 학습 알고리즘으로, 주로 분류 및 회귀 문제에 사용된다. SVM의 핵심 아이디어는 클래스 간의 마진을 최대화하는 초평면(hyperplane)을 찾는 것이다. 마진은 초평면과 가장 가까운 데이터 포인트(서포트 벡트) 사이의 거리로 정의된다. 이렇게 하면 새로운 데이터에 대한 일반화 성능이 향상된다. 비선형 문제에 대해서는 커널 트릭(kernel tirck)을 사용하여 고차원 공간으로 변환한 후 초평면을 찾는다. SVM은 이미지 인식, 텍스트 분류, 생물정보학 등 다양한 분야에서 좋은 성능을 보여주며, 작은 데이터셋에서도 효과적이다."
AI,머신러닝,"의사결정 트리(Decision Tree)알고리즘이란 무엇이며, 어떻게 작동하는가?","의사결정 트리는 분류 및 회귀 문제에 사용되는 지도학습 알고리즘이다. 데이터를 분석하여 일련의 질문과 결정을 통해 결과를 도출하는 트리 구조를만든다. 각 노드는 특정 속성에 기밚나 질문이며, 각 분기는 해당 질문에 대핞 의사결정을 나타낸다. 잎 노드는 최종 에측 클래스 또는 값을 나타낸다. 의사결정 트리는 의사결정 과정을 이해하기 쉽고 해석하기 쉬운 시각적 표현을 제공한다. 작동 원리는 재귀적 분할을 통해 데이터를 순수한 하위 집합으로 나누는 것이다. 이 분할은 엔트로피, 지니 불순도 등의 기준에 따라 결정된다."
AI,머신러닝,랜덤 포레스트(Random Forest)와 그래디언트 부스팅(Gradient Boosting)의 차이점은 무엇인가?,"랜덤 포레스트와 그래디언 부스팅은 모두 앙상블 기법을 사용하는 머신러닝 알고리즘이다. 랜덤 포레스트는 여러 개의 의사결정 트리를 만드록, 각 트리의 예측 결과를 집계하여 최종 결과를 얻는다. 이 트리들은 독립적으로 생성되며, 부스트트랩 샘플링과 특성 무작위를 선택을 사용하여 다양성을 부여한다. 그래디언트 부스팅은 순차적으로 개선된 여러 의사결정 트리를 만들어 학습한다. 각 트리는 이전 트리의 오차를 줄이는 방향으로 학습되며, 경사하강법을 사용하여 손실 함수를 최소화한다. 그래디언트 부스팅은 일반적으로 더 나은 성능을 제공하지만, 랜덤 포레스트보다 학습 시간이 오래 걸린다."
AI,머신러닝,군집화 알고리즘의 종류와 특징을 설명하시오.,"군집화는 비지도학습 기법으로, 데이터를 유사한 그룹으로 분류하는 과정이다. 주요 군집화 알고리즘은 다음과 가탇."
AI,머신러닝,"주성분 분석(PCA)이란 무엇이며, 왜 사용되는가?","주성분 분석(PCA)은 차원 축소 기법 중 하나로, 고차원 데이터에서 주요한 변동성을 설명하는 새로운 축을 찾아 데이터를 낮은 차원으로 투영한다. 이 과정은 공분산 행렬의 고유벡터와 고유값 분석을 통해 이루어진다. PCA는 다음과 같은 목적으로 사용된다. 데이터 시각화, 노이즈 제거, 계산 효율성 향상, 특성 간 상관성 제거 등"
AI,머신러닝,"교차 검증(cross-validation)이란 무엇이며, 어떻게 사용되는가?","교차 검증은 머신러닝 모델의 성능을 평가하고 일반화 능력을 측정하는 방법이다. 데이터 세트를 여러 개의 하위 집합으로 나누고, 이를 통해 모델을 반복적으로 훈련 및 검증하는 과정을 거칩니다. 이 과정에서 사용되는 대표적인 교차 검증 방법은 K-겹 교차 검증이다. 데이터를 K개의 동일한 크기의 부분으로 집합으로 나눈 후, k-1개의 부분 집합으로 모델을 훈련하고 나머지 하나의 부분 집합으로 모델을 검증한다. 이 과정을 K번 반복하며, 각 반복마다 다른 부분 집합을 검증 데이터로 사용한다. 최정적으로 K개의 결과를 평균내어 모델의 성능을 평가한다. 교차 검증을 사용하면 모델이 훈련 데이터에 과적합되는 것을 방지하고, 모델의 일반화 능력을 높일 수 있다."
AI,머신러닝,"정규화(regularization)란 무엇이며, 왜 필요한다?","정규화는 머신러닝 모델의 복잡성을 줄이고 과적합을 방지하기 위한 기법이다. 이는 모델의 가중치에 일정한 제약을 부과하여, 가중치가 너무 커지지 않도록 한다. 정규화를 사용하면 모델이 훈련 데이터에 너무 적합하지 않아 일반화 능력이 향상된다. 대표적인 정규화 방법으로는 L1 규제와 L2 규제가 있다."
AI,머신러닝,과적합(overfiting)과 과소적합(underfition)의 차이점은 무엇인가?,"과적합은 모델이 훈련 데이터에 지나치게 적합하여, 새로운 데이터에 대한 일반화 성능이 저하되는 현상입니다. 이는 모델이 훈련 데이터의 노이즈까지 학습하여 발생합니다. 반면 과소적합은 모델이 훈련 데이터를 충분히 학습하지 못해, 훈련 데이터와 새로운 데이터 모두에 대한 성능이 저하되는 현상이다. 이는 모델의 복잡성이 너무 낮거나 학습이 제대로 이루어지지 않을 때 발생한다."
AI,통계,"정확도(accuracy), 정밀도(precision), 재현율(reclaa)의 차이점은 무엇인가?","ROC(Receiver Operating Characteristic) 곡선은 이진 분류 문제에서 모델으 성능을 평가하는 데 사용되는 그래프이다. ROC 곡선은 False Positive Rate(FPR)을 x 축으로, True Positive Rate(TPR, 재현율)을 y축으로 놓고, 다양한 분류 임계에 대해 그린 곡선이다. 이 곡선은 모델의 성능이 얼마나 민감한지를 보여준다.-AUC(Area Under the Curve)는 ROC 곡선 아래의 면적을 나타내며, 모델의 성능을 하나의 숫자로 표현하는 데 사용된다. AUC 값이 1에 가까울수록 모델의 성능이 좋다고 평가할 수 있으며, 0.5는 무작위 예측과 동일한 성능을 의미한다."
AI,통계,ROC 곡선과 AUC의 개념을 설명하시오.,하이퍼파라미터 최적화는 머신러닝 모델의 성능을 향상시키기 위해 모델의 하이퍼파라미터를 조정하는 과정이다. 주요 하이퍼파라미터 최적화 방법에는 다음과 같은 것들이 있다.
AI,딥러닝,하이퍼파라미터 최적화 방법들에 대해 설명하시오.,"그리드 탐색은 하이퍼파라미터 공간을 균일하게 탐색하여 최적의 하이퍼파라미터 조합을 찾는 방법이다. 이 방법은 모든 가능한 조합을 시도하므로 계산 비용이 높을 수 있지만, 완전한 탐색을 수행한다. 그리드 탐색은 하이퍼파라미터의 가능한 값들을 미리 정의하고, 이들의 조합을 시스템적으로 탐색하며, 교차 검증을 사용하여 모델의 성능을 평가한다."
AI,딥러닝,그리드 탐색(Grid Search)과 랜덤 탐색(Random Search)의 차이점은 무엇인가?,"특성 선택은 머신러닝 모델의 성능을 향상시키기 위해 중요한 특성만 선택하고, 불필요한 특성을 제거하는 과정이다. 특성 선택의 주요 목적은 다음과 같다."
AI,머신러닝,특성 선택(feature selection)의 목적과 방법들에 대해서 설명해주세요.,차원 축소는 고차원 데이터를 저차원 공간으로 변환하는 과정이다. 차원 축소의 주요 목적은 다음과 같다.
AI,머신러닝,차원 축소(dimensionality reduction)의 목적과 기법들에 대해 설명하시오.,"데이터 전처리는 머신러닝 프로젝트에서 매우 중요한 단계로, 모델 성능에 큰 영향을 미친다. 전처리 과정에서 이루어지는 주요 작업들은 다음과 같다."
AI,머신러닝,"머신러닝 프로젝트를 진행할 때, 데이터 전처리 과정에서 이루어지는 작업들은 무엇이 있는가?",데이터 불균형은 머신러닝에서 클래스 라벨의 분포가 고르지 않은 상황을 의미한다. 이러한 불균형은 모델이 소수 클래스에 대해 제대로 학습하지 못하게 만들어 성능 저하를 초래할 수 있다. 데이터 불균형을 해결하기 위한 주요 방법들은 다음과 같다.
AI,머신러닝,"데이터 분균형이란 무엇이며, 이를 해결하기 위한 방법들을 설명하시오.",다중 공선성은 머신러닝에서 독립 변수들 간에 강한 상관관계가 존재하는 상황을 의미한다. 다중 공선성이 발생하면 다음과 같은 문제가 발생할 수 있다.
AI,통계,"다중 공선성(multicollinearity)이란 무엇이며, 왜 문제가 되는지 설명하시오. 이를 해결하는 방법은 무엇인가?","앙상블 학습은 어러 개의 기본 학습 모델을 결합하여 전체적인 예측 성능을 향상시키는 머신러닝 기법이다. 이 방법은 개별 모델의 단점을 서로 상쇄하고 강점을 조합함으로써, 더 안정적이고 정확한 예측 결과를 도출할 수 있다. 주요 앙상블 기법들은 다음과 같다."
AI,머신러닝,Data mining과 machine learning의 차이점,데이터 마이닝이란 용어는 데이터를 마이닝하여 패턴을 추출하는 것에 해당합니다. 많은 양의 데이터에서 지식을 추출합니다. 머신러닝은 학습할 수 있도록 하는 알고리즘을 개발하는 연구입니다.
AI,딥러닝,인공 지능과 머신 러닝의 차이점,"인공지능은 머신러닝보다 더 큰 개념입니다. 인공지능은 인간 두뇌의 인지 기능을 모방하고, AI의 목적은 알고리즘을 기반으로 지능적으로 작업을 수행하는 것입니다. 반면에 머신러닝은 인공지능의 하위 개념이며, 프로그래밍 되지 않고 학습할 수 있도록 머신을 개발하는 것이 목표입니다."
AI,머신러닝,5가지 인기 있는 기계 학습 알고리즘,머신러닝 알고리즘을 선택할 수 있는 몇 가지 옵션이 있습니다. 시스템 요구 사항에 따라 적절한 알고리즘을 선택할 수 있습니다.
AI,머신러닝,머신 러닝과 빅데이터의 차이점,빅데이터는 대용량 데이터 세트(Big data라고 함)를 수집하고 분석하는 접근 방식입니다. 빅데이터의 목적은 조직에 도움이 되는 대용량 데이터에서 유용한 숨겨진 패턴을 발견하는 것입니다. 이에 반해 머신러닝은 명시적인 지시 없이 어떤 작업도 수행할 수 있는 지능적인 장치를 만드는 연구입니다.
AI,머신러닝,의사결정나무의 장단점,"Decision tree는 모든 내부 노드(Node)가 속성에 대한 '테스트(test)'를 의미합니다. 모든 분기가 테스트 결과를 나타내고, 각 리프(leaf) 노드가 클래스 레이블을 나타내는 순사도와 같은 구조를 가집니다. 루트(Root)에서 리프(leaf)까지의 경로를 분류 규칙이라고도 합니다."
AI,머신러닝,"Inductive Machine Learning과, Deductive Machine Learning을 비교하여 설명",연역적 머신러닝은 어떤 방식으로든 증명할 수 있는 지식을 학습하기 위한 알고리즘을 연구합니다. 문제 해결 속도를 높이기 위해 일반적으로 기존 지식을 활용하여 연역적으로 지식을 추가하여 사용합니다.
AI,머신러닝,분류 문제에 적합한 기계 학습 알고리즘을 선택하는 데 필요한 단계,"첫째, 데이터, 제약 조건 및 문제에 대해 파악해야 합니다."
AI,머신러닝,Training Set과 Test Set의 차이,"머신러닝에서 학습에 사용되는 데이터가 training set이고, 이를 검증하기 위해 사용하는 데이터가 test set입니다."
AI,머신러닝,과적합(Overfitting)이란?,머신 러닝에서 training set에만 맞게 모델이 학습된 경우를 과적합이라고 합니다. 이는 모델이 training set의 세부 정보와 노이즈를 획득하여 너무 복잡한 모델을 만든 경우인데요. 새 데이터에서도 중요한 데이터라 인식해버려 잘 맞지 않는 현상을 말합니다.
AI,머신러닝,해시 테이블이란?,"해시 테이블은 각 데이터에 고유한 인덱스 값이 있는 정렬된 배열로 데이터를 쌓는 데이터 구조입니다. 즉, 데이터는 연관 방식으로 저장됩니다."
AI,딥러닝,경사하강법이란?,경사하강법은 모델의 매개변수를 업데이트하는데 사용됩니다. 함수를 가장 단순한 형태로 최소화할 수 있는 최적화 알고리즘입니다. 여기서 최소화하는 함수는 손실 함수로 이 값이 최소가 될 때의 매개변수 값이 최적화 된 값입니다.
AI,머신러닝,차원 축소를 위한 몇 가지 특징 추출 기법을 언급하시오,독립변수에 해당하는 feature를 통해 종속변수인 target을 예측하고 분류하는 문제이다.
AI,머신러닝,Decision tree을 Pruned 하는 방법,Pruning은 가지치기라고 합니다. 가지치기는 복잡도를 줄이고 예측의 정확도를 올립니다.error를 제거하고 cost 복잡성을 제거하면서 수행할 수 있습니다.
AI,머신러닝,Model Accuracy와 Model Performance 중 어떤 것이 필수입니까?,모델 정확도는 머신러닝 모델의 가장 중요한 특성이므로 모델 성능보다 중요합니다.
AI,딥러닝,푸리에 변환을 정의,푸리에 변환은 입력으로 시간이 걸리고 파형을 구성하는 주파수로 분해하는 수학 함수입니다.
AI,통계,True positive rate와 Recall의 관계,True positive rate와 Recall은 같습니다. Recall이 실제 positive를 positive라고 예측한 비율을 의미하기 때문입니다.
AI,통계,'Naive' Bayes가 'Naive'라고 불리는 이유,"Naive bayes는 단순한 확률적 분류법을 사용하는 classifier입니다. 확률 모델에 베이즈 정리를 사용하여 유도되고, 실제로는 생길 수 없는 강한 독립 가정을 포함한다는 사실로부터 naive라는 말을 사용하였습니다."
AI,통계,"Likelihood, Prior, Posterior 의미",상관 관계란 얼마나 밀접하게 관련된 두 변수가 선형인지를 측정하는 것입니다.
AI,통계,연속형 변수와 범주형 변수 간의 상관 관계 측정 방법,상관 관계란 얼마나 밀접하게 관련된 두 변수가 선형인지를 측정하는 것입니다.
AI,통계,모델 정확도를 평가하기 위해 가장 자주 사용되는 metric 정의,분류 정확도는 모델 정확도를 평가하는데 가장 자주 사용되는 metric입니다. 전체 예측 샘플 수에 대한 올바른 예측의 비율이 얼마큼 되는지가 분류 정확도입니다.
AI,머신러닝,SVM은 언제 사용하나요?,서포트 벡터 머신은 분류와 회귀 문제를 해결하는데 사용할 수 있습니다.
AI,머신러닝,PCA에 회전이 필요한가요?,PCA는 특성들이 통계적으로 상관 관계가 없도록 데이터셋을 회전시키는 기술입니다. 원래 변수들 사이의 겹치는 부분을 제거함으로써 변수를 줄입니다.
AI,딥러닝,딥러닝이란 무엇인가?,"딥러닝은 인공 신경망(Artificial Neural Networks, ANN)을 기반으로 한 머신러닝의 한 분야이다. 딥러닝 모델은 여러 층의 뉴런으로 구성되어 있으며, 이를 통해 복잡한 데이터에서 패턴을 학습하고 추출할 수 있다. 대표적인 딥러닝 모델로는 컨볼루션 신경망(CNN), 순환 신경망(RNN), 변환자(Transformer)등이 있다."
AI,딥러닝,왜 딥러닝이 인공지능에 큰 영향을 미치고 있는가?,"딥러닝 기술의 성장과 발전은 인공지능 분야 전반에 큰 영향을 미치고 있다. 따라서 딥러닝은 인공지능의 핵심 기술로 인식되며, 앞으로도 계속해서 연구와 개발이 활발하게 진행될 것으로 예상된다."
AI,딥러닝,주요 딥러닝 알고리즘은 어떤 것들이 있나?,"주요 딥러닝 알고리즘에는 합성곱(CNN), 순환 신경망(RNN), 장단기 메모리(LSTM), 게이트 순환 유닛(GRU), 생성적 적대 신경망(GAN), 오토인코더(Autoencoder)등이 있다."
AI,딥러닝,"합성곱 신경망(CNN)이란 무엇이고, 언제 사용되는가?","CNN은 주로 이미지 인식과 관련된 문제를 해결하기 위한 딥러닝 구조이다. CNN은 합성곱 계층과 풀링 계층을 사용하여 이미지의 지역적 특징을 추출하고, 이를 기반으로 이미지를 분류하거나 다른 작업ㅇ르 수행한다. CNN은 이미지 분류, 객체 탐지, 이미지 생성, 시맨틱 분할 등 다양한 이미지 처리 작업에 활용되는 신경망이다."
AI,딥러닝,"순환 신경망(RNN)이란 무엇이고, 어떤 경우에 사용되는가?","RNN은 시퀀스 데이터를 처리하는 데 적합한 딥러닝 구조이다. RNN은 내부에 순환 구조를 가지고 있어 과거의 정보를 기억하고 이를 기반으로 시퀀스의 다음 값을 예측하거나 분류하는 데 사용된다. RNN은 자연어 처리, 음성 인식, 시계열 데이터 분석 등에 사용되는 신경망이다."
AI,머신러닝,강화학습이란 무엇이며 어떤 문제에 적합한가?,"강화학습은 에이전트가 환경과 상화작용하며 보상을 최대화하는 행동을 학습하는 머신러닝 방법이다. 강화학습은 의사결정, 로봇 제어, 자율주행 자동차, 게임 인공지능 등에 적합한 기법이다. 강화학습은 순차적인 의사결정 문제를 해결하는 데 특히 유용하다."
AI,딥러닝,역전파 알고리즘이란 무엇이며 왜 중요한가?,역전파(Backpropagation)는 신경망에서 사용되는 가중치를 최적화하기 위한 알고리즘이다. 손실 함수를 통해 게산된 오차를 출력층에서 입력층으로 거꾸로 전파하면서 각 가중치의 기울기를 계산하고 업데이트를 한다. 이를 통해 신경망의 학습이 가능해진다. 역전파는 딥러닝의 핵심 알고리즘으로 신경망의 성능 향상에 기여한다.
AI,딥러닝,딥러닝에서 사용되는 활성화 함수의 종류와 특징을 설명하시오.,"활성화 함수는 신경망의 비선형성을 추가하는 역할을 한다. 주요 활성화 함수에는 시그모이드(Sigmoid), 하이퍼볼릭 탄젠트(Tanh), 렐루(ReLU), 리키 렐루(Leaky ReLU), 소프트맥스(Softmax)등이 있다. 각 함수의 특징과 사용 사례에 따라 선택된다."
AI,딥러닝,"드롭아웃(dropout)이란 무엇이며, 왜 사용되는가?","드롭아웃은 학습 과정에서 일부 뉴런을 무작위로 비활성화하는 기법이다. 이를 통해 신경망의 과적합을 방지하고 일반화 성능을 향상시키는 데 도움이 된다. 드롭아웃은 각 뉴런이 독립적으로 학습되도록 강제함으로써 네트워크의 복잡도를 줄이고, 다양한 구조를 학습할 수 있게 한다."
AI,딥러닝,"배치 정규화(batch normalization)이란 무엇이며, 어떻게 동작하는가?","배치 정규화는 학습 과정에서 각 층의 입력 분포를 정규화하여 신경망의 학습을 더 빠르게 진행시키는 기법이다. 배치 정규화는 각 층의 입력에 대해 평균과 분산을 계산하고, 이를 이용해 정규화를 수행한다. 이를 통해 기울기 소실 문제를 완화하고, 학습률을 높게 설정할 수 있으며, 일반화 성능도 향상된다."
AI,딥러닝,딥러닝 모델의 손실 함수를 최적화하기 위해 사용되는 최적화 알고리즘은 어떤 것들이 있나?,"딥러닝 모델의 손실 함수를 최적화하기 위한 주요 알고리즘에는 확률적 경사 하강법(SGD), 모멘텀(Momentum), 아다그라드(Adagrad), 알엠에스프롭(RMSprop), 아담(Adam), 아다델타(Adadelta), AdamW등이 있다."
AI,딥러닝,확률적 경사하강법(SGD)과 아담(Adam) 최적화 알고리즘의 차이점은 무엇인가?,"확률적 경사 하강법(SGD)은 손실 함수의 그래디언트를 따라 하강하는 방식으로 가중치를 업데이트하는 방법이다. SGD는 간닪나 구조와 빠른 계산 속도가 장점이지만, 학습률 조절이 어렵고, 특정 상황에서 최적화가 느리게 진행될 수 있다."
AI,딥러닝,L2 규제와 L2 규제의 차이점은 무엇인가?,L1 규제와 L2 규제는 신경망 모델의 괒거합을 방지하기 위해 가중치에 적용되는 규제 기법이다.
AI,딥러닝,"전이학습(transfer learning)이란 무엇이고, 어떤 상황에서 사용되나?","전이학습은 이미 학습된 신경망 모델의 일부를 새로운 문제에 적용하여 빠르게 학습하는 기법이다. 전이 학습은 특히 학습 데이터가 부족한 상황이나, 새로운 문제가 기존 문제와 유사한 특성을 가질 때 효과적이다. 예를 들어, 사전에 학습된 이미지 분류 모델을 사용하여 새로운 카테고리의 이미지 분류 문제를 빠르게 해결할 수 있다."
AI,딥러닝,"데이터 증강(data augmentation)이란 무엇이며, 왜 사용하는가?","데이터 증강은 기존 학습 데이터를 변형하여 새로운 학습 데이터를 생성하는 기법이다. 데이터 증강을 통해 학습 데이터의 다양성을 높여 모델의 일반화 성능을 향상시킬 수 있다. 데이터 증강은 주로 이미지, 오디오 등의 비정형 데이터에 적용되며, 회전, 반전, 조명 변화, 노이즈 추가 등 다양한 변형 방법을 사용할 수 있다."
AI,딥러닝,오토인코더(autoencoder)와 생성적 적대 신경망(GAN)의 차이점은 무엇인가?,"오토인코더는 입력 데이터를 저차원 표현으로 압축하고 다시 복원하는 비지도 학습 모델이다. 데이터 압축, 노이즈 제거, 특성 추출 등의 목적으로 사용된다. 오토인코더는 인코더와 디코더로 구성되며, 인코더는 입력 데이터를 표현 벡터로 압축하고, 디코더는 표현 벡터를 원본 데이터로 복우너한다."
AI,딥러닝,"어텐션 메커니즘(attention mechanism)이란 무엇이며, 어던 문제에 도움이 되나?","어텐션 메커니즘은 입력 데이터의 중요한 부분에 가중치를 부여하여 모델의 성능을 향상시키는 기법이다. 기존의 시퀀스-투-시퀀스 모델에서는 입력 데이터의 정보를 고정된 길이의 벡터로 압축하는데, 이 때 중요한 정보가 손실될 수 있다. 어텐션 메니즘은 이를 해결하기 위해 각 시간 단계의 정보가 가중치를 부여하여 중요한 정보를 집중적으로 활용할 수 있게 한다. 어텐션 메커니즘은 번역, 텍스트 요약, 질문-답변 등 다양한 자연어 처리 문제에 적용되어 성능 향상을 이루어 냈다."
AI,딥러닝,"시퀀스-투-시퀀스(sequence-to-sequence)모델이란 무엇이고, 어떤 경우에 사용되는가?","시퀀스-투-시퀀스 모델은 입력 시퀀스를 다른 도메인의 출력 시퀀스로 변환하는 딥러닝 모델이다. 일반적으로 인코더와 디코더로 구성되며, 인코더는 입력 시퀀스를 고정된 길이의 표현 벡터로 압축하고, 디코더는 표현 벡터를 출력 시퀀스로 변환한다. 시퀀스-투-시퀀스 모델은 기계 번역, 음성 인식, 텍스트 요약, 대화 몯레 등 다양한 시퀀스 기반 문제에 사용된다."
AI,딥러닝,딥러닝에서의 하이퍼파라미터 최적화 방법은 어떤 것들이 있나?,"딥러닝에서의 하이퍼파라미터 최적화 방법은 다양한다. 대표적으로 그리드 탐색(Grid Search), 랜덤 탐색(Random Search), 베이지안 최적화(Bayesian Optimization), 유전 알고리즘(Genetic Algorithm), 그리고 하이퍼밴드(Hyperband)등이 있다. 이러한 방법들은 각각 다른 탐색 전략을 사용하여 하이퍼파라미터 공간에서 쵲거의 조합을 찾는다. 최적화 방법 선택은 문제의 복잡성, 연산 지원, 시간 등에 따라 달라질 수 있다."
AI,딥러닝,딥러닝 모델의 성능을 평가하는 지표들은 어떤 것들이 있나?,"딥러닝 모델의 성능 평가 지표는 문제의 종류에 따라 다릅니다. 회귀 문제의 경우, 평균 제곱 오차(Mean Squared Error, MSE), 평균 절대 오차(Mean Absolute Error, MAE) 등이 사용됩니다. 분류 문제에서는 정확도(Accuracy), 정밀도(Precision), 재현율(Recall), F1 스코어(F1 score) 등이 사용되며, 멀티 클래스 문제의 경우, 마이크로(micro) 및 매크로(macro) 평균 등의 평가 방법이 추가로 사용됩니다. 또한, AUC-ROC(Receiver Operating Characteristic curve)와 같은 지표도 사용됩니다."
AI,통계,"정밀도(precision), 재현율(recall), F1 스코어(F1 score)의 차이점은 무엇인가요?",이 문제를 해결하기 위해 다음과 같은 방법을 사용할 수 있다.
AI,딥러닝,딥러닝 모델의 학습 속도를 향상시키기 위한 전략들은 무엇인가?,이 문제를 해결하기 위해 다음과 같은 방법을 사용할 수 있다.
AI,딥러닝,"딥러닝 모델의 크기가 클 때, 어떤 어려움이 발생하며 이를 해결하는 방법은 무엇인가?",이 문제를 해결하기 위해 다음과 같은 방법을 사용할 수 있다.
AI,딥러닝,"딥러닝 프레임워크 중 어떤 것들을 경험해 보았으며, 각각의 장단점은 무엇인가?","TensorFlow: 구글이 개발한 딥러닝 프레임워크로, 다양한 기능과 커뮤니티 지원이 장점입니다. 그러나 초보자에게는 사용하기 어려울 수 있습니다.Keras: TensorFlow를 기반으로 하는 고수준 API로, 사용하기 쉽고 직관적인 구조가 장점입니다. 그러나 낮은 수준의 커스터마이징이 어려울 수 있습니다.PyTorch: 페이스북이 개발한 딥러닝 프레임워크로, 동적 계산 그래프와 쉬운 디버깅이 장점입니다. 그러나 TensorFlow보다 지원하는 기능이 상대적으로 적을 수 있습니다.JAX : 구글 연구팀이 개발한 고성능 머신러닝 프레임워크로, 파이썬과 NumPy를 기반으로 하면서 자동 미분, XLA 컴파일러를 통한 GPU/TPU 가속화를 지원하여 딥러닝 및 수치 연산 작업을 빠르게 수행할 수 있다."
AI,딥러닝,모델의 설명 가능성(XAI)이 왜 중요한가? 이를 향상시키기 위한 기법들은 어떤 것들이 있는가?,"설명 가능성이 중요한 이유는 모델의 예측을 이해하고 신뢰할 수 있어야 하며, 잘못된 추론을 수정하거나 개선할 수있어야 한다. 또한, 법적 요구사항이나 윤리적 책임을 충족하기 위해서도 중요하다."
AI,통계,고유값(eigen value)와 고유벡터(eigen vector)이 무엇이고 왜 중요한지 설명해주세요.,"정방행렬 $(n times n)$인 $A$는 임의의 벡터 $(n times 1)$인 $x$의 방향과 크기를 변화시킬 수 있다. 수많은 벡터 $x$중 어떤 벡터들은 $A$에 의해 선형 변환되었을 때에도 원래 벡터와 평행한 경우가 있다. 이렇듯 $Ax$가 원래 $x$에 상수 $lambda$를 곱한 것과 같을 때의 $x$를 고유 벡터, 람다를 고유값이라 한다. $$ Ax = lambda x $$ 아래처럼 $x 1$은 $A$에 의해 변환되었음에도 $x 1$과 평행하다. 따라서 $x 1$은 고유벡터이다. 고유값과 고유벡터를 통해 $A$를 고유값과 고유벡터들로 분해하는 고유값 분해(eigen decomposition) , 정방행렬 뿐만 아닌 $m times n$행렬도 분해할 수 있는 특이값 분해(SVD) , 데이터들을 차원 축소시킬 때 가장 원래 의미를 잘 보존시키는 주성분 분석(PCA) 등에 활용할 수 있으므로 중요하다."
AI,통계,샘플링(Sampling)과 리샘플링(Resampling)이 무엇이고 리샘플링의 장점을 말씀해주세요.,"샘플링이란 표본추출 을 의미하는 것으로, 모집단 전체에 대한 추정치(estimate)를 얻기 위해 임의의 sample을 뽑아내는 것이다. 모집단 전체에 대한 조사는 불가능하기 때문에 sample을 이용하여 모집단에 대한 추론(inference)을 하게되는 것이다. 하지만 표본은 모집단을 닮은 모집단의 mirror image 같은 존재이지만, 모집단 그 자체일수는 없다. 따라서 표본에는 반드시 모집단의 원래 패턴에서 놓친 부분, 즉 noise가 존재할 수 밖에 없다. 리샘플링은 모집단의 분포 형태를 알 수 없을 때 주로 사용하는 방법 이다. 즉, 모분포를 알 수 없으므로 일반적인 통계적 공식들을 사용하기 힘들 때, 현재 갖고 있는 데이터를 이용하여 모분포와 비슷할 것으로 추정되는 분포를 만들어 보자는 것이다. 리샘플링은 가지고 있는 샘플에서 다시 샘플 부분집합을 뽑아서 통계량의 변동성(variability of statistics)을 확인하는 것 이라고 할 수 있다. 즉, 같은 샘플을 여러 번 사용해서 성능을 측정하는 방식이다. 가장 많이 사용되는 방법이며 종류로는 K fold 교차 검증, 부트스트래핑이 있다. 리샘플링은 표본을 추출하면서 원래 데이터 셋을 복원하기 때문에 이를 통해서 모집단의 분포에 어떤 가정도 필요 없이 표본만으로 추론이 가능하다는 장점이 있다."
AI,통계,확률 모형과 확률 변수는 무엇인가요?,"확률변수(Random Variable) 란, 표본 공간의 각 단위 사건에 실수 값을 부여하는 변수이다. 확률변수는 어떠한 함수로 해석할 수 있으므로 대문자 X 라고 표기한다. 무작위(Random) 실험을 했을 때, 특정 확률로 발생하는 각각의 결과를 수치적 값으로 표현하는 변수라고 할 수 있다. 또한 확률 변수에는 이산확률변수 , 연속확률변수 두가지 경우가 있다. 이산확률변수 는 확률변수 $X$가 취할 수 있는 값이 유한하기 떄문에 셀 수 있는 확률변수이다. 반면에 연속확률변수 는 어떠한 두 수 사이에 반드시 다른 수가 존재하는, 셀 수 없는 범위의 확률변수를 가지는 경우에 사용된다. 주사위 굴리기 예제를 생각해보자. text 일단 주사위를 굴리는 상황은 어떤 수가 나올지 모르므로, 확률상황이다. ""주사위를 굴렸을 때 나오는 값""을 확률변수 X라고 할 수 있다. 1~6이 표본공간이 되고, 셀 수 있으므로 이산확률변수가 된다. P(X=1)와 같은 식으로 표현하고, 이는 ""주사위를 굴렸을 때, 1이라는 값이 나올 확률""로 해석할 수 있다. 확률모형(Probability Model) 이란 확률변수를 이용하여 데이터의 분포를 수학적으로 정의한 모형이다. 데이터 분포를 묘사하기 위해서 사용된다. 보통 확률 분포 함수(probability distribution function) 또는 strong 확률 밀도 함수(probability density function) /strong 를 주로 사용하며, 이때 함수의 계수를 분포의 모수(parameter)라고 부른다. 확률분포(Probability Distribution) 란 표본공간에 정의된 확률을 이용하여 확률변수의 값 또는 영역에 대한 확률을 표현한 것이다. 예를 들어 가장 널리 쓰이는 확률 모형의 하나인 가우시안 정규 분포(Gaussian normal distribution) 는 다음과 같은 수식으로 확률 밀도 함수를 정의한다. $$ N(x ; mu, sigma) = frac{1}{sigma sqrt{2 pi}} e^{ frac{(x  mu)^2}{2 sigma^2}} $$ 다음과 같은 함수들이 확률모형에 포함될 수 있다. (자세한 내용은 참고) 확률질량함수(PMF, Probability Mass Function) 이산형 확률밀도함수(PDF, Probability Density Function) 연속형 누적분포함수(CDF, Cumulative Distribution Function) 추가적으로 확률 통계의 기초 용어 를 정리하면 다음과 같다. (주사위 굴리기 예제 사용) text 실험(Experiment)은 하나의 행위가 하나 이상의 결과를 도출하는 것에 대한 과정 혹은 절차를 나타낸다. 예시) 주사위를 던진다. 결과(Outcome)는 어떤 실험에 의해 발생 가능한 결과이다. 특정 실험의 가능한 결과들은 각각 유일(unique)하다. 한번의 실험을 시행했을 때, 단 하나의 outcome만을 나타낸다. 예시) 주사위의 눈 (ex. 3, 4, 6) 표본 공간(Sample space)은 확률 실험에서 발생할 수 있는 모든 결과로 구성된 집합(set)이다. 발생할 수 있는 모든 결과의 집합이므로, 중복된 원소를 가질 수 있다. 예시) 가능한 주사위의 모든 눈 집합 (ex. Ω = {1, 2, 3, 4, 5, 6}) 사건(Event)은 우리가 관심있는 Sample space의 부분집합이다. 예시) 주사위 눈이 3이 나온다, 짝수/홀수가 나온다."
AI,통계,누적 분포 함수와 확률 밀도 함수는 무엇인가요? 수식과 함께 표현해주세요.,"확률 변수 $X$가 임의의 실수 집합 $B$에 포함되는 사건의 확률이 다음과 같이 어떤 음이 아닌 함수 $f$의 적분으로 주어진다고 하자. $$ P(X in B) = int {B} f(x) dx $$ 이 때의 $X$를 연속확률변수라고 하며, 함수 $f(x)$를 strong 확률 밀도 함수(Probability Density Function, PDF) /strong 라고 한다. 단, 실수 집합 $B$가 실수 전체일 경우 실수 전체에 대한 확률밀도함수의 적분은 1을 만족해야 한다. $$ P(X in R) = int {R} f(x) dx = 1 $$ strong 누적 분포 함수(Cumulative Distribution Function, CDF) /strong 는 확률변수가 특정 값보다 작거나 같을 확률을 나타내는 함수이다. 특정 값을 $a$라고 할 때, 누적 분포 함수는 다음과 같이 나타낼 수 있다. $$ F(a) = P(X ≤ a) = int^a { infty} f(x) dx $$ 확률 밀도 함수와 누적 분포 함수는 미분과 적분의 관계 를 갖는다. 확률 밀도 함수를 음의 무한대에서 특정값 $a$까지 적분을 하면, $a$에 대한 누적 분포 함수를 얻을 수 있다. 반대로 누적 분포 함수를 미분하면 확률 밀도 함수를 얻을 수 있다."
AI,통계,조건부 확률은 무엇인가요?,"조건부 확률은 사건 $A$가 일어났다는 전제 하에 사건 $B$가 일어날 확률이다. 이는 $P(B A) = P(B cap A) / P(A)$로 표현 가능하다. 조건부 확률은 베이즈 정리 와도 이어지며, 조건부 확률을 이용한 가장 유명한 문제는 가 있다. 베이즈 정리 베이즈 정리를 통해 가능도(Likelihood)와 증거(Evidence)를 바탕으로 사전확률을 사후확률로 업데이트한다. $D$: 새로 관찰되는 데이터 $theta$: 모델에서 계산하고 싶어하는 모수 (가설) 사후확률(Posterior): 데이터를 관찰했을 때, 이 가설이 성립할 확률 (데이터 관찰 이후 측정하기 때문에 사후확률) 사전확률(Prior): 가설에 대해 사전에 세운 확률 (데이터 관측 이후 사후확률이 사전확률이 된다.) 가능도(Likelihood): 현재 주어진 모수 (가정) 에서 이 데이터가 관찰될 가능성 증거(Evidence): 데이터 전체의 분포"
AI,통계,공분산과 상관계수는 무엇일까요? 수식과 함께 표현해주세요.,"공분산은 확률변수 X의 편차(평균으로부터 얼마나 떨어져 있는지)와 확률변수 Y의 편차를 곱한 것의 평균값이다. $$ Cov(X, Y) = E((X mu X)(Y mu Y)) $$ 공분산은 두 변수 간에 양의 상관관계가 있는지, 음의 상관관계가 있는지 정도를 알려준다. 하지만 상관관계가 얼마나 큰지는 제대로 반영하지 못한다. 공분산의 문제는 확률변수의 단위 크기에 영향을 많이 받는다는 것이다. 이를 보완할 수 있는 것이 바로 상관계수이다. 상관계수는 확률변수의 절대적 크기에 영향을 받지 않도록 공분산을 단위화시킨 것이다. 즉, 공분산에 각 확률변수의 분산을 나눠주었다. $$ rho = frac{Cov(X, Y)}{sqrt{Var(X) cdot Var(Y)}}, quad  1 ≤ rho≤ 1 $$ 상관계수는 양의 상관관계가 있는지 음의 상관관계가 있는지 알려줄 뿐만 아니라, 그 상관성이 얼마나 큰지도 알려준다. 1 또는  1에 가까울수록 상관성이 큰 것이고, 0에 가까울수록 상관성이 작은 것이다."
AI,통계,신뢰 구간의 정의는 무엇인가요?,"구간 추정에서 strong 모수가 a 에서 b 사이에 있을 것으로 추정(신뢰구간) /strong 하고 strong 그 확률(%, 신뢰수준) /strong 을 구한다. 신뢰구간(Confidence Interval) 은 모집단의 모수(parameter)가 위치해 있을 것으로 신뢰할 수 있는 구간이다. 모수가 어느 범위 안에 있는지를 확률적으로 보여주는 방법이라고 할 수 있다. 신뢰구간을 구하는 이유는 모수의 신뢰성을 가늠하기 위함이다. 추가적으로, 신뢰구간에 대한 정확한 해석은 모평균을 포함할 확률이 95%가 되는 구간이 아닌, 같은 방법으로 100번 표본을 추출했을 때, 함께 계산되는 100개의 신뢰구간 중 모평균을 포함한 신뢰구간들의 숫자가 95개정도 된다라고 해야한다. 왜냐면, 모평균은 이미 정해져 있는 값이므로 전자의 해석을 사용할 수 없기 때문이다. 신뢰수준 은 방법의 정확도, 참값을 구하기 위한 작업을 많이 반복했을 때, 참값이 특정 범위에 있는 비율이다. 모수(Parameter) 는 모집단의 특성을 보여주는 값이다. 예를들어, 평균, 분산 등의 고정인 값이 있을 수 있다."
AI,통계,p value를 모르는 사람에게 설명한다면 어떻게 설명하실 건가요?,"p value를 알기 위해서는 먼저 1종 오류를 알아야 한다. 여기서 1종 오류란 귀무가설이 참인데 기각한 경우 을 말한다. 귀무가설이란 기존의 주장을 말하며, 이와 반대로 새로운 주장을 대립가설이라고 한다. 예를 들어, 어느 제약회사에서 치료약 A를 개발했다. 기존에는 치료약 A가 없었으므로 귀무가설은 ""치료약 A가 효과가 없다""라고 설정한다. 반대로 대립가설은 ""치료약 A는 효과가 있다""로 설정한다. 회사에서는 검정을 한 결과, 귀무가설을 기각하고 대립가설을 채택했다. 치료약 A는 판매되었고 높은 매출을 기록했다. 그런데 알고보니 치료약 A가 효과가 없다는 것이 밝혀졌다. 참인 귀무가설을 기각했기에 이는 1종 오류가 일어났다고 볼 수 있다. 다시 돌아와서 p value는 1종 오류를 범할 확률 을 말한다. 예를 들어, p value가 5%라면, 100번 중 5번 1종 오류가 발생한다는 말이다. 검정을 할 때는 유의 수준 $alpha$를 정하는데, 이것이 1종 오류의 상한선이 된다. 그래서 유의 수준보다 p value가 작다면 실험의 오류가 상한선보다 작으므로 귀무가설을 기각하고 대립가설을 채택한다. 만약 크다면 상한선을 넘었으므로 귀무가설을 채택한다."
AI,통계,R square의 의미는 무엇인가요?,"strong 결정계수(R square) /strong 는 선형 회귀 모델에서 데이터에 대해 회귀선이 얼마나 잘 설명하는지에 대한 설명력을 의미한다. 결정계수는 0~1 의 값을 가질 수 있고, 만약 값이 1 이라면 회귀선으로 모든 데이터를 다 설명할 수 있다고 이해할 수 있다. 참고로 결정계수는 다음의 식으로 구할 수 있다. $$ R^2 = SSE/SST = 1 SSR/SST $$ SSE( E xplained S um of S quares) = $sum(text{추정값 관측값 평균})^2$ SST( T otal S um of S quares) = $sum(text{관측값 관측값 평균})^2$ SSR( R esidual S um of S quares) = $SSR = sum(text{관측값 추정값})^2$ 관측값은 실제 데이터의 값을 말하며, 추정값은 회귀 모델을 통해 나온 값을 말한다. 회귀 모델의 성능을 평가하는 방법은 결정계수 외에도 MAE, MSE, RMSE 가 있다."
AI,통계,평균(mean)과 중앙값(median)중에 어떤 케이스에서 뭐를 써야할까요?,"  평균(mean) : 모든 관측값의 합을 자료의 개수로 나눈 것 중앙값(median) : 전체 관측값을 크기 순서로 배열했을 때 가운데 위치하는 값 평균은 전체 관측값이 골고루 반영되므로 대표값으로서 가치가 있다. 평균 근처에 표본이 몰려 있는 상황에서 대표값으로 유용 하지만 극단적인 값에 영향을 많이 받는다. 중앙값에서는 관측값을 크기 순서로 배열할 때 관측값의 위치가 중요하고, 가운데 위치한 관측값 이외의 관측값들의 크기는 중요하지 않다. 따라서 평균과는 달리 중앙값은 관측값들의 변화에 민감하지 않고 특히 아주 큰 관측값이나 아주 작은 관측값(즉, outlier)에 영향을 받지 않는다. 중앙값이 유용한 경우는 표본의 편차, 혹은 왜곡이 심하게 나타나는 경우 이다."
AI,통계,중심극한정리는 왜 유용한걸까요?,"중심극한정리 란 크기가 n인 표본추출(30개 이상)이 무수히 많이 수행되면(최소 100회 이상을 의미), 표본 평균의 분포가 정규분포에 수렴한다는 것이다. 중심극한정리가 유용한 이유는 모집단의 형태가 어떻든지 간에 상관없이 표본 평균의 분포가 정규분포를 따르기 때문 이다."
AI,통계,엔트로피(Entropy)에 대해 설명해주세요. 가능하면 정보이득(Information Gain)도요.,"엔트로피 는 주어진 데이터의 혼잡도를 의미하며, 엔트로피는 다음과 같이 데이터가 어떤 클래스에 속할 확률에 대한 기댓값으로 표현할 수 있다. $$ E = sum^k {i=1} p i log 2 (p i) $$ 엔트로피는 데이터가 서로 다른 클래스에 속하면 높고, 같은 클래스에 속하면 낮다. 다시 말하면 각각의 데이터가 특정 클래스에 속할 확률이 높고 나머지 클래스에 속할 확률이 낮다면 엔트로피가 낮고, 모든 각각의 클래스에 속할 확률이 비슷하다면 엔트로피는 높다. 정보이득 은 데이터가 어떤 클래스에 속할 확률이 커짐에 따라 정보를 잘 얻게되는 것을 말하며, 감소되는 엔트로피 양을 의미한다. 수식으로는 기존 시스템의 엔트로피에서 현재 엔트로피를 뺀 값으로 표현된다. 의사결정트리는 가지를 칠 때 이 값을 사용하여 가지를 친다. 이 때 어떤 데이터를 두 집합으로 나누었을 때 두 집합의 정보이득이 크도록, 엔트로피는 작아지도록 분할을 한다."
AI,통계,"어떨 때 모수적 방법론을 쓸 수 있고, 어떨 때 비모수적 방법론을 쓸 수 있나요?","표본의 통계량(평균, 표준편차 등)을 통해 모집단의 모수(모평균, 모표준편차 등)를 추정하는 방법을 통계적 추론이라고 한다. 모집단이 어떤 분포를 따른다는 가정 하에 통계적 추론을 하는 방법을 모수적 방법이라 하는데, 표본의 수가 30개 이상일 때 중심극한 정리에 의해 정규분포를 따르므로 모수적 방법론 을 사용한다. 반대로, 모집단의 분포를 가정하지 않는 비모수적 방법은, 표본의 수가 30개 미만이거나 정규성 검정에서 정규 분포를 따르지 않는다고 증명되는 경우 비모수적 방법론 을 사용한다."
AI,통계,“likelihood”와 “probability”의 차이는 무엇일까요?,"strong 확률(Probability) /strong 은 어떤 시행(trial)에서 특정 결과(sample)가 나올 가능성을 말한다. 즉, 시행 전 모든 경우의 수의 가능성은 정해져 있으며 그 총합은 1(100%)이다. strong 가능도(Likelihood) /strong 은 어떤 시행(trial)을 충분히 수행한 뒤 그 결과(sample)를 토대로 경우의 수의 가능성을 도출하는 것을 말한다. 아무리 충분히 수행해도 어디까지나 추론(inference)이기 때문에 가능성의 합이 1이 되지 않을수도 있다. PDF(probability density function)에서는 확률변수 를 변수로 보기 때문에 총합이 1이지만, likelihood function에서는 분포의 모수 를 변수로 보기 때문에 총합이 1이 되지 않을수도 있다."
AI,통계,통계에서 사용되는 bootstrap의 의미는 무엇인가요.,"부트스트랩(Bootstrap) 은 가설검증을 하거나 metric을 계산하기 전에 random sampling을 적용하는 방법이다. 모수의 분포를 추정하는 방법 중 하나는, 현재 가진 표본에서 추가적으로 표본을 복원추출하고 각 표본에 대한 통계량을 다시 계산하는 것이다. 부트스트랩이 여기에 해당하며, 여러번의 무작위 추출을 통해, 평균의 신뢰구간을 구할 수 있다. 200개로만 통계량을 구하는 것이 아니라 200개를 기준으로 복원 추출하여 새로운 통계량을 구하는 것을 예시로 들 수 있다. 머신러닝에서 부트스트램의 의미 머신러닝에서 부트스트랩은 아래와 같이 해석될 수 있다. 랜덤 샘플링을 통해 학습 데이터를 늘리는 방법 여러 모델을 학습시켜 추론 결과의 평균을 사용하는 방법(=앙상블) 복원추출이란? 복원추출(Sampling with replacement)이란 확률을 구할 때, 추출했던 것을 원래대로 돌려놓고 다시 추출하는 방법을 말한다."
AI,통계,모수가 매우 적은 (수십개 이하) 케이스의 경우 어떤 방식으로 예측 모델을 수립할 수 있을까요?,"모수는 모집단의 수가 아닌, 평균, 표준편차 등의 모집단의 특징을 말합니다. 여기서는 모집단의 수로 잘못 쓰인 것으로 보이며, 데이터가 적은 경우라 가정하고 답변을 작성하였습니다. 표본이 매우 작은 경우 표본평균의 분포가 정규분포를 따른다고 가정할 수 없으므로 비모수적 방법 을 채택하여 예측 모델을 수립할 수 있다. 하지만 중심극한정리에 의해 표본의 크기가 30보다 클 경우 표본평균이 정규분포를 따른다고 가정할 수 있으므로, 이 경우에는 모수적 방법을 사용한다."
AI,통계,베이지안과 프리퀀티스트 간의 입장차이를 설명해주실 수 있나요?,"베이지안은 사건의 확률을 바라볼 때, 사전 확률을 미리 염두해두고 사건의 발생에 따라 베이즈 정리로 사후 확률을 구해 다시 사전 확률을 업데이트시킨다. 즉, 베이지안은 과거의 사건이 현재 사건에 영향을 끼친다는 입장 을 가지고 있다. 반면, 프리퀀티스트는 확률을 무한번 실험한 결과, 객관적으로 발생하는 현상의 빈도수로 바라본다. 즉, 프리퀀티스트는 현재의 객관적인 확률에 의해서만 사건이 발생한다는 입장 을 가지고 있다."
AI,통계,검정력(statistical power)은 무엇일까요?,"귀무가설 H0 참 귀무가설 H0 거짓 : : : : : : 귀무가설 H0 채택 옳은 결정(1 α) 제 2종 오류(β) 귀무가설 H0 기각 제 1종 오류(α) 옳은 결정(1 β), 검정력 검정력은 대립가설 H1이 참인 경우 귀무가설 H0를 기각(대립가설 H1을 채택)할 확률이다."
AI,통계,missing value가 있을 경우 채워야 할까요? 그 이유는 무엇인가요?,"missing value를 처리하는 방법에는 크게 4가지가 있다. 1. 그대로 놔두기 : 누락된 데이터를 그대로 놔두는 방법이다. 2. 삭제하기 : 누락된 데이터를 제거하는 방법이다. 그러나 중요한 정보를 가진 데이터를 잃을 위험이 있다. 3. 특정 값으로 채우기 : 0, 빈번한 값, 지정한 상수값으로 채우기 4. 예측하여 채우기 : K means, 평균값, 중앙값으로 대체하는 것 1번 방법을 사용하여, 데이터가 누락된 채로 놔둔다고 가정하자. 일부 xgboost같은 알고리즘은 결측값을 고려하여 잘 학습한다. 그러나 결측치를 처리하는 로직이 없는 알고리즘(ex. sklearn의 LinearRegression)은 누락된 데이터 때문에 엉망이 될 수 있다. 따라서 결측치를 처리해주어야한다. 2번 방법을 사용하여, 누락된 데이터를 제거한다고 해보자. 제거하는 방법은 가장 쉬운 방법이다. 그러나 만약 100명 중 한명의 특징(feature)이 누락된 상태이므로, 해당 특징을 전부 삭제한다면 중요한 특성을 잃어버리는 결과를 초래하게 된다. 3번, 4번 방법을 사용하여 결측치를 채운다고 해보자. 결측치를 채움으로서, 중요한 정보를 잃지않고 특성을 유지할 수 있다. 그러나 만약 100명 중 99명의 특징이 누락된 상태라고 한다면, 해당 특징을 어떠한 값으로 채우는 행위가 무의미할 것이다. 따라서 결측치 상태나 비율, 어떤 모델을 사용할 것인지 에 따라서 결측치 대응 방법이 달라질 수 있다."
AI,통계,아웃라이어의 판단하는 기준은 무엇인가요?,"strong 이상치(outlier) /strong 는 전체 데이터의 패턴에서 벗어난 이상한 값을 가진 데이터를 말한다. 이상치는 모델의 성능에 영향을 미치므로 이를 탐지하는 것은 정말 중요하다. 이상치를 탐지하는 방법 중 하나로 IQR(Inter Quantile Range) 기법 이 있다. IQR 기법을 사용하기 위해서는 우선 데이터를 오름차순으로 정렬하고 25%, 50%, 75%, 100%로 4등분을 한다. 이 75% 지점과 25% 지점의 값의 차이를 IQR이라고 한다. 이 IQR에 1.5를 곱한 값을 75% 지점의 값에 더하여 최대값을, 25% 지점의 값에서 빼서 최소값을 계산한다. 이 때 최소값보다 작거나 최대값보다 큰 값을 이상치라고 판단한다. 또 다른 탐지 방법으로는 Z score를 계산하는 방식 이 있다. Z score는 데이터가 평균에서 얼마나 떨어져 있는지를 나타내는 지표로, 임계값을 설정하여 Z score이 이 값보다 크다면 이상치로 판단한다. 하지만 Z score 방식은 데이터가 가우시안 분포를 따른다고 가정하기 때문에 데이터가 가우시안 분포가 아닐 경우 별도의 변환이 필요하다."
AI,통계,필요한 표본의 크기를 어떻게 계산합니까?,"먼저 모집단의 크기 $N$ 을 구하고, 신뢰수준 $z$ 와 오차범위 $e$ 를 얼마로 할지 선정하여 표본의 크기를 구할 수 있다. $$ frac{frac{z^2 times p(1 p)}{e^2}}{1 + (frac{z^2 times p(1 p)}{e^2 N})} $$ 참고로 신뢰수준은 표본추출을 반복했을 때 얼마나 그 결과를 신뢰할 수 있는지에 대한 정도로 95% 를 주로 사용한다. 오차범위는 작을 수록 모집단의 특성에 대한 유용한 정보를 제공하지만 모집단에 대한 추론이 틀릴 가능성도 높아지므로 10% 를 넘지 않게 한다."
AI,통계,Bias를 통제하는 방법은 무엇입니까?,"편향(Bias)는 데이터 내에 있는 모든 정보를 고려하지 않음으로 인해, 지속적으로 잘못된 것들을 학습하는 경향을 의미한다. 이는 언더피팅(Underfitting)과 관계되어 있다. 반대로 분산(Variance)는 데이터 내에 있는 에러나 노이즈까지 잘 잡아내는 highly flexible models에 데이터를 피팅시킴으로써, 실제 현상과 관계 없는 랜덤한 것들까지 학습하는 알고리즘의 경향을 의미한다. 이는 오버피팅(Overfitting)과 관계되어 있다. 편향(Bias)과 분산(Variance)은 한 쪽이 증가하면 다른 한 쪽이 감소하고, 한쪽이 감소하면 다른 한쪽이 증가하는 tradeoff 관계를 가진다. Bias를 통제하기 위한 방법 으로는 뉴런이나 계층의 개수가 같은 모델의 크기 증가, 오류평가시 얻은 지식을 기반으로 입력 특성 수정, 정규화, 모델 구조를 수정, 학습 데이터 추가 등의 방법이 있다."
AI,통계,로그 함수는 어떤 경우 유용합니까? 사례를 들어 설명해주세요.,"우선 단위 수가 너무 큰 값들을 바로 회귀분석 할 경우 결과를 왜곡할 우려가 있으므로 이를 방지하기 위해 사용 된다. 예를들어, 나이와 재산보유액의 관계를 회귀분석으로 푼다고 했을 때, 재산보유액의 숫자가 굉장히 클 수 있다. 재산보유액에 로그를 취할 경우, 데이터의 왜도와 첨도를 줄일 수 있어 정규성이 높아지는 효과를 얻는다. 또한 비선형관계의 데이터를 선형으로 만들기 위해 사용된다. 예를들어, 기하급수적으로 늘어나는 제곱 형식의 그래프에 자연로그를 취하면 그 관계가 직선(선형)이 된다. 로그함수 주의사항 로그 함수는 0~1 사이에서는 음수값을 가지므로, $log(1+x)$와 같은 방법으로 처리해주어야한다. 왜도(skewness)와 첨도(Kurtosis) 왜도는 데이터가 한쪽으로 치우친 정도이다. 첨도는 분포가 얼마나 뾰족한지를 나타내는 정도이다."
AI,통계,"베르누이 분포, 이항 분포, 카테고리 분포, 다항 분포, 가우시안 정규 분포, t 분포, 카이제곱 분포, F 분포, 베타 분포, 감마 분포에 대해 설명해주세요.",  참고 (TODO: 추후 수정)
AI,통계,출장을 위해 비행기를 타려고 합니다. 당신은 우산을 가져가야 하는지 알고 싶어 출장지에 사는 친구 3명에게 무작위로 전화를 하고 비가 오는 경우를 독립적으로 질문했습니다. 각 친구는 2/3로 진실을 말하고 1/3으로 거짓을 말합니다. 3명의 친구가 모두 “그렇습니다. 비가 내리고 있습니다”라고 말했습니다. 실제로 비가 내릴 확률은 얼마입니까?,"출장지에 비가 내릴 때 $p$, 내리지 않을 때를 $1 p$라고 하자. 출장지에 비가 내리는데( $p$ ) 모든 친구가 비가 내린다라고 한다면 모든 친구가 진실을 말하는 것( $frac{8}{27}$ )이다. 이 경우 확률은 $frac{8p}{27}$이다. 출장지가 비가 내리지 않는데( $(1 p)$ ) 모든 친구가 비가 내린다라고 한다면 모든 친구가 거짓을 말하는 것( $frac{1}{27}$ )이다. 이 경우 확률은 $frac{(1 p)}{27}$이다. 위에서 계산한 확률을 위의 식에 대입하고 식을 정리하면 아래와 같다. $$ Pr(raining Yes) = frac{frac{8p}{27}}{frac{8p}{27} + frac{(1 p)}{27}} = frac{8p}{8p + (1 p)} = frac{8p}{7p+1} $$ 만약 출장지에 비가 올 확률이 25%라면 실제로 출장지에 비가 내릴 확률은 약 72.7%이다."
BACKEND,네트워크,클래스 다이어그램에 대해 설명해 주세요,"아이폰의 이어폰을 생각해보자 가장 흔한 이어폰 잭을 아이폰에 사용하려면, 잭 자체가 맞지 않는다. 따라서 우리는 어댑터를 따로 구매해서 연결해야 이런 이어폰들을 사용할 수 있다 이처럼 어댑터는 필요로 하는 인터페이스로 바꿔주는 역할 을 한다 이처럼 업체에서 제공한 클래스가 기존 시스템에 맞지 않으면? 기존 시스템을 수정할 것이 아니라, 어댑터를 활용해 유연하게 해결하자"
공통,디자인패턴,코드로 어댑터 패턴 이해하기에 대해 설명해 주세요,"오리와 칠면조 인터페이스 생성 만약 오리 객체가 부족해서 칠면조 객체를 대신 사용해야 한다면? 두 객체는 인터페이스가 다르므로, 바로 칠면조 객체를 사용하는 것은 불가능함 따라서 칠면조 어댑터를 생성해서 활용해야 한다 Duck.java java package AdapterPattern; public interface Duck { public void quack(); public void fly(); } Turkey.java java package AdapterPattern; public interface Turkey { public void gobble(); public void fly(); } WildTurkey.java java package AdapterPattern; public class WildTurkey implements Turkey { @Override public void gobble() { System.out.println(""Gobble gobble""); } @Override public void fly() { System.out.println(""I'm flying a short distance""); } } TurkeyAdapter.java java package AdapterPattern; public class TurkeyAdapter implements Duck { Turkey turkey; public TurkeyAdapter(Turkey turkey) { this.turkey = turkey; } @Override public void quack() { turkey.gobble(); } @Override public void fly() { turkey.fly(); } } DuckTest.java java package AdapterPattern; public class DuckTest { public static void main(String[] args) { MallardDuck duck = new MallardDuck(); WildTurkey turkey = new WildTurkey(); Duck turkeyAdapter = new TurkeyAdapter(turkey); System.out.println(""The turkey says...""); turkey.gobble(); turkey.fly(); System.out.println(""The Duck says...""); testDuck(duck); System.out.println(""The TurkeyAdapter says...""); testDuck(turkeyAdapter); } public static void testDuck(Duck duck) { duck.quack(); duck.fly(); } } 아까 확인한 클래스 다이어그램에서 Target은 오리에 해당하며, Adapter는 칠면조라고 생각하면 된다."
공통,디자인패턴,Design Pattern Adapter Pattern에 대해 설명해 주세요,"[어댑터 패턴] 국가별 사용하는 전압이 달라서 220v를 110v형으로 바꿔서 끼우는 경우를 생각해보기. 실행 부분 (Main.java) java public class Main { public static void main (String[] args) { MediaPlayer player = new MP3(); player.play(""file.mp3""); // MediaPlayer로 실행 못하는 MP4가 있음. // 이것을 mp3처럼 실행시키기 위해서, // Adapter를 생성하기. player = new FormatAdapter(new MP4()); player.play(""file.mp4""); } } 변환 장치 부분 (FormatAdapter.java) java // MediaPlayer의 기능을 활용하기 위해 FormatAdapter라는 새로운 클래스를 생성 // 그리고 그 클래스 내부에 (MP4, MKV와 같은) 클래스를 정리하려고 함. public class FormatAdapter implements MediaPlayer { private MediaPackage media; public FormatAdapter(MediaPackage m) { media = m; } // 그리고 반드시 사용해야하는 클래스의 함수를 선언해 둠 @Override public void play(String filename) { System.out.print(""Using Adapter""); media.playFile(filename); } }"
공통,디자인패턴,Design Pattern Factory Method Pattern에 대해 설명해 주세요,"한 줄 설명 : 객체를 만드는 부분을 Sub class에 맡기는 패턴. Robot (추상 클래스) ​ ㄴ SuperRobot ​ ㄴ PowerRobot RobotFactory (추상 클래스) ​ ㄴ SuperRobotFactory ​ ㄴ ModifiedSuperRobotFactory 즉 Robot이라는 클래스를 RobotFactory에서 생성함. RobotFactory 클래스 생성 java public abstract class RobotFactory { abstract Robot createRobot(String name); } SuperRobotFactory 클래스 생성 java public class SuperRobotFactory extends RobotFactory { @Override Robot createRobot(String name) { switch(name) { case ""super"" : return new SuperRobot(); case ""power"" : return new PowerRobot(); } return null; } } 생성하는 클래스를 따로 만듬... 그 클래스는 factory 클래스를 상속하고 있기 때문에, 반드시 createRobot을 선언해야 함. name으로 건너오는 값에 따라서, 생성되는 Robot이 다르게 설계됨. 정리하면, 생성하는 객체를 별도로 둔다. 그리고, 그 객체에 넘어오는 값에 따라서, 다른 로봇 (피자)를 만들어 낸다."
공통,디자인패턴,디자인 패턴 Template Method Pattern에 대해 설명해 주세요,"[디자인 패턴 예] 1. 템플릿 메서드 패턴 특정 환경 or 상황에 맞게 확장, 변경할 때 유용한 패턴 u 추상 클래스, 구현 클래스 /u 둘로 구분. 추상클래스 (Abstract Class) : 메인이 되는 로직 부분은 일반 메소드로 선언해 둠. 구현클래스 (Concrete Class) : 메소드를 선언 후 호출하는 방식. 장점 구현 클래스에서는 추상 클래스에 선언된 메소드만 사용하므로, u 핵심 로직 관리가 용이 /u 객체 추가 및 확장 가능 단점 추상 메소드가 많아지면, 클래스 관리가 복잡함. 설명 1) HouseTemplate.java Template 추상 클래스를 하나 생성. (예, HouseTemplate) 이 HouseTemplate을 사용할 때는, ""HouseTemplate houseType = new WoodenHouse()"" 이런 식으로 넣음. HouseTemplate 내부에 u buildHouse /u 라는 변해서는 안되는 핵심 로직을 만들어 놓음. (장점 1) Template 클래스 내부의 u 핵심 로직 내부의 함수 /u 를 상속하는 클래스가 직접 구현하도록, abstract를 지정해 둠. java public abstract class HouseTemplate { // 이런 식으로 buildHouse라는 함수 (핵심 로직)을 선언해 둠. public final void buildHouse() { buildFoundation(); // (1) buildPillars(); // (2) buildWalls(); // (3) buildWindows(); // (4) System.out.println(""House is built.""); } // buildFoundation(); 정의 부분 (1) // buildWalls(); 정의 부분 (2) // 위의 두 함수와는 다르게 이 클래스를 상속받는 클래스가 별도로 구현했으면 하는 메소드들은 abstract로 선언하여, 정의하도록 함 public abstract void buildWalls(); // (3) public abstract void buildPillars();// (4) } 2) WoodenHouse.java (GlassHouse.java도 가능) HouseTemplate을 상속받는 클래스. Wooden이나, Glass에 따라서 buildHouse 내부의 핵심 로직이 바뀔 수 있으므로, 이 부분을 반드시 선언하도록 지정해둠. java public class WoodenHouse extends HouseTemplate { @Override public void buildWalls() { System.out.println(""Building Wooden Walls""); } @Override public void buildPillars() { System.out.println(""Building Pillars with Wood coating""); } }"
공통,디자인패턴,주체 객체와 관찰 객체의 예는?,"잡지사 : 구독자 우유배달업체 : 고객 구독자, 고객들은 정보를 얻거나 받아야 하는 주체와 관계를 형성하게 된다. 관계가 지속되다가 정보를 원하지 않으면 해제할 수도 있다. (잡지 구독을 취소하거나 우유 배달을 중지하는 것처럼) 이때, 객체와의 관계를 맺고 끊는 상태 변경 정보를 Observer에 알려줘서 관리하는 것을 말한다. Observer들을 관리하는 메소드를 가지고 있음 옵저버 등록(add), 제외(delete), 옵저버들에게 정보를 알려줌(notifyObserver) java public interface Publisher { public void add(Observer observer); public void delete(Observer observer); public void notifyObserver(); } Observer 인터페이스 정보를 업데이트(update) java public interface Observer { public void update(String title, String news); } NewsMachine 클래스 Publisher를 구현한 클래스로, 정보를 제공해주는 퍼블리셔가 됨 java public class NewsMachine implements Publisher { private ArrayList Observer observers; private String title; private String news; public NewsMachine() { observers = new ArrayList (); } @Override public void add(Observer observer) { observers.add(observer); } @Override public void delete(Observer observer) { int index = observers.indexOf(observer); observers.remove(index); } @Override public void notifyObserver() { for(Observer observer : observers) { observer.update(title, news); } } public void setNewsInfo(String title, String news) { this.title = title; this.news = news; notifyObserver(); } public String getTitle() { return title; } public String getNews() { return news; } } AnnualSubscriber, EventSubscriber 클래스 Observer를 구현한 클래스들로, notifyObserver()를 호출하면서 알려줄 때마다 Update가 호출됨 java public class EventSubscriber implements Observer { private String newsString; private Publisher publisher; public EventSubscriber(Publisher publisher) { this.publisher = publisher; publisher.add(this); } @Override public void update(String title, String news) { newsString = title + "" "" + news; display(); } public void withdraw() { publisher.delete(this); } public void display() { System.out.println(""이벤트 유저""); System.out.println(newsString); } } Java에는 옵저버 패턴을 적용한 것들을 기본적으로 제공해줌 Observer 인터페이스, Observable 클래스 하지만 Observable은 클래스로 구현되어 있기 때문에 사용하려면 상속을 해야 함. 따라서 다른 상속을 함께 이용할 수 없는 단점 존재"
공통,디자인패턴,싱글톤 패턴이란?,"애플리케이션이 시작될 때, 어떤 클래스가 최초 한 번만 메모리를 할당(static)하고 해당 메모리에 인스턴스를 만들어 사용하는 패턴 즉, 싱글톤 패턴은 '하나'의 인스턴스만 생성하여 사용하는 디자인 패턴이다. 인스턴스가 필요할 때, 똑같은 인스턴스를 만들지 않고 기존의 인스턴스를 활용하는 것! 생성자가 여러번 호출되도, 실제로 생성되는 객체는 하나이며 최초로 생성된 이후에 호출된 생성자는 이미 생성한 객체를 반환시키도록 만드는 것이다 (java에서는 생성자를 private으로 선언해 다른 곳에서 생성하지 못하도록 만들고, getInstance() 메소드를 통해 받아서 사용하도록 구현한다)"
공통,JAVA,멀티스레드 환경에서 안전한 싱글톤 만드는 법에 대해 설명해 주세요,"1. Lazy Initialization (초기화 지연) java public class ThreadSafe Lazy Initialization{ private static ThreadSafe Lazy Initialization instance; private ThreadSafe Lazy Initialization(){} public static synchronized ThreadSafe Lazy Initialization getInstance(){ if(instance == null){ instance = new ThreadSafe Lazy Initialization(); } return instance; } } private static으로 인스턴스 변수 만듬 private으로 생성자를 만들어 외부에서의 생성을 막음 synchronized 동기화를 활용해 스레드를 안전하게 만듬 하지만, synchronized는 큰 성능저하를 발생시키므로 권장하지 않는 방법 2. Lazy Initialization + Double checked Locking 1번의 성능저하를 완화시키는 방법 java public class ThreadSafe Lazy Initialization{ private volatile static ThreadSafe Lazy Initialization instance; private ThreadSafe Lazy Initialization(){} public static ThreadSafe Lazy Initialization getInstance(){ if(instance == null) { synchronized (ThreadSafe Lazy Initialization.class){ if(instance == null){ instance = new ThreadSafe Lazy Initialization(); } } } return instance; } } 1번과는 달리, 먼저 조건문으로 인스턴스의 존재 여부를 확인한 다음 두번째 조건문에서 synchronized를 통해 동기화를 시켜 인스턴스를 생성하는 방법 스레드를 안전하게 만들면서, 처음 생성 이후에는 synchronized를 실행하지 않기 때문에 성능저하 완화가 가능함 하지만 완전히 완벽한 방법은 아님 3. Initialization on demand holder idiom (holder에 의한 초기화) 클래스 안에 클래스(holder)를 두어 JVM의 클래스 로더 매커니즘과 클래스가 로드되는 시점을 이용한 방법 java public class Something { private Something() { } private static class LazyHolder { public static final Something INSTANCE = new Something(); } public static Something getInstance() { return LazyHolder.INSTANCE; } } 2번처럼 동기화를 사용하지 않는 방법을 안하는 이유는, 개발자가 직접 동기화 문제에 대한 코드를 작성하면서 회피하려고 하면 프로그램 구조가 그만큼 복잡해지고 비용 문제가 발생할 수 있음. 또한 코드 자체가 정확하지 못할 때도 많음 이 때문에, 3번과 같은 방식으로 JVM의 클래스 초기화 과정에서 보장되는 원자적 특성 을 이용해 싱글톤의 초기화 문제에 대한 책임을 JVM에게 떠넘기는 걸 활용함 클래스 안에 선언한 클래스인 holder에서 선언된 인스턴스는 static이기 때문에 클래스 로딩시점에서 한번만 호출된다. 또한 final을 사용해서 다시 값이 할당되지 않도록 만드는 방식을 사용한 것 실제로 가장 많이 사용되는 일반적인 싱글톤 클래스 사용 방법이 3번이다."
공통,디자인패턴,전투기 예시에 대해 설명해 주세요,"java class Fighter extends Unit { private ShootAction shootAction; private BombAction bombAction; public Fighter() { shootAction = new OneWayMissle(); bombAction = new SpreadBomb(); } } Fighter.doAttack() 을 호출하면, OneWayMissle의 attack()이 호출될 것이다."
공통,디자인패턴,abstract와 Interface의 차이는?,  abstract : 부모의 기능을 자식에서 확장시켜나가고 싶을 때 interface : 해당 클래스가 가진 함수의 기능을 활용하고 싶을 때 abstract는 다중 상속이 안된다. 상황에 맞게 활용하자!
공통,JAVA,Git과 GitHub을 활용한 협업 개발에 대해 설명해 주세요,"Git : 프로젝트를 진행할 때 소스 코드의 버전 관리를 효율적으로 처리할 수 있게 설계된 도구 GitHub : Git의 원격 저장소를 생성하고 관리할 수 있는 기능 제공함. 이슈와 pull request를 중심으로 요구사항을 관리 Git 저장소 생성 $ mkdir awesome javascript $ cd awesome javascript $ git init GitHub 계정에 같은 이름의 저장소를 생성한 후, git remote 명령어를 통해 원격 저장소 추가 $ git remote add origin 'Github 주소'"
공통,JAVA,GitHub에 이슈 등록하기에 대해 설명해 주세요,"이슈는 왜 등록하는거죠? 코드 작성하기에 앞서, 요구사항이나 해결할 문제를 명확하게 정의하는 것이 중요 GitHub의 이슈 관리 기능을 활용하면 협업하는 동료와 쉽게 공유가 가능함 GitHub 저장소의 Issues 탭에서 New issue를 클릭 해서 이슈를 작성할 수 있음 이슈와 pull request 요청에 작성하는 글의 형식을 템플릿으로 관리할 수 있음 (템플릿은 마크다운 형식)"
공통,JAVA,숨긴 폴더인 .github 폴더에서 이슈 템플릿과 pull request 템플릿을 관리하는 방법에 대해 설명해 주세요,devops/github templates 브랜치에 템플릿 파일을 생성하고 github에 푸시하자 $ git checkout  b devops/github templates $ mkdir .github $ touch .github/ISSUE TEMPLATE.md Create issue template $ touch .github/PULL REQUEST TEMPLATE.md Create pull request template $ git add . $ git commit  m ':memo: Add GitHub Templates' $ git push  u origin devops/github templates
공통,JAVA,Node.js와 Yarn으로 개발 환경 설정하기에 대해 설명해 주세요,"오늘날 javascript는 애플리케이션 개발에 많이 사용되고 있다. 이때 git을 활용한 협업 환경뿐만 아니라 코드 검증, 테스트, 빌드, 배포 등의 과정에서 만나는 문제를 해결할 수 있는 개발 환경도 설정해야 한다. 이때 많이 사용하는 것이 Node.js와 npm, yarn Node.js와 npm : JavaScript가 거대한 오픈소스 생태계를 확보하는 데 결정적인 역할을 함 Node.js 는 Google이 V8 엔진으로 만든 Javascript 런타임 환경으로 오늘날 상당히 많이 쓰이는 중! npm 은 Node.js를 설치할 때 포함되는데, 패키지를 프로젝트에 추가할 수 있도록 다양한 명령을 제공하는 패키지 관리 도구라고 보면 된다. yarn 은 페이스북이 개발한 패키지 매니저로, 규모가 커지는 프로젝트에서 npm을 사용하다가 보안, 빌드 성능 문제를 겪는 문제를 해결하기 위해 탄생함 Node.js 설치 후, yarn을 npm 명령어를 통해 전역으로 설치하자 $ npm install yarn  g"
공통,JAVA,프로젝트 생성에 대해 설명해 주세요,"yarn init 명령어 실행 프로젝트 기본 정보를 입력하면 새로운 프로젝트가 생성됨 pakage.json 파일이 생성된 것을 확인할 수 있다. json { ""name"": ""awesome javascript"", ""version"": ""1.0.0"", ""main"": ""index.js"", ""repository"": "" ""author"": ""gyuseok gyuseok6394@gmail.com "", ""license"": ""MIT"" } 이 파일은 프로젝트의 모든 정보를 담고 있다. 이 파일에서 가장 중요한 속성은 dependencies 로, 프로젝트와 패키지 간의 의존성을 관리하는 속성 이다. yarn의 cli 명령어로 패키지를 설치하면 package.json 파일의 dependencies 속성이 자동으로 변경됨 node fetch 모듈을 설치해보자 $ yarn add node fetch pakage.json안에 아래와 같은 내용이 추가된다. ""dependencies"": { ""node fetch"": ""^2.6.0"" } 추가로 생성된 yarn.lock 파일은 뭔가요? 앱을 개발하는 도중 혹은 배포할 때 프로젝트에서 사용하는 패키지가 업데이트 되는 경우가 있다. 또한 협업하는 동료들마다 다른 버전의 패키지가 설치될 수도 있다. yarn은 모든 시스템에서 패키지 버전을 일관되게 관리하기 위해 yarn.lock 파일을 프로젝트 최상위 폴더에 자동으로 생성함. (사용자는 이 파일을 직접 수정하면 안됨. 오로지 cli 명령어를 사용해 관리해야한다!)"
공통,JAVA,프로젝트 공유에 대해 설명해 주세요,"현재 프로젝트는 Git의 원격 저장소에 반영해요 협업하는 동료와 공유가 가능하다. 프로젝트에 생성된 pakage.json 과 yarn.lock 파일도 원격 저장소에서 관리해야 협업하는 동료들과 애플리케이션을 안정적으로 운영하는 것이 가능해짐 원격 저장소에 공유 시, 모듈이 설치되는 node  modules 폴더는 제외시켜야 한다. 폴더의 용량도 크고, 어차피 yarn.lock 파일을 통해 동기화 되기 때문 에 따로 git 저장소에서 관리할 필요가 없음 따라서, 해당 폴더를 .gitignore 파일에 추가해 git 관리 대상에서 제외시키자 $ echo ""node modules/"" .gitignore"
공통,JAVA,이슈 해결 관련 브랜치 생성 & 프로젝트 push에 대해 설명해 주세요,"이번엔 이슈 해결과 관련된 브랜치를 생성하고, 프로젝트를 github에 푸시해보자 $ git add . $ git checkout  b issue/1 $ git commit  m 'Create project with Yarn' $ git push  u origin issue/1 푸시가 완려되면, GitHub 저장소에 pull request 가 생성된 것을 확인할 수 있다. pull request는 작성한 코드를 master 브랜치에 병합하기 위해 협업하는 동료들에게 코드 리뷰를 요청하는 작업 임 Pull requests 탭에서 New pull request 버튼을 클릭해 pull request를 생성할 수 있다"
공통,JAVA,pull request시 주의할 점에 대해 설명해 주세요,"리뷰를 하는 사람에게 충분한 정보를 제공해야 함 새로운 기능을 추가했으면, 기능을 사용하기 위한 재현 시나리오와 테스트 시나리오를 추가하는 것이 좋음. 개발 환경이 변경되었다면 변경 내역도 반드시 포함하자"
공통,JAVA,Jest로 테스트 환경 설정에 대해 설명해 주세요,"실제로 프로젝트를 진행하면, 활용되는 Javascript 구현 코드가 만들어질 것이고 이를 검증하는 테스트 환경이 필요하게 된다. Javascript 테스트 도구로는 jest를 많이 사용한다. GitHub의 REST API v3을 활용해 특정 GitHub 사용자 정보를 가져오는 코드를 작성해보고, 테스트 환경 설정 방법에 대해 알아보자"
공통,JAVA,테스트 코드 작성에 대해 설명해 주세요,"구현 코드 작성 이전, 구현하려는 기능의 의도를 테스트 코드로 표현해보자 테스트 코드 저장 폴더 : test 구현 코드 저장 폴더 : lib 테스트 코드 : github.test.js $ mkdir tests lib $ touch tests /github.test.js github.test.js에 테스트 코드를 작성해보자 내 GitHub kim6394 계정의 사용자 정보를 가져왔는지 확인하는 코드다. javascript const GitHub = require('../lib/github') describe('Integration with GitHub API', () = { let github beforeAll ( () = { github = new GitHub({ accessToken: process.env.ACCESS TOKEN, baseURL: ' }) }) test('Get a user', async () = { const res = await github.getUser('kim6394') expect(res).toEqual ( expect.objectContaining({ login: 'kim6394', }) ) }) })"
공통,JAVA,Jest 설치에 대해 설명해 주세요,"yarn에서 테스트 코드를 실행할 때는 yarn test 먼저 설치를 진행하자 $ yarn add jest dev dev 속성은 뭔가요? 설치할 때 이처럼 작성하면, devDependencies 속성에 패키지를 추가시킨다. 이 옵션으로 설치된 패키지는, 앱이 실행되는 런타임 환경에는 영향을 미치지 않는다. 테스트 명령을 위한 script 속성을 pakage.json에 설정하자 json ""scripts"": { ""test"": ""jest"" }, ""dependencies"": { ""axios"": ""^0.19.0"", ""node fetch"": ""^2.6.0"" }, ""devDependencies"": { ""jest"": ""^24.8.0"" }"
공통,JAVA,구현 코드 작성에 대해 설명해 주세요,"아직 구현 코드를 작성하지 않았기 때문에 테스트 실행이 되지 않을 것이다. lib 폴더에 구현 코드를 작성해보자 lib/github.js javascript const fetch = require('node fetch') class GitHub { constructor({ accessToken, baseURL }) { this.accessToken = accessToken this.baseURL = baseURL } async getUser(username) { if(!this.accessToken) { throw new Error('accessToken is required.') } return fetch( ${this.baseURL}/users/${username} , { method: 'GET', headers: { Authorization: token ${this.accessToken} , 'Content Type' : 'application/json', }, }).then(res = res.json()) } } module.exports = GitHub 이제 GitHub 홈페이지에서 access token을 생성해서 테스트해보자 토큰은 사용자마다 다르므로 자신이 생성한 토큰 값으로 입력한다 $ ACCESS TOKEN=29ed3249e4aebc0d5cfc39e84a2081ad6b24a57c yarn test 아래와 같이 테스트가 정상적으로 작동되어 출력되는 것을 확인할 수 있을 것이다! yarn run v1.10.1 $ jest PASS tests /github.test.js Integration with GitHub API √ Get a user (947ms) Test Suites: 1 passed, 1 total Tests: 1 passed, 1 total Snapshots: 0 total Time: 3.758s Ran all test suites. Done in 5.30s."
공통,JAVA,Travis CI를 활용한 리뷰 환경 개선에 대해 설명해 주세요,"동료와 협업하여 애플리케이션을 개발하는 과정은, pull request를 생성하고 공유한 코드를 리뷰, 함께 개선하는 과정이라고 말할 수 있다. 지금까지 진행한 과정을 확인한 리뷰어가 다음과 같이 답을 보내왔다. README.md를 참고해 테스트 명령을 실행했지만 실패했습니다.. 무슨 문제일까? 내 로컬 환경에서는 분명 테스트 케이스를 통해 테스트 성공을 확인할 수 있었다. 리뷰어가 보낸 문제는, 다른 환경에서 테스트 실패로 인한 문제다. 이처럼 테스트케이스에 정의된 테스트를 실행하는 일은 개발과정에서 반복되는 작업이다. 따라서 리뷰어가 테스트를 매번 실행하게 하는 건 매우 비효율적이다. CI 도구가 자동으로 실행하도록 프로젝트 리뷰 방법을 개선시켜보자"
공통,JAVA,Travis CI로 테스트 자동화에 대해 설명해 주세요,"저장소의 Settings 탭에서 Branches를 클릭한 후, Branch protection rules에서 CI 연동기능을 사용해보자 (CI 도구 빌드 프로세스에 정의한 작업이 성공해야만 master 브랜치에 소스코드가 병합되도록 제약 조건을 주는 것) 대표적인 CI 도구는 Jenkins이지만, CI 서버 구축 운영에 비용이 든다. Travis CI는 아래와 같은 작업을 위임한다 ESLint를 통한 코드 컨벤션 검증 Jest를 통한 테스트 자동화 Travis CI의 연동과 설정이 완료되면, pull request를 요청한 소스코드가 Travis CI를 거치도록 GitHub 저장소의 Branch protection rules 항목을 설정한다. 이를 설정해두면, 작성해둔 구현 코드와 테스트 코드로 pull request를 요청했을 때 Travis CI 서버에서 자동으로 테스트를 실행할 수 있게 된다."
공통,JAVA,GitHub Travis CI 연동에 대해 설명해 주세요,"GitHub Login 연결할 repository 허용 프로젝트에 .travis.yml 설정 파일 추가 .travis.yml yml language: node js node js: 10.15.0 cache: yarn: true directories: node modules env: global: PATH=$HOME/.yarn/bin:$PATH services: mongodb before install: curl  o   L bash script: yarn install yarn test 다시 돌아와서, 리뷰어가 테스트를 실패한 이유는 access token 값이 전달되지 못했기 때문이다. 환경 변수를 관리하기 위해선 Git 저장소에서 설정 정보를 관리하고, 값의 유효성을 검증하는 것이 좋다. (보안 문제가 있을 때는 다른 방법 강구) dotenv과 joi 모듈 을 사용하면, .env 할 일에 원하는 값을 등록하고 유효성 검증을 할 수 있다. 프로젝트에 .env 파일을 생성하고, access token 값을 등록해두자 이제 yarn으로 두 모듈을 설치한다. $ yarn add dotenv joi $ git add . $ git commit  m 'Integration with dotenv and joi to manage config properties' $ git push 이제 Travis CI로 자동 테스트 결과를 확인할 수 있다."
BACKEND,운영체제,운영체제에 대해 설명해 주세요,"1. 저장소 미러링 1. 복사하고자 하는 저장소의 bare clone 생성 bach git clone bare {복사하고자하는저장소의 git 주소} 2. 새로운 저장소로 mirror push bash cd {복사하고자하는저장소의git 주소} git push mirror {붙여놓을저장소의git주소} 3. 1번에서 생성된 저장소 삭제 1. 100MB를 넘어가는 파일을 가진 저장소 미러링 1. 와 설치 2. 복사하고자 하는 저장소의 bare clone 생성 bach git clone mirror {복사하고자하는저장소의 git 주소} 3. commit history에서 large file을 찾아 트랙킹 bash git filter branch tree filter 'git lfs track "" .{zip,jar}""' all 4. BFG를 이용하여 해당 파일들을 git lfs로 변경 bash java  jar ~/usr/bfg repo cleaner/bfg 1.13.0.jar convert to git lfs ' .zip' java  jar ~/usr/bfg repo cleaner/bfg 1.13.0.jar convert to git lfs ' .jar' 5. 새로운 저장소로 mirror push bash cd {복사하고자하는저장소의git 주소} git push mirror {붙여놓을저장소의git주소} 6. 1번에서 생성된 저장소 삭제 ref  "
BACKEND,네트워크,메모리 반도체 종류에 대해 설명해 주세요,"  램(Random Access Memory) 정보를 기록하고, 기록해 둔 정보를 읽거나 수정할 수 있음 (휘발성 전원이 꺼지면 정보 날아감) DRAM : 일정 시간마다 자료 유지를 위해 리프레시가 필요 (트랜지스터 1개 & 커패시터 1개) SRAM : 전원이 공급되는 한 기억정보가 유지 롬(Read Only Memory) 기록된 정보만 읽을 수 있고, 수정할 수는 없음 (비휘발성 전원이 꺼져도 정보 유지) Flash Memory : 전력소모가 적고 고속 프로그래밍 가능(트랜지스터 1개) 메모리 반도체는 기억장치로, 얼마나 많은 양을 기억하고 얼마나 빨리 동작하는가 가 중요 (대용량 & 고성능) 모바일 기기의 사용이 많아지면서 초박형 & 저전력성 도 중요해짐"
AI,데이터,시스템 반도체 종류에 대해 설명해 주세요,"  마이크로컴포넌츠 전자 제품의 두뇌 역할을 하는 시스템 반도체 (마이컴이라고도 부름) MPU MCU(Micro Controller Unit) : 단순 기능부터 특수 기능까지 제품의 다양한 특성을 컨트롤 DSP(Digital Signal Processor) : 빠른 속도로 디지털 신호를 처리해 영상, 음성, 데이터를 사용하는 전자제품에 많이 사용 아날로그 IC 음악과 같은 각종 아날로그 신호를 컴퓨터가 인식할 수 있는 디지털 신호로 바꿔주는 반도체 로직 IC 논리회로(AND, OR, NOT 등)로 구성되며, 제품 특정 부분을 제어하는 반도체 광학 반도체 빛 → 전기신호, 전기신호 → 빛으로 변환해주는 반도체"
AI,데이터,모바일 AP(Mobile Applicaton Processor)에 대해 설명해 주세요,"스마트폰, 태플릿PC 등 전자기기에 탑재되어 명령해석, 연산, 제어 등의 두뇌 역할을 하는 시스템 반도체 일반적으로 PC는 CPU와 메모리, 그래픽카드, 하드디스크 등 연결을 제어하는 칩셋으로 구성됨. 모바일 AP는 CPU 기능과 다른 장치를 제어하는 칩셋의 기능을 모두 포함함. 필요한 OS와 앱을 구동시키며 여러 시스템 장치/인터페이스를 컨트롤하는 기능을 하나의 칩에 모두 포함하는 것 주요 기능 : OS 실행, 웹 브라우징, 멀티 터치 스크린 입력 실행 등 스마트 기기 핵심기능 담당하는 CPU & 그래픽 영상 데이터를 처리해 화면에 표시해주는 GPU 이 밖에도 비디오 녹화, 카메라, 모바일 게임 등 여러 시스템 구동을 담당하는 서브 프로세서들이 존재함"
공통,C,임베디드 플래시 로직 공정에 대해 설명해 주세요,"시스템 반도체 회로 안에 플래시메모리 회로를 구현한 것 시스템 반도체 칩 : 데이터를 제어 및 처리 플래시 메모리 칩 : 데이터를 기억 집적도와 전력 효율을 높일 수 있어 가전, 모바일, 자동차 등 다양한 애플리케이션 제품에 적용함"
AI,데이터,플래시 메모리(Flash Memory)에 대해 설명해 주세요,"전원이 끊겨도 데이터를 보존하는 특성을 가진 반도체 ROM과 RAM의 장점을 동시에 지님 (전원이 꺼져도 데이터 보존 + 정보의 입출력이 자유로움) 따라서 휴대전화, USB 드라이브, 디지털 카메라 등 휴대용 기기의 대용량 정보 저장 용도로 사용"
AI,데이터,플래시 메모리 종류에 대해 설명해 주세요,"반도체 칩 내부의 전자회로 형태에 따라 구분됨 NAND(데이터 저장) 소형화, 대용량화 직렬 형태, 셀을 수직으로 배열하는 구조라 좁은 면적에 많이 만들 수 있어 용량을 늘리기 쉬움 데이터를 순차적으로 찾아 읽기 때문에, 별도 셀의 주소를 기억할 필요가 없어 쓰기 속도가 빠름 NOR(코드 저장) 안전성, 빠른 검색 병렬 형태, 데이터를 빨리 찾을 수 있어서 읽기 속도가 빠르고 안전성이 우수함 셀의 주소를 기억해야돼서 회로가 복잡하고 대용량화가 어려움"
AI,데이터,SSD(Solid State Drive)에 대해 설명해 주세요,"메모리 반도체를 저장매체로 사용하는 차세대 대용량 저장장치 HDD를 대체한 컴퓨터의 OS와 데이터를 저장하는 보조기억장치임 (반도체 칩에 정보가 저장되어 SSD라고 불림) NAND 플래시 메모리에 정보를 저장하여 전력소모가 적고, 소형 및 경량화가 가능함"
AI,데이터,SSD 구성에 대해 설명해 주세요,"  NAND Flash : 데이터 저장용 메모리 Controller : 인터페이스와 메모리 사이 데이터 교환 작업 제어 DRAM : 외부 장치와 캐시메모리 역할 보급형 SSD가 출시되면서 노트북 & 데스크탑 PC에 많이 사용되며, 빅데이터 시대에 급증하는 데이터를 관리하기 위해 데이터센터의 핵심 저장 장치로 이용되고 있음"
AI,데이터,NFC(Near Field Communication)에 대해 설명해 주세요,"10cm 이내의 근거리에서 데이터를 교환할 수 있는 무선통신기술 통신거리가 짧아 상대적 보안이 우수하고, 가격이 저렴함 교통카드 or 전자결제에서 대표적으로 사용되며 IT기기 및 생활 가전제품으로 확대되고 있음"
BACKEND,네트워크,이미지 센서(Image Sensor)에 대해 설명해 주세요,"피사체 정보를 읽어 전기적인 영상신호로 변화해주는 소자 카메라 렌즈를 통해 들어온 빛을 전기적 디지털 신호로 변환해주는 역할 영상신호를 저장 및 전송해 디스플레이 장치로 촬영 사진을 볼수 있도록 만들어주는 반도체 (필름 카메라의 필름과 유사) CCD : 전하결합소자 CMOS : 상보성 금속산화 반도체 디지털 영상기기에 많이 활용된다. (스마트폰, 태블릿PC, 고해상도 디지털 카메라 등)"
공통,C,임베디드 시스템의 특징에 대해 설명해 주세요,  특정 기능 수행 실시간 처리 대량 생산 안정성 배터리로 동작
공통,C,임베디드 구성 요소에 대해 설명해 주세요,  하드웨어 소프트웨어
공통,C,임베디드 하드웨어의 구성요소에 대해 설명해 주세요,  입출력 장치 Flash Memory CPU RAM 통신장치 회로기판
공통,C,임베디드 소프트웨어 분류에 대해 설명해 주세요,  시스템 소프트웨어 : 시스템 전체 운영 담당 응용 소프트웨어 : 입출력 장치 포함 특수 용도 작업 담당 (사용자와 대면)
공통,C,펌웨어 기반 소프트웨어에 대해 설명해 주세요,  운영체제없이 하드웨어 시스템을 구동하기 위한 응용 프로그램 간단한 임베디드 시스템의 소프트웨어
공통,C,운영체제 기반 소프트웨어에 대해 설명해 주세요,"  소프트웨어가 복잡해지면서 펌웨어 형태로는 한계 도달 운영체제는 하드웨어에 의존적인 부분, 여러 프로그램이 공통으로 이용할 수 있는 부분을 별도로 분리하는 프로그램"
공통,JAVA,Serialization에 대해 설명해 주세요,직렬화. 객체의 상태 혹은 데이터 구조를 기록할 수 있는 포맷으로 변환해줌 나중에 재구성 할 수 있게 JAVA 객체를 JSON으로 변환해주거나 JSON을 JAVA 객체로 변환해주는 라이브러리
AI,데이터,Hash에 대해 설명해 주세요,"데이터 삽입 및 삭제 시, 기존 데이터를 밀어내거나 채우지 않고 데이터와 연관된 고유한 숫자를 생성해 인덱스로 사용하는 방법 검색 속도가 매우 빠르다"
AI,데이터,배열과 연결리스트 차이는?,"배열은 인덱스를 가짐. 원하는 데이터를 한번에 접근하기 때문에 접근 속도 빠름. 크기 변경이 불가능하며, 데이터 삽입 및 삭제 시 그 위치의 다음 위치부터 모든 데이터 위치를 변경해야 되는 단점 존재 연결리스트는 인덱스 대신에 현재 위치의 이전/다음 위치를 기억함. 크기는 가변적. 인덱스 접근이 아니기 때문에 연결되어 있는 링크를 쭉 따라가야 접근이 가능함. (따라서 배열보다 속도 느림) 데이터 삽입 및 삭제는 논리적 주소만 바꿔주면 되기 때문에 매우 용이함 데이터의 양이 많고 삽입/삭제가 없음. 데이터 검색을 많이 해야할 때 → Array 데이터의 양이 적고 삽입/삭제 빈번함 → LinkedList"
공통,C,C++ 실행 과정에 대해 설명해 주세요,"전처리 : define, include 지시자 해석 컴파일 : 고급 언어 소스 프로그램 입력 받고, 어셈블리 파일 만듬 어셈블 : 어셈블리 파일을 오브젝트 파일로 만듬 링크 : 오브젝트 파일을 엮어 실행파일을 만들고 라이브러리 함수 연결 실행"
공통,C,클래스와 구조체의 차이는?,"구조체는 하나의 구조로 묶일 수 있는 변수들의 집합이다. 클래스는 변수뿐만 아니라, 메소드도 포함시킬 수 있음 (물론 함수 포인터를 이용해 구조체도 클래스처럼 만들어 낼 수도 있다.)"
공통,C,포인터를 이해하기 쉽도록 설명해주세요,"포인터는 메모리 주소를 저장하는 변수임 주소를 지칭하고 있는 곳인데, 예를 들면 엘리베이터에서 포인터는 해당 층을 표시하는 버튼이라고 할 수 있음. 10층을 누르면 10층으로 이동하듯, 해당 위치를 가리키고 있는 변수! 포인터를 사용할 때 주의할 점은, 어떤 주소를 가리키고 있어야만 사용이 가능함"
AI,데이터,프로세스와 스레드 차이에 대해 설명해 주세요,"프로세스는 메모리 상에서 실행중인 프로그램을 말하며, 스레드는 이 프로세스 안에서 실행되는 흐름 단위를 말한다. 프로세스마다 최소 하나의 스레드를 보유하고 있으며, 각각 별도의 주소공간을 독립적으로 할당받는다. (code, data, heap, stack) 스레드는 이중에 stack만 따로 할당받고 나머지 영역은 스레드끼리 서로 공유한다. 요약 프로세스 : 자신만의 고유 공간과 자원을 할당받아 사용 스레드 : 다른 스레드와 공간과 자원을 공유하면서 사용"
공통,알고리즘,"메모리 할당 알고리즘 First fit, Next fit, Best fit 결과에 대해 설명해 주세요",First fit : 메모리의 처음부터 검사해서 크기가 충분한 첫번째 메모리에 할당 Next fit : 마지막으로 참조한 메모리 공간에서부터 탐색을 시작해 공간을 찾음 Best fit : 모든 메모리 공간을 검사해서 내부 단편화를 최소화하는 공간에 할당
공통,알고리즘,페이지 교체 알고리즘에 따른 페이지 폴트 방식에 대해 설명해 주세요,OPT : 최적 교체. 앞으로 가장 오랫동안 사용하지 않을 페이지 교체 (실현 가능성 희박) FIFO : 메모리가 할당된 순서대로 페이지를 교체 LRU : 최근에 가장 오랫동안 사용하지 않은 페이지를 교체 LFU : 사용 빈도가 가장 적은 페이지를 교체 NUR : 최근에 사용하지 않은 페이지를 교체
공통,C,페이징과 세그먼테이션이란?,"페이징 페이지 단위의 논리 물리 주소 관리 기법. 논리 주소 공간이 하나의 연속적인 물리 메모리 공간에 들어가야하는 제약을 해결하기 위한 기법 논리 주소 공간과 물리 주소 공간을 분리해야함(주소의 동적 재배치 허용), 변환을 위한 MMU 필요 특징 : 외부 단편화를 없앨 수 있음. 페이지가 클수록 내부 단편화도 커짐 세그먼테이션 사용자/프로그래머 관점의 메모리 관리 기법. 페이징 기법은 같은 크기의 페이지를 갖는 것 과는 다르게 논리적 단위(세그먼트)로 나누므로 미리 분할하는 것이 아니고 메모리 사용할 시점에 할당됨"
BACKEND,운영체제,"뮤텍스, 세마포어가 뭔지, 차이점은?","세마포어 운영체제에서 공유 자원에 대한 접속을 제어하기 위해 사용되는 신호 공유자원에 접근할 수 있는 최대 허용치만큼만 동시에 사용자 접근 가능 스레드들은 리소스 접근 요청을 할 수 있고, 세마포어는 카운트가 하나씩 줄어들게 되며 리소스가 모두 사용중인 경우(카운트=0) 다음 작업은 대기를 하게 된다 뮤텍스 상호배제, 제어되는 섹션에 하나의 스레드만 허용하기 때문에, 해당 섹션에 접근하려는 다른 스레드들을 강제적으로 막음으로써 첫 번째 스레드가 해당 섹션을 빠져나올 때까지 기다리는 것 (대기열(큐) 구조라고 생각하면 됨) 차이점 세마포어는 뮤텍스가 될 수 있지만, 뮤텍스는 세마포어가 될 수 없음 세마포어는 소유 불가능하지만, 뮤택스는 소유가 가능함 동기화의 개수가 다름"
AI,데이터,가상메모리에 대해 설명해 주세요,"프로세스에서 사용하는 메모리 주소와 실제 물리적 메모리 주소는 다를 수 있음 따라서 메모리 = 실제 + 가상 메모리라고 생각하면 안됨 메모리가 부족해서 가상메모리를 사용하는 건 맞지만, 가상메모리를 쓴다고 실제 메모리처럼 사용하는 것은 아님 실제 메모리 안에 공간이 부족하면, 현재 사용하고 있지 않은 데이터를 빼내어 가상 메모리에 저장해두고, 실제 메모리에선 처리만 하게 하는 것이 가상 메모리의 역할 이다. 즉, 실제 메모리에 놀고 있는 공간이 없게 계속 일을 시키는 것. 이를 도와주는 것이 '가상 메모리'"
AI,데이터,Race Condition에 대해 설명해 주세요,"두 개 이상의 프로세스가 공통 자원을 병행적으로 읽거나 쓸 때, 공용 데이터에 대한 접근이 순서에 따라 실행 결과가 달라지는 상황 Race Condition이 발생하게 되면, 모든 프로세스에 원하는 결과가 발생하는 것을 보장할 수 없음. 따라서 이러한 상황은 피해야 하며 상호배제나 임계구역으로 해결이 가능하다."
AI,데이터,리눅스에서 시스템 콜과 서브루틴의 차이는?,"우선 커널을 확인하자 커널은 하드웨어를 둘러싸고 있음 즉, 커널은 하드웨어를 제어하기 위한 일종의 API와 같음 서브루틴(SubRoutine)은 우리가 프로그래밍할 때 사용하는 대부분의 API를 얘기하는 것 stdio.h에 있는 printf나 scanf string.h에 있는 strcmp나 strcpy 서브루틴과 시스템 콜의 차이는? 서브루틴이 시스템 콜을 호출하고, 시스템 콜이 수행한 결과를 서브루틴에 보냄 시스템 콜 호출 시, 커널이 호출되고 커널이 수행한 임의의 결과 데이터를 다시 시스템 콜로 보냄 즉, 진행 방식은 아래와 같다. 서브루틴이 시스템 콜 호출 → 시스템 콜은 커널 호출 → 커널은 자신의 역할을 수행하고 (하드웨어를 제어함) 나온 결과 데이터를 시스템 콜에게 보냄 → 시스템 콜이 다시 서브루틴에게 보냄 실무로 사용할 때 둘의 큰 차이는 없음(api를 호출해서 사용하는 것은 동일)"
AI,데이터,DBMS에 대해 설명해 주세요,데이터베이스 관리 시스템 다수의 사용자가 데이터베이스 내의 데이터를 접근할 수 있도록 설계된 시스템
AI,데이터,DBMS의 기능에 대해 설명해 주세요,"정의 기능(DDL: Data Definition Language) 데이터베이스가 어떤 용도이며 어떤 식으로 이용될것이라는 것에 대한 정의가 필요함 CREATE, ALTER, DROP, RENAME 조작 기능(DML: Data Manipulation Language) 데이터베이스를 만들었을 때 그 정보를 수정하거나 삭제 추가 검색 할 수 있어야함 SELECT, INSERT, UPDATE, DELETE 제어 기능(DCL: Data Control Language) 데이터베이스에 접근하고 객체들을 사용하도록 권한을 주고 회수하는 명령 GRANT REVOKE"
AI,데이터,DB에서 View는 무엇인가? 가상 테이블에 대해 설명해 주세요,허용된 데이터를 제한적으로 보여주기 위한 것 하나 이상의 테이블에서 유도된 가상 테이블이다. 사용자가 view에 접근했을 때 해당하는 데이터를 원본에서 가져온다. view에 나타나지 않은 데이터를 간편히 보호할 수 있는 장점 존재
AI,데이터,정규화에 대해 설명해 주세요,"중복을 최대한 줄여 데이터를 구조화하고, 불필요한 데이터를 제거해 데이터를 논리적으로 저장하는 것 이상현상이 일어나지 않도록 정규화 시킨다!"
AI,데이터,이상현상에 대해 설명해 주세요,"릴레이션에서 일부 속성들의 종속으로 인해 데이터 중복이 발생하는 것 (insert, update, delete)"
AI,데이터,데이터베이스를 설계할 때 가장 중요한 것이 무엇이라고 생각하나요?,"무결성을 보장해야 합니다. 무결성 보장 방법은? 데이터를 조작하는 프로그램 내에서 데이터 생성, 수정, 삭제 시 무결성 조건을 검증한다. 트리거 이벤트 시 저장 SQL을 실행하고 무결성 조건을 실행한다. DB제약조건 기능을 선언한다."
AI,데이터,데이터베이스 무결성에 대해 설명해 주세요,"테이블에 있는 모든 행들이 유일한 식별자를 가질 것을 요구함 (같은 값 X) 외래키 값은 NULL이거나 참조 테이블의 PK값이어야 함 한 컬럼에 대해 NULL 허용 여부와 자료형, 규칙으로 타당한 데이터 값 지정"
AI,데이터,트리거에 대해 설명해 주세요,"자동으로 실행되도록 정의된 저장 프로시저 (insert, update, delete문에 대한 응답을 자동으로 호출한다.) 사용하는 이유는? 업무 규칙 보장, 업무 처리 자동화, 데이터 무결성 강화"
AI,데이터,오라클과 MySQL의 차이에 대해 설명해 주세요,"일단 Oracle이 MySQL보다 훨~씬 좋음 오라클 : 대규모 트랜잭션 로드를 처리하고, 성능 최적화를 위해 여러 서버에 대용량 DB를 분산함 MySQL : 단일 데이터베이스로 제한되어있고, 대용량 데이터베이스로는 부적합. 작은 프로젝트에서 적용시키기 용이하며 이전 상태를 복원하는데 commit과 rollback만 존재"
AI,데이터,JDBC와 ODBC의 차이에 대해 설명해 주세요,"JDBC JAVA에서 DB에 접근하여 데이터를 조회, 삽입, 수정, 삭제 가능 DBMS 종류에 따라 맞는 jdbc를 설치해야함 ODBC 응용 프로그램에서 DB 접근을 위한 표준 개방형 응용 프로그램 인터페이스 MS사에서 만들었으며, Excel/Text 등 여러 종류의 데이터에 접근할 수 있음"
AI,데이터,데이터 베이스에서 인덱스(색인)이란 무엇인가요,"책으로 비유하자면 목차로 비유할 수 있다. DBMS에서 저장 성능을 희생하여 데이터 읽기 속도를 높이는 기능 데이터가 정렬되어 들어간다 양이 많은 테이블에서 일부 데이터만 불러 왔을 때, 이를 풀 스캔 시 처리 성능 떨어짐 종류 B+ Tree 인덱스 : 원래의 값을 이용하여 인덱싱 Hash 인덱스 : 칼럼 값으로 해시 값 게산하여 인덱싱, 메모리 기반 DB에서 많이 사용 B Hash 생성시 고려해야 할 점 테이블 전체 로우 수 15%이하 데이터 조회시 생성 테이블 건수가 적으면 인덱스 생성 하지 않음, 풀 스캔이 빠름 자주 쓰는 컬럼을 앞으로 지정 DML시 인덱스에도 수정 작업이 동시에 발생하므로 DML이 많은 테이블은 인덱스 생성 하지 않음"
BACKEND,네트워크,OSI 7계층을 설명하시오,"OSI 7계층이란, 통신 접속에서 완료까지의 과정을 7단계로 정의한 국제 통신 표준 규약 물리 : 전송하는데 필요한 기능을 제공 ( 통신 케이블, 허브 ) 데이터링크 : 송/수신 확인. MAC 주소를 가지고 통신함 ( 브릿지, 스위치 ) 네트워크 : 패킷을 네트워크 간의 IP를 통해 데이터 전달 ( 라우팅 ) 전송 : 두 host 시스템으로부터 발생하는 데이터 흐름 제공 세션 : 통신 시스템 사용자간의 연결을 유지 및 설정함 표현 : 세션 계층 간의 주고받는 인터페이스를 일관성있게 제공 응용 : 사용자가 네트워크에 접근할 수 있도록 서비스 제공"
BACKEND,네트워크,TCP/IP 프로토콜을 스택 4계층으로 짓고 설명하시오,"LINK 계층 물리적인 영역의 표준화에 대한 결과 가장 기본이 되는 영역으로 LAN, WAN과 같은 네트워크 표준과 관련된 프로토콜을 정의하는 영역이다 IP 계층 경로 검색을 해주는 계층임 IP 자체는 비연결지향적이며, 신뢰할 수 없는 프로토콜이다 데이터를 전송할 때마다 거쳐야할 경로를 선택해주지만, 경로가 일정하지 않음. 또한 데이터 전송 중에 경로상 문제가 발생할 때 데이터가 손실되거나 오류가 발생하는 문제가 발생할 수 있음. 따라서 IP 계층은 오류 발생에 대한 대비가 되어있지 않은 프로토콜임 TCP/UDP (전송) 계층 데이터의 실제 송수신을 담당함 UDP는 TCP에 비해 상대적으로 간단하고, TCP는 신뢰성잇는 데이터 전송을 담당함 TCP는 데이터 전송 시, IP 프로토콜이 기반임 (IP는 문제 해결에 문제가 있는데 TCP가 신뢰라고?) → IP의 문제를 해결해주는 것이 TCP인 것. 데이터의 순서가 올바르게 전송 갔는지 확인해주며 대화를 주고받는 방식임. 이처럼 확인 절차를 걸치며 신뢰성 없는 IP에 신뢰성을 부여한 프로토콜이 TCP이다 애플리케이션 계층 서버와 클라이언트를 만드는 과정에서 프로그램 성격에 따라 데이터 송수신에 대한 약속들이 정해지는데, 이것이 바로 애플리케이션 계층이다"
BACKEND,네트워크,TCP에 대해 설명해 주세요,"서버와 클라이언트의 함수 호출 순서가 중요하다 서버 : socket() 생성 → bind() 소켓 주소할당 → listen() 연결요청 대기상태 → accept() 연결허용 → read/write() 데이터 송수신 → close() 연결종료 클라이언트 : socket() 생성 → connect() 연결요청 → read/write() 데이터 송수신 → close() 연결종료 둘의 차이는? 클라이언트 소켓을 생성한 후, 서버로 연결을 요청하는 과정에서 차이가 존재한다. 서버는 listen() 호출 이후부터 연결요청 대기 큐를 만들어 놓고, 그 이후에 클라이언트가 연결 요청을 할 수 있다. 이때 서버가 바로 accept()를 호출할 수 있는데, 연결되기 전까지 호출된 위치에서 블로킹 상태에 놓이게 된다. 이처럼 연결지향적인 TCP는 신뢰성 있는 데이터 전송이 가능함 (3 way handshaking) 흐름제어와 혼잡제어를 지원해서 데이터 순서를 보장해줌 흐름제어 : 송신 측과 수신 측의 데이터 처리 속도 차이를 조절해주는 것 혼잡 제어 : 네트워크 내의 패킷 수가 넘치게 증가하지 않도록 방지하는 것 정확성 높은 전송을 하기 위해 속도가 느린 단점이 있고, 주로 웹 HTTP 통신, 이메일, 파일 전송에 사용됨"
BACKEND,네트워크,3 way handshaking에 대해 설명해 주세요,"TCP 소켓은 연결 설정과정 중에 총 3번의 대화를 주고 받는다. (SYN : 연결 요청 플래그 / ACK : 응답) 클라이언트는 서버에 접속 요청하는 SYN(M) 패킷을 보냄 서버는 클라이언트 요청인 SYN(M)을 받고, 클라이언트에게 요청을 수락한다는 ACK(M+1)와 SYN(N)이 설정된 패킷을 발송함 클라이언트는 서버의 수락 응답인 ACK(M+1)와 SYN(N) 패킷을 받고, ACK(N+1)를 서버로 보내면 연결이 성립됨 클라이언트가 연결 종료하겠다는 FIN 플래그를 전송함 서버는 클라이언트의 요청(FIN)을 받고, 알겠다는 확인 메시지로 ACK를 보냄. 그 이후 데이터를 모두 보낼 때까지 잠깐 TIME OUT이 됨 데이터를 모두 보내고 통신이 끝났으면 연결이 종료되었다고 클라이언트에게 FIN플래그를 전송함 클라이언트는 FIN 메시지를 확인했다는 ACK를 보냄 클라이언트의 ACK 메시지를 받은 서버는 소켓 연결을 close함 클라이언트는 아직 서버로부터 받지 못한 데이터가 있을 것을 대비해서, 일정 시간동안 세션을 남겨놓고 잉여 패킷을 기다리는 과정을 거침 ( TIME WAIT )"
BACKEND,네트워크,UDP에 대해 설명해 주세요,"TCP의 대안으로, IP와 같이 쓰일 땐 UDP/IP라고도 부름 TCP와 마찬가지로, 실제 데이터 단위를 받기 위해 IP를 사용함. 그러나 TCP와는 달리 메시지를 패킷으로 나누고, 반대편에서 재조립하는 등의 서비스를 제공하지 않음 즉, 여러 컴퓨터를 거치지 않고 데이터를 주고 받을 컴퓨터끼리 직접 연결할 때 UDP를 사용한다. UDP를 사용해 목적지(IP)로 메시지를 보낼 수 있으며, 컴퓨터를 거쳐 목적지까지 도달할 수도 있음 (도착하지 않을 가능성도 존재함) 정보를 받는 컴퓨터는 포트를 열어두고, 패킷이 올 때까지 기다리며 데이터가 오면 모두 다 받아들인다. 패킷이 도착했을 때 출발지에 대한 정보(IP와 PORT)를 알 수 있음 UDP는 이런 특성 때문에 비신뢰적이고, 안정적이지 않은 프로토콜임. 하지만 TCP보다 속도가 매우 빠르고 편해서 데이터 유실이 일어나도 큰 상관이 없는 스트리밍이나 화면 전송에 사용됨"
BACKEND,네트워크,HTTP와 HTTPS의 차이에 대해 설명해 주세요,"HTTP 동작 순서 : TCP → HTTP HTTPS 동작 순서 : TCP → SSL → HTTP SSL(Secure Socket Layer)을 쓰냐 안쓰냐의 차이다. SSL 프로토콜은 정보를 암호화시키고 이때 공개키와 개인키 두가지를 이용한다. HTTPS는 인터넷 상에서 정보를 암호화하기 위해 SSL 프로토콜을 이용해 데이터를 전송하고 있다는 것을 말한다. 즉, 문서 전송시 암호화 처리 유무에 따라 HTTP와 HTTPS로 나누어지는 것 모든 사이트가 HTTPS로 하지 않는 이유는, 암호화 과정으로 인한 속도 저하가 발생하기 때문이다."
BACKEND,네트워크,GET과 POST의 차이에 대해 설명해 주세요,"둘다 HTTP 프로토콜을 이용해 서버에 무언가 요청할 때 사용하는 방식이다. GET 방식은, URL을 통해 모든 파라미터를 전달하기 때문에 주소창에 전달 값이 노출됨. URL 길이가 제한이 있기 때문에 전송 데이터 양이 한정되어 있고, 형식에 맞지 않으면 인코딩해서 전달해야 함 POST 방식은 HTTP BODY에 데이터를 포함해서 전달함. 웹 브라우저 사용자의 눈에는 직접적으로 파라미터가 노출되지 않고 길이 제한도 없음. 보통 GET은 가져올 때, POST는 수행하는 역할에 활용한다. GET은 SELECT 성향이 있어서 서버에서 어떤 데이터를 가져와서 보여주는 용도로 활용 POST는 서버의 값이나 상태를 바꾸기 위해 활용"
BACKEND,네트워크,IOCP를 설명하시오,"IOCP는 어떤 I/O 핸들에 대해, 블록 되지 않게 비동기 작업을 하면서 프로그램 대기시간을 줄이는 목적으로 사용된다. 동기화 Object 세마포어의 특성과, 큐를 가진 커널 Object다. 대부분 멀티 스레드 상에서 사용되고, 큐는 자체적으로 운영하는 특징 때문에 스레드 풀링에 적합함 동기화와 동시에 큐를 통한 데이터 전달 IOCP는, 스레드 풀링을 위한 것이라고 할 수 있음 POOLING이란? 여러 스레드를 생성하여 대기시키고, 필요할 때 가져다가 사용한 뒤에 다시 반납하는 과정 (스레드의 생성과 파괴는 상당히 큰 오버헤드가 존재하기 때문에 이 과정을 이용한다) IOCP의 장점은 사용자가 설정한 버퍼만 사용하기 때문에 더 효율적으로 작동시킬 수 있음. (기존에는 OS버퍼, 사용자 버퍼로 따로 분리해서 운영했음) 커널 레벨에서는 모든 I/O를 비동기로 처리하기 때문에 효율적인 순서에 따라 접근할 수 있음"
BACKEND,네트워크,라우터와 스위치의 차이는?,"라우터는 3계층 장비로, 수신한 패킷의 정보를 보고 경로를 설정해 패킷을 전송하는 역할을 수행하는 장비 스위치는 주로 내부 네트워크에 위치하며 MAC 주소 테이블을 이용해 해당 프레임을 전송하는 2계층 장비"
공통,디자인패턴,Dispatcher Servlet에 대해 설명해 주세요,"서블릿 컨테이너에서 HTTP 프로토콜을 통해 들어오는 모든 요청을 제일 앞에서 처리해주는 프론트 컨트롤러를 말함 따라서 서버가 받기 전에, 공통처리 작업을 디스패처 서블릿이 처리해주고 적절한 세부 컨트롤러로 작업을 위임해줍니다. 디스패처 서블릿이 처리하는 url 패턴을 지정해줘야 하는데, 일반적으로는 .mvc와 같은 패턴으로 처리하라고 미리 지정해줍니다. 디스패처 서블릿으로 인해 web.xml이 가진 역할이 상당히 축소되었습니다. 기존에는 모든 서블릿을 url 매핑 활용을 위해 모두 web.xml에 등록해 주었지만, 디스패처 서블릿은 그 전에 모든 요청을 핸들링해주면서 작업을 편리하게 할 수 있도록 도와줍니다. 또한 이 서블릿을 통해 MVC를 사용할 수 있기 때문에 웹 개발 시 큰 장점을 가져다 줍니다."
AI,데이터,DAO(Data Access Object)에 대해 설명해 주세요,"DB에 데이터를 조회하거나 조작하는 기능들을 전담합니다. Mybatis를 이용할 때는, mapper.xml에 쿼리문을 작성하고 이를 mapper 클래스에서 받아와 DAO에게 넘겨주는 식으로 구현합니다."
AI,데이터,Annotation에 대해 설명해 주세요,"소스코드에 @어노테이션의 형태로 표현하며 클래스, 필드, 메소드의 선언부에 적용할 수 있는 특정기능이 부여된 표현법을 말합니다. 애플리케이션 규모가 커질수록, xml 환경설정이 매우 복잡해지는데 이러한 어려움을 개선시키기 위해 JAVA 파일에 어노테이션을 적용해서 개발자가 설정 파일 작업을 할 때 발생시키는 오류를 최소화해주는 역할을 합니다. 어노테이션 사용으로 소스 코드에 메타데이터를 보관할 수 있고, 컴파일 타임의 체크뿐 아니라 어노테이션 API를 사용해 코드 가독성도 높여줍니다. @Controller : dispatcher servlet.xml에서 bean 태그로 정의하는 것과 같음. @RequestMapping : 특정 메소드에서 요청되는 URL과 매칭시키는 어노테이션 @Autowired : 자동으로 의존성 주입하기 위한 어노테이션 @Service : 비즈니스 로직 처리하는 서비스 클래스에 등록 @Repository : DAO에 등록"
AI,데이터,Spring JDBC에 대해 설명해 주세요,"데이터베이스 테이블과, JAVA 객체 사이의 단순한 매핑을 간단한 설정을 통해 처리하는 것 기존의 JDBC에서는 구현하고 싶은 로직마다 필요한 SQL문이 모두 달랐고, 이에 필요한 Connection, PrepareStatement, ResultSet 등을 생성하고 Exception 처리도 모두 해야하는 번거러움이 존재했습니다. Spring에서는 JDBC와 ORM 프레임워크를 직접 지원하기 때문에 따로 작성하지 않아도 모두 다 처리해주는 장점이 있습니다."
AI,데이터,MyBatis에 대해 설명해 주세요,"객체, 데이터베이스, Mapper 자체를 독립적으로 작성하고, DTO에 해당하는 부분과 SQL 실행결과를 매핑해서 사용할 수 있도록 지원함 기존에는 DAO에 모두 SQL문이 JAVA 소스상에 위치했으나, MyBatis를 통해 SQL은 XML 설정 파일로 관리합니다. 설정파일로 분리하면, 수정할 때 설정파일만 건드리면 되므로 유지보수에 매우 좋습니다. 또한 매개변수나 리턴 타입으로 매핑되는 모든 DTO에 관련된 부분도 모두 설정파일에서 작업할 수 있는 장점이 있습니다."
공통,C,선언 규칙에 대해 설명해 주세요,"  클래스의 public 영역에 선언해야 한다. 가상 함수는 static일 수 없다. 실행시간 다형성을 얻기 위해, 기본 클래스의 포인터 또는 참조를 통해 접근해야 한다. 가상 함수는 반환형과 매개변수가 자식 클래스에서도 일치해야 한다. c++ class parent { public : virtual void v print() { cout ""parent"" ""n""; } void print() { cout ""parent"" ""n""; } }; class child : public parent { public : void v print() { cout ""child"" ""n""; } void print() { cout ""child"" ""n""; } }; int main() { parent p; child c; p = &c; p  v print(); p  print(); return 0; } // 출력 결과 // child // parent parent 클래스를 가리키는 포인터 p를 선언하고 child 클래스의 객체 c를 선언한 상태 포인터 p가 c 객체를 가리키고 있음 (몸체는 parent 클래스지만, 현재 실제 객체는 child 클래스) 포인터 p를 활용해 virtual 을 활용한 가상 함수인 v print() 와 오버라이딩된 함수 print() 의 출력은 다르게 나오는 것을 확인할 수 있다. 가상 함수는 실행시간에 값이 결정됨 (후기 바인딩) print()는 컴파일 시간에 이미 결정되어 parent가 호출되는 것으로 결정이 끝남"
공통,C,크기 계산에 대해 설명해 주세요,"c typedef struct student { char a; int b; }S; void main() { printf(""메모리 크기 = %d/n"", sizeof(S)); // 8 } char는 1바이트고, int는 4바이트라서 5바이트가 필요하다. 하지만 메모리 공간은 5가 아닌 8이 찍힐 것이다 . Why? 구조체가 메모리 공간을 잡는 원리에는 크게 두가지 규칙이 있다. 1. 각각의 멤버를 저장하기 위해서는 기본 4바이트 단위로 구성 된다. (4의 배수 단위) 즉, char 데이터 1개를 저장할 때 이 1개의 데이터를 읽어오기 위해서 1바이트를 읽어오는 것이 아니라 이 데이터가 포함된 '4바이트'를 읽는다. 2. 구조체 각 멤버 중에서 가장 큰 멤버의 크기에 영향을 받는다. 이 규칙이 적용된 메모리 공간은 아래와 같을 것이다. a는 char형이지만, 기본 4바이트 단위 구성으로 인해 3바이트의 여유공간이 생긴다. 그렇다면 이와 같을 때는 어떨까? c typedef struct student { char a; char b; int c; }S; 이제부터 헷갈리는 경우다. c typedef struct student { char a; int c; char b; }S; 구성은 같지만, 순서가 다르다. 자료타입은 일치하지만, 선언된 순서에 따라 할당되는 메모리 공간이 아래와 같이 달라진다. c typedef struct student { char a; int c; double b; }S; 두 규칙이 모두 적용되는 상황이다. b가 double로 8바이트이므로 기본 공간이 8바이트로 설정된다. 하지만 a와 c는 8바이트로 해결이 가능하기 때문에 16바이트로 해결이 가능하다."
공통,C,동적할당에 대해 설명해 주세요,"프로그램 실행 중에 동적으로 메모리를 할당하는 것 Heap 영역에 할당한다 stdlib.h 헤더 파일을 include 해야한다. 함수(Function) 메모리 할당 함수 : malloc void malloc(size t size) 메모리 할당은 size t 크기만큼 할당해준다. 메모리 할당 및 초기화 : calloc void calloc(size t nelem, sizeo t elsize) 첫번째 인자는 배열요소 개수, 두번째 인자는 각 배열요소 사이즈 할당된 메모리를 0으로 초기화 메모리 추가 할당 : realloc void realloc(void ptr, size t size) 이미 할당받은 메모리에 추가로 메모리 할당 (이전 메모리 주소 없어짐) 메모리 해제 함수 : free void free(void ptr) 할당된 메모리 해제"
공통,C,이중 포인터에 대해 설명해 주세요,"포인터의 포인터, 즉 포인터의 메모리 주소를 저장하는 것을 말한다. c"
공통,JAVA,그렇다면 const와 let은 무슨 차이에 대해 설명해 주세요,"간단히 말해서 let은 대입한 값을 계속 수정할 수 있지만, const는 한번 대입하면 다른 값 대입을 할 수 없고 초기화 시 값이 필요다. javascript const a = 0; a = 1; // error let b = 0; b = 1; // 1 const c; // error"
공통,JAVA,오토 박싱 & 오토 언박싱에 대해 설명해 주세요,JDK 1.5부터는 JAVA 컴파일러가 박싱과 언박싱이 필요한 상황에 자동으로 처리를 해준다. JAVA // 오토 박싱 int i = 10; Integer num = i; // 오토 언박싱 Integer num = new Integer(10); int i = num;
공통,JAVA,오토 박싱 연산에 대해 설명해 주세요,"java public static void main(String[] args) { long t = System.currentTimeMillis(); Long sum = 0L; for (long i = 0; i 1000000; i++) { sum += i; } System.out.println(""실행 시간: "" + (System.currentTimeMillis() t) + "" ms""); } // 실행 시간 : 19 ms"
공통,JAVA,동일 타입 연산에 대해 설명해 주세요,"java public static void main(String[] args) { long t = System.currentTimeMillis(); long sum = 0L; for (long i = 0; i 1000000; i++) { sum += i; } System.out.println(""실행 시간: "" + (System.currentTimeMillis() t) + "" ms"") ; } // 실행 시간 : 4 ms 100만건 기준으로 약 5배의 성능 차이가 난다. 따라서 서비스를 개발하면서 불필요한 오토 캐스팅이 일어나는 지 확인하는 습관을 가지자."
공통,C,call by reference에 대해 설명해 주세요,"참조에 의한 호출 call by reference 호출 방식은 함수 호출 시 인자로 전달되는 변수의 레퍼런스를 전달함 따라서 함수 안에서 인자 값이 변경되면, 아규먼트로 전달된 객체의 값도 변경됨 c++ void func(int n) { n = 20; } void main() { int n = 10; func(&n); printf(""%d"", n); } printf로 출력되는 값은 20이 된다."
공통,JAVA,Java 함수 호출 방식에 대해 설명해 주세요,"del JAVA의 경우, 함수에 전달되는 인자의 데이터 타입에 따라 함수 호출 방식이 달라짐 /del del primitive type(원시 자료형) : call by value /del del int, short, long, float, double, char, boolean /del del reference type(참조 자료형) : call by reference /del del array, Class instance /del JAVA의 경우, 항상 call by value 로 값을 넘긴다. C/C++와 같이 변수의 주소값 자체를 가져올 방법이 없으며, 이를 넘길 수 있는 방법 또한 있지 않다. reference type(참조 자료형)을 넘길 시에는 해당 객체의 주소값을 복사하여 이를 가지고 사용한다. 따라서 원본 객체의 프로퍼티까지는 접근이 가능하나, 원본 객체 자체를 변경할 수는 없다. 아래의 예제 코드를 봐보자. java User a = new User(""gyoogle""); // 1 foo(a); public void foo(User b){ // 2 b = new User(""jongnan""); // 3 } / ========================================== // 1 : a에 User 객체 생성 및 할당(새로 생성된 객체의 주소값을 가지고 있음) a User Object [name = ""gyoogle""] ========================================== // 2 : b라는 파라미터에 a가 가진 주소값을 복사하여 가짐 a User Object [name = ""gyoogle""] ↑ b ========================================== // 3 : 새로운 객체를 생성하고 새로 생성된 주소값을 b가 가지며 a는 그대로 원본 객체를 가리킴 a User Object [name = ""gyoogle""] b User Object [name = ""jongnan""] / 파라미터에 객체/값의 주소값을 복사하여 넘겨주는 방식을 사용하고 있는 Java는 주소값을 넘겨 주소값에 저장되어 있는 값을 사용하는 call by reference 라고 오해할 수 있다. 이는 C/C++와 Java에서 변수를 할당하는 방식을 보면 알 수 있다. java // c/c++ int a = 10; int b = a; cout &a "", "" &b endl; // out: 0x7ffeefbff49c, 0x7ffeefbff498 a = 11; cout &a endl; // out: 0x7ffeefbff49c //java int a = 10; int b = a; System.out.println(System.identityHashCode(a)); // out: 1627674070 System.out.println(System.identityHashCode(b)); // out: 1627674070 a = 11; System.out.println(System.identityHashCode(a)); // out: 1360875712 C/C++에서는 생성한 변수마다 새로운 메모리 공간을 할당하고 이에 값을 덮어씌우는 형식으로 값을 할당한다. ( 포인터를 사용한다면, 같은 주소값을 가리킬 수 있도록 할 수 있다.) Java에서 또한 생성한 변수마다 새로운 메모리 공간을 갖는 것은 마찬가지지만, 그 메모리 공간에 값 자체를 저장하는 것이 아니라 값을 다른 메모리 공간에 할당하고 이 주소값을 저장하는 것이다. 이를 다음과 같이 나타낼 수 있다. java C/C++ Java a [ 10 ] a [ XXXX ] [ 10 ] XXXX(위치) b [ 10 ] b [ XXXX ] 값 변경 a [ 11 ] a [ YYYY ] [ 10 ] XXXX(위치) b [ 10 ] b [ XXXX ] [ 11 ] YYYY(위치) b = a; 일 때 a의 값을 b의 값으로 덮어 씌우는 것은 같지만, 실제 값을 저장하는 것과 값의 주소값을 저장하는 것의 차이가 존재한다. 즉, Java에서의 변수는 [할당된 값의 위치]를 [값]으로 가지고 있는 것이다. C/C++에서는 주소값 자체를 인자로 넘겼을 때 값을 변경하면 새로운 값으로 덮어 쓰여 기존 값이 변경되고, Java에서는 주소값이 덮어 쓰여지므로 원본 값은 전혀 영향이 가지 않는 것이다. (객체의 속성값에 접근하여 변경하는 것은 직접 접근하여 변경하는 것이므로 이를 가리키는 변수들에서 변경이 일어난다.) java 객체 접근하여 속성값 변경 a : [ XXXX ] [ Object [prop : ~ ] ] XXXX(위치) b : [ XXXX ] prop : ~ (이 또한 변수이므로 어딘가에 ~가 저장되어있고 prop는 이의 주소값을 가지고 있는 셈) prop : [ YYYY ] [ ~ ] YYYY(위치) a.prop = (a를 통해 prop를 변경) prop : [ ZZZZ ] [ ~ ] YYYY(위치) [ ] ZZZZ b Object에 접근 prop 접근 ZZZZ 위와 같은 이유로 Java에서 인자로 넘길 때는 주소값이란 값을 복사하여 넘기는 것이므로 call by value라고 할 수 있다. 출처 :"
공통,JAVA,캐스팅에 대해 설명해 주세요,"변수가 원하는 정보를 다 갖고 있는 것 java int a = 0.1; // (1) 에러 발생 X int b = (int) true; // (2) 에러 발생 O, boolean은 int로 캐스트 불가 (1)은 0.1이 double형이지만, int로 될 정보 또한 가지고 있음 (2)는 true는 int형이 될 정보를 가지고 있지 않음"
공통,C,형변환의 종류에 대해 설명해 주세요,1. 묵시적 형변환 : 캐스팅이 자동으로 발생 (업캐스팅) java Parent p = new Child(); // (Parent) new Child()할 필요가 없음 Parent를 상속받은 Child는 Parent의 속성을 포함하고 있기 때문 2. 명시적 형변환 : 캐스팅할 내용을 적어줘야 하는 경우 (다운캐스팅) java Parent p = new Child(); Child c = (Child) p; 다운캐스팅은 업캐스팅이 발생한 이후에 작용한다.
공통,JAVA,Intrinsic Lock / Synchronized Block / Reentrancy에 대해 설명해 주세요,"Intrinsic Lock (= monitor lock = monitor) : Java의 모든 객체는 lock을 갖고 있음. Synchronized 블록은 Intrinsic Lock을 이용해서, Thread의 접근을 제어함. java public class Counter { private int count; public int increase() { return ++count; // Thread safe 하지 않은 연산 } } Q) ++count 문이 atomic 연산인가? A) read (count 값을 읽음) modify (count 값 수정) write (count 값 저장)의 과정에서, 여러 Thread가 u 공유 자원(count)으로 접근할 수 있으므로, 동시성 문제가 발생 /u 함."
공통,JAVA,Synchronized 블록을 사용한 Thread safe Case에 대해 설명해 주세요,"java public class Counter{ private Object lock = new Object(); // 모든 객체가 가능 (Lock이 있음) private int count; public int increase() { // 단계 (1) synchronized(lock){ // lock을 이용하여, count 변수에의 접근을 막음 return ++count; } / 단계 (2) synchronized(this) { // this도 객체이므로 lock으로 사용 가능 return ++count; } / } / 단계 (3) public synchronized int increase() { return ++count; } / } 단계 3과 같이 lock 생성 없이 synchronized 블록 구현 가능"
공통,JAVA,Reentrancy에 대해 설명해 주세요,"재진입 : Lock을 획득한 Thread가 같은 Lock을 얻기 위해 대기할 필요가 없는 것 (Lock의 획득이 ' u 호출 단위 /u '가 아닌 u Thread 단위 /u 로 일어나는 것) java public class Reentrancy { // b가 Synchronized로 선언되어 있더라도, a 진입시 lock을 획득하였음. // b를 호출할 수 있게 됨. public synchronized void a() { System.out.println(""a""); b(); } public synchronized void b() { System.out.println(""b""); } public static void main (String[] args) { new Reentrancy().a(); } }"
공통,JAVA,Structured Lock vs Reentrant Lock에 대해 설명해 주세요,"u Structured Lock (구조적 Lock) : 고유 lock을 이용한 동기화 /u (Synchronized 블록 단위로 lock의 획득 / 해제가 일어나므로) 따라서, A획득 B획득 B해제 A해제는 가능하지만, A획득 B획득 A해제 B해제는 불가능함. 이것을 가능하게 하기 위해서는 u Reentrant Lock (명시적 Lock) 을 사용 /u 해야 함."
공통,JAVA,Visibility에 대해 설명해 주세요,"가시성 : 여러 Thread가 동시에 작동하였을 때, 한 Thread가 쓴 값을 다른 Thread가 볼 수 있는지, 없는지 여부 문제 : 하나의 Thread가 쓴 값을 다른 Thread가 볼 수 있느냐 없느냐. (볼 수 없으면 문제가 됨) Lock : Structure Lock과 Reentrant Lock은 Visibility를 보장. 원인 : 1. 최적화를 위해 Compiler나 CPU에서 발생하는 코드 재배열로 인해서. 2. CPU core의 cache 값이 Memory에 제때 쓰이지 않아 발생하는 문제."
공통,JAVA,스레드 구현에 대해 설명해 주세요,JAVA에서 스레드 구현 방법은 2가지가 있다. 1. Runnable 인터페이스 구현 2. Thread 클래스 상속 둘다 run() 메소드를 오버라이딩 하는 방식이다. java public class MyThread implements Runnable { @Override public void run() { // 수행 코드 } } java public class MyThread extends Thread { @Override public void run() { // 수행 코드 } }
공통,JAVA,스레드 생성에 대해 설명해 주세요,"하지만 두가지 방법은 인스턴스 생성 방법에 차이가 있다. Runnable 인터페이스를 구현한 경우는, 해당 클래스를 인스턴스화해서 Thread 생성자에 argument로 넘겨줘야 한다. 그리고 run()을 호출하면 Runnable 인터페이스에서 구현한 run()이 호출되므로 따로 오버라이딩하지 않아도 되는 장점이 있다. java public static void main(String[] args) { Runnable r = new MyThread(); Thread t = new Thread(r, ""mythread""); } Thread 클래스를 상속받은 경우는, 상속받은 클래스 자체를 스레드로 사용할 수 있다. 또, Thread 클래스를 상속받으면 스레드 클래스의 메소드(getName())를 바로 사용할 수 있지만, Runnable 구현의 경우 Thread 클래스의 static 메소드인 currentThread()를 호출하여 현재 스레드에 대한 참조를 얻어와야만 호출이 가능하다. java public class ThreadTest implements Runnable { public ThreadTest() {} public ThreadTest(String name){ Thread t = new Thread(this, name); t.start(); } @Override public void run() { for(int i = 0; i = 50; i++) { System.out.print(i + "":"" + Thread.currentThread().getName() + "" ""); try { Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } } } }"
공통,JAVA,스레드 실행에 대해 설명해 주세요,"스레드의 실행은 run() 호출이 아닌 start() 호출로 해야한다. Why? 우리는 분명 run() 메소드를 정의했는데, 실제 스레드 작업을 시키려면 start()로 작업해야 한다고 한다. run()으로 작업 지시를 하면 스레드가 일을 안할까? 그렇지 않다. 두 메소드 모두 같은 작업을 한다. 하지만 run() 메소드를 사용한다면, 이건 스레드를 사용하는 것이 아니다. Java에는 콜 스택(call stack)이 있다. 이 영역이 실질적인 명령어들을 담고 있는 메모리로, 하나씩 꺼내서 실행시키는 역할을 한다. 만약 동시에 두 가지 작업을 한다면, 두 개 이상의 콜 스택이 필요하게 된다. 스레드를 이용한다는 건, JVM이 다수의 콜 스택을 번갈아가며 일처리 를 하고 사용자는 동시에 작업하는 것처럼 보여준다. 즉, run() 메소드를 이용한다는 것은 main()의 콜 스택 하나만 이용하는 것으로 스레드 활용이 아니다. (그냥 스레드 객체의 run이라는 메소드를 호출하는 것 뿐이게 되는 것..) start() 메소드를 호출하면, JVM은 알아서 스레드를 위한 콜 스택을 새로 만들어주고 context switching을 통해 스레드답게 동작하도록 해준다. u 우리는 새로운 콜 스택을 만들어 작업을 해야 스레드 일처리가 되는 것이기 때문에 start() 메소드를 써야하는 것이다! /u start()는 스레드가 작업을 실행하는데 필요한 콜 스택을 생성한 다음 run()을 호출해서 그 스택 안에 run()을 저장할 수 있도록 해준다."
공통,JAVA,스레드의 실행제어에 대해 설명해 주세요,"스레드의 상태는 5가지가 있다 NEW : 스레드가 생성되고 아직 start()가 호출되지 않은 상태 RUNNABLE : 실행 중 또는 실행 가능 상태 BLOCKED : 동기화 블럭에 의해 일시정지된 상태(lock이 풀릴 때까지 기다림) WAITING, TIME WAITING : 실행가능하지 않은 일시정지 상태 TERMINATED : 스레드 작업이 종료된 상태 스레드로 구현하는 것이 어려운 이유는 바로 동기화와 스케줄링 때문이다. 스케줄링과 관련된 메소드는 sleep(), join(), yield(), interrupt()와 같은 것들이 있다. start() 이후에 join()을 해주면 main 스레드가 모두 종료될 때까지 기다려주는 일도 해준다."
공통,JAVA,동기화에 대해 설명해 주세요,"멀티스레드로 구현을 하다보면, 동기화는 필수적이다. 동기화가 필요한 이유는, 여러 스레드가 같은 프로세스 내의 자원을 공유하면서 작업할 때 서로의 작업이 다른 작업에 영향을 주기 때문 이다. 스레드의 동기화를 위해선, 임계 영역(critical section)과 잠금(lock)을 활용한다. 임계영역을 지정하고, 임계영역을 가지고 있는 lock을 단 하나의 스레드에게만 빌려주는 개념으로 이루어져있다. 따라서 임계구역 안에서 수행할 코드가 완료되면, lock을 반납해줘야 한다."
공통,JAVA,스레드 동기화 방법에 대해 설명해 주세요,  임계 영역(critical section) : 공유 자원에 단 하나의 스레드만 접근하도록(하나의 프로세스에 속한 스레드만 가능) 뮤텍스(mutex) : 공유 자원에 단 하나의 스레드만 접근하도록(서로 다른 프로세스에 속한 스레드도 가능) 이벤트(event) : 특정한 사건 발생을 다른 스레드에게 알림 세마포어(semaphore) : 한정된 개수의 자원을 여러 스레드가 사용하려고 할 때 접근 제한 대기 가능 타이머(waitable timer) : 특정 시간이 되면 대기 중이던 스레드 깨움
공통,JAVA,synchronized 활용에 대해 설명해 주세요,"synchronized를 활용해 임계영역을 설정할 수 있다. 서로 다른 두 객체가 동기화를 하지 않은 메소드를 같이 오버라이딩해서 이용하면, 두 스레드가 동시에 진행되므로 원하는 출력 값을 얻지 못한다. 이때 오버라이딩되는 부모 클래스의 메소드에 synchronized 키워드로 임계영역을 설정해주면 해결할 수 있다. java //synchronized : 스레드의 동기화. 공유 자원에 lock public synchronized void saveMoney(int save){ // 입금 int m = money; try{ Thread.sleep(2000); // 지연시간 2초 } catch (Exception e){ } money = m + save; System.out.println(""입금 처리""); } public synchronized void minusMoney(int minus){ // 출금 int m = money; try{ Thread.sleep(3000); // 지연시간 3초 } catch (Exception e){ } money = m minus; System.out.println(""출금 완료""); }"
공통,JAVA,wait()과 notify() 활용에 대해 설명해 주세요,"스레드가 서로 협력관계일 경우에는 무작정 대기시키는 것으로 올바르게 실행되지 않기 때문에 사용한다. wait() : 스레드가 lock을 가지고 있으면, lock 권한을 반납하고 대기하게 만듬 notify() : 대기 상태인 스레드에게 다시 lock 권한을 부여하고 수행하게 만듬 이 두 메소드는 동기화 된 영역(임계 영역)내에서 사용되어야 한다. 동기화 처리한 메소드들이 반복문에서 활용된다면, 의도한대로 결과가 나오지 않는다. 이때 wait()과 notify()를 try catch 문에서 적절히 활용해 해결할 수 있다. java / 스레드 동기화 중 협력관계 처리작업 : wait() notify() 스레드 간 협력 작업 강화 / public synchronized void makeBread(){ if (breadCount = 10){ try { System.out.println(""빵 생산 초과""); wait(); // Thread를 Not Runnable 상태로 전환 } catch (Exception e) { } } breadCount++; // 빵 생산 System.out.println(""빵을 만듦. 총 "" + breadCount + ""개""); notify(); // Thread를 Runnable 상태로 전환 } public synchronized void eatBread(){ if (breadCount 1){ try { System.out.println(""빵이 없어 기다림""); wait(); } catch (Exception e) { } } breadCount ; System.out.println(""빵을 먹음. 총 "" + breadCount + ""개""); notify(); } 조건 만족 안할 시 wait(), 만족 시 notify()를 받아 수행한다."
공통,JAVA,Collection에 대해 설명해 주세요,  모든 값을 메모리에 저장하는 자료구조다. 따라서 Collection에 추가하기 전에 미리 계산이 완료되어있어야 한다. 외부 반복을 통해 사용자가 직접 반복 작업을 거쳐 요소를 가져올 수 있다(for each)
공통,JAVA,Stream에 대해 설명해 주세요,"  요청할 때만 요소를 계산한다. 내부 반복을 사용하므로, 추출 요소만 선언해주면 알아서 반복 처리를 진행한다. 스트림에 요소를 따로 추가 혹은 제거하는 작업은 불가능하다. Collection은 핸드폰에 음악 파일을 미리 저장하여 재생하는 플레이어라면, Stream은 필요할 때 검색해서 듣는 멜론과 같은 음악 어플이라고 생각하면 된다."
공통,JAVA,외부 반복 & 내부 반복에 대해 설명해 주세요,"Collection은 외부 반복, Stream은 내부 반복이라고 했다. 두 차이를 알아보자. 성능 면에서는 '내부 반복' 이 비교적 좋다. 내부 반복은 작업을 병렬 처리하면서 최적화된 순서로 처리해준다. 하지만 외부 반복은 명시적으로 컬렉션 항목을 하나씩 가져와서 처리해야하기 때문에 최적화에 불리하다. 즉, Collection에서 병렬성을 이용하려면 직접 synchronized 를 통해 관리해야만 한다."
공통,JAVA,Stream 연산에 대해 설명해 주세요,"스트림은 연산 과정이 '중간'과 '최종'으로 나누어진다. filter, map, limit 등 파이프라이닝이 가능한 연산을 중간 연산, count, collect 등 스트림을 닫는 연산을 최종 연산이라고 한다. 둘로 나누는 이유는, 중간 연산들은 스트림을 반환해야 하는데, 모두 한꺼번에 병합하여 연산을 처리한 다음 최종 연산에서 한꺼번에 처리하게 된다. ex) Item 중에 가격이 1000 이상인 이름을 5개 선택한다. java List String items = item.stream() .filter(d  d.getPrices() =1000) .map(d  d.getName()) .limit(5) .collect(tpList()); filter와 map은 다른 연산이지만, 한 과정으로 병합된다. 만약 Collection 이었다면, 우선 가격이 1000 이상인 아이템을 찾은 다음, 이름만 따로 저장한 뒤 5개를 선택해야 한다. 연산 최적화는 물론, 가독성 면에서도 Stream이 더 좋다."
공통,JAVA,Stream 중간 연산에 대해 설명해 주세요,  filter(Predicate) : Predicate를 인자로 받아 true인 요소를 포함한 스트림 반환 distinct() : 중복 필터링 limit(n) : 주어진 사이즈 이하 크기를 갖는 스트림 반환 skip(n) : 처음 요소 n개 제외한 스트림 반환 map(Function) : 매핑 함수의 result로 구성된 스트림 반환 flatMap() : 스트림의 콘텐츠로 매핑함. map과 달리 평면화된 스트림 반환 중간 연산은 모두 스트림을 반환한다.
공통,JAVA,Stream 최종 연산에 대해 설명해 주세요,"  (boolean) allMatch(Predicate) : 모든 스트림 요소가 Predicate와 일치하는지 검사 (boolean) anyMatch(Predicate) : 하나라도 일치하는 요소가 있는지 검사 (boolean) noneMatch(Predicate) : 매치되는 요소가 없는지 검사 (Optional) findAny() : 현재 스트림에서 임의의 요소 반환 (Optional) findFirst() : 스트림의 첫번째 요소 reduce() : 모든 스트림 요소를 처리해 값을 도출. 두 개의 인자를 가짐 collect() : 스트림을 reduce하여 list, map, 정수 형식 컬렉션을 만듬 (void) forEach() : 스트림 각 요소를 소비하며 람다 적용 (Long) count : 스트림 요소 개수 반환"
공통,JAVA,Optional 클래스에 대해 설명해 주세요,값의 존재나 여부를 표현하는 컨테이너 Class null로 인한 버그를 막을 수 있는 장점이 있다. isPresent() : Optional이 값을 포함할 때 True 반환
공통,JAVA,String 특징에 대해 설명해 주세요,"new 연산을 통해 생성된 인스턴스의 메모리 공간은 변하지 않음 (Immutable) Garbage Collector로 제거되어야 함. 문자열 연산시 새로 객체를 만드는 Overhead 발생 객체가 불변하므로, Multithread에서 동기화를 신경 쓸 필요가 없음. (조회 연산에 매우 큰 장점) String 클래스 : 문자열 연산이 적고, 조회가 많은 멀티쓰레드 환경에서 좋음"
공통,JAVA,"StringBuffer, StringBuilder 특징에 대해 설명해 주세요","  공통점 new 연산으로 클래스를 한 번만 만듬 (Mutable) 문자열 연산시 새로 객체를 만들지 않고, 크기를 변경시킴 StringBuffer와 StringBuilder 클래스의 메서드가 동일함. 차이점 StringBuffer는 Thread Safe함 / StringBuilder는 Thread safe하지 않음 (불가능) StringBuffer 클래스 : 문자열 연산이 많은 Multi Thread 환경 StringBuilder 클래스 : 문자열 연산이 많은 Single Thread 또는 Thread 신경 안쓰는 환경"
공통,JAVA,"Object 클래스 wait, notify, notifyAll에 대해 설명해 주세요","Java의 최상위 클래스 = Object 클래스 Object Class 가 갖고 있는 메서드 toString() hashCode() wait() 갖고 있던 u 고유 lock 해제, Thread를 잠들게 함 /u notify() u 잠들던 Thread /u 중 임의의 u 하나를 깨움 /u . notifyAll() 잠들어 있던 Thread 를 u 모두 깨움 /u . wait, notify, notifyAll : 호출하는 스레드가 반드시 고유 락을 갖고 있어야 함. = Synchronized 블록 내에서 실행되어야 함. = 그 블록 안에서 호출하는 경우 IllegalMonitorStateException 발생."
AI,머신러닝,JVM에서의 메모리 관리에 대해 설명해 주세요,"JVM 실행에 있어서 가장 일반적인 상호작용은, 힙과 스택의 메모리 사용을 확인하는 것"
AI,머신러닝,머신러닝실행 과정에 대해 설명해 주세요,"1. 프로그램이 실행되면, JVM은 OS로부터 이 프로그램이 필요로하는 메모리를 할당받음. JVM은 이 메모리를 용도에 따라 여러 영역으로 나누어 관리함 2. JAVA 컴파일러(JAVAC)가 JAVA 소스코드를 읽고, JAVA 바이트코드(.class)로 변환시킴 3. 변경된 class 파일들을 클래스 로더를 통해 JVM 메모리 영역으로 로딩함 4. 로딩된 class파일들은 Execution engine을 통해 해석됨 5. 해석된 바이트 코드는 메모리 영역에 배치되어 실질적인 수행이 이루어짐. 이러한 실행 과정 속 JVM은 필요에 따라 스레드 동기화나 가비지 컬렉션 같은 메모리 관리 작업을 수행함"
AI,머신러닝,JAVA 컴파일러에 대해 설명해 주세요,JAVA 소스코드(.java)를 바이트 코드(.class)로 변환시켜줌
AI,머신러닝,클래스 로더에 대해 설명해 주세요,JVM은 런타임시에 처음으로 클래스를 참조할 때 해당 클래스를 로드하고 메모리 영역에 배치시킴. 이 동적 로드를 담당하는 부분이 바로 클래스 로더
AI,머신러닝,Runtime Data Areas에 대해 설명해 주세요,"JVM이 운영체제 위에서 실행되면서 할당받는 메모리 영역임 총 5가지 영역으로 나누어짐 : PC 레지스터, JVM 스택, 네이티브 메서드 스택, 힙, 메서드 영역 (이 중에 힙과 메서드 영역은 모든 스레드가 공유해서 사용함) PC 레지스터 : 스레드가 어떤 명령어로 실행되어야 할지 기록하는 부분(JVM 명령의 주소를 가짐) 스택 Area : 지역변수, 매개변수, 메서드 정보, 임시 데이터 등을 저장 네이티브 메서드 스택 : 실제 실행할 수 있는 기계어로 작성된 프로그램을 실행시키는 영역 힙 : 런타임에 동적으로 할당되는 데이터가 저장되는 영역. 객체나 배열 생성이 여기에 해당함 (또한 힙에 할당된 데이터들은 가비지컬렉터의 대상이 됨. JVM 성능 이슈에서 가장 많이 언급되는 공간임) 메서드 영역 : JVM이 시작될 때 생성되고, JVM이 읽은 각각의 클래스와 인터페이스에 대한 런타임 상수 풀, 필드 및 메서드 코드, 정적 변수, 메서드의 바이트 코드 등을 보관함"
AI,머신러닝,가비지 컬렉션(Garbage Collection)에 대해 설명해 주세요,"JAVA 이전에는 프로그래머가 모든 프로그램 메모리를 관리했음 하지만, JAVA에서는 JVM 이 프로그램 메모리를 관리함! JVM은 가비지 컬렉션이라는 프로세스를 통해 메모리를 관리함. 가비지 컬렉션은 JAVA 프로그램에서 사용되지 않는 메모리를 지속적으로 찾아내서 제거하는 역할을 함. 실행순서 : 참조되지 않은 객체들을 탐색 후 삭제 → 삭제된 객체의 메모리 반환 → 힙 메모리 재사용"
공통,JAVA,JAVA에 대해 설명해 주세요,"JAVA는 OS에 독립적인 특징을 가지고 있습니다. 그게 가능한 이유는 JVM(Java Vitual Machine) 덕분인데요. 그렇다면 JVM(Java Vitual Machine)의 어떠한 기능 때문에, OS에 독립적으로 실행시킬 수 있는지 JAVA 컴파일 과정을 통해 알아보도록 하겠습니다. img src="" img src="""
공통,JAVA,JAVA 컴파일 순서에 대해 설명해 주세요,"1. 개발자가 JAVA 소스코드(.java)를 작성합니다. 2. JAVA 컴파일러(Java Compiler)가 JAVA 소스파일을 컴파일합니다. 이때 나오는 파일은 JAVA 바이트 코드(.class)파일로 아직 컴퓨터가 읽을 수 없는 JAVA 가상 머신이 이해할 수 있는 코드입니다. 바이트 코드의 각 명령어는 1바이트 크기의 Opcode와 추가 피연산자로 이루어져 있습니다. 3. 컴파일된 바이트 코드를 JVM의 클래스로더(Class Loader)에게 전달합니다. 4. 클래스 로더는 동적로딩(Dynamic Loading)을 통해 필요한 클래스들을 로딩 및 링크하여 런타임 데이터 영역(Runtime Data area), 즉 JVM의 메모리에 올립니다. 클래스 로더 세부 동작 1. 로드 : 클래스 파일을 가져와서 JVM의 메모리에 로드합니다. 2. 검증 : JAVA 언어 명세(Java Language Specification) 및 JVM 명세에 명시된 대로 구성되어 있는지 검사합니다. 3. 준비 : 클래스가 필요로 하는 메모리를 할당합니다. (필드, 메서드, 인터페이스 등등) 4. 분석 : 클래스의 상수 풀 내 모든 심볼릭 레퍼런스를 다이렉트 레퍼런스로 변경합니다. 5. 초기화 : 클래스 변수들을 적절한 값으로 초기화합니다. (static 필드) 5. 실행엔진(Execution Engine)은 JVM 메모리에 올라온 바이트 코드들을 명령어 단위로 하나씩 가져와서 실행합니다. 이때, 실행 엔진은 두가지 방식으로 변경합니다. 1. 인터프리터 : 바이트 코드 명령어를 하나씩 읽어서 해석하고 실행합니다. 하나하나의 실행은 빠르나, 전체적인 실행 속도가 느리다는 단점을 가집니다. 2. JIT 컴파일러(Just In Time Compiler) : 인터프리터의 단점을 보완하기 위해 도입된 방식으로 바이트 코드 전체를 컴파일하여 바이너리 코드로 변경하고 이후에는 해당 메서드를 더이상 인터프리팅 하지 않고, 바이너리 코드로 직접 실행하는 방식입니다. 하나씩 인터프리팅하여 실행하는 것이 아니라 바이트 코드 전체가 컴파일된 바이너리 코드를 실행하는 것이기 때문에 전체적인 실행속도는 인터프리팅 방식보다 빠릅니다. Reference (추가로 읽어보면 좋은 자료) [1] [2]"
공통,JAVA,구현 상속(클래스→클래스)의 단점에 대해 설명해 주세요,1) 캡슐화를 위반 2) 유연하지 못한 설계 3) 다중상속 불가능
공통,JAVA,오류의 예시에 대해 설명해 주세요,"다음은, HashSet에 요소를 몇 번 삽입했는지 count 변수로 체크하여 출력하는 예제다. java public class CustomHashSet E extends HashSet { private int count = 0; public CustomHashSet(){} public CustomHashSet(int initCap, float loadFactor){ super(initCap,loadFactor); } @Override public boolean add(Object o) { count++; return super.add(o); } @Override public boolean addAll(Collection c) { count += c.size(); return super.addAll(c); } public int getCount() { return count; } } add와 addAll 메서드를 호출 시, count 변수에 해당 횟수를 더해주면서, getCount()로 호출 수를 알아낼 수 있다. 하지만, 실제로 사용해보면 원하는 값을 얻지 못한다. java public class Main { public static void main(String[] args) { CustomHashSet String customHashSet = new CustomHashSet (); List String test = Arrays.asList(""a"",""b"",""c""); customHashSet.addAll(test); System.out.println(customHashSet.getCount()); // 6 } } a, b, c 의 3가지 요소만 배열에 담아 전달했지만, 실제 getCount 메서드에서는 6이 출력된다. 이는 CustomHashSet에서 상속을 받고 있는 HashSet의 부모 클래스인 AbstractCollection 의 addAll 메서드에서 확인할 수 있다. java // AbstractCollection의 addAll 메서드 public boolean addAll(Collection ? extends E c) { boolean modified = false; for (E e : c) if (add(e)) modified = true; return modified; } 해당 메서드를 보면, add(e) 가 사용되는 것을 볼 수 있다. 여기서 왜 6이 나온지 이해가 되었을 것이다. 우리는 CustomHashSet에서 add() 와 addAll() 를 모두 오버라이딩하여 count 변수를 각각 증가시켜줬다. 결국 두 메서드가 모두 실행되면서 총 6번의 count가 저장되는 것이다. 따라서 이를 해결하기 위해선 두 메소드 중에 하나의 count를 증가하는 곳을 지워야한다. 하지만 이러면 눈으로 봤을 때 코드의 논리가 깨질 뿐만 아니라, 추후에 HashSet 클래스에 변경이 생기기라도 한다면 큰 오류를 범할 수도 있게 된다. 결과론적으로, 위와 같이 상속을 사용했을 때 유연하지 못함과 캡슐화에 위배될 수 있다는 문제점을 볼 수 있다."
BACKEND,운영체제,삼성전자 오픈소스 추진 현황에 대해 설명해 주세요,"  2002 : PDA 2009 : Galaxy, Smart TV, Exynos 2012 : Z Phone, Tizen TV, Gear, Refrigerator, Washer 2018 : IoT Devices 2019 ~ : 5G, AI, Robot"
BACKEND,운영체제,오픈소스 핵심 역할에 대해 설명해 주세요,1. OPENESS 소스코드/프로젝트 공개 확대 ( ) 국내 주요 커뮤니티 협력 강화 2. Collaboration 글로벌 오픈소스 리딩 국내 주요 SW 단체 협력 3. Developemnt Culture 사내 개발 인프라 강화 Inner Source 확대 오픈소스를 통해 미래 주요 기술을 확보 → 고객에게 더욱 새로운 가치와 경험을 제공
BACKEND,운영체제,5G에 대해 설명해 주세요,"2G : HUMAN to HUMAN 3G/4G : HUMAN to MACHINE 5G : MACHINE to MACHINE 2G/3G/4G : Voice & Data 5G : Autonomous Driving, Smart City, Smart Factory, Drone, Immersive Media, Telecom Service"
공통,알고리즘,사전 코딩테스트 코드 리뷰 (NHN Lab 팀장),동아리별 제출한 코드 평균 점수 : 78점 해당 문제는 작년 하반기 3차 기술과제 문제였음 적절한 해결방법 : Tree를 그리고 LCA or LCP 알고리즘을 통해 공통 조상 찾기
AI,데이터,SPA(Single Page Applictaion)에 대해 설명해 주세요,"최초 한 번 페이지 전체를 로딩한 뒤, 데이터만 변경하여 사용할 수 있는 애플리케이션 SPA는 기본적으로 페이지 로드가 없고, 모든 페이지가 단순히 Html5 History에 의해 렌더링된다. 기존의 전통적 방법인 SSR 방식에는 성능 문제가 있었다. 요즘 웹에서 제공되는 정보가 워낙 많다. 요청할 때마다 새로고침이 일어나면서 페이지를 로딩할 때마다 서버로부터 리소스를 전달받아 해석하고, 화면에 렌더링하는 방식인 SSR은 데이터가 많을 수록 성능문제가 발생했다. 현재 주소에서 동일한 주소를 가리키는 버튼을 눌렀을 때, 설정페이지에서 필요한 데이터를 다시 가져올 수 없다. 이는, 인터랙션이 많은 환경에서 비효율적이다. 렌더링을 서버쪽에서 진행하면 그만큼 서버 자원이 많이 사용되기 때문에 불필요한 트래픽이 낭비된다. CSR 방식은 사용자의 행동에 따라 필요한 부분만 다시 읽어온다. 따라서 서버 측에서 렌더링하여 전체 페이지를 다시 읽어들이는 것보다 빠른 인터렉션을 기대할 수 있다. 서버는 단지 JSON파일만 보내주고, HTML을 그리는 역할은 JAVA스크립트를 통해 클라이언트 측에서 수행하는 방식이다. 뷰 렌더링을 유저의 브라우저가 담당하고, 먼저 웹앱을 브라우저에게 로드한 다음 필요한 데이터만 전달받아 보여주는 CSR은 트래픽을 감소시키고, 사용자에게 더 나은 경험을 제공할 수 있도록 도와준다."
AI,데이터,CSR 장단점에 대해 설명해 주세요,"장점 트래픽 감소 필요한 데이터만 받는다 사용자 경험 새로고침이 발생하지 않음. 사용자가 네이티브 앱과 같은 경험을 할 수 있음 단점 검색 엔진 크롬에서 리액트로 만든 웹앱 소스를 확인하면 내용이 비어있음. 이처럼 검색엔진 크롤러가 데이터 수집에 어려움이 있을 가능성 존재 구글 검색엔진은 JAVA스크립트 엔진이 내장되어있지만, 네이버나 다음 등 검색엔진은 크롤링에 어려움이 있어 SSR을 따로 구현해야하는 번거로움 존재"
BACKEND,네트워크,200번대 : 통신 성공에 대해 설명해 주세요,"상태코드 이름 의미 200 OK 요청 성공(GET) 201 Create 생성 성공(POST) 202 Accepted 요청 접수O, 리소스 처리X 204 No Contents 요청 성공O, 내용 없음"
BACKEND,네트워크,300번대 : 리다이렉트에 대해 설명해 주세요,상태코드 이름 의미 300 Multiple Choice 요청 URI에 여러 리소스가 존재 301 Move Permanently 요청 URI가 새 위치로 옮겨감 304 Not Modified 요청 URI의 내용이 변경X
BACKEND,네트워크,400번대 : 클라이언트 오류에 대해 설명해 주세요,상태코드 이름 의미 400 Bad Request API에서 정의되지 않은 요청 들어옴 401 Unauthorized 인증 오류 403 Forbidden 권한 밖의 접근 시도 404 Not Found 요청 URI에 대한 리소스 존재X 405 Method Not Allowed API에서 정의되지 않은 메소드 호출 406 Not Acceptable 처리 불가 408 Request Timeout 요청 대기 시간 초과 409 Conflict 모순 429 Too Many Request 요청 횟수 상한 초과
BACKEND,네트워크,500번대 : 서버 오류에 대해 설명해 주세요,상태코드 이름 의미 500 Internal Server Error 서버 내부 오류 502 Bad Gateway 게이트웨이 오류 503 Service Unavailable 서비스 이용 불가 504 Gateway Timeout 게이트웨이 시간 초과
BACKEND,네트워크,PWA 제공 기능에 대해 설명해 주세요,"프로그래시브 : 점진적 개선을 통해 작성돼서 어떤 브라우저든 상관없이 모든 사용자에게 적합 반응형 : 데스크톱, 모바일, 테블릿 등 모든 폼 factor에 맞음 연결 독립적 : 서비스 워커를 사용해 오프라인에서도 작동이 가능함 안전 : HTTPS를 통해 제공이 되므로 스누핑이 차단되어 콘텐츠가 변조되지 않음 검색 가능 : W3C 매니페스트 및 서비스 워커 등록 범위 덕분에 '앱'으로 식별되어 검색이 가능함 재참여 가능 : 푸시 알림과 같은 기능을 통해 쉽게 재참여가 가능함"
AI,데이터,데이터 변이에 대해 설명해 주세요,"Vue.js : 반드시 데이터 객체를 생성한 이후 data를 업데이트 할 수 있음 React : state 객체를 만들고, 업데이트에 조금 더 작업이 필요 name: kim 값을 lee로 바꾸려면 Vue.js : this.name = 'lee' React : this.setState({name:'lee'}) Vue에서는 data를 업데이트할 때마다 setState를 알아서 결합해분다."
공통,JAVA,Static Pages에 대해 설명해 주세요,"바뀌지 않는 페이지 웹 서버는 파일 경로 이름을 받고, 경로와 일치하는 file contents를 반환함 항상 동일한 페이지를 반환함 image, html, css, javascript 파일과 같이 컴퓨터에 저장된 파일들"
공통,JAVA,Dynamic Pages에 대해 설명해 주세요,인자에 따라 바뀌는 페이지 인자의 내용에 맞게 동적인 contents를 반환함 웹 서버에 의해 실행되는 프로그램을 통해 만들어진 결과물임 (Servlet : was 위에서 돌아가는 JAVA 프로그램) 개발자는 Servlet에 doGet() 메소드를 구현함
BACKEND,네트워크,웹 서버에 대해 설명해 주세요,"개념에 있어서 하드웨어와 소프트웨어로 구분된다. 하드웨어 : Web 서버가 설치되어 있는 컴퓨터 소프트웨어 : 웹 브라우저 클라이언트로부터 HTTP 요청을 받고, 정적인 컨텐츠(html, css 등)를 제공하는 컴퓨터 프로그램"
BACKEND,네트워크,웹 서버 기능에 대해 설명해 주세요,"Http 프로토콜을 기반으로, 클라이언트의 요청을 서비스하는 기능을 담당 요청에 맞게 두가지 기능 중 선택해서 제공해야 한다. 정적 컨텐츠 제공 WAS를 거치지 않고 바로 자원 제공 동적 컨텐츠 제공을 위한 요청 전달 클라이언트 요청을 WAS에 보내고, WAS에서 처리한 결과를 클라이언트에게 전달 웹 서버 종류 : Apache, Nginx, IIS 등"
BACKEND,네트워크,WAS에 대해 설명해 주세요,"Web Application Server의 약자 DB 조회 및 다양한 로직 처리 요구시 동적인 컨텐츠를 제공 하기 위해 만들어진 애플리케이션 서버 HTTP를 통해 애플리케이션을 수행해주는 미들웨어다. WAS는 웹 컨테이너 혹은 서블릿 컨테이너 라고도 불림 (컨테이너란 JSP, Servlet을 실행시킬 수 있는 소프트웨어. 즉, WAS는 JSP, Servlet 구동 환경을 제공해줌)"
BACKEND,운영체제,WAS 주요 기능에 대해 설명해 주세요,"1.프로그램 실행 환경 및 DB 접속 기능 제공 2.여러 트랜잭션 관리 기능 3.업무 처리하는 비즈니스 로직 수행 WAS 종류 : Tomcat, JBoss 등"
AI,데이터,WAS가 필요한 이유에 대해 설명해 주세요,WAS를 통해 요청에 맞는 데이터를 DB에서 가져와 비즈니스 로직에 맞게 그때마다 결과를 만들고 제공하면서 자원을 효율적으로 사용할 수 있음 동적인 컨텐츠를 제공해야 할때.. 웹 서버만으로는 사용자가 원하는 요청에 대한 결과값을 모두 미리 만들어놓고 서비스하기에는 자원이 절대적으로 부족함 따라서 WAS를 통해 요청이 들어올 때마다 DB와 비즈니스 로직을 통해 결과물을 만들어 제공!
공통,JAVA,만약 Travis CI에서 push 후에도 아무런 반응이 없다면?,"현재 진행 중인 프로젝트의 GitHub Repository가 바로 루트 경로에 있지 않은 확률이 높다. 즉, 해당 레포지토리에서 추가로 폴더를 생성하여 프로젝트가 생성된 경우를 말한다. 이럴 때는 .travis.yml 을 build.gradle 이 위치한 경로에 만드는 것이 아니라, 레포지토리 루트 경로에 생성해야 한다. 그 이후 다음과 같이 코드를 추가해주자 (현재 위치로 부터 프로젝트 빌드를 진행할 곳으로 이동이 필요하기 때문) yml language: java jdk: openjdk11 branches: only: main"
공통,파이썬,REST ( u RE /u presentational u S /u tate u T /u ransfer) 기본에 대해 설명해 주세요,"REST의 요소 Method Method 의미 Idempotent POST Create No GET Select Yes PUT Update Yes DELETE Delete Yes Idempotent : 한 번 수행하냐, 여러 번 수행했을 때 결과가 같나? Resource 같은 URI 모든 것을 Resource (명사)로 표현하고, 세부 Resource에는 id를 붙임 Message 메시지 포맷이 존재 : JSON, XML 과 같은 형태가 있음 (최근에는 JSON 을 씀) text HTTP POST, { ""users"" : { ""name"" : ""terry"" } } REST 특징 Uniform Interface HTTP 표준만 맞는다면, 어떤 기술도 가능한 Interface 스타일 예) REST API 정의를 HTTP + JSON로 하였다면, C, Java, Python, IOS 플랫폼 등 특정 언어나 기술에 종속 받지 않고, 모든 플랫폼에 사용이 가능한 Loosely Coupling 구조 포함 Self Descriptive Messages API 메시지만 보고, API를 이해할 수 있는 구조 (Resource, Method를 이용해 무슨 행위를 하는지 직관적으로 이해할 수 있음) HATEOAS(Hypermedia As The Engine Of Application State) Application의 상태(State)는 Hyperlink를 통해 전이되어야 함. 서버는 현재 이용 가능한 다른 작업에 대한 하이퍼링크를 포함하여 응답해야 함. Resource Identification In Requests Resource Manipulation Through Representations Statelessness 즉, HTTP Session과 같은 컨텍스트 저장소에 u 상태 정보 저장 안함 /u u Request만 Message로 처리 /u 하면 되고, 컨텍스트 정보를 신경쓰지 않아도 되므로, u 구현이 단순해짐 /u . 따라서, REST API 실행중 실패가 발생한 경우, Transaction 복구를 위해 기존의 상태를 저장할 필요가 있다. (POST Method 제외) Resource 지향 아키텍쳐 (ROA : Resource Oriented Architecture) Resource 기반의 복수형 명사 형태의 정의를 권장. Client Server Architecture Cache Ability Layered System Code On Demand(Optional)"
BACKEND,네트워크,모바일 웹 앱 (Mobile Wep App)에 대해 설명해 주세요,"쉽게 말해, PC용 홈페이지를 모바일 스크린 크기에 맞춰 줄여 놓은 것이라고 생각하면 편함"
BACKEND,네트워크,하이브리드 앱 (Hybrid App)에 대해 설명해 주세요,"네이티브 + 웹앱 네이티브 웹에, 웹 view를 띄워 웹앱을 실행시킨다. 양쪽의 API를 모두 사용할 수 있는 것이 가장 큰 장점"
BACKEND,네트워크,통신에 대해 설명해 주세요,http 요청과 같은 네트워크 호출에 사용 (플랫폼의 독립적인 인터페이스로 구성되어있음)
공통,JAVA,JAVA스크립트 해석기에 대해 설명해 주세요,JAVA스크립트 코드를 해석하고 실행
공통,JAVA,렌더링 동작 과정에 대해 설명해 주세요,"먼저 html 문서를 파싱한다. 그리고 콘텐츠 트리 내부에서 태그를 모두 DOM 노드로 변환한다. 그 다음 외부 css 파일과 함께 포함된 스타일 요소를 파싱한다. 이 스타일 정보와 html 표시 규칙은 렌더 트리라고 부르는 또 다른 트리를 생성한다. 이렇게 생성된 렌더 트리는 정해진 순서대로 화면에 표시되는데, 생성 과정이 끝났을 때 배치가 진행되면서 노드가 화면의 정확한 위치에 표시되는 것을 의미한다. 이후에 UI 백엔드에서 렌더 트리의 각 노드를 가로지으며 형상을 만드는 그리기 과정이 진행된다. 이러한 과정이 점진적으로 진행되며, 렌더링 엔진은 좀더 빠르게 사용자에게 제공하기 위해 모든 html을 파싱할 때까지 기다리지 않고 배치와 그리기 과정을 시작한다. (마치 비동기처럼..?) 전송을 받고 기다리는 동시에 받은 내용을 먼저 화면에 보여준다 (우리가 웹페이지에 접속할 때 한꺼번에 뜨지 않고 점점 화면에 나오는 것이 이 때문!!!) DOM이란? Document Object Model(문서 객체 모델) 웹페이지 소스를 까보면 html , body 와 같은 태그들이 존재한다. 이를 Javascript가 활용할 수 있는 객체로 만들면 문서 객체 가 된다. 모델은 말 그대로, 모듈화로 만들었다거나 객체를 인식한다라고 해석하면 된다. 즉, DOM은 웹 브라우저가 html 페이지를 인식하는 방식 을 말한다. (트리구조)"
BACKEND,네트워크,웹킷 동작 구조에 대해 설명해 주세요,어태치먼트 : 웹킷이 렌더 트리를 생성하기 위해 DOM 노드와 스타일 정보를 연결하는 과정 이제 조금 트리 구조의 진행 방식이 이해되기 시작한다..ㅎㅎ
공통,C,ARM Advanced RISC Machine에 대해 설명해 주세요,"즉, 진보된 RISC 기기 의 약자로 ARM의 핵심은 RISC이다. RISC : Reduced Instruction Set Computing (감소된 명령 집합 컴퓨팅) 단순한 명령 집합을 가진 프로세서 가 복잡한 명령 집합을 가진 프로세서 보다 훨씬 더 효율적이지 않을까?로 탄생함"
BACKEND,네트워크,ARM 구조에 대해 설명해 주세요,"ARM은 칩의 기본 설계 구조만 만들고, 실제 기능 추가와 최적화 부분은 개별 반도체 제조사의 영역으로 맡긴다. 따라서 물리적 설계는 같아도, 명령 집합이 모두 다르기 때문에 서로 다른 칩이 되기도 하는 것이 ARM. 소비자에게는 칩이 논리적 구조인 명령 집합으로 구성되면서, 이런 특성 때문에 물리적 설계 베이스는 같지만 용도에 따라 다양한 제품군을 만날 수 있는 특징이 있다. 아무래도 아키텍처는 논리적인 명령 집합을 물리적으로 표현한 것이므로, 명령어가 많고 복잡해질수록 실제 물리적인 칩 구조도 크고 복잡해진다. 하지만, ARM은 RISC 설계 기반으로 '단순한 명령집합을 가진 프로세서가 복잡한 것보다 효율적'임을 기반하기 때문에 명령 집합과 구조 자체가 단순하다. 따라서 ARM 기반 프로세서가 더 작고, 효율적이며 상대적으로 느린 것이다. 단순한 명령 집합은, 적은 수의 트랜지스터만 필요하므로 간결한 설계와 더 작은 크기를 가능케 한다. 반도체 기본 부품인 트랜지스터는 전원을 소비해 다이의 크기를 증가시키기 때문에 스마트폰이나 태블릿PC를 위한 프로세서에는 가능한 적은 트랜지스터를 가진 것이 이상적이다. 따라서, 명령 집합의 수가 적기 때문에 트랜지스터 수가 적고 이를 통해 크기가 작고 전원 소모가 낮은 ARM CPU가 스마트폰, 태블릿PC와 같은 모바일 기기에 많이 사용되고 있다."
BACKEND,네트워크,ARM의 장점에 대해 설명해 주세요,"소비자에 있어 ARM은 '생태계'의 하나라고 생각할 수 있다. ARM을 위해 개발된 프로그램은 오직 ARM 프로세서가 탑재된 기기에서만 실행할 수 있다. (즉, x86 CPU 프로세서 기반 프로그램에서는 ARM 기반 기기에서 실행할 수 없음) 따라서 ARM에서 실행되던 프로그램을 x86 프로세서에서 실행되도록 하려면 (혹은 그 반대로) 프로그램에 수정이 가해져야만 한다. 하지만, 하나의 ARM 기기에 동작하는 OS는 다른 ARM 기반 기기에서도 잘 동작한다. 이러한 장점 덕분에 수많은 버전의 안드로이드가 탄생하고 있으며 또한 HP나 블랙베리의 태블릿에도 안드로이드가 탑재될 수 있는 가능성이 생기게 된 것이다. (하지만 애플사는 iOS 소스코드를 공개하지 않고 있기 때문에 애플 기기는 불가능하다) ARM을 만드는 기업들은 전력 소모를 줄이고 성능을 높이기 위해 설계를 개선하며 노력하고 있다."
AI,데이터,Fetch Cycle에 대해 설명해 주세요,"명령어를 주기억장치에서 CPU 명령어 레지스터로 가져와 해독하는 단계 1) PC에 있는 명령어 주소를 MAR로 가져옴 (그 이후 PC는 +1) 2) MAR에 저장된 주소에 해당하는 값을 메모리에서 가져와서 MBR에 저장 (이때 가져온 값은 Data 또는 Opcode(명령어)) 3) 만약 Opcode를 가져왔다면, IR에서 Decode하는 단계 거침 (명령어를 해석하여 Data로 만들어야 함) 4) 1~2과정에서 가져온 데이터를 ALU에서 수행 (Excute Cycle). 연산 결과는 MBR을 거쳐 메모리로 다시 저장"
AI,데이터,특수 목적 레지스터 중 중요한 것들에 대해 설명해 주세요,  MAR(메모리 주소 레지스터) : 읽기와 쓰기 연산을 수행할 주기억장치 주소 저장 PC(프로그램 카운터) : 다음에 수행할 명령어 주소 저장 IR(명령어 레지스터) : 현재 실행 중인 명령어 저장 MBR(메모리 버퍼 레지스터) : 주기억장치에서 읽어온 데이터 or 저장할 데이터 임시 저장 AC(누산기) : 연산 결과 임시 저장
AI,데이터,CPU의 동작 과정에 대해 설명해 주세요,1. 주기억장치는 입력장치에서 입력받은 데이터 또는 보조기억장치에 저장된 프로그램 읽어옴 2. CPU는 프로그램을 실행하기 위해 주기억장치에 저장된 프로그램 명령어와 데이터를 읽어와 처리하고 결과를 다시 주기억장치에 저장 3. 주기억장치는 처리 결과를 보조기억장치에 저장하거나 출력장치로 보냄 4. 제어장치는 1~3 과정에서 명령어가 순서대로 실행되도록 각 장치를 제어
AI,데이터,명령어 세트에 대해 설명해 주세요,"CPU가 실행할 명령어의 집합 연산 코드(Operation Code) + 피연산자(Operand)로 이루어짐 연산 코드 : 실행할 연산 피연산자 : 필요한 데이터 or 저장 위치 연산 코드는 연산, 제어, 데이터 전달, 입출력 기능을 가짐 피연산자는 주소, 숫자/문자, 논리 데이터 등을 저장 CPU는 프로그램 실행하기 위해 주기억장치에서 명령어를 순차적으로 인출하여 해독하고 실행하는 과정을 반복함 CPU가 주기억장치에서 한번에 하나의 명령어를 인출하여 실행하는데 필요한 일련의 활동을 '명령어 사이클'이라고 말함 명령어 사이클은 인출/실행/간접/인터럽트 사이클로 나누어짐 주기억장치의 지정된 주소에서 하나의 명령어를 가져오고, 실행 사이클에서는 명령어를 실행함. 하나의 명령어 실행이 완료되면 그 다음 명령어에 대한 인출 사이클 시작"
AI,데이터,"인출한 이후, 명령어를 실행하는 과정에 대해 설명해 주세요",ADD addr 명령어 연산 T0 : MAR ← IR(Addr) T1 : MBR ← M[MAR] T2 : AC ← AC + MBR 이미 인출이 진행되고 명령어만 실행하면 되기 때문에 PC를 증가할 필요x IR에 MBR의 값이 이미 저장된 상태를 의미함 따라서 AC에 MBR을 더해주기만 하면 됨 LOAD addr 명령어 연산 T0 : MAR ← IR(Addr) T1 : MBR ← M[MAR] T2 : AC ← MBR 기억장치에 있는 데이터를 AC로 이동하는 명령어 STA addr 명령어 연산 T0 : MAR ← IR(Addr) T1 : MBR ← AC T2 : M[MAR] ← MBR AC에 있는 데이터를 기억장치로 저장하는 명령어 JUMP addr 명령어 연산 T0 : PC ← IR(Addr) PC값을 IR의 주소값으로 변경하는 분기 명령어
AI,데이터,캐시 메모리 작동 원리에 대해 설명해 주세요,"  시간 지역성 for나 while 같은 반복문에 사용하는 조건 변수처럼 한번 참조된 데이터는 잠시후 또 참조될 가능성이 높음 공간 지역성 A[0], A[1]과 같은 연속 접근 시, 참조된 데이터 근처에 있는 데이터가 잠시후 또 사용될 가능성이 높음 이처럼 참조 지역성의 원리가 존재한다. 캐시에 데이터를 저장할 때는, 이러한 참조 지역성(공간)을 최대한 활용하기 위해 해당 데이터뿐만 아니라, 옆 주소의 데이터도 같이 가져와 미래에 쓰일 것을 대비한다. CPU가 요청한 데이터가 캐시에 있으면 'Cache Hit', 없어서 DRAM에서 가져오면 'Cache Miss'"
AI,데이터,캐시 미스 경우 3가지에 대해 설명해 주세요,"1. Cold miss 해당 메모리 주소를 처음 불러서 나는 미스 2. Conflict miss 캐시 메모리에 A와 B 데이터를 저장해야 하는데, A와 B가 같은 캐시 메모리 주소에 할당되어 있어서 나는 미스 (direct mapped cache에서 많이 발생) 항상 핸드폰과 열쇠를 오른쪽 주머니에 넣고 다니는데, 잠깐 친구가 준 물건을 받느라 손에 들고 있던 핸드폰을 가방에 넣었음. 그 이후 핸드폰을 찾으려 오른쪽 주머니에서 찾는데 없는 상황 3. Capacity miss 캐시 메모리의 공간이 부족해서 나는 미스 (Conflict는 주소 할당 문제, Capacity는 공간 문제) 캐시 크기를 키워서 문제를 해결하려하면, 캐시 접근속도가 느려지고 파워를 많이 먹는 단점 이 생김"
AI,데이터,구조 및 작동 방식에 대해 설명해 주세요,"  Direct Mapped Cache Fully Associative Cache 비어있는 캐시 메모리가 있으면, 마음대로 주소를 저장하는 방식 저장할 때는 매우 간단하지만, 찾을 때가 문제 조건이나 규칙이 없어서 특정 캐시 Set 안에 있는 모든 블럭을 한번에 찾아 원하는 데이터가 있는지 검색해야 한다. CAM이라는 특수한 메모리 구조를 사용해야하지만 가격이 매우 비싸다. Set Associative Cache Direct + Fully 방식이다. 특정 행을 지정하고, 그 행안의 어떤 열이든 비어있을 때 저장하는 방식이다. Direct에 비해 검색 속도는 느리지만, 저장이 빠르고 Fully에 비해 저장이 느린 대신 검색이 빠른 중간형이다. 실제로 위 두가지보다 나중에 나온 방식"
AI,데이터,소프트웨어에 대해 설명해 주세요,"시스템 소프트웨어 : 운영체제, 컴파일러 응용 소프트웨어 : 워드프로세서, 스프레드시트 먼저 하드웨어부터 살펴보자 하드웨어는 중앙처리장치(CPU), 기억장치, 입출력장치로 구성되어 있다. 이들은 시스템 버스로 연결되어 있으며, 시스템 버스는 데이터와 명령 제어 신호를 각 장치로 실어나르는 역할을 한다."
AI,데이터,중앙처리장치(CPU)에 대해 설명해 주세요,"인간으로 따지면 두뇌에 해당하는 부분 주기억장치에서 프로그램 명령어와 데이터를 읽어와 처리하고 명령어의 수행 순서를 제어함 중앙처리장치는 비교와 연산을 담당하는 strong 산술논리연산장치(ALU) /strong 와 명령어의 해석과 실행을 담당하는 제어장치 , 속도가 빠른 데이터 기억장소인 레지스터 로 구성되어있음 개인용 컴퓨터와 같은 소형 컴퓨터에서는 CPU를 마이크로프로세서라고도 부름"
AI,데이터,기억장치에 대해 설명해 주세요,"프로그램, 데이터, 연산의 중간 결과를 저장하는 장치 주기억장치와 보조기억장치로 나누어지며, RAM과 ROM도 이곳에 해당함. 실행중인 프로그램과 같은 프로그램에 필요한 데이터를 일시적으로 저장한다. 보조기억장치는 하드디스크 등을 말하며, 주기억장치에 비해 속도는 느리지만 많은 자료를 영구적으로 보관할 수 있는 장점이 있다."
AI,데이터,시스템 버스에 대해 설명해 주세요,"하드웨어 구성 요소를 물리적으로 연결하는 선 각 구성요소가 다른 구성요소로 데이터를 보낼 수 있도록 통로가 되어줌 용도에 따라 데이터 버스, 주소 버스, 제어 버스로 나누어짐"
AI,데이터,데이터 버스에 대해 설명해 주세요,"중앙처리장치와 기타 장치 사이에서 데이터를 전달하는 통로 기억장치와 입출력장치의 명령어와 데이터를 중앙처리장치로 보내거나, 중앙처리장치의 연산 결과를 기억장치와 입출력장치로 보내는 '양방향' 버스임"
AI,데이터,주소 버스에 대해 설명해 주세요,데이터를 정확히 실어나르기 위해서는 기억장치 '주소'를 정해주어야 함. 주소버스는 중앙처리장치가 주기억장치나 입출력장치로 기억장치 주소를 전달하는 통로이기 때문에 '단방향' 버스임
AI,데이터,제어 버스에 대해 설명해 주세요,"주소 버스와 데이터 버스는 모든 장치에 공유되기 때문에 이를 제어할 수단이 필요함 제어 버스는 중앙처리장치가 기억장치나 입출력장치에 제어 신호를 전달하는 통로임 제어 신호 종류 : 기억장치 읽기 및 쓰기, 버스 요청 및 승인, 인터럽트 요청 및 승인, 클락, 리셋 등 제어 버스는 읽기 동작과 쓰기 동작을 모두 수행하기 때문에 '양방향' 버스임 컴퓨터는 기본적으로 읽고 처리한 뒤 저장 하는 과정으로 이루어짐 (READ → PROCESS → WRITE) 이 과정을 진행하면서 끊임없이 주기억장치(RAM)과 소통한다. 이때 운영체제가 64bit라면, CPU는 RAM으로부터 데이터를 한번에 64비트씩 읽어온다."
AI,데이터,데이터베이스 접근 방법에 대해 설명해 주세요,"arr[i]의 전체 합과 i arr[i]의 전체 합을 저장할 변수 선언 최종 가장 큰 sum 값을 저장할 변수 선언 배열을 회전시키면서 i arr[i]의 합의 값을 저장하고, 가장 큰 값을 저장해서 출력하면 된다. / arr[i]가  1이 아니고, arr[i]이 i가 아닐 때가 우선 조건 해당 arr[i] 값을 저장(x)해두고, 이 값이 x일 때 arr[x]를 탐색 arr[x] 값을 저장(y)해두고, arr[x]가  1이 아니면서 arr[x]가 x가 아닌 동안을 탐색 arr[x]를 x값으로 저장해주고, 기존의 x를 y로 수정 int fix(int A[], int len){ for(int i = 0; i len; i++) { if (A[i] !=  1 && A[i] != i){ // A[i]가  1이 아니고, i도 아닐 때 int x = A[i]; // 해당 값을 x에 저장 while(A[x] !=  1 && A[x] != x){ // A[x]가  1이 아니고, x도 아닐 때 int y = A[x]; // 해당 값을 y에 저장 A[x] = x; x = y; } A[x] = x; if (A[i] != i){ A[i] =  1; } } } } / 1. 순차 접근(Sequential Access) 가장 간단한 접근 방법으로, 대부분 연산은 read와 write 특별한 순서없이, 빠르게 레코드를 read, write 가능 직접 접근 파일에 기반하여 색인 구축"
AI,데이터,해결법에 대해 설명해 주세요,"회전 없이 i arr[i]의 sum을 저장한 값 R0 = 0 arr[0] + 1 arr[1] +...+ (n 1) arr[n 1] 1번 회전하고 i arr[i]의 sum을 저장한 값 R1 = 0 arr[n 1] + 1 arr[0] +...+ (n 1) arr[n 2] 이 두개를 빼면? R1 R0 = arr[0] + arr[1] + ... + arr[n 2] (n 1) arr[n 1] 2번 회전하고 i arr[i]의 sum을 저장한 값 R2 = 0 arr[n 2] + 1 arr[n 1] +...+ (n 1) arr[n 3] 1번 회전한 값과 빼면? R2 R1 = arr[0] + arr[1] + ... + arr[n 3] (n 1) arr[n 2] + arr[n 1] 여기서 규칙을 찾을 수 있음. Rj Rj 1 = arrSum n arr[n j] 이를 활용해서 몇번 회전했을 때 최대값이 나오는 지 구할 수 있다. 3. 특정 배열을 arr[i] = i로 재배열 하기 예시) 주어진 배열에서 arr[i] = i이 가능한 것만 재배열 시키기 Input : arr = { 1,  1, 6, 1, 9, 3, 2,  1, 4,  1} Output : [ 1, 1, 2, 3, 4,  1, 6,  1,  1, 9] Input : arr = {19, 7, 0, 3, 18, 15, 12, 6, 1, 8, 11, 10, 9, 5, 13, 16, 2, 14, 17, 4} Output : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19] arr[i] = i가 없으면  1로 채운다."
AI,데이터,B Tree에 대해 설명해 주세요,"데이터베이스, 파일 시스템에서 널리 사용되는 트리 자료구조의 일종이다. 이진 트리를 확장해서, 더 많은 수의 자식을 가질 수 있게 일반화 시킨 것이 B Tree 자식 수에 대한 일반화를 진행하면서, 하나의 레벨에 더 저장되는 것 뿐만 아니라 트리의 균형을 자동으로 맞춰주는 로직까지 갖추었다. 단순하고 효율적이며, 레벨로만 따지면 완전히 균형을 맞춘 트리다. 대량의 데이터를 처리해야 할 때, 검색 구조의 경우 하나의 노드에 많은 데이터를 가질 수 있다는 점은 상당히 큰 장점이다. 대량의 데이터는 메모리보다 블럭 단위로 입출력하는 하드디스크 or SSD에 저장해야하기 때문! ex) 한 블럭이 1024 바이트면, 2바이트를 읽으나 1024바이트를 읽으나 똑같은 입출력 비용 발생. 따라서 하나의 노드를 모두 1024바이트로 꽉 채워서 조절할 수 있으면 입출력에 있어서 효율적인 구성을 갖출 수 있다. → B Tree는 이러한 장점을 토대로 많은 데이터베이스 시스템의 인덱스 저장 방법으로 애용하고 있음"
AI,데이터,B+ Tree에 대해 설명해 주세요,"데이터의 빠른 접근을 위한 인덱스 역할만 하는 비단말 노드(not Leaf)가 추가로 있음 (기존의 B Tree와 데이터의 연결리스트로 구현된 색인구조) B Tree의 변형 구조로, index 부분과 leaf 노드로 구성된 순차 데이터 부분으로 이루어진다. 인덱스 부분의 key 값은 leaf에 있는 key 값을 직접 찾아가는데 사용함."
AI,데이터,B Tree & B+ Tree에 대해 설명해 주세요,"B tree는 각 노드에 데이터가 저장됨 B+tree는 index 노드와 leaf 노드로 분리되어 저장됨 (또한, leaf 노드는 서로 연결되어 있어서 임의접근이나 순차접근 모두 성능이 우수함) B tree는 각 노드에서 key와 data 모두 들어갈 수 있고, data는 disk block으로 포인터가 될 수 있음 B+tree는 각 노드에서 key만 들어감. 따라서 data는 모두 leaf 노드에만 존재 B+tree는 add와 delete가 모두 leaf 노드에서만 이루어짐 참고자료 :"
공통,자료구조,BST 핵심연산에 대해 설명해 주세요,  검색 삽입 삭제 트리 생성 트리 삭제
공통,자료구조,시간 복잡도에 대해 설명해 주세요,"  균등 트리 : 노드 개수가 N개일 때 O(logN) 편향 트리 : 노드 개수가 N개일 때 O(N) 삽입, 검색, 삭제 시간복잡도는 트리의 Depth 에 비례"
공통,자료구조,삭제의 3가지 Case에 대해 설명해 주세요,"1) 자식이 없는 leaf 노드일 때 → 그냥 삭제 2) 자식이 1개인 노드일 때 → 지워진 노드에 자식을 올리기 3) 자식이 2개인 노드일 때 → 오른쪽 자식 노드에서 가장 작은 값 or 왼쪽 자식 노드에서 가장 큰 값 올리기 편향된 트리(정렬된 상태 값을 트리로 만들면 한쪽으로만 뻗음)는 시간복잡도가 O(N)이므로 트리를 사용할 이유가 사라짐 → 이를 바로 잡도록 도와주는 개선된 트리가 AVL Tree, RedBlack Tree"
AI,데이터,충돌 문제 해결에 대해 설명해 주세요,"1. 체이닝 : 연결리스트로 노드를 계속 추가해나가는 방식 (제한 없이 계속 연결 가능, but 메모리 문제) 2. Open Addressing : 해시 함수로 얻은 주소가 아닌 다른 주소에 데이터를 저장할 수 있도록 허용 (해당 키 값에 저장되어있으면 다음 주소에 저장) 3. 선형 탐사 : 정해진 고정 폭으로 옮겨 해시값의 중복을 피함 4. 제곱 탐사 : 정해진 고정 폭을 제곱수로 옮겨 해시값의 중복을 피함"
공통,C,C에 대해알아야할 것,"1.힙의 개념 2.힙의 삽입 및 삭제 힙은, 우선순위 큐를 위해 만들어진 자료구조다. 먼저 우선순위 큐 에 대해서 간략히 알아보자 우선순위 큐 : 우선순위의 개념을 큐에 도입한 자료구조 데이터들이 우선순위를 가지고 있음. 우선순위가 높은 데이터가 먼저 나감 스택은 LIFO, 큐는 FIFO"
공통,C,C는 언제 사용?,"시뮬레이션 시스템, 작업 스케줄링, 수치해석 계산 우선순위 큐는 배열, 연결리스트, 힙으로 구현 (힙으로 구현이 가장 효율적!) 힙 → 삽입 : O(logn) , 삭제 : O(logn)"
공통,C,힙 종류에 대해 설명해 주세요,부모 노드의 키 값이 자식 노드의 키 값보다 크거나 같은 완전 이진 트리 부모 노드의 키 값이 자식 노드의 키 값보다 작거나 같은 완전 이진 트리
공통,C,구현에 대해 설명해 주세요,힙을 저장하는 표준적인 자료구조는 배열 구현을 쉽게 하기 위해 배열의 첫번째 인덱스인 0은 사용되지 않음 특정 위치의 노드 번호는 새로운 노드가 추가되어도 변하지 않음 (ex. 루트 노드(1)의 오른쪽 노드 번호는 항상 3)
공통,C,부모 노드와 자식 노드 관계에 대해 설명해 주세요,왼쪽 자식 index = (부모 index) 2 오른쪽 자식 index = (부모 index) 2 + 1 부모 index = (자식 index) / 2
공통,C,힙의 삽입에 대해 설명해 주세요,"1.힙에 새로운 요소가 들어오면, 일단 새로운 노드를 힙의 마지막 노드에 삽입 2.새로운 노드를 부모 노드들과 교환 java void insert max heap(int x) { maxHeap[++heapSize] = x; // 힙 크기를 하나 증가하고, 마지막 노드에 x를 넣음 for( int i = heapSize; i 1; i /= 2) { // 마지막 노드가 자신의 부모 노드보다 크면 swap if(maxHeap[i/2] maxHeap[i]) { swap(i/2, i); } else { break; } } } 부모 노드는 자신의 인덱스의 /2 이므로, 비교하고 자신이 더 크면 swap하는 방식"
공통,자료구조,배열(Array)에 대해 설명해 주세요,u 정적으로 필요한만큼만 원소를 저장 /u 할 수 있는 공간이 할당 이때 각 원소의 주소는 연속적으로 할당됨 index를 통해 O(1)에 접근이 가능함 삽입 및 삭제는 O(N) 지정된 개수가 초과되면? → 배열 크기를 재할당한 후 복사 해야함
공통,자료구조,리스트(List)에 대해 설명해 주세요,u 노드(Node)들의 연결 /u 로 이루어짐 크기 제한이 없음 ( heap 용량만 충분하면! ) 다음 노드에 대한 참조를 통해 접근 ( O(N) ) 삽입과 삭제가 편함 O(1)
공통,자료구조,ArrayList에 대해 설명해 주세요,"동적으로 크기가 조정되는 배열 배열이 가득 차면? → 알아서 그 크기를 2배로 할당하고 복사 수행 재할당에 걸리는 시간은 O(N)이지만, 자주 일어나는 일이 아니므로 접근시간은 O(1)"
공통,자료구조,스택(Stack)에 대해 설명해 주세요,"LIFO 방식 (나중에 들어온게 먼저 나감) 원소의 삽입 및 삭제가 한쪽 끝에서만 이루어짐 (이 부분을 top이라고 칭함) 함수 호출 시 지역변수, 매개변수 정보를 저장하기 위한 공간을 스택으로 사용함"
공통,자료구조,큐(Queue)에 대해 설명해 주세요,"FIFO 방식 (먼저 들어온게 먼저 나감) 원소의 삽입 및 삭제가 양쪽 끝에서 일어남 (front, rear) FIFO 운영체제, 은행 대기열 등에 해당"
공통,자료구조,우선순위 큐(Priority Queue)에 대해 설명해 주세요,"FIFO 방식이 아닌 u 데이터를 근거로 한 우선순위를 판단하고, 우선순위가 높은 것부터 /u 나감 구현 방법 3가지 (배열, 연결리스트, 힙)"
공통,자료구조,에 대해 설명해 주세요,"간단하게 구현이 가능 데이터 삽입 및 삭제 과정을 진행 시, O(N)으로 비효율 발생 ( 한 칸씩 당기거나 밀어야하기 때문 ) 삽입 위치를 찾기 위해 배열의 모든 데이터를 탐색해야 함 (우선순위가 가장 낮을 경우)"
공통,자료구조,에 대해 설명해 주세요,삽입 및 삭제 O(1) 하지만 삽입 위치를 찾을 때는 배열과 마찬가지로 비효율 발생
공통,자료구조,힙에 대해 설명해 주세요,"힙은 위 2가지를 모두 효율적으로 처리가 가능함 (따라서 우선순위 큐는 대부분 힙으로 구현) 힙은 완전이진트리의 성질을 만족하므로, 1차원 배열로 표현이 가능 함 ( O(1)에 접근이 가능 ) root index에 따라 child index를 계산할 수 있음 root index = 0 left index = index 2 + 1 right index = index 2 + 2 데이터의 삽입 은 트리의 leaf node(자식이 없는 노드)부터 시작 삽입 후, heapify 과정을 통해 힙의 모든 부모 자식 노드의 우선순위에 맞게 설정됨 (이때, 부모의 우선순위는 자식의 우선순위보다 커야 함) 데이터의 삭제 는 root node를 삭제함 (우선순위가 가장 큰 것) 삭제 후, 마지막 leaf node를 root node로 옮긴 뒤 heapify 과정 수행"
공통,자료구조,트리(Tree)에 대해 설명해 주세요,사이클이 없는 무방향 그래프 완전이진트리 기준 높이는 logN 트리를 순회하는 방법은 여러가지가 있음 1. 중위 순회 : left root right 2. 전위 순회 : root left right 3. 후위 순회 : left right root 4. 레벨 순서 순회 : 노드를 레벨 순서로 방문 (BFS와 동일해 큐로 구현 가능)
공통,자료구조,이진탐색트리(BST)에 대해 설명해 주세요,"노드의 왼쪽은 노드의 값보다 작은 값들, 오른쪽은 노드의 값보다 큰 값으로 구성 삽입 및 삭제, 탐색까지 이상적일 때는 모두 O(logN) 가능 만약 편향된 트리면 O(N)으로 최악의 경우가 발생"
공통,자료구조,해시 테이블(Hash Table)에 대해 설명해 주세요,효율적 탐색을 위한 자료구조 key value 쌍으로 이루어짐 해시 함수를 통해 입력받은 key를 정수값(index)로 대응시킴 충돌(collision)에 대한 고려 필요
공통,자료구조,충돌(collision) 해결방안에 대해 설명해 주세요,해시 테이블에서 중복된 값에 대한 충돌 가능성이 있기 때문에 해결방안을 세워야 함
공통,자료구조,선형 조사법(linear probing)에 대해 설명해 주세요,"충돌이 일어난 항목을 해시 테이블의 다른 위치에 저장 예시) ht[k], ht[k+1], ht[k+2] ... ※ 삽입 상황 충돌이 ht[k]에서 일어났다면, ht[k+1]이 비어있는지 조사함. 차있으면 ht[k+2] 조사 ... 테이블 끝까지 도달하면 다시 처음으로 돌아옴. 시작 위치로 돌아온 경우는 테이블이 모두 가득 찬 경우임 ※ 검색 상황 ht[k]에 있는 키가 다른 값이면, ht[k+1]에 같은 키가 있는지 조사함. 비어있는 공간이 나오거나, 검색을 시작한 위치로 돌아오면 찾는 키가 없는 경우"
공통,자료구조,이차 조사법에 대해 설명해 주세요,"선형 조사법에서 발생하는 집적화 문제를 완화 시켜 줌 h(k), h(k)+1, h(k)+4, h(k)+9 ..."
공통,자료구조,이중 해시법에 대해 설명해 주세요,"재해싱(rehasing)이라고도 함 충돌로 인해 비어있는 버킷을 찾을 때 추가적인 해시 함수 h'()를 사용하는 방식 h'(k) = C (k mod C) 조사 위치 h(k), h(k)+h'(k), h(k) + 2h'(k) ..."
공통,자료구조,체이닝에 대해 설명해 주세요,"각 버킷을 고정된 개수의 슬롯 대신, 유동적 크기를 갖는 연결리스트로 구성 하는 방식 충돌 뿐만 아니라 오버플로우 문제도 해결 가능 버킷 내에서 항목을 찾을 때는 연결리스트 순차 탐색 활용"
공통,자료구조,해싱 성능 분석에 대해 설명해 주세요,a = n / M a = 적재 비율 n = 저장되는 항목 개수 M = 해시테이블 크기
공통,자료구조,맵(map)과 해시맵(hashMap)의 차이에 대해 설명해 주세요,"map 컨테이너는 이진탐색트리(BST)를 사용하다가 최근에 레드블랙트리를 사용하는 중 key 값을 이용해 트리를 탐색하는 방식임 → 따라서 데이터 접근, 삽입, 삭제는 O( logN ) 반면 해시맵은 해시함수를 활용해 O(1)에 접근 가능 하지만 C++에서는 해시맵을 STL로 지원해주지 않는데, 충돌 해결에 있어서 안정적인 방법이 아니기 때문 (해시 함수는 collision 정책에 따라 성능차이가 큼)"
공통,C,"LIFO (Last In First Out, 후입선출) 에 대해 설명해 주세요","함수의 콜스택, 문자열 역순 출력, 연산자 후위표기법 데이터 넣음 : push() 데이터 최상위 값 뺌 : pop() 비어있는 지 확인 : isEmpty() 꽉차있는 지 확인 : isFull() +SP push와 pop할 때는 해당 위치를 알고 있어야 하므로 기억하고 있는 '스택 포인터(SP)'가 필요함 스택 포인터는 다음 값이 들어갈 위치를 가리키고 있음 (처음 기본값은  1) java private int sp =  1;"
공통,C,push에 대해 설명해 주세요,java public void push(Object o) { if(isFull(o)) { return; } stack[++sp] = o; } 스택 포인터가 최대 크기와 같으면 return 아니면 스택의 최상위 위치에 값을 넣음
공통,C,pop에 대해 설명해 주세요,java public Object pop() { if(isEmpty(sp)) { return null; } Object o = stack[sp ]; return o; } 스택 포인터가 0이 되면 null로 return; 아니면 스택의 최상위 위치 값을 꺼내옴
공통,C,isEmpty에 대해 설명해 주세요,"java private boolean isEmpty(int cnt) { return sp ==  1 ? true : false; } 입력 값이 최초 값과 같다면 true, 아니면 false / java public boolean isEmpty() { return front == rear; } front와 rear가 같아지면 비어진 것"
공통,C,isFull에 대해 설명해 주세요,"java private boolean isFull(int cnt) { return sp + 1 == MAX SIZE ? true : false; } 스택 포인터 값+1이 MAX SIZE와 같으면 true, 아니면 false / java public boolean isFull() { return (rear == queueSize 1); } rear가 사이즈 1과 같아지면 가득찬 것 일반 큐의 단점 : 큐에 빈 메모리가 남아 있어도, 꽉 차있는것으로 판단할 수도 있음 (rear가 끝에 도달했을 때) 이를 개선한 것이 '원형 큐' 논리적으로 배열의 처음과 끝이 연결되어 있는 것으로 간주함! 원형 큐는 초기 공백 상태일 때 front와 rear가 0 공백, 포화 상태를 쉽게 구분하기 위해 자리 하나를 항상 비워둠 (index + 1) % size로 순환시킨다 / java public boolean isFull() { return ((rear+1) % size == front); } rear+1%size가 front와 같으면 가득찬 것 원형 큐의 단점 : 메모리 공간은 잘 활용하지만, 배열로 구현되어 있기 때문에 큐의 크기가 제한 이를 개선한 것이 '연결리스트 큐'"
공통,C,동적 배열 스택에 대해 설명해 주세요,"위처럼 구현하면 스택에는 MAX SIZE라는 최대 크기가 존재해야 한다 (스택 포인터와 MAX SIZE를 비교해서 isFull 메소드로 비교해야되기 때문!) 최대 크기가 없는 스택을 만드려면? arraycopy를 활용한 동적배열 사용 java public void push(Object o) { if(isFull(sp)) { Object[] arr = new Object[MAX SIZE 2]; System.arraycopy(stack, 0, arr, 0, MAX SIZE); stack = arr; MAX SIZE = 2; // 2배로 증가 } stack[sp++] = o; } 기존 스택의 2배 크기만큼 임시 배열(arr)을 만들고 arraycopy를 통해 stack의 인덱스 0부터 MAX SIZE만큼을 arr 배열의 0번째부터 복사한다 복사 후에 arr의 참조값을 stack에 덮어씌운다 마지막으로 MAX SIZE의 값을 2배로 증가시켜주면 된다. 이러면, 스택이 가득찼을 때 자동으로 확장되는 스택을 구현할 수 있음"
공통,C,스택을 연결리스트로 구현해도 해결 가능,java public class Node { public int data; public Node next; public Node() { } public Node(int data) { this.data = data; this.next = null; } } java public class Stack { private Node head; private Node top; public Stack() { head = top = null; } private Node createNode(int data) { return new Node(data); } private boolean isEmpty() { return top == null ? true : false; } public void push(int data) { if (isEmpty()) { // 스택이 비어있다면 head = createNode(data); top = head; } else { //스택이 비어있지 않다면 마지막 위치를 찾아 새 노드를 연결시킨다. Node pointer = head; while (pointer.next != null) pointer = pointer.next; pointer.next = createNode(data); top = pointer.next; } } public int pop() { int popData; if (!isEmpty()) { // 스택이 비어있지 않다면!! = 데이터가 있다면!! popData = top.data; // pop될 데이터를 미리 받아놓는다. Node pointer = head; // 현재 위치를 확인할 임시 노드 포인터 if (head == top) // 데이터가 하나라면 head = top = null; else { // 데이터가 2개 이상이라면 while (pointer.next != top) // top을 가리키는 노드를 찾는다. pointer = pointer.next; pointer.next = null; // 마지막 노드의 연결을 끊는다. top = pointer; // top을 이동시킨다. } return popData; } return  1; //  1은 데이터가 없다는 의미로 지정해둠. } }
AI,데이터,"FIFO (First In First Out, 선입선출) 에 대해 설명해 주세요","버퍼, 마구 입력된 것을 처리하지 못하고 있는 상황, BFS 큐의 가장 첫 원소를 front, 끝 원소를 rear라고 부름 큐는 들어올 때 rear로 들어오지만, 나올 때는 front부터 빠지는 특성 을 가짐 접근방법은 가장 첫 원소와 끝 원소로만 가능 데이터 넣음 : enQueue() 데이터 뺌 : deQueue() 비어있는 지 확인 : isEmpty() 꽉차있는 지 확인 : isFull() 데이터를 넣고 뺄 때 해당 값의 위치를 기억해야 함. (스택에서 스택 포인터와 같은 역할) 이 위치를 기억하고 있는 게 front와 rear front : deQueue 할 위치 기억 rear : enQueue 할 위치 기억"
공통,JAVA,기본값에 대해 설명해 주세요,java private int size = 0; private int rear =  1; private int front =  1; Queue(int size) { this.size = size; this.queue = new Object[size]; } / java private int size = 0; private int rear = 0; private int front = 0; Queue(int size) { this.size = size; this.queue = new Object[size]; }
공통,JAVA,enQueue에 대해 설명해 주세요,"java public void enQueue(Object o) { if(isFull()) { return; } queue[++rear] = o; } enQueue 시, 가득 찼다면 꽉 차 있는 상태에서 enQueue를 했기 때문에 overflow 아니면 rear에 값 넣고 1 증가 / java public void enQueue(Object o) { if(isFull()) { return; } rear = (++rear) % size; queue[rear] = o; } enQueue 시, 가득 찼다면 꽉 차 있는 상태에서 enQueue를 했기 때문에 overflow"
공통,JAVA,deQueue에 대해 설명해 주세요,"java public Object deQueue(Object o) { if(isEmpty()) { return null; } Object o = queue[front]; queue[front++] = null; return o; } deQueue를 할 때 공백이면 underflow front에 위치한 값을 object에 꺼낸 후, 꺼낸 위치는 null로 채워줌 / java public Object deQueue(Object o) { if(isEmpty()) { return null; } front = (++front) % size; Object o = queue[front]; return o; } deQueue를 할 때 공백이면 underflow"
AI,데이터,enqueue 구현에 대해 설명해 주세요,"java public void enqueue(E item) { Node oldlast = tail; // 기존의 tail 임시 저장 tail = new Node; // 새로운 tail 생성 tail.item = item; tail.next = null; if(isEmpty()) head = tail; // 큐가 비어있으면 head와 tail 모두 같은 노드 가리킴 else oldlast.next = tail; // 비어있지 않으면 기존 tail의 next = 새로운 tail로 설정 } 데이터 추가는 끝 부분인 tail에 한다. 기존의 tail는 보관하고, 새로운 tail 생성 큐가 비었으면 head = tail를 통해 둘이 같은 노드를 가리키도록 한다. 큐가 비어있지 않으면, 기존 tail의 next에 새로만든 tail를 설정해준다."
AI,데이터,dequeue 구현에 대해 설명해 주세요,"java public T dequeue() { // 비어있으면 if(isEmpty()) { tail = head; return null; } // 비어있지 않으면 else { T item = head.item; // 빼낼 현재 front 값 저장 head = head.next; // front를 다음 노드로 설정 return item; } } 데이터는 head로부터 꺼낸다. (가장 먼저 들어온 것부터 빼야하므로) head의 데이터를 미리 저장해둔다. 기존의 head를 그 다음 노드의 head로 설정한다. 저장해둔 데이터를 return 해서 값을 빼온다. 이처럼 삽입은 tail, 제거는 head로 하면서 삽입/삭제를 스택처럼 O(1)에 가능하도록 구현이 가능하다."
공통,JAVA,문제에서 Trie를 java로 구현한 코드에 대해 설명해 주세요,"java static class Trie { boolean end; boolean pass; Trie[] child; Trie() { end = false; pass = false; child = new Trie[10]; } public boolean insert(String str, int idx) { //끝나는 단어 있으면 false 종료 if(end) return false; //idx가 str만큼 왔을때 if(idx == str.length()) { end = true; if(pass) return false; // 더 지나가는 단어 있으면 false 종료 else return true; } //아직 안왔을 때 else { int next = str.charAt(idx) '0'; if(child[next] == null) { child[next] = new Trie(); pass = true; } return child[next].insert(str, idx+1); } } }"
AI,데이터,value 5가지에 대해 설명해 주세요,"1. String (text, binary data) 512MB까지 저장이 가능함 2. set (String 집합) 3. sorted set (set을 정렬해둔 상태) 4. Hash 5. List (양방향 연결리스트도 가능)"
AI,데이터,인증 우회에 대해 설명해 주세요,"보통 로그인을 할 때, 아이디와 비밀번호를 input 창에 입력하게 된다. 쉽게 이해하기 위해 가벼운 예를 들어보자. 아이디가 abc, 비밀번호가 만약 1234일 때 쿼리는 아래와 같은 방식으로 전송될 것이다. SELECT FROM USER WHERE ID = ""abc"" AND PASSWORD = ""1234""; SQL Injection으로 공격할 때, input 창에 비밀번호를 입력함과 동시에 다른 쿼리문을 함께 입력하는 것이다. 1234; DELETE USER FROM ID = ""1""; 보안이 완벽하지 않은 경우, 이처럼 비밀번호가 아이디와 일치해서 True가 되고 뒤에 작성한 DELETE 문도 데이터베이스에 영향을 줄 수도 있게 되는 치명적인 상황이다. 이 밖에도 기본 쿼리문의 WHERE 절에 OR문을 추가하여 '1' = '1' 과 같은 true문을 작성하여 무조건 적용되도록 수정한 뒤 DB를 마음대로 조작할 수도 있다."
AI,데이터,데이터 노출에 대해 설명해 주세요,"시스템에서 발생하는 에러 메시지를 이용해 공격하는 방법이다. 보통 에러는 개발자가 버그를 수정하는 면에서 도움을 받을 수 있는 존재다. 해커들은 이를 역이용해 악의적인 구문을 삽입하여 에러를 유발시킨다. 즉 예를 들면, 해커는 GET 방식으로 동작하는 URL 쿼리 스트링을 추가하여 에러를 발생 시킨다. 이에 해당하는 오류가 발생하면, 이를 통해 해당 웹앱의 데이터베이스 구조를 유추할 수 있고 해킹에 활용한다."
AI,데이터,"SQL 서버 오류 발생 시, 해당하는 에러 메시지 감추기에 대해 설명해 주세요",view를 활용하여 원본 데이터베이스 테이블에는 접근 권한을 높인다. 일반 사용자는 view로만 접근하여 에러를 볼 수 없도록 만든다.
BACKEND,운영체제,SQL (관계형 DB)에 대해 설명해 주세요,"SQL을 사용하면 RDBMS에서 데이터를 저장, 수정, 삭제 및 검색 할 수 있음 관계형 데이터베이스에는 핵심적인 두 가지 특징이 있다. 데이터는 정해진 데이터 스키마에 따라 테이블에 저장 된다. 데이터는 관계를 통해 여러 테이블에 분산 된다. 데이터는 테이블에 레코드로 저장되는데, 각 테이블마다 명확하게 정의된 구조가 있다. 해당 구조는 필드의 이름과 데이터 유형으로 정의된다. 따라서 스키마를 준수하지 않은 레코드는 테이블에 추가할 수 없다. 즉, 스키마를 수정하지 않는 이상은 정해진 구조에 맞는 레코드만 추가가 가능한 것이 관계형 데이터베이스의 특징 중 하나다. 또한, 데이터의 중복을 피하기 위해 '관계'를 이용한다."
BACKEND,운영체제,NoSQL (비관계형 DB)에 대해 설명해 주세요,"말그대로 관계형 DB의 반대다. 스키마도 없고, 관계도 없다! NoSQL에서는 레코드를 문서(documents)라고 부른다. 여기서 SQL과 핵심적인 차이가 있는데, SQL은 정해진 스키마를 따르지 않으면 데이터 추가가 불가능했다. 하지만 NoSQL에서는 다른 구조의 데이터를 같은 컬렉션에 추가가 가능하다. 문서(documents)는 Json과 비슷한 형태로 가지고 있다. 관계형 데이터베이스처럼 여러 테이블에 나누어담지 않고, 관련 데이터를 동일한 '컬렉션'에 넣는다. 따라서 위 사진에 SQL에서 진행한 Orders, Users, Products 테이블로 나눈 것을 NoSQL에서는 Orders에 한꺼번에 포함해서 저장하게 된다. 따라서 여러 테이블에 조인할 필요없이 이미 필요한 모든 것을 갖춘 문서를 작성하는 것이 NoSQL이다. (NoSQL에는 조인이라는 개념이 존재하지 않음) 그러면 조인하고 싶을 때 NoSQL은 어떻게 할까? 컬렉션을 통해 데이터를 복제하여 각 컬렉션 일부분에 속하는 데이터를 정확하게 산출하도록 한다. 하지만 이러면 데이터가 중복되어 서로 영향을 줄 위험이 있다. 따라서 조인을 잘 사용하지 않고 자주 변경되지 않는 데이터일 때 NoSQL을 쓰면 상당히 효율적이다."
BACKEND,운영체제,확장 개념에 대해 설명해 주세요,두 데이터베이스를 비교할 때 중요한 Scaling 개념도 존재한다. 데이터베이스 서버의 확장성은 '수직적' 확장과 '수평적' 확장으로 나누어진다. 수직적 확장 : 단순히 데이터베이스 서버의 성능을 향상시키는 것 (ex. CPU 업그레이드) 수평적 확장 : 더 많은 서버가 추가되고 데이터베이스가 전체적으로 분산됨을 의미 (하나의 데이터베이스에서 작동하지만 여러 호스트에서 작동) 데이터 저장 방식으로 인해 SQL 데이터베이스는 일반적으로 수직적 확장만 지원함 수평적 확장은 NoSQL 데이터베이스에서만 가능
BACKEND,운영체제,SQL 장점에 대해 설명해 주세요,"  명확하게 정의된 스키마, 데이터 무결성 보장 관계는 각 데이터를 중복없이 한번만 저장"
BACKEND,운영체제,SQL 단점에 대해 설명해 주세요,  덜 유연함. 데이터 스키마를 사전에 계획하고 알려야 함. (나중에 수정하기 힘듬) 관계를 맺고 있어서 조인문이 많은 복잡한 쿼리가 만들어질 수 있음 대체로 수직적 확장만 가능함
BACKEND,운영체제,NoSQL 장점에 대해 설명해 주세요,  스키마가 없어서 유연함. 언제든지 저장된 데이터를 조정하고 새로운 필드 추가 가능 데이터는 애플리케이션이 필요로 하는 형식으로 저장됨. 데이터 읽어오는 속도 빨라짐 수직 및 수평 확장이 가능해서 애플리케이션이 발생시키는 모든 읽기/쓰기 요청 처리 가능
BACKEND,운영체제,NoSQL 단점에 대해 설명해 주세요,  유연성으로 인해 데이터 구조 결정을 미루게 될 수 있음 데이터 중복을 계속 업데이트 해야 함 데이터가 여러 컬렉션에 중복되어 있기 때문에 수정 시 모든 컬렉션에서 수행해야 함 (SQL에서는 중복 데이터가 없으므로 한번만 수행이 가능)
BACKEND,운영체제,SQL 데이터베이스 사용이 더 좋을 때에 대해 설명해 주세요,"  관계를 맺고 있는 데이터가 자주 변경되는 애플리케이션의 경우 NoSQL에서는 여러 컬렉션을 모두 수정해야 하기 때문에 비효율적 변경될 여지가 없고, 명확한 스키마가 사용자와 데이터에게 중요한 경우"
BACKEND,운영체제,NoSQL 데이터베이스 사용이 더 좋을 때에 대해 설명해 주세요,"  정확한 데이터 구조를 알 수 없거나 변경/확장 될 수 있는 경우 읽기를 자주 하지만, 데이터 변경은 자주 없는 경우 데이터베이스를 수평으로 확장해야 하는 경우 (막대한 양의 데이터를 다뤄야 하는 경우) 하나의 제시 방법이지 완전한 정답이 정해져 있는 것은 아니다. SQL을 선택해서 복잡한 JOIN문을 만들지 않도록 설계하여 단점을 없앨 수도 있고 NoSQL을 선택해서 중복 데이터를 줄이는 방법으로 설계해서 단점을 없앨 수도 있다."
AI,데이터,Isolation level에 대해 설명해 주세요,트랜잭션에서 일관성 없는 데이터를 허용하도록 하는 수준
AI,데이터,Isolation level의 필요성에 대해 설명해 주세요,"데이터베이스는 ACID 특징과 같이 트랜잭션이 독립적인 수행을 하도록 한다. 따라서 Locking을 통해, 트랜잭션이 DB를 다루는 동안 다른 트랜잭션이 관여하지 못하도록 막는 것이 필요하다. 하지만 무조건 Locking으로 동시에 수행되는 수많은 트랜잭션들을 순서대로 처리하는 방식으로 구현하게 되면 데이터베이스의 성능은 떨어지게 될 것이다. 그렇다고 해서, 성능을 높이기 위해 Locking의 범위를 줄인다면, 잘못된 값이 처리될 문제가 발생하게 된다. 따라서 최대한 효율적인 Locking 방법이 필요함!"
AI,데이터,Isolation level 종류에 대해 설명해 주세요,"1. Read Uncommitted (레벨 0) SELECT 문장이 수행되는 동안 해당 데이터에 Shared Lock이 걸리지 않는 계층 트랜잭션에 처리중이거나, 아직 Commit되지 않은 데이터를 다른 트랜잭션이 읽는 것을 허용함 사용자1이 A라는 데이터를 B라는 데이터로 변경하는 동안 사용자2는 아직 완료되지 않은(Uncommitted) 트랜잭션이지만 데이터B를 읽을 수 있다 데이터베이스의 일관성을 유지하는 것이 불가능함 2. Read Committed (레벨 1) SELECT 문장이 수행되는 동안 해당 데이터에 Shared Lock이 걸리는 계층 트랜잭션이 수행되는 동안 다른 트랜잭션이 접근할 수 없어 대기하게 됨 Commit이 이루어진 트랜잭션만 조회 가능 대부분의 SQL 서버가 Default로 사용하는 Isolation Level임 사용자1이 A라는 데이터를 B라는 데이터로 변경하는 동안 사용자2는 해당 데이터에 접근이 불가능함 3. Repeatable Read (레벨 2) 트랜잭션이 완료될 때까지 SELECT 문장이 사용하는 모든 데이터에 Shared Lock이 걸리는 계층 트랜잭션이 범위 내에서 조회한 데이터 내용이 항상 동일함을 보장함 다른 사용자는 트랜잭션 영역에 해당되는 데이터에 대한 수정 불가능 MySQL에서 Default로 사용하는 Isolation Level 4. Serializable (레벨 3) 트랜잭션이 완료될 때까지 SELECT 문장이 사용하는 모든 데이터에 Shared Lock이 걸리는 계층 완벽한 읽기 일관성 모드를 제공함 다른 사용자는 트랜잭션 영역에 해당되는 데이터에 대한 수정 및 입력 불가능 선택 시 고려사항 Isolation Level에 대한 조정은, 동시성과 데이터 무결성에 연관되어 있음 동시성을 증가시키면 데이터 무결성에 문제가 발생하고, 데이터 무결성을 유지하면 동시성이 떨어지게 됨 레벨을 높게 조정할 수록 발생하는 비용이 증가함"
AI,데이터,낮은 단계 Isolation Level을 활용할 때 발생하는 현상들에 대해 설명해 주세요,"  Dirty Read 커밋되지 않은 수정중인 데이터를 다른 트랜잭션에서 읽을 수 있도록 허용할 때 발생하는 현상 어떤 트랜잭션에서 아직 실행이 끝나지 않은 다른 트랜잭션에 의한 변경사항을 보게되는 경우 발생 Level: Read Uncommitted Non Repeatable Read 한 트랜잭션에서 같은 쿼리를 두 번 수행할 때 그 사이에 다른 트랜잭션 값을 수정 또는 삭제하면서 두 쿼리의 결과가 상이하게 나타나는 일관성이 깨진 현상 발생 Level: Read Committed, Read Uncommitted Phantom Read 한 트랜잭션 안에서 일정 범위의 레코드를 두 번 이상 읽었을 때, 첫번째 쿼리에서 없던 레코드가 두번째 쿼리에서 나타나는 현상 트랜잭션 도중 새로운 레코드 삽입을 허용하기 때문에 나타나는 현상임 발생 Level: Repeatable Read, Read Committed, Read Uncommitted"
AI,데이터,트렌잭션에 대해 설명해 주세요,"데이터베이스의 상태를 변화시키기 위해 수행하는 작업 단위 상태를 변화시킨다는 것 → SQL 질의어를 통해 DB에 접근하는 것 SELECT INSERT DELETE UPDATE 작업 단위 → 많은 SQL 명령문들을 사람이 정하는 기준에 따라 정하는 것 예시) 사용자 A가 사용자 B에게 만원을 송금한다. 이때 DB 작업 1. 사용자 A의 계좌에서 만원을 차감한다 : UPDATE 문을 사용해 사용자 A의 잔고를 변경 2. 사용자 B의 계좌에 만원을 추가한다 : UPDATE 문을 사용해 사용자 B의 잔고를 변경 현재 작업 단위 : 출금 UPDATE문 + 입금 UPDATE문 → 이를 통틀어 하나의 트랜잭션이라고 한다. 위 두 쿼리문 모두 성공적으로 완료되어야만 ""하나의 작업(트랜잭션)""이 완료되는 것이다. Commit 작업 단위에 속하는 쿼리 중 하나라도 실패하면 모든 쿼리문을 취소하고 이전 상태로 돌려놓아야한다. Rollback 즉, 하나의 트랜잭션 설계를 잘 만드는 것이 데이터를 다룰 때 많은 이점을 가져다준다."
공통,알고리즘,Transaction 관리를 위한 DBMS의 전략에 대해 설명해 주세요,"이해를 위한 2가지 개념 : DBMS의 구조 / Buffer 관리 정책 1) DBMS의 구조 크게 2가지 : Query Processor (질의 처리기), Storage System (저장 시스템) 입출력 단위 : 고정 길이의 page 단위로 disk에 읽거나 쓴다. 저장 공간 : 비휘발성 저장 장치인 disk에 저장, 일부분을 Main Memory에 저장 2) Page Buffer Manager or Buffer Manager DBMS의 Storage System에 속하는 모듈 중 하나로, Main Memory에 유지하는 페이지를 관리하는 모듈 Buffer 관리 정책에 따라, UNDO 복구와 REDO 복구가 요구되거나 그렇지 않게 되므로, transaction 관리에 매우 중요한 결정을 가져온다. 3) UNDO 필요한 이유 : 수정된 Page들이 u Buffer 교체 알고리즘에 따라서 디스크에 출력 /u 될 수 있음. Buffer 교체는 u transaction과는 무관하게 buffer의 상태에 따라서, 결정됨 /u . 이로 인해, 정상적으로 종료되지 않은 transaction이 변경한 page들은 원상 복구 되어야 하는데, 이 복구를 undo라고 함. 2개의 정책 (수정된 페이지를 디스크에 쓰는 시점으로 분류) steal : 수정된 페이지를 언제든지 디스크에 쓸 수 있는 정책 대부분의 DBMS가 채택하는 Buffer 관리 정책 UNDO logging과 복구를 필요로 함. ¬steal : 수정된 페이지들을 EOT (End Of Transaction)까지는 버퍼에 유지하는 정책 UNDO 작업이 필요하지 않지만, 매우 큰 메모리 버퍼가 필요함. 4) REDO 이미 commit한 transaction의 수정을 재반영하는 복구 작업 Buffer 관리 정책에 영향을 받음 Transaction이 종료되는 시점에 해당 transaction이 수정한 page를 디스크에 쓸 것인가 아닌가로 기준. FORCE : 수정했던 모든 페이지를 Transaction commit 시점에 disk에 반영 transaction이 commit 되었을 때 수정된 페이지들이 disk 상에 반영되므로 redo 필요 없음. ¬FORCE : commit 시점에 반영하지 않는 정책 transaction이 disk 상의 db에 반영되지 않을 수 있기에 redo 복구가 필요. (대부분의 DBMS 정책)"
AI,데이터,조인에 대해 설명해 주세요,"두 개 이상의 테이블이나 데이터베이스를 연결하여 데이터를 검색하는 방법 테이블을 연결하려면, 적어도 하나의 칼럼을 서로 공유하고 있어야 하므로 이를 이용하여 데이터 검색에 활용한다."
AI,데이터,JOIN 종류에 대해 설명해 주세요,INNER JOIN LEFT OUTER JOIN RIGHT OUTER JOIN FULL OUTER JOIN CROSS JOIN SELF JOIN INNER JOIN LEFT OUTER JOIN RIGHT OUTER JOIN FULL OUTER JOIN CROSS JOIN SELF JOIN
AI,데이터,[DB] Anomaly에 대해 설명해 주세요,"정규화를 해야하는 이유는 잘못된 테이블 설계로 인해 Anomaly (이상 현상)가 나타나기 때문이다. 이 페이지에서는 Anomaly가 무엇인지 살펴본다. 예) {Student ID, Course ID, Department, Course ID, Grade} 1. 삽입 이상 (Insertion Anomaly) 기본키가 {Student ID, Course ID} 인 경우 Course를 수강하지 않은 학생은 Course ID가 없는 현상이 발생함. 결국 Course ID를 Null로 할 수밖에 없는데, 기본키는 Null이 될 수 없으므로, Table에 추가될 수 없음. 굳이 삽입하기 위해서는 '미수강'과 같은 Course ID를 만들어야 함. 불필요한 데이터를 추가해야지, 삽입할 수 있는 상황 = Insertion Anomaly 2. 갱신 이상 (Update Anomaly) 만약 어떤 학생의 전공 (Department) 이 ""컴퓨터에서 음악""으로 바뀌는 경우. 모든 Department를 ""음악""으로 바꾸어야 함. 그러나 일부를 깜빡하고 바꾸지 못하는 경우, 제대로 파악 못함. 일부만 변경하여, 데이터가 불일치 하는 모순의 문제 = Update Anomaly 3. 삭제 이상 (Deletion Anomaly) 만약 어떤 학생이 수강을 철회하는 경우, {Student ID, Department, Course ID, Grade}의 정보 중 Student ID, Department 와 같은 학생에 대한 정보도 함께 삭제됨. 튜플 삭제로 인해 꼭 필요한 데이터까지 함께 삭제되는 문제 = Deletion Anomaly"
AI,데이터,데이터 베이스 사용목적에 대해 설명해 주세요,"추가적인 쓰기 작업과 저장 공간을 활용하여 데이터베이스 테이블의 검색 속도를 향상시키기 위한 자료구조 테이블의 칼럼을 색인화한다. 마치, 두꺼운 책의 목차와 같다고 생각하면 편하다. 데이터베이스 안의 레코드를 처음부터 풀스캔하지 않고, B+ Tree로 구성된 구조에서 Index 파일 검색으로 속도를 향상시키는 기술이다."
AI,데이터,데이터베이스 파일 구성에 대해 설명해 주세요,"테이블 생성 시, 3가지 파일이 생성된다. FRM : 테이블 구조 저장 파일 MYD : 실제 데이터 파일 MYI : Index 정보 파일 (Index 사용 시 생성) 사용자가 쿼리를 통해 Index를 사용하는 칼럼을 검색하게 되면, 이때 MYI 파일의 내용을 활용한다."
AI,데이터,데이터베이스 상황 분석에 대해 설명해 주세요,  사용하면 좋은 경우 (1) Where 절에서 자주 사용되는 Column (2) 외래키가 사용되는 Column (3) Join에 자주 사용되는 Column Index 사용을 피해야 하는 경우 (1) Data 중복도가 높은 Column (2) DML이 자주 일어나는 Column
AI,데이터,DML이 일어났을 때의 상황에 대해 설명해 주세요,"  INSERT 기존 Block에 여유가 없을 때, 새로운 Data가 입력된다. → 새로운 Block을 할당 받은 후, Key를 옮기는 작업을 수행한다. → Index split 작업 동안, 해당 Block의 Key 값에 대해서 DML이 블로킹 된다. (대기 이벤트 발생) → 이때 Block의 논리적인 순서와 물리적인 순서가 달라질 수 있다. (인덱스 조각화) DELETE Table과 Index 상황 비교 Table에서 data가 delete 되는 경우 : Data가 지워지고, 다른 Data가 그 공간을 사용 가능하다. Index에서 Data가 delete 되는 경우 : Data가 지워지지 않고, 사용 안 됨 표시만 해둔다. → Table의 Data 수와 Index의 Data 수가 다를 수 있음 UPDATE Table에서 update가 발생하면 → Index는 Update 할 수 없다. Index에서는 Delete가 발생한 후, 새로운 작업의 Insert 작업 / 2배의 작업이 소요되어 힘들다."
공통,C,인덱스 관리 방식에 대해 설명해 주세요,"  B Tree 자료구조 이진 탐색트리와 유사한 자료구조 자식 노드를 둘이상 가질 수 있고 Balanced Tree 라는 특징이 있다 → 즉 탐색 연산에 있어 O(log N)의 시간복잡도를 갖는다. 모든 노드들에 대해 값을 저장하고 있으며 포인터 역할을 동반한다. B+Tree 자료구조 B Tree를 개선한 형태의 자료구조 값을 리프노드에만 저장하며 리프노드들 끼리는 링크드 리스트로 연결되어 있다 → 때문에 부등호문 연산에 대해 효과적이다. 리프 노드를 제외한 노드들은 포인터의 역할만을 수행한다. HashTable 자료구조 해시 함수를 이용해서 값을 인덱스로 변경 하여 관리하는 자료구조 일반적인 경우 탐색, 삽입, 삭제 연산에 대해 O(1)의 시간 복잡도를 갖는다. 다른 관리 방식에 비해 빠른 성능을 갖는다. 최악의 경우 해시 충돌이 발생하는 것으로 탐색, 삽입, 삭제 연산에 대해 O(N)의 시간복잡도를 갖는다. 값 자체를 변경하기 때문에 부등호문, 포함문등의 연산에 사용할 수 없다."
AI,데이터,프로시저 생성 및 호출에 대해 설명해 주세요,"plsql CREATE OR REPLACE PROCEDURE 프로시저명(변수명1 IN 데이터타입, 변수명2 OUT 데이터타입) 인자 값은 필수 아님 IS [ 변수명1 데이터타입; 변수명2 데이터타입; .. ] BEGIN 필요한 기능; 인자값 활용 가능 END; EXEC 프로시저명; 호출"
BACKEND,네트워크,HTTP의 보안 취약점에 대해 설명해 주세요,"1. 도청이 가능하다 평문으로 통신하기 때문에 도청이 가능하다 이를 해결하기 위해서 통신자체를암호화(HTTPS)하거나 데이터를 암호화 하는 방법등이 있다 데이터를 암호화 하는 경우 수신측에서는 보호화 과정이 필요하다 2. 위장이 가능하다 통신 상대를 확인하지 않기 깨문에 위장된 상대와 통신할 수 있다 HTTPS는 CA 인증서를 통해 인증된 상대와 통신이 가능하다 3. 변조가 가능하다 완전성을 보장하지 않기 때문에 변조가 가능하다 HTTPS는 메세지 인증 코드(MAC), 전자 서명등을 통해 변조를 방지 한다 HTTPS(HyperText Transfer Protocol Secure) 인터넷 상에서 정보를 암호화하는 SSL 프로토콜을 사용해 클라이언트와 서버가 자원을 주고 받을 때 쓰는 통신 규약 HTTPS는 텍스트를 암호화한다. (공개키 암호화 방식으로!) :"
BACKEND,네트워크,HTTPS 통신 흐름에 대해 설명해 주세요,"1. 애플리케이션 서버(A)를 만드는 기업은 HTTPS를 적용하기 위해 공개키와 개인키를 만든다. 2. 신뢰할 수 있는 CA 기업을 선택하고, 그 기업에게 내 공개키 관리를 부탁하며 계약을 한다. CA란? : Certificate Authority로, 공개키를 저장해주는 신뢰성이 검증된 민간기업 3. 계약 완료된 CA 기업은 해당 기업의 이름, A서버 공개키, 공개키 암호화 방법을 담은 인증서를 만들고, 해당 인증서를 CA 기업의 개인키로 암호화해서 A서버에게 제공한다. 4. A서버는 암호화된 인증서를 갖게 되었다. 이제 A서버는 A서버의 공개키로 암호화된 HTTPS 요청이 아닌 요청이 오면, 이 암호화된 인증서를 클라이언트에게 건내준다. 5. 클라이언트가 main.html 파일을 달라고 A서버에 요청했다고 가정하자. HTTPS 요청이 아니기 때문에 CA기업이 A서버의 정보를 CA 기업의 개인키로 암호화한 인증서를 받게 된다. CA 기업의 공개키는 브라우저가 이미 알고있다. (세계적으로 신뢰할 수 있는 기업으로 등록되어 있기 때문에, 브라우저가 인증서를 탐색하여 해독이 가능한 것) 6. 브라우저는 해독한 뒤 A서버의 공개키를 얻게 되었다. 7. 클라이언트가 A서버와 HandShaking 과정에서 주고받은 난수를 조합하여 pre master secret key 를 생성한 뒤, A서버의 공개키로 해당 대칭키를 암호화하여 서버로 보냅니다. 8. A서버는 암호화된 대칭키를 자신의 개인키로 복호화 하여 클라이언트와 동일한 대칭키를 획득합니다. 9. 클라이언트, 서버는 각각 pre master secret key를 master secret key으로 만듭니다. 10. master secret key 를 통해 session key를 생성하고 이를 이용하여 대칭키 방식으로 통신합니다. 11. 각 통신이 종료될 때마다 session key를 파기합니다. HTTPS도 무조건 안전한 것은 아니다. (신뢰받는 CA 기업이 아닌 자체 인증서 발급한 경우 등) 이때는 HTTPS지만 브라우저에서 주의 요함 , 안전하지 않은 사이트 와 같은 알림으로 주의 받게 된다."
BACKEND,운영체제,7계층은 왜 나누는가에 대해 설명해 주세요,"통신이 일어나는 과정을 단계별로 알 수 있고, 특정한 곳에 이상이 생기면 그 단계만 수정할 수 있기 때문이다."
BACKEND,운영체제,물리(Physical)에 대해 설명해 주세요,"리피터, 케이블, 허브 등 단지 데이터를 전기적인 신호로 변환해서 주고받는 기능을 진행하는 공간 즉, 데이터를 전송하는 역할만 진행한다."
BACKEND,운영체제,데이터 링크(Data Link)에 대해 설명해 주세요,"브릿지, 스위치 등 물리 계층으로 송수신되는 정보를 관리하여 안전하게 전달되도록 도와주는 역할 Mac 주소를 통해 통신한다. 프레임에 Mac 주소를 부여하고 에러검출, 재전송, 흐름제어를 진행한다."
BACKEND,운영체제,"네트워크(Network)에 대해 설명해 주세요
","라우터, IP 데이터를 목적지까지 가장 안전하고 빠르게 전달하는 기능을 담당한다. 라우터를 통해 이동할 경로를 선택하여 IP 주소를 지정하고, 해당 경로에 따라 패킷을 전달해준다. 라우팅, 흐름 제어, 오류 제어, 세그먼테이션 등을 수행한다."
BACKEND,운영체제,전송(Transport)에 대해 설명해 주세요,"TCP, UDP TCP와 UDP 프로토콜을 통해 통신을 활성화한다. 포트를 열어두고, 프로그램들이 전송을 할 수 있도록 제공해준다. TCP : 신뢰성, 연결지향적 UDP : 비신뢰성, 비연결성, 실시간"
BACKEND,운영체제,세션(Session)에 대해 설명해 주세요,"API, Socket 데이터가 통신하기 위한 논리적 연결을 담당한다. TCP/IP 세션을 만들고 없애는 책임을 지니고 있다."
BACKEND,운영체제,표현(Presentation)에 대해 설명해 주세요,"JPEG, MPEG 등 데이터 표현에 대한 독립성을 제공하고 암호화하는 역할을 담당한다. 파일 인코딩, 명령어를 포장, 압축, 암호화한다."
BACKEND,운영체제,응용(Application)에 대해 설명해 주세요,"HTTP, FTP, DNS 등 최종 목적지로, 응용 프로세스와 직접 관계하여 일반적인 응용 서비스를 수행한다. 사용자 인터페이스, 전자우편, 데이터베이스 관리 등의 서비스를 제공한다."
BACKEND,네트워크,통신에 대해 설명하시오,"  TCP 통신이란? 네트워크 통신에서 신뢰적인 연결방식 TCP는 기본적으로 unreliable network에서, reliable network를 보장할 수 있도록 하는 프로토콜 TCP는 network congestion avoidance algorithm을 사용 TCP는 흐름제어와 혼잡제어를 통해 안정적인 데이터 전송을 보장 unreliable network 환경에서는 4가지 문제점 존재 손실 : packet이 손실될 수 있는 문제 순서 바뀜 : packet의 순서가 바뀌는 문제 Congestion : 네트워크가 혼잡한 문제 Overload : receiver가 overload 되는 문제 흐름제어/혼잡제어란? 흐름제어 (endsystem 대 endsystem) 송신측과 수신측의 데이터 처리 속도 차이를 해결하기 위한 기법 Flow Control은 receiver가 packet을 지나치게 많이 받지 않도록 조절하는 것 기본 개념은 receiver가 sender에게 현재 자신의 상태를 feedback 한다는 점 혼잡제어 : 송신측의 데이터 전달과 네트워크의 데이터 처리 속도 차이를 해결하기 위한 기법 전송의 전체 과정 응용 계층(Application Layer)에서 데이터를 전송할 때, 보내는 쪽(sender)의 애플리케이션(Application)은 소켓(Socket)에 데이터를 쓰게 됩니다. 이 데이터는 전송 계층(Transport Layer)으로 전달되어 세그먼트(Segment)라는 작은 단위로 나누어집니다. 전송 계층은 이 세그먼트를 네트워크 계층(Network Layer)에 넘겨줍니다. 전송된 데이터는 수신자(receiver) 쪽으로 전달되어, 수신자 쪽에서는 수신 버퍼(Receive Buffer)에 저장됩니다. 이때, 수신자 쪽에서는 수신 버퍼의 용량을 넘치게 하지 않도록 조절해야 합니다. 수신자 쪽에서는 자신의 수신 버퍼의 남은 용량을 상대방(sender)에게 알려주는데, 이를 ""수신 윈도우(Receive Window)""라고 합니다. 송신자(sender)는 수신자의 수신 윈도우를 확인하여 수신자의 수신 버퍼 용량을 초과하지 않도록 데이터를 전송합니다. 이를 통해 데이터 전송 중에 수신 버퍼가 넘치는 현상을 방지하면서, 안정적인 데이터 전송을 보장합니다. 이를 ""플로우 컨트롤(Flow Control)""이라고 합니다. 따라서, 플로우 컨트롤은 전송 중에 발생하는 수신 버퍼의 오버플로우를 방지하면서, 안정적인 데이터 전송을 위해 중요한 기술입니다. / UDP 통신이란? User Datagram Protocol의 약자로 데이터를 데이터그램 단위로 처리하는 프로토콜이다. 비연결형, 신뢰성 없는 전송 프로토콜이다. 데이터그램 단위로 쪼개면서 전송을 해야하기 때문에 전송 계층이다. Transport layer에서 사용하는 프로토콜. TCP와 UDP는 왜 나오게 됐는가? 1. IP의 역할은 Host to Host (장치 to 장치)만을 지원한다. 장치에서 장치로 이동은 IP로 해결되지만, 하나의 장비안에서 수많은 프로그램들이 통신을 할 경우에는 IP만으로는 한계가 있다. 2. 또한, IP에서 오류가 발생한다면 ICMP에서 알려준다. 하지만 ICMP는 알려주기만 할 뿐 대처를 못하기 때문에 IP보다 위에서 처리를 해줘야 한다. 1번을 해결하기 위하여 포트 번호가 나오게 됐고, 2번을 해결하기 위해 상위 프로토콜인 TCP와 UDP가 나오게 되었다. ICMP : 인터넷 제어 메시지 프로토콜로 네트워크 컴퓨터 위에서 돌아가는 운영체제에서 오류 메시지를 전송받는데 주로 쓰임 그렇다면 TCP와 UDP가 어떻게 오류를 해결하는가? TCP : 데이터의 분실, 중복, 순서가 뒤바뀜 등을 자동으로 보정해줘서 송수신 데이터의 정확한 전달을 할 수 있도록 해준다. UDP : IP가 제공하는 정도의 수준만을 제공하는 간단한 IP 상위 계층의 프로토콜이다. TCP와는 다르게 에러가 날 수도 있고, 재전송이나 순서가 뒤바뀔 수도 있어서 이 경우, 어플리케이션에서 처리하는 번거로움이 존재한다. UDP는 왜 사용할까? UDP의 결정적인 장점은 데이터의 신속성이다. 데이터의 처리가 TCP보다 빠르다. 주로 실시간 방송과 온라인 게임에서 사용된다. 네트워크 환경이 안 좋을때, 끊기는 현상을 생각하면 된다. DNS(Domain Name System)에서 UDP를 사용하는 이유 Request의 양이 작음 UDP Request에 담길 수 있다. 3 way handshaking으로 연결을 유지할 필요가 없다. (오버헤드 발생) Request에 대한 손실은 Application Layer에서 제어가 가능하다. DNS : port 53번 But, TCP를 사용할 때가 있다! 크기가 512(UDP 제한)이 넘을 때, TCP를 사용해야한다."
BACKEND,네트워크,흐름제어 (Flow Control)에 대해 설명해 주세요,"  수신측이 송신측보다 데이터 처리 속도가 빠르면 문제없지만, 송신측의 속도가 빠를 경우 문제가 생긴다. 수신측에서 제한된 저장 용량을 초과한 이후에 도착하는 데이터는 손실 될 수 있으며, 만약 손실 된다면 불필요하게 응답과 데이터 전송이 송/수신 측 간에 빈번히 발생한다. 이러한 위험을 줄이기 위해 송신 측의 데이터 전송량을 수신측에 따라 조절해야한다. 해결방법 Stop and Wait : 매번 전송한 패킷에 대해 확인 응답을 받아야만 그 다음 패킷을 전송하는 방법"
BACKEND,네트워크,혼잡제어 (Congestion Control)에 대해 설명해 주세요,"  송신측의 데이터는 지역망이나 인터넷으로 연결된 대형 네트워크를 통해 전달된다. 만약 한 라우터에 데이터가 몰릴 경우, 자신에게 온 데이터를 모두 처리할 수 없게 된다. 이런 경우 호스트들은 또 다시 재전송을 하게되고 결국 혼잡만 가중시켜 오버플로우나 데이터 손실을 발생시키게 된다. 따라서 이러한 네트워크의 혼잡을 피하기 위해 송신측에서 보내는 데이터의 전송속도를 강제로 줄이게 되는데, 이러한 작업을 혼잡제어라고 한다. 또한 네트워크 내에 패킷의 수가 과도하게 증가하는 현상을 혼잡이라 하며, 혼잡 현상을 방지하거나 제거하는 기능을 혼잡제어라고 한다. 흐름제어가 송신측과 수신측 사이의 전송속도를 다루는데 반해, 혼잡제어는 호스트와 라우터를 포함한 보다 넓은 관점에서 전송 문제를 다루게 된다. 해결 방법 [ref]  "
BACKEND,네트워크,UDP Header에 대해 설명해 주세요,"  이렇게 간단하므로, TCP 보다 용량이 가볍고 송신 속도가 빠르게 작동됨. 그러나 확인 응답을 못하므로, TCP보다 신뢰도가 떨어짐. UDP는 비연결성, TCP는 연결성으로 정의할 수 있음."
BACKEND,네트워크,DNS과 UDP 통신 프로토콜에 대해 설명해 주세요,"DNS는 데이터를 교환하는 경우임 이때, TCP를 사용하게 되면, 데이터를 송신할 때까지 세션 확립을 위한 처리를 하고, 송신한 데이터가 수신되었는지 점검하는 과정이 필요하므로, Protocol overhead가 UDP에 비해서 큼. DNS는 Application layer protocol임. 모든 Application layer protocol은 TCP, UDP 중 하나의 Transport layer protocol을 사용해야 함. (TCP는 reliable, UDP는 not reliable임) / DNS는 reliable해야할 것 같은데 왜 UDP를 사용할까? 사용하는 이유 1. TCP가 3 way handshake를 사용하는 반면, UDP는 connection 을 유지할 필요가 없음. 2. DNS request는 UDP segment에 꼭 들어갈 정도로 작음. DNS query는 single UDP request와 server로부터의 single UDP reply로 구성되어 있음. 3. UDP는 not reliable이나, reliability는 application layer에 추가될 수 있음. (Timeout 추가나, resend 작업을 통해) DNS는 UDP를 53번 port에서 사용함. 그러나 TCP를 사용하는 경우가 있음. Zone transfer 을 사용해야하는 경우에는 TCP를 사용해야 함. (Zone Transfer : DNS 서버 간의 요청을 주고 받을 떄 사용하는 transfer) 만약에 데이터가 512 bytes를 넘거나, 응답을 못받은 경우 TCP로 함. [ref]  "
AI,데이터,Blocking I/O & Non Blocking I/O에 대해 설명해 주세요,"I/O 작업은 Kernel level에서만 수행할 수 있다. 따라서, Process, Thread는 커널에게 I/O를 요청해야 한다. 1. Blocking I/O I/O Blocking 형태의 작업은 (1) Process(Thread)가 Kernel에게 I/O를 요청하는 함수를 호출 (2) Kernel이 작업을 완료하면 작업 결과를 반환 받음. 특징 I/O 작업이 진행되는 동안 user Process(Thread) 는 자신의 작업을 중단한 채 대기 Resource 낭비가 심함 (I/O 작업이 CPU 자원을 거의 쓰지 않으므로) 여러 Client 가 접속하는 서버를 Blocking 방식으로 구현하는 경우 I/O 작업을 진행하는 작업을 중지 다른 Client가 진행중인 작업을 중지하면 안되므로, client 별로 별도의 Thread를 생성해야 함 접속자 수가 매우 많아짐 이로 인해, 많아진 Threads 로 컨텍스트 스위칭 횟수가 증가함,,, 비효율적인 동작 방식 2. Non Blocking I/O I/O 작업이 진행되는 동안 User Process의 작업을 중단하지 않음. 진행 순서 1. User Process가 recvfrom 함수 호출 (커널에게 해당 Socket으로부터 data를 받고 싶다고 요청함) 2. Kernel은 이 요청에 대해서, 곧바로 recvBuffer를 채워서 보내지 못하므로, ""EWOULDBLOCK""을 return함. 3. Blocking 방식과 달리, User Process는 다른 작업을 진행할 수 있음. 4. recvBuffer에 user가 받을 수 있는 데이터가 있는 경우, Buffer로부터 데이터를 복사하여 받아옴. 이때, recvBuffer는 Kernel이 가지고 있는 메모리에 적재되어 있으므로, Memory간 복사로 인해, I/O보다 훨씬 빠른 속도로 data를 받아올 수 있음. 5. recvfrom 함수는 빠른 속도로 data를 복사한 후, 복사한 data의 길이와 함께 반환함."
공통,알고리즘,대칭키(Symmetric Key)에 대해 설명해 주세요,"암호화와 복호화에 같은 암호키(대칭키)를 사용하는 알고리즘 동일한 키를 주고받기 때문에, 매우 빠르다는 장점이 있음 but, 대칭키 전달과정에서 해킹 위험에 노출"
공통,알고리즘,공개키(Public Key)/비대칭키(Asymmetric Key)에 대해 설명해 주세요,"암호화와 복호화에 사용하는 암호키를 분리한 알고리즘 대칭키의 키 분배 문제를 해결하기 위해 고안됨.(대칭키일 때는 송수신자 간만 키를 알아야하기 때문에 분배가 복잡하고 어렵지만 공개키와 비밀키로 분리할 경우, 남들이 알아도 되는 공개키만 공개하면 되므로) 자신이 가지고 있는 고유한 암호키(비밀키)로만 복호화할 수 있는 암호키(공개키)를 대중에 공개함"
BACKEND,네트워크,로드 밸런서가 서버를 선택하는 방식에 대해 설명해 주세요,  라운드 로빈(Round Robin) : CPU 스케줄링의 라운드 로빈 방식 활용 Least Connections : 연결 개수가 가장 적은 서버 선택 (트래픽으로 인해 세션이 길어지는 경우 권장) Source : 사용자 IP를 해싱하여 분배 (특정 사용자가 항상 같은 서버로 연결되는 것 보장)
BACKEND,네트워크,로드 밸런서 장애 대비에 대해 설명해 주세요,서버를 분배하는 로드 밸런서에 문제가 생길 수 있기 때문에 로드 밸런서를 이중화하여 대비한다. Active 상태와 Passive 상태
공통,알고리즘,교착 상태를 예방 & 회피에 대해 설명해 주세요,"1. 예방(prevention) 교착 상태 발생 조건 중 하나를 제거하면서 해결한다 (자원 낭비 엄청 심함) 상호배제 부정 : 여러 프로세스가 공유 자원 사용 점유대기 부정 : 프로세스 실행전 모든 자원을 할당 비선점 부정 : 자원 점유 중인 프로세스가 다른 자원을 요구할 때 가진 자원 반납 순환대기 부정 : 자원에 고유번호 할당 후 순서대로 자원 요구 2. 회피(avoidance) 교착 상태 발생 시 피해나가는 방법 은행원 알고리즘(Banker's Algorithm) 은행에서 모든 고객의 요구가 충족되도록 현금을 할당하는데서 유래함 프로세스가 자원을 요구할 때, 시스템은 자원을 할당한 후에도 안정 상태로 남아있게 되는지 사전에 검사하여 교착 상태 회피 안정 상태면 자원 할당, 아니면 다른 프로세스들이 자원 해지까지 대기 자원 할당 그래프 알고리즘(Resource Allocation Graph Algorithm) 자원과 프로세스에 대해 요청 간선과 할당 간선을 적용하여 교착 상태를 회피하는 알고리즘 프로세스가 자원을 요구 시 요청 간선을 할당 간선으로 변경 했을 시 사이클이 생성 되는지 확인한다 사이클이 생성된다 하여 무조건 교착상태인 것은 아니다 자원에 하나의 인스턴스만 존재 시 교착 상태 로 판별한다 자원에 여러 인스턴스가 존재 시 교착 상태 가능성 으로 판별한다 사이클을 생성하지 않으면 자원을 할당한다"
공통,알고리즘,교착 상태를 탐지 & 회복에 대해 설명해 주세요,"교착 상태가 되도록 허용한 다음 회복시키는 방법 1. 탐지(Detection) 자원 할당 그래프를 통해 교착 상태를 탐지함 자원 요청 시, 탐지 알고리즘을 실행시켜 그에 대한 오버헤드 발생함 2. 회복(Recovery) 교착 상태 일으킨 프로세스를 종료하거나, 할당된 자원을 해제시켜 회복시키는 방법 프로세스 종료 방법 교착 상태의 프로세스를 모두 중지 교착 상태가 제거될 때까지 하나씩 프로세스 중지 자원 선점 방법 교착 상태의 프로세스가 점유하고 있는 자원을 선점해 다른 프로세스에게 할당 (해당 프로세스 일시정지 시킴) 우선 순위가 낮은 프로세스나 수행 횟수 적은 프로세스 위주로 프로세스 자원 선점"
공통,알고리즘,알고리증에 대한 기본을 설명해 주세요,1. 데드락(교착 상태)가 뭔가요? 발생 조건에 대해 말해보세요. 2. 회피 기법인 은행원 알고리즘이 뭔지 설명해보세요. 3. 기아상태를 설명하는 식사하는 철학자 문제에 대해 설명해보세요. 교착 상태 해결책 1. n명이 앉을 수 있는 테이블에서 철학자를 n 1명만 앉힘 2. 한 철학자가 젓가락 두개를 모두 집을 수 있는 상황에서만 젓가락 집도록 허용 3. 누군가는 왼쪽 젓가락을 먼저 집지 않고 오른쪽 젓가락을 먼저 집도록 허용
AI,데이터,데이터구조에 대해 설명해 주세요,"  메타 영역 : 데이터 영역에 기록된 파일의 이름, 위치, 크기, 시간정보, 삭제유무 등의 파일 정보 데이터 영역 : 파일의 데이터"
AI,데이터,데이터정의에 대해 설명해 주세요,"프로그램을 실행하는 도중에 예기치 않은 상황이 발생할 경우 현재 실행 중인 작업을 즉시 중단하고, 발생된 상황에 대한 우선 처리가 필요함을 CPU에게 알리는 것 지금 수행 중인 일보다 더 중요한 일(ex. 입출력, 우선 순위 연산 등)이 발생하면 그 일을 먼저 처리하고 나서 하던 일을 계속해야한다. 외부/내부 인터럽트는 CPU의 하드웨어 신호에 의해 발생 소프트웨어 인터럽트는 명령어의 수행에 의해 발생 외부 인터럽트 입출력 장치, 타이밍 장치, 전원 등 외부적인 요인으로 발생 전원 이상, 기계 착오, 외부 신호, 입출력 내부 인터럽트 Trap이라고 부르며, 잘못된 명령이나 데이터를 사용할 때 발생 0으로 나누기가 발생, 오버플로우, 명령어를 잘못 사용한 경우 (Exception) 소프트웨어 인터럽트 프로그램 처리 중 명령의 요청에 의해 발생한 것 (SVC 인터럽트) 사용자가 프로그램을 실행시킬 때 발생 소프트웨어 이용 중에 다른 프로세스를 실행시키면 시분할 처리를 위해 자원 할당 동작이 수행된다."
공통,C,인터럽트 발생 처리 과정에 대해 설명해 주세요,"주 프로그램이 실행되다가 인터럽트가 발생했다. 현재 수행 중인 프로그램을 멈추고, 상태 레지스터와 PC 등을 스택에 잠시 저장한 뒤에 인터럽트 서비스 루틴으로 간다. (잠시 저장하는 이유는, 인터럽트 서비스 루틴이 끝난 뒤 다시 원래 작업으로 돌아와야 하기 때문) 만약 인터럽트 기능이 없었다면 , 컨트롤러는 특정한 어떤 일을 할 시기를 알기 위해 계속 체크를 해야 한다. (이를 폴링(Polling) 이라고 한다) 폴링을 하는 시간에는 원래 하던 일에 집중할 수가 없게 되어 많은 기능을 제대로 수행하지 못하는 단점이 있었다. 즉, 컨트롤러가 입력을 받아들이는 방법(우선순위 판별방법)에는 두가지가 있다. 폴링 방식 사용자가 명령어를 사용해 입력 핀의 값을 계속 읽어 변화를 알아내는 방식 인터럽트 요청 플래그를 차례로 비교하여 우선순위가 가장 높은 인터럽트 자원을 찾아 이에 맞는 인터럽트 서비스 루틴을 수행한다. (하드웨어에 비해 속도 느림) 인터럽트 방식 MCU 자체가 하드웨어적으로 변화를 체크하여 변화 시에만 일정한 동작을 하는 방식 Daisy Chain 병렬 우선순위 부여 인터럽트 방식은 하드웨어로 지원을 받아야 하는 제약이 있지만, 폴링에 비해 신속하게 대응하는 것이 가능하다. 따라서 '실시간 대응' 이 필요할 때는 필수적인 기능이다. 즉, 인터럽트는 발생시기를 예측하기 힘든 경우에 컨트롤러가 가장 빠르게 대응할 수 있는 방법 이다."
AI,데이터,IPC 종류에 대해 설명해 주세요,"1. 익명 PIPE 파이프는 두 개의 프로세스를 연결하는데 하나의 프로세스는 데이터를 쓰기만 하고, 다른 하나는 데이터를 읽기만 할 수 있다. 한쪽 방향으로만 통신이 가능한 반이중 통신 이라고도 부른다. 따라서 양쪽으로 모두 송/수신을 하고 싶으면 2개의 파이프를 만들어야 한다. 매우 간단하게 사용할 수 있는 장점이 있고, 단순한 데이터 흐름을 가질 땐 파이프를 사용하는 것이 효율적이다. 단점으로는 전이중 통신을 위해 2개를 만들어야 할 때는 구현이 복잡해지게 된다. 2. Named PIPE(FIFO) 익명 파이프는 통신할 프로세스를 명확히 알 수 있는 경우에 사용한다. (부모 자식 프로세스 간 통신처럼) Named 파이프는 전혀 모르는 상태의 프로세스들 사이 통신에 사용한다. 즉, 익명 파이프의 확장된 상태로 부모 프로세스와 무관한 다른 프로세스도 통신이 가능한 것 (통신을 위해 이름있는 파일을 사용) 하지만, Named 파이프 역시 읽기/쓰기 동시에 불가능함. 따라서 전이중 통신을 위해서는 익명 파이프처럼 2개를 만들어야 가능 3. Message Queue 입출력 방식은 Named 파이프와 동일함 다른점은 메시지 큐는 파이프처럼 데이터의 흐름이 아니라 메모리 공간이다. 사용할 데이터에 번호를 붙이면서 여러 프로세스가 동시에 데이터를 쉽게 다룰 수 있다. 4. 공유 메모리 파이프, 메시지 큐가 통신을 이용한 설비라면, 공유 메모리는 데이터 자체를 공유하도록 지원하는 설비 다. 프로세스의 메모리 영역은 독립적으로 가지며 다른 프로세스가 접근하지 못하도록 반드시 보호돼야한다. 하지만 다른 프로세스가 데이터를 사용하도록 해야하는 상황도 필요할 것이다. 파이프를 이용해 통신을 통해 데이터 전달도 가능하지만, 스레드처럼 메모리를 공유하도록 해준다면 더욱 편할 것이다. 공유 메모리는 프로세스간 메모리 영역을 공유해서 사용할 수 있도록 허용 해준다. 프로세스가 공유 메모리 할당을 커널에 요청하면, 커널은 해당 프로세스에 메모리 공간을 할당해주고 이후 모든 프로세스는 해당 메모리 영역에 접근할 수 있게 된다. 중개자 없이 곧바로 메모리에 접근할 수 있어서 IPC 중에 가장 빠르게 작동함 5. 메모리 맵 공유 메모리처럼 메모리를 공유해준다. 메모리 맵은 열린 파일을 메모리에 맵핑시켜서 공유 하는 방식이다. (즉 공유 매개체가 파일+메모리) 주로 파일로 대용량 데이터를 공유해야 할 때 사용한다. 6. 소켓 네트워크 소켓 통신을 통해 데이터를 공유한다. 클라이언트와 서버가 소켓을 통해서 통신하는 구조로, 원격에서 프로세스 간 데이터를 공유할 때 사용한다. 서버(bind, listen, accept), 클라이언트(connect) 이러한 IPC 통신에서 프로세스 간 데이터를 동기화하고 보호하기 위해 세마포어와 뮤텍스를 사용한다. (공유된 자원에 한번에 하나의 프로세스만 접근시킬 때)"
BACKEND,네트워크,MMU의 메모리 보호에 대해 설명해 주세요,"프로세스는 독립적인 메모리 공간을 가져야 하고, 자신의 공간에만 접근해야 한다. 따라서 한 프로세스의 합법적인 주소 영역을 설정하고, 잘못된 접근이 오면 trap을 발생시키며 보호한다."
공통,알고리즘,오버헤드를 감소시키는 해결법에 대해 설명해 주세요,"이처럼 빈 프레임이 없는 상황에서 victim 프레임을 비울 때와 원하는 페이지를 프레임으로 올릴 때 두 번의 디스크 접근이 이루어진다. 페이지 교체가 많이 이루어지면, 이처럼 입출력 연산이 많이 발생하게 되면서 오버헤드 문제가 발생한다. 방법 1 비트를 활용해 디스크에 기록하는 횟수를 줄이면서 오버헤드를 최대 절반으로 감소시키는 방법이다. 모든 페이지마다 변경 비트를 두고, victim 페이지가 정해지면 해당 페이지의 변경 비트를 확인한다. 변경 비트가 set 상태라면? 메모리상의 페이지 내용이 디스크상의 페이지 내용과 달라졌다는 뜻 페이지가 메모리로 올라온 이후 수정돼서 내려갈 때 디스크에 기록해야 함 변경 비트가 clear 상태라면? 메모리상의 페이지 내용이 디스크상의 페이지 내용과 정확히 일치한다는 뜻 페이지가 디스크상의 페이지 내용과 같아서 내려갈 때 기록할 필요가 없음 방법 2 현재 상황에서 페이지 폴트가 발생할 확률을 최대한 줄일 수 있는 교체 알고리즘을 선택한다. FIFO OPT LRU"
AI,데이터,지역성에 대해 설명해 주세요,기억 장치 내의 데이터에 균일하게 접근하는 것이 아니라 한순간에 특정 부분을 집중적으로 참조하는 특성 지역성의 종류는 시간과 공간으로 나누어진다. 시간 지역성 : 최근에 참조된 주소의 내용은 곧 다음에도 참조되는 특성 공간 지역성 : 실제 프로그램이 참조된 주소와 인접한 주소의 내용이 다시 참조되는 특성
공통,C,저장장치 관리에 대해 설명해 주세요,  메모리 관리 가상 메모리 파일 시스템
BACKEND,네트워크,네트워킹에 대해 설명해 주세요,  TCP/IP 기타 프로토콜
BACKEND,네트워크,디바이스 드라이버에 대해 설명해 주세요,  순차접근 장치 임의접근 장치 네트워크 장치
공통,알고리즘,Page Reference String에 대해 설명해 주세요,"CPU는 논리 주소를 통해 특정 주소를 요구함 메인 메모리에 올라와 있는 주소들은 페이지의 단위로 가져오기 때문에 페이지 번호가 연속되어 나타나게 되면 페이지 결함 발생 X 따라서 CPU의 주소 요구에 따라 페이지 결함이 일어나지 않는 부분은 생략하여 표시하는 방법이 바로 Page Reference String 1. FIFO 알고리즘 First in First out, 메모리에 먼저 올라온 페이지를 먼저 내보내는 알고리즘 victim page : out 되는 페이지는, 가장 먼저 메모리에 올라온 페이지 가장 간단한 방법으로, 특히 초기화 코드에서 적절한 방법임 초기화 코드 : 처음 프로세스 실행될 때 최초 초기화를 시키는 역할만 진행하고 다른 역할은 수행하지 않으므로, 메인 메모리에서 빼도 괜찮음 하지만 처음 프로세스 실행시에는 무조건 필요한 코드이므로, FIFO 알고리즘을 사용하면 초기화를 시켜준 후 가장 먼저 내보내는 것이 가능함 2. OPT 알고리즘 Optimal Page Replacement 알고리즘, 앞으로 가장 사용하지 않을 페이지를 가장 우선적으로 내보냄 FIFO에 비해 페이지 결함의 횟수를 많이 감소시킬 수 있음 하지만, 실질적으로 페이지가 앞으로 잘 사용되지 않을 것이라는 보장이 없기 때문에 수행하기 어려운 알고리즘임 3. LRU 알고리즘 Least Recently Used, 최근에 사용하지 않은 페이지를 가장 먼저 내려보내는 알고리즘 최근에 사용하지 않았으면, 나중에도 사용되지 않을 것이라는 아이디어에서 나옴 OPT의 경우 미래 예측이지만, LRU의 경우는 과거를 보고 판단하므로 실질적으로 사용이 가능한 알고리즘 (실제로도 최근에 사용하지 않은 페이지는 앞으로도 사용하지 않을 확률이 높다) OPT보다는 페이지 결함이 더 일어날 수 있지만, 실제로 사용할 수 있는 페이지 교체 알고리즘에서는 가장 좋은 방법 중 하나임 img src="""
공통,알고리즘,교체 방식에 대해 설명해 주세요,"  Global 교체 메모리 상의 모든 프로세스 페이지에 대해 교체하는 방식 Local 교체 메모리 상의 자기 프로세스 페이지에서만 교체하는 방식 다중 프로그래밍의 경우, 메인 메모리에 다양한 프로세스가 동시에 올라올 수 있음 따라서, 다양한 프로세스의 페이지가 메모리에 존재함 페이지 교체 시, 다양한 페이지 교체 알고리즘을 활용해 victim page를 선정하는데, 선정 기준을 Global로 하느냐, Local로 하느냐에 대한 차이 → 실제로는 전체를 기준으로 페이지를 교체하는 것이 더 효율적이라고 함. 자기 프로세스 페이지에서만 교체를 하면, 교체를 해야할 때 각각 모두 교체를 진행해야 하므로 비효율적"
공통,C,기법을 쓰는 이유에 대해 설명해 주세요,다중 프로그래밍 시스템에 여러 프로세스를 수용하기 위해 주기억장치를 동적 분할하는 메모리 관리 작업이 필요해서
공통,C,메모리 관리 기법에 대해 설명해 주세요,"1. 연속 메모리 관리 프로그램 전체가 하나의 커다란 공간에 연속적으로 할당되어야 함 고정 분할 기법 : 주기억장치가 고정된 파티션으로 분할 ( 내부 단편화 발생 ) 동적 분할 기법 : 파티션들이 동적 생성되며 자신의 크기와 같은 파티션에 적재 ( 외부 단편화 발생 ) 2. 불연속 메모리 관리 프로그램의 일부가 서로 다른 주소 공간에 할당될 수 있는 기법 페이지 : 고정 사이즈의 작은 프로세스 조각 프레임 : 페이지 크기와 같은 주기억장치 메모리 조각 단편화 : 기억 장치의 빈 공간 or 자료가 여러 조각으로 나뉘는 현상 세그먼트 : 서로 다른 크기를 가진 논리적 블록이 연속적 공간에 배치되는 것 고정 크기 : 페이징(Paging) 가변 크기 : 세그먼테이션(Segmentation) 단순 페이징 각 프로세스는 프레임들과 같은 길이를 가진 균등 페이지로 나뉨 외부 단편화 X 소량의 내부 단편화 존재 단순 세그먼테이션 각 프로세스는 여러 세그먼트들로 나뉨 내부 단편화 X, 메모리 사용 효율 개선, 동적 분할을 통한 오버헤드 감소 외부 단편화 존재 가상 메모리 페이징 단순 페이징과 비교해 프로세스 페이지 전부를 로드시킬 필요X 필요한 페이지가 있으면 나중에 자동으로 불러들어짐 외부 단편화 X 복잡한 메모리 관리로 오버헤드 발생 가상 메모리 세그먼테이션 필요하지 않은 세그먼트들은 로드되지 않음 필요한 세그먼트 있을때 나중에 자동으로 불러들어짐 내부 단편화X 복잡한 메모리 관리로 오버헤드 발생"
AI,데이터,Process Management에 대해 설명해 주세요,"CPU가 프로세스가 여러개일 때, CPU 스케줄링을 통해 관리하는 것을 말함 이때, CPU는 각 프로세스들이 누군지 알아야 관리가 가능함 프로세스들의 특징을 갖고있는 것이 바로 Process Metadata Process Metadata Process ID Process State Process Priority CPU Registers Owner CPU Usage Memeory Usage 이 메타데이터는 프로세스가 생성되면 PCB(Process Control Block) 이라는 곳에 저장됨"
AI,데이터,PCB(Process Control Block)에 대해 설명해 주세요,"프로세스 메타데이터들을 저장해 놓는 곳, 한 PCB 안에는 한 프로세스의 정보가 담김"
BACKEND,운영체제,멀티프로세스에 대해 설명해 주세요,"하나의 프로그램을 여러 개의 프로세스로 구성하여 각 프로세스가 병렬적으로 작업을 처리하도록 하는 것 장점 : 안전성 (메모리 침범 문제를 OS 차원에서 해결) 단점 : 각각 독립된 메모리를 갖고 있어 작업량이 많을수록 오버헤드 발생, Context Switching으로 인한 성능 저하 Context Switching 이란? 프로세스의 상태 정보를 저장하고 복원하는 일련의 과정 동작 중인 프로세스가 대기하면서 해당 프로세스 상태를 보관 대기하고 있던 다음 순번의 프로세스가 동작하면서 이전에 보관했던 프로세스 상태를 복구 문제점: 프로세스는 독립된 메모리 영역을 할당받으므로, 캐시 메모리 초기화와 같은 무거운 작업이 진행되면 오버헤드가 발생할 수 있음"
AI,데이터,멀티스레드에 대해 설명해 주세요,"하나의 프로그램을 여러 개의 스레드로 구성하여 각 스레드가 하나의 작업을 처리하도록 하는 것 스레드들이 공유 메모리를 통해 다수의 작업을 동시에 처리하도록 해 준다. 장점 : 독립적인 프로세스에 비해 공유 메모리만큼의 시간과 자원 손실 감소, 전역 변수와 정적 변수 공유 가능 단점 : 안전성 (공유 메모리를 갖기 때문에 하나의 스레드가 데이터 공간을 망가뜨리면, 모든 스레드 작동 불능) 멀티스레드의 안전성에 대한 단점은 Critical Section 기법을 통해 대비한다. 하나의 스레드가 공유 데이터값을 변경하는 시점에 다른 스레드가 그 값을 읽으려 할 때 발생하는 문제를 해결하기 위한 동기화 과정 상호 배제, 진행, 한정된 대기를 충족해야 함"
BACKEND,운영체제,Race Condition이 발생하는 경우에 대해 설명해 주세요,"1. 커널 작업을 수행하는 중에 인터럽트 발생 문제점 : 커널모드에서 데이터를 로드하여 작업을 수행하다가 인터럽트가 발생하여 같은 데이터를 조작하는 경우 해결법 : 커널모드에서 작업을 수행하는 동안, 인터럽트를 disable 시켜 CPU 제어권을 가져가지 못하도록 한다. 2. 프로세스가 'System Call'을 하여 커널 모드로 진입하여 작업을 수행하는 도중 문맥 교환이 발생할 때 문제점 : 프로세스1이 커널모드에서 데이터를 조작하는 도중, 시간이 초과되어 CPU 제어권이 프로세스2로 넘어가 같은 데이터를 조작하는 경우 ( 프로세스2가 작업에 반영되지 않음 ) 해결법 : 프로세스가 커널모드에서 작업을 하는 경우 시간이 초과되어도 CPU 제어권이 다른 프로세스에게 넘어가지 않도록 함 3. 멀티 프로세서 환경에서 공유 메모리 내의 커널 데이터에 접근할 때 문제점 : 멀티 프로세서 환경에서 2개의 CPU가 동시에 커널 내부의 공유 데이터에 접근하여 조작하는 경우 해결법 : 커널 내부에 있는 각 공유 데이터에 접근할 때마다, 그 데이터에 대한 lock/unlock을 하는 방법"
AI,데이터,임계 구역(Critical Section)에 대해 설명해 주세요,"여러 프로세스가 데이터를 공유하며 수행될 때, 각 프로세스에서 공유 데이터를 접근하는 프로그램 코드 부분 공유 데이터를 여러 프로세스가 동시에 접근할 때 잘못된 결과를 만들 수 있기 때문에, 한 프로세스가 임계 구역을 수행할 때는 다른 프로세스가 접근하지 못하도록 해야 한다."
공통,알고리즘,뮤텍스 알고리즘에 대해 설명해 주세요,"1. 데커(Dekker) 알고리즘 flag와 turn 변수를 통해 임계 구역에 들어갈 프로세스/스레드를 결정하는 방식 flag : 프로세스 중 누가 임계영역에 진입할 것인지 나타내는 변수 turn : 누가 임계구역에 들어갈 차례인지 나타내는 변수 java while(true) { flag[i] = true; // 프로세스 i가 임계 구역 진입 시도 while(flag[j]) { // 프로세스 j가 현재 임계 구역에 있는지 확인 if(turn == j) { // j가 임계 구역 사용 중이면 flag[i] = false; // 프로세스 i 진입 취소 while(turn == j); // turn이 j에서 변경될 때까지 대기 flag[i] = true; // j turn이 끝나면 다시 진입 시도 } } } // 임계 구역 turn = j; // 임계 구역 사용 끝나면 turn을 넘김 flag[i] = false; // flag 값을 false로 바꿔 임계 구역 사용 완료를 알림 2. 피터슨(Peterson) 알고리즘 데커와 유사하지만, 상대방 프로세스/스레드에게 진입 기회를 양보하는 것에 차이가 있음 java while(true) { flag[i] = true; // 프로세스 i가 임계 구역 진입 시도 turn = j; // 다른 프로세스에게 진입 기회 양보 while(flag[j] && turn == j) { // 다른 프로세스가 진입 시도하면 대기 } } // 임계 구역 flag[i] = false; // flag 값을 false로 바꿔 임계 구역 사용 완료를 알림 3. 제과점(Bakery) 알고리즘 여러 프로세스/스레드에 대한 처리가 가능한 알고리즘. 가장 작은 수의 번호표를 가지고 있는 프로세스가 임계 구역에 진입한다. java while(true) { isReady[i] = true; // 번호표 받을 준비 number[i] = max(number[0~n 1]) + 1; // 현재 실행 중인 프로세스 중에 가장 큰 번호 배정 isReady[i] = false; // 번호표 수령 완료 for(j = 0; j n; j++) { // 모든 프로세스 번호표 비교 while(isReady[j]); // 비교 프로세스가 번호표 받을 때까지 대기 while(number[j] && number[j] number[i] && j i); // 프로세스 j가 번호표 가지고 있어야 함 // 프로세스 j의 번호표 프로세스 i의 번호표 } // 임계 구역 number[i] = 0; // 임계 구역 사용 종료 }"
BACKEND,운영체제,[Operating System] System Call에 대해 설명해 주세요,"fork( ), exec( ), wait( )와 같은 것들은 Process 생성과 제어를 위한 System call임. fork, exec는 새로운 Process 생성과 관련이 되어 있다. wait는 Process (Parent)가 만든 다른 Process(child) 가 끝날 때까지 기다리는 명령어임."
BACKEND,운영체제,Fork에 대해 설명해 주세요,"새로운 Process를 생성할 때 사용. 그러나, 이상한 방식임. c"
BACKEND,운영체제,wait에 대해 설명해 주세요,child 프로세스가 종료될 때까지 기다리는 작업 위의 예시에 int wc = wait(NULL)만 추가함. C
BACKEND,운영체제,exec에 대해 설명해 주세요,단순 fork는 동일한 프로세스의 내용을 여러 번 동작할 때 사용함. child에서는 parent와 다른 동작을 하고 싶을 때는 exec를 사용할 수 있음. c
공통,JAVA,클린코드에 대해 설명해 주세요,"클린코드란, 가독성이 높은 코드를 말한다. 가독성을 높이려면 다음과 같이 구현해야 한다. 네이밍이 잘 되어야 함 오류가 없어야 함 중복이 없어야 함 의존성을 최대한 줄여야 함 클래스 혹은 메소드가 한가지 일만 처리해야 함 얼마나 코드가 잘 읽히는 지, 코드가 지저분하지 않고 정리된 코드인지 를 나타내는 것이 바로 '클린 코드' java public int AAA(int a, int b){ return a+b; } public int BBB(int a, int b){ return a b; } 두 가지 문제점이 있다. java public int sum(int a, int b){ return a+b; } public int sub(int a, int b){ return a b; } 첫째는 함수 네이밍 이다. 다른 사람들이 봐도 무슨 역할을 하는 함수인 지 알 수 있는 이름을 사용해야 한다. 둘째는 함수와 함수 사이의 간격 이다. 여러 함수가 존재할 때 간격을 나누지 않으면 시작과 끝을 구분하는 것이 매우 힘들다."
공통,JAVA,Java에서 활용할 수 있는 함수형 프로그래밍에 대해 설명해 주세요,"  람다식 stream api 함수형 인터페이스 Java 8에는 Stream API가 추가되었다. java import java.util.Arrays; import java.util.List; public class stream { public static void main(String[] args) { List String myList = Arrays.asList(""a"", ""b"", ""c"", ""d"", ""e""); // 기존방식 for(int i=0; i myList.size(); i++){ String s = myList.get(i); if(s.startsWith(""c"")){ System.out.println(s.toUpperCase()); } } // stream API를 이용한 방식 myList.stream() .filter(s s.startsWith(""c"")) .map(String::toUpperCase) .forEach(System.out::println); } } 뭐가 다른건지 크게 와닿지 않을 수 있지만, 중요한건 프로그래밍의 패러다임 변화라는 것이다. 단순히 함수를 선언해서 데이터를 내가 원하는 방향으로 처리해나가는 함수형 프로그래밍 방식을 볼 수 있다. 한눈에 보더라도 함수형 프로그래밍은 내가 무엇을 구현했는지 명확히 알 수 있다 . (무슨 함수인지 사전학습이 필요한 점이 있음)"
AI,데이터,프로시저에 대해 설명해 주세요,"반환값(리턴)이 따로 존재하지 않는 함수를 뜻한다. 예를 들면, printf와 같은 함수는 반환값을 얻기 위한 것보단, 화면에 출력하는 용도로 쓰이는 함수다. 이와 같은 함수를 프로시저로 부른다. (정확히 말하면 printf는 int형을 리턴해주기는 함. 하지만 목적 자체는 프로시저에 가까움) 하지만 이런 패러다임도 문제점이 존재한다. 바로 너무 추상적 이라는 것.. 실제로 사용되는 프로그램들은 추상적이지만은 않다. 함수는 논리적 단위로 표현되지만, 실제 데이터에 해당하는 변수나 상수 값들은 물리적 요소로 되어있기 때문이다. 도서관리 프로그램이 있다고 가정해보자. 책에 해당하는 자료형(필드)를 구현해야 한다. 또한 책과 관련된 함수를 구현해야 한다. 구조적인 프로그래밍에서는 이들을 따로 만들어야 한다. 결국 많은 데이터를 만들어야 할 때, 구분하기 힘들고 비효율적으로 코딩할 가능성이 높아진다. 책에 대한 자료형, 책에 대한 함수가 물리적으론 같이 있을 수 있지만 (같은 위치에 기록) 논리적으로는 함께할 수 없는 구조가 바로 구조적 프로그래밍 따라서, 이를 한번에 묶기 위한 패러다임이 탄생한다. 바로 객체지향 프로그래밍 이다. 우리가 vo를 만들 때와 같은 형태다. 클래스마다 필요한 필드를 선언하고, getter와 setter로 구성된 모습으로 해결한다. 바로 특정한 개념의 함수와 자료형을 함께 묶어서 관리하기 위해 탄생 한 것! 가장 중요한 점은, 객체 내부에 자료형(필드)와 함수(메소드)가 같이 존재하는 것 이다. 이제 도서관리 프로그램을 만들 때, 해당하는 책의 제목, 저자, 페이지와 같은 자료형과 읽기, 예약하기 등 메소드를 '책'이라는 객체에 한번에 묶어서 저장하는 것이 가능해졌다. 이처럼 가능한 모든 물리적, 논리적 요소를 객체로 만드려는 것이 객체지향 프로그래밍 이라고 말할 수 있다. 객체지향으로 구현하게 되면, 객체 간의 독립성이 생기고 중복코드의 양이 줄어드는 장점이 있다. 또한 독립성이 확립되면 유지보수에도 도움이 될 것이다."
AI,데이터,객체 지향 설계 과정에 대해 설명해 주세요,  제공해야 할 기능을 찾고 세분화한다. 그리고 그 기능을 알맞은 객체에 할당한다. 기능을 구현하는데 필요한 데이터를 객체에 추가한다. 그 데이터를 이용하는 기능을 넣는다. 기능은 최대한 캡슐화하여 구현한다. 객체 간에 어떻게 메소드 요청을 주고받을 지 결정한다.
BACKEND,운영체제,객체 지향 설계 원칙에 대해 설명해 주세요,"SOLID라고 부르는 5가지 설계 원칙이 존재한다. 1. SRP(Single Responsibility) 단일 책임 원칙 클래스는 단 한 개의 책임을 가져야 한다. 클래스를 변경하는 이유는 단 한개여야 한다. 이를 지키지 않으면, 한 책임의 변경에 의해 다른 책임과 관련된 코드에 영향이 갈 수 있다. 2. OCP(Open Closed) 개방 폐쇄 원칙 확장에는 열려 있어야 하고, 변경에는 닫혀 있어야 한다. 기능을 변경하거나 확장할 수 있으면서, 그 기능을 사용하는 코드는 수정하지 않는다. 이를 지키지 않으면, instanceof와 같은 연산자를 사용하거나 다운 캐스팅이 일어난다. 3. LSP(Liskov Substitution) 리스코프 치환 원칙 상위 타입의 객체를 하위 타입의 객체로 치환해도, 상위 타입을 사용하는 프로그램은 정상적으로 동작해야 한다. 상속 관계가 아닌 클래스들을 상속 관계로 설정하면, 이 원칙이 위배된다. 4. ISP(Interface Segregation) 인터페이스 분리 원칙 인터페이스는 그 인터페이스를 사용하는 클라이언트를 기준으로 분리해야 한다. 각 클라이언트가 필요로 하는 인터페이스들을 분리함으로써, 각 클라이언트가 사용하지 않는 인터페이스에 변경이 발생하더라도 영향을 받지 않도록 만들어야 한다. 5. DIP(Dependency Inversion) 의존 역전 원칙 고수준 모듈은 저수준 모듈의 구현에 의존해서는 안된다. 저수준 모듈이 고수준 모듈에서 정의한 추상 타입에 의존해야 한다. 즉, 저수준 모듈이 변경돼도 고수준 모듈은 변경할 필요가 없는 것이다."
공통,디자인패턴,TDD : 테스트 주도 개발에 대해 설명해 주세요,"테스트가 개발을 이끌어 나간다.' 우리는 보통 개발할 때, 설계(디자인)를 한 이후 코드 개발과 테스트 과정을 거치게 된다. 하지만 TDD는 기존 방법과는 다르게, 테스트케이스를 먼저 작성한 이후에 실제 코드를 개발하는 리팩토링 절차를 밟는다. 작가가 책을 쓰는 과정에 대해서 생각해보자. 책을 쓰기 전, 목차를 먼저 구성한다. 이후 목차에 맞는 내용을 먼저 구상한 뒤, 초안을 작성하고 고쳐쓰기를 반복한다. 목차 구성 : 테스트 코드 작성 초안 작성 : 코드 개발 고쳐 쓰기 : 코드 수정(리팩토링) 반복적인 '검토'와 '고쳐쓰기'를 통해 좋은 글이 완성된다. 이런 방법을 소프트웨어에 적용한 것이 TDD! 소프트웨어 또한 반복적인 테스트와 수정을 통해 고품질의 소프트웨어를 탄생시킬 수 있다."
공통,JAVA,점수 계산 프로그램을 통한 TDD 예제 진행,"중간고사, 기말고사, 과제 점수를 통한 성적을 내는 간단한 프로그램을 만들어보자 점수 총합 90점 이상은 A, 80점 이상은 B, 70점 이상은 C, 60점 이상은 D, 나머지는 F다. TDD 테스트케이스를 먼저 작성한다. 35 + 25 + 25 = 85점이므로 등급이 B가 나와야 한다. 따라서 assertEquals의 인자값을 ""B""로 주고, 테스트 결과가 일치하는지 확인하는 과정을 진행해보자 java public class GradeTest { @Test public void scoreResult() { Score score = new Score(35, 25, 25); // Score 클래스 생성 SimpleScoreStrategy scores = new SimpleScoreStrategy(); String resultGrade = scores.computeGrade(score); // 점수 계산 assertEquals(""B"", resultGrade); // 확인 } } 현재는 Score 클래스와 computeGrade() 메소드가 구현되지 않은 상태 다. (테스트 코드로만 존재) 테스트 코드에 맞춰서 코드 개발을 진행하자 우선 점수를 저장할 Score 클래스를 생성한다 java public class Score { private int middleScore = 0; private int finalScore = 0; private int homeworkScore = 0; public Score(int middleScore, int finalScore, int homeworkScore) { this.middleScore = middleScore; this.finalScore = finalScore; this.homeworkScore = homeworkScore; } public int getMiddleScore(){ return middleScore; } public int getFinalScore(){ return finalScore; } public int getHomeworkScore(){ return homeworkScore; } } 이제 점수 계산을 통해 성적을 뿌려줄 computeGrade() 메소드를 가진 클래스를 만든다. 우선 인터페이스를 구현하자 java public interface ScoreStrategy { public String computeGrade(Score score); } 인터페이스를 가져와 오버라이딩한 클래스를 구현한다 java public class SimpleScoreStrategy implements ScoreStrategy { public String computeGrade(Score score) { int totalScore = score.getMiddleScore() + score.getFinalScore() + score.getHomeworkScore(); // 점수 총합 String gradeResult = null; // 학점 저장할 String 변수 if(totalScore = 90) { gradeResult = ""A""; } else if(totalScore = 80) { gradeResult = ""B""; } else if(totalScore = 70) { gradeResult = ""C""; } else if(totalScore = 60) { gradeResult = ""D""; } else { gradeResult = ""F""; } return gradeResult; } } 이제 테스트 코드로 돌아가서, 실제로 통과할 정보를 입력해본 뒤 결과를 확인해보자 이때 예외 처리, 중복 제거, 추가 기능을 통한 리팩토링 작업을 통해 완성도 높은 프로젝트를 구현할 수 있도록 노력하자! 통과가 가능한 정보를 넣고 실행하면, 아래와 같이 에러 없이 제대로 실행되는 모습을 볼 수 있다. 굳이 필요하나요? 딱봐도 귀찮아 보인다. 저렇게 확인 안해도 결과물을 알 수 있지 않냐고 반문할 수도 있다. 하지만 예시는 간단하게 보였을 뿐, 실제 실무 프로젝트에서는 다양한 출력 결과물이 필요하고, 원하는 테스트 결과가 나오는 지 확인하는 과정은 필수적인 부분이다. TDD를 활용하면, 처음 시작하는 단계에서 테스트케이스를 설계하기 위한 초기 비용이 확실히 더 들게 된다. 하지만 개발 과정에 있어서 '초기 비용'보다 '유지보수 비용'이 더 클 수 있다는 것을 명심하자 또한 안전성이 필요한 소프트웨어 프로젝트에서는 개발 초기 단계부터 확실하게 다져놓고 가는 것이 중요하다. 유지보수 비용이 더 크거나 비행기, 기차에 필요한 소프트웨어 등 안전성이 중요한 프로젝트의 경우 현재 실무에서도 TDD를 활용한 개발을 통해 이루어지고 있다."
BACKEND,네트워크,애자일에 대해 설명해 주세요,애자일의 핵심은 바로 '협력'과 '피드백'이다.
BACKEND,네트워크,진행 방법에 대해 설명해 주세요,"1. 개발자와 고객 사이의 u 지속적 커뮤니케이션을 통해 변화하는 요구사항을 수용 /u 한다. 2. 고객이 결정한 사항을 가장 우선으로 시행하고, u 개발자 개인의 가치보다 팀의 목표를 우선 /u 으로 한다. 3. 팀원들과 u 주기적인 미팅 /u 을 통해 프로젝트를 점검한다. 4. 주기적으로 제품 시현을 하고 u 고객으로부터 피드백 /u 을 받는다. 5. 프로그램 품질 향상에 신경쓰며 간단한 내부 구조 형성을 통한 u 비용절감을 목표 /u 로 한다. 애자일을 통한 가장 많이 사용하는 개발 방법론이 '스크럼' 럭비 경기에서 사용되던 용어인데, 반칙으로 인해 경기가 중단됐을 때 쓰는 대형을 말함 즉, 소프트웨어 측면에서 팀이라는 단어가 주는 의미를 적용시키고, 효율적인 성과를 얻기 위한 것 1. 제품 기능 목록 작성 개발할 제품에 대한 요구사항 목록 작성 우선순위가 매겨진, 사용자의 요구사항 목록이라고 말할 수 있음 개발 중에 수정이 가능하기는 하지만, 일반적으로 한 주기가 끝날 때까지는 제품 기능 목록을 수정하지 않는 것이 원칙 2. 스프린트 Backlog 스프린트 각각의 목표에 도달하기 위해 필요한 작업 목록 세부적으로 어떤 것을 구현해야 하는지 작업자 예상 작업 시간 최종적으로 개발이 어떻게 진행되고 있는지 상황 파악 가능 3. 스프린트 작은 단위의 개발 업무를 단기간 내에 전력질주하여 개발한다 한달동안의 큰 계획을 3~5일 단위로 반복 주기 를 정했다면 이것이 스크럼에서 스프린트에 해당함 주기가 회의를 통해 결정되면 (보통 2주 ~ 4주) 목표와 내용이 개발 도중에 바뀌지 않아야 하고, 팀원들 동의 없이 바꿀 수 없는 것이 원칙 4. 일일 스크럼 회의 몇가지 규칙이 있다. 모든 팀원이 참석하여 매일하고, 짧게(15분)하고, 진행 상황 점검한다. 한사람씩 어제 한 일, 오늘 할 일, 문제점 및 어려운 점을 이야기함 완료된 세부 작업 항목을 스프린트 현황판에서 업데이트 시킴 5. 제품완성 및 스프린트 검토 회의 모든 스프린트 주기가 끝나면, 제품 기능 목록에서 작성한 제품이 완성된다. 최종 제품이 나오면 고객들 앞에서 시연을 통한 스프린트 검토 회의 진행 고객의 요구사항에 얼마나 부합했는가? 개선점 및 피드백 6. 스프린트 회고 스프린트에서 수행한 활동과 개발한 것을 되돌아보며 개선점이나 규칙 및 표준을 잘 준수했는지 검토 팀의 단점보다는 강점과 장점을 찾아 더 극대화하는데 초점을 둔다"
공통,JAVA,네이밍(Naming)에 대해 설명해 주세요,"변수, 클래스, 메소드에 의도가 분명한 이름을 사용한다. java int elapsedTimeInDays; int daysSinceCreation; int fileAgeInDays; 잘못된 정보를 전달할 수 있는 이름을 사용하지 않는다. 범용적으로 사용되는 단어 사용X (aix, hp 등) 연속된 숫자나 불용어를 덧붙이는 방식은 피해야함"
공통,디자인패턴,꾸미기(Aesthetics)에 대해 설명해 주세요,"보기좋게 배치하고 꾸민다. 보기 좋은 코드가 읽기도 좋다. 규칙적인 들여쓰기와 줄바꿈으로 가독성을 향상시키자 일관성있고 간결한 패턴을 적용해 줄바꿈한다. 메소드를 이용해 불규칙한 중복 코드를 제거한다. 클래스 전체를 하나의 그룹이라고 생각하지 말고, 그 안에서도 여러 그룹으로 나누는 것이 읽기에 좋다."
공통,JAVA,흐름제어 만들기(Making control flow easy to read)에 대해 설명해 주세요,"  왼쪽에는 변수를, 오른쪽에는 상수를 두고 비교 java if(length = 10) while(bytes received bytest expected) 부정이 아닌 긍정을 다루자 java if( a == b ) { // a!=b는 부정 // same } else { // different } if/else를 사용하며, 삼항 연산자는 매우 간단한 경우만 사용 do/while 루프는 피하자"
공통,JAVA,착한 함수(Function)에 대해 설명해 주세요,"함수는 가급적 작게, 한번에 하나의 작업만 수행하도록 작성 온라인 투표로 예를 들어보자 사용자가 추천을 하거나, 이미 선택한 추천을 변경하기 위해 버튼을 누르면 vote change(old vote, new vote) 함수를 호출한다고 가정해보자 javascript var vote changed = function (old vote, new vote) { var score = get score(); if (new vote !== old vote) { if (new vote == 'Up') { score += (old vote === 'Down' ? 2 : 1); } else if (new vote == 'Down') { score  = (old vote === 'Up' ? 2 : 1); } else if (new vote == '') { score += (old vote === 'Up' ?  1 : 1); } } set score(score); }; 총점을 변경해주는 한 가지 역할을 하는 함수같지만, 두가지 일을 하고 있다. old vote와 new vote의 상태에 따른 score 계산 총점을 계산 별도로 함수로 분리하여 가독성을 향상시키자 javascript var vote value = function (vote) { if(vote === 'Up') { return +1; } if(vote === 'Down') { return  1; } return 0; }; var vote changed = function (old vote, new vote) { var score = get score(); score  = vote value(old vote); // 이전 값 제거 score += vote value(new vote); // 새로운 값 더함 set score(score); }; 훨씬 깔끔한 코드가 되었다!"
AI,데이터,리팩토링 대상에 대해 설명해 주세요,"  메소드 정리 : 그룹으로 묶을 수 있는 코드, 수식을 메소드로 변경함 객체 간의 기능 이동 : 메소드 기능에 따른 위치 변경, 클래스 기능을 명확히 구분 데이터 구성 : 캡슐화 기법을 적용해 데이터 접근 관리 조건문 단순화 : 조건 논리를 단순하고 명확하게 작성 메소드 호출 단순화 : 메소드 이름이나 목적이 맞지 않을 때 변경 클래스 및 메소드 일반화 : 동일 기능 메소드가 여러개 있으면 수퍼클래스로 이동"
공통,디자인패턴,리팩토링 진행 방법에 대해 설명해 주세요,아키텍처 관점 시작 → 디자인 패턴 적용 → 단계적으로 하위 기능에 대한 변경으로 진행 의도하지 않은 기능 변경이나 버그 발생 대비해 회귀테스트 진행 이클립스와 같은 IDE 도구로 이용
공통,알고리즘,Linear regression 알고리즘의 최종 목적 : cost 값을 최소화하는 W와 b를 찾자에 대해 설명해 주세요,"(예측값 실제값)의 제곱을 하는 이유는? 양수가 나올 수도 있고, 음수가 나올 수도 있다. 또한 제곱을 하면, 거리가 더 먼 결과일 수록 값은 더욱 커지게 되어 패널티를 더 줄 수 있는 장점이 있다."
공통,파이썬,placeholder를 이용해서 실행되는 값을 나중에 던져줄 때에 대해 설명해 주세요,"python import tensorflow as tf W = tf.Variable(tf.random normal([1]), name='weight') b = tf.Variable(tf.random normal([1]), name='bias') X = tf.placeholder(tf.float32, shape=[None]) Y = tf.placeholder(tf.float32, shape=[None])"
공통,알고리즘,DBSCAN 장점에 대해 설명해 주세요,"  클러스터의 수를 미리 정하지 않아도 된다. K Means 알고리즘처럼 미리 점을 지정해놓고 군집화를 하지 않아도 된다. 다양한 모양과 크기의 클러스터를 얻는 것이 가능하다. 모양이 기하학적인 분포라도, 밀도 여부에 따라 군집도를 찾을 수 있다. 아웃라이어 검출을 통해 필요하지 않은 noise 데이터를 검출하는 것이 가능하다."
공통,알고리즘,DBSCAN 단점에 대해 설명해 주세요,  Epslion에 너무 민감하다. 반경으로 설정한 값에 상당히 민감하게 작용된다. 따라서 DBSCAN 알고리즘을 사용하려면 적절한 Epsilon 값을 설정하는 것이 중요하다.
AI,데이터,데이터 분석에 대해 설명해 주세요,"스칼라 : 하나의 값을 가진 변수 a = 'hello' 벡터 : 여러 값을 가진 변수 b = ['hello', 'world'] 데이터 분석은 주로 '벡터'를 다루고, DataFrame의 변수도 벡터 이런 '벡터'를 pandas에서는 Series라고 부르고, numpy에서는 ndarray라 부름"
AI,데이터,파이썬에서 제공하는 벡터 다루는 함수들에 대해 설명해 주세요,"all([1, 1, 1]) 벡터 데이터 모두 True면 True 반환 any([1,0,0]) 한 개라도 True면 True 반환 max([1,2,3]) 가장 큰 값을 반환한다. min([1,2,3]) 가장 작은 값을 반환한다. list(range(10)) 0부터 10까지 순열을 만듬 list(range(3,6)) 3부터 5까지 순열을 만듬 list(range(1, 6, 2)) 1부터 6까지 2단위로 순열을 만듬"
AI,데이터,pandas에 대해 설명해 주세요,"python import pandas as pd pandas import df = pd.read csv(""data.csv"") csv파일 불러오기 다양한 함수를 활용해서 데이터를 관측할 수 있다. python df.head() 맨 앞 5개를 보여줌 df.tail() 맨 뒤 5개를 보여줌 df[0:2] 특정 관측치 슬라이싱 df.columns 변수명 확인 df.describe() count, mean(평균), std(표준편차), min, max"
AI,데이터,왜 많은 기업들이 반도체에 대한 투자에 열망하는가?에 대해 설명해 주세요,"4차 산업혁명 이후 5G 산업이 발전하고 있다. 현재까지 5G 디바이스는 아주 미세한 보급 상태지만, 향후 3~4년 안에 대부분의 사람들이 5G를 이용하게 될 것이다. 5G가 가능해짐으로써, AI, 빅데이터, IoT, 자율주행 등 다양한 신사업 기술들이 발전해나갈 것으로 보이는데, 이때 모든 영역에 필요한 제품이 바로 '반도체'다. 따라서 현재 전세계 비메모리 시장에서는 각 분야에서 선도하기 위해 무한 경쟁에 돌입했으며 아낌없이 천문학적인 금액을 투자하고 있는 것이다. 작년 메모리 반도체가 불황이었지만, 비메모리 반도체 (특히 파운드리)가 호황이었던 이유"
BACKEND,네트워크,Intel은 그럼 놀고 있나?에 대해 설명해 주세요,"시장 점유율에 있어서 AMD가 많이 따라오긴 했지만, 아직도 7대3정도의 상황이다. 마찬가지로 Intel의 주가도 똑같이 미친듯이 상승하고 있다. ( 2015년 30달러 → 2020년 59.60달러 ) 현재 AMD에서 따라오고 있는 컴퓨터에 들어가는 CPU 말고, 서버 시장 CPU는 Intel이 압도적인 점유율을 보여주고 있다. (Intel이 2018년만 해도 시장 점유율 약 99%로 압도적인 유지를 기록) AMD도 서버에서 따라가려고 노력하고는 있다. 하지만 2019년 현재 시장점유율은 Intel이 약 96%, AMD가 약 3%로 거의 독점 수준인 것은 다름없다. 하지만 현재가 아닌 미래를 봤을 때 Intel이 좋은 상황이 아닌 건 확실하다. 하지만 현재 Intel은 CPU 시장에 집중이 아닌 자율주행 에 관심과 거액의 투자를 진행하고 있다. Intel, 2017년 17조원에 자율주행 기업 '모빌아이' 인수 현재 Intel의 주목 8가지 산업 : 스마트시티, 금융서비스, 인더스트리얼, 게이밍, 교통, 홈/리테일, 로봇, 드론 이는 즉, 선도를 유지하고 있는 CPU 시장과 함께 자율주행을 포함한 미래산업 또한 이끌어가겠다는 Intel의 목표를 볼 수 있다. 심지어 Intel은 2019년 삼성전자를 넘어 반도체 시장 1위를 재탈환했다. (삼성전자 2위, TSMC 3위, 하이닉스 4위) 매출에 변동이 없던 Intel과 TSMC에 달리, 메모리 중심이었던 삼성전자와 하이닉스는 약 30%의 이익 감소가 발생했다. 이처럼 수많은 기업들간 경쟁 속에서 각자 성장과 발전을 위해 꾸준한 투자가 지속되고 있다. 그리고 그 중심에는 '반도체'가 있는 상황이다. 리사 수 CEO 인터뷰 ""앞으로 반도체는 10년 간 유례없는 호황기가 지속될 것으로 본다. AI, IoT 등 혁신의 중심에 반도체가 핵심 역할을 할 것이다."" 과연 정말로 IT버블의 시대가 올 것인지, 비메모리 반도체를 중심으로 세계 시장의 변화가 어떻게 이루어질 것인지 귀추가 주목되고 있다."
BACKEND,운영체제,useState에 대해 설명해 주세요,"기본적인 Hook으로 상태관리를 해야할 때 사용하면 된다. 상태를 변경할 때는, set 으로 준 이름의 함수를 호출한다. jsx const [posts, setPosts] = useState([]); // 비구조화 할당 문법 useState([]); 와 같이 ( ) 안에 초기화를 설정해줄 수 있다. 현재 예제는 빈 배열을 만들어 둔 상황인 것이다."
BACKEND,운영체제,useEffect에 대해 설명해 주세요,"컴포넌트가 렌더링 될 때마다 특정 작업을 수행하도록 설정할 수 있는 Hook '클래스' 컴포넌트의 componentDidMount()와 componentDidUpdate()의 역할을 동시에 한다고 봐도 된다. jsx useEffect(() = { console.log(""렌더링 완료""); console.log(posts); }); posts가 변경돼 리렌더링이 되면, useEffect가 실행된다."
AI,데이터,ORM(Object Relational Mapping)에 대해 설명해 주세요,"ORM 프레임워크는 JAVA 객체와 관계형 DB를 매핑한다. 즉, 객체가 DB 테이블이 되도록 만들어주는 것이다. ORM을 사용하면, SQL을 작성하지 않아도 직관적인 메소드로 데이터를 조작할 수 있다는 장점이 있다. ( 개발자에게 생산성을 향상시켜줄 수 있음 ) 종류로는 Hibernate, EclipseLink, DataNucleus 등이 있다. JPA는 애플리케이션과 JDBC 사이에서 동작하며, 개발자가 JPA를 활용했을 때 JDBC API를 통해 SQL을 호출하여 데이터베이스와 호출하는 전개가 이루어진다. 즉, 개발자는 JPA의 활용법만 익히면 DB 쿼리 구현없이 데이터베이스를 관리할 수 있다."
AI,통계,제약사항에 대해 설명해 주세요,"JPA는 복잡한 쿼리보다는 실시간 쿼리에 최적화되어있다. 예를 들어 통계 처리와 같은 복잡한 작업이 필요한 경우에는 기존의 Mybatis와 같은 Mapper 방식이 더 효율적일 수 있다. Spring에서는 JPA와 Mybatis를 같이 사용할 수 있기 때문에, 상황에 맞는 방식을 택하여 개발하면 된다."
BACKEND,네트워크,Dispatcher Servlet에 대해 설명해 주세요,"모든 request를 처리하는 중심 컨트롤러라고 생각하면 된다. 서블릿 컨테이너에서 http 프로토콜을 통해 들어오는 모든 request에 대해 제일 앞단에서 중앙집중식으로 처리해주는 핵심적인 역할을 한다. 기존에는 web.xml에 모두 등록해줘야 했지만, 디스패처 서블릿이 모든 request를 핸들링하면서 작업을 편리하게 할 수 있다."
BACKEND,네트워크,Handler Mapping에 대해 설명해 주세요,"클라이언트의 request url을 어떤 컨트롤러가 처리해야 할 지 찾아서 Dispatcher Servlet에게 전달해주는 역할을 담당한다. 컨트롤러 상에서 url을 매핑시키기 위해 @RequestMapping 을 사용하는데, 핸들러가 이를 찾아주는 역할을 한다."
BACKEND,네트워크,테스트 코드를 작성해야 하는 이유에 대해 설명해 주세요,"  개발단계 초기에 문제를 발견할 수 있음 나중에 코드를 리팩토링하거나 라이브러리 업그레이드 시 기존 기능이 잘 작동하는 지 확인 가능함 기능에 대한 불확실성 감소 개발 코드 이외에 테스트 코드를 작성하는 일은 개발 시간이 늘어날 것이라고 생각할 수 있다. 하지만 내 코드에 오류가 있는 지 검증할 때, 테스트 코드를 작성하지 않고 진행한다면 더 시간 소모가 클 것이다. 1. 코드를 작성한 뒤 프로그램을 실행하여 서버를 킨다. 2. API 프로그램(ex. Postman)으로 HTTP 요청 후 결과를 Print로 찍어서 확인한다. 3. 결과가 예상과 다르면, 다시 프로그램을 종료한 뒤 코드를 수정하고 반복한다. 위와 같은 방식이 얼마나 반복될 지 모른다. 그리고 하나의 기능마다 저렇게 테스트를 하면 서버를 키고 끄는 작업 또한 너무 비효율적이다. 이 밖에도 Print로 눈으로 검증하는 것도 어느정도 선에서 한계가 있다. 테스트 코드는 자동으로 검증을 해주기 때문에 성공한다면 수동으로 검증할 필요 자체가 없어진다. 새로운 기능이 추가되었을 때도 테스트 코드를 통해 만약 기존의 코드에 영향이 갔다면 어떤 부분을 수정해야 하는 지 알 수 있는 장점도 존재한다. 따라서 테스트 코드는 개발하는 데 있어서 필수적인 부분이며 반드시 활용해야 한다."
공통,JAVA,테스트 코드 예제에 대해 설명해 주세요,"java import org.junit.Test; import org.junit.runner.RunWith; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTest; import org.springframework.test.context.junit4.SpringRunner; import org.springframework.test.web.servlet.MockMvc; import static org.springframework.test.web.servlet.result.MockMvcResultMatchers. ; import static org.springframework.test.web.servlet.request.MockMvcRequestBuilders. ; @RunWith(SpringRunner.class) @WebMvcTest(controllers = HomeController.class) public class HomeControllerTest { @Autowired private MockMvc mvc; @Test public void home return() throws Exception { //when String home = ""home""; //then mvc.perform(get(""/home"")) .andExpect(status().isOk()) .andExpect(content().string(home)); } } 1) @RunWith(SpringRunner.class) 테스트를 진행할 때 JUnit에 내장된 실행자 외에 다른 실행자를 실행시킨다. 스프링 부트 테스트와 JUnit 사이의 연결자 역할을 한다고 생각하면 된다. 2) @WebMvcTest 컨트롤러만 사용할 때 선언이 가능하며, Spring MVC에 집중할 수 있는 어노테이션이다. 3) @Autowired 스프링이 관리하는 Bean을 주입시켜준다. 4) MockMvc 웹 API를 테스트할 때 사용하며, 이를 통해 HTTP GET, POST, DELETE 등에 대한 API 테스트가 가능하다. 5) mvc.perform(get(""/home"")) /home 주소로 HTTP GET 요청을 한 상황이다. 6) .andExpect(status().isOk()) 결과를 검증하는 andExpect 로, 여러개를 붙여서 사용이 가능하다. status() 는 HTTP Header를 검증하는 것으로 결과에 대한 HTTP Status 상태를 확인할 수 있다. 현재 isOK() 는 200 코드가 맞는지 확인하고 있다. 프로젝트를 만들면서 다양한 기능들을 구현하게 되는데, 이처럼 테스트 코드로 견고한 프로젝트를 만들기 위한 기능별 단위 테스트를 진행하는 습관을 길러야 한다."
AI,데이터,"Spring Boot Project에 대해 설명해 주세요
","먼저, 스프링 부트 프로젝트를 만든다. (우리는 스프링 부트 프로젝트 안에 Vue 프로젝트를 넣을 것이다) 프로젝트는 을 이용할 것이다. 스프링 부트 프로젝트를 매우 쉽고 간편하게 만들어주는 곳이다. 자신이 만들 프로젝트 목적에 맞게 설정해주면 된다. Dependencies도 미리 추가해놓을 수 있다. (Web, JDBC, Lombok, MySQL 등) 나중에 따로 추가할 수 있으니 기억나는 것들만 지정해도 무방하다. 프로젝트 Metadata 부분은 생성할 프로젝트 패키지나 이름 등 옵션을 지정해줄 수 있다. 처음에는 demo로 되어있는데 자신이 만들고 싶은대로 수정할 수 있다. 마지막으로 'Generate the project' 버튼을 클릭하면, zip 파일로 프로젝트가 다운로드 된다. 해당 파일을 압축 해제하고 현재 VS Code에서 접속 중인 폴더에 복사하면 된다."
BACKEND,네트워크,Vue.js Project에 대해 설명해 주세요,"이제 스프링 부트에서 Vue.js 프로젝트를 만들어보자. 프로젝트 생성은 Vue CLI를 이용할 것이다. Vue CLI는 Vue.js 개발을 위한 시스템으로, Vue.js Core에서 공식적으로 제공하는 CLI다. 개발에 집중할 수 있도록 프로젝트 구성을 빠르고 쉽게 도와주는 역할을 하고 있다. (따라서 반드시 이용해야 한다는 건 아니다. 다만 쉽게 구축할 수 있도록 만들어준거니 이용하면 편하다) 현재는 Vue CLI 버전 3가 나온 상태다. 2보다 더욱 편하고 많은 기능들을 제공한다고 하지만, 많은 정보가 없어서 일단 2로 진행하고자 한다. Node.js를 설치한 상태기 때문에, npm을 통해 터미널에서 Vue CLI 설치가 가능하다. VS Code에서 터미널을 열고, 아래와 같이 설치를 진행하자 $ npm i  g @vue/cli $ npm i  g @vue/cli init @vue/cli init은 2버전 템플릿을 가져오기 위한 vue init을 제공해준다. 이제 필요한 설치는 끝났다! Vue 프로젝트를 만들어보자. 이름은 그냥 frontend로 생성했다. (현재 프로젝트 생성은, 스프링 부트 루트 폴더 위치에서 진행하는 것이다.) $ vue init webpack frontend 몇가지 설정하는 부분이 나온다. Project name Project description Author 이 3가지는 자신의 프로젝트에 맞게 작성해주면 된다. Vue build는 standalone vue router는 설치(Yes) Use ESLint to lint your code도 Yes ESLint preset은 Standard 그 이후 test부분은 진행할 사람들은 Yes, 안할사람은 No로 넘어가면 된다. 터미널 창에서 열심히 파일들이 다운로드되는 모습을 볼 수 있다. (시간 조금 걸림) 끝나면 스프링부트 루트 폴더에 'frontend'라는 Vue 프로젝트 폴더가 생성된 모습을 확인할 수 있다."
AI,데이터,Webpack 번들링 output 설정에 대해 설명해 주세요,"Vue에서 작성한 코드들을 번들링하고, 이 결과를 어느 위치에서 뽑아낼 지 정해야 한다. Spring Boot에서는 자동설정으로 src/main/resources에 번들링한 결과들을 저장하도록 되어있다. (이곳에 index.html과 정적 파일(css, img, javascript)들이 인식됨) 이 구역에 잘 번들링 될 수 있도록, Vue 프로젝트에서 경로 지정을 해주자. config/index.js을 열어 build 부분에 정의한 곳을 수정해야 한다. 해당 위치에 절대 경로로 위와 같이 수정해준다. 이제 터미널에서 'npm run build' 커맨드를 입력하여 빌드를 실행한다. 이제 스프링 부트 애플리케이션을 실행해보자 .vscode 폴더의 launch.json에 들어가서 F5키를 누르면 스프링 부트 서버가 실행된다. ??? 에러가 뜰 것이다. APPLICATION FAILED TO START Description: Failed to configure a DataSource: 'url' attribute is not specified and no embedded datasource could be configured. Reason: Failed to determine a suitable driver class datasource 내용이 없어서 뜬 에러다. 스프링부트에서 프로젝트를 생성할 때, application.properties 파일이 자동생성되나 확인해보면 빈 파일일 것이다. 사용자가 원하는 데이터베이스를 선택하고, 그에 맞는 드라이버 라이브러리 설치와 jdbc 설정을 직접 해야한다. 이 공간이 비어있기 때문에 서버가 실행을 하고 있지 못하는 것이다. 현재는 어떤 데이터베이스를 지정할 지 결정이 되있는 상태가 아니기 때문에 스프링 부트의 메인 클래스에서 어노테이션을 추가해주자 import org.springframework.boot.autoconfigure.EnableAutoConfiguration; import org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration; @EnableAutoConfiguration(exclude={DataSourceAutoConfiguration.class}) 이를 추가한 메인 클래스는 아래와 같이 된다. java package com.example.mvc; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.boot.autoconfigure.EnableAutoConfiguration; import org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration; @SpringBootApplication @EnableAutoConfiguration(exclude={DataSourceAutoConfiguration.class}) public class MvcApplication { public static void main(String[] args) { SpringApplication.run(MvcApplication.class, args); } } 이제 다시 스프링 부트 메인 애플리케이션을 실행하면, 디버깅 창에서 에러가 없어진 걸 확인할 수 있다. 이제 localhost:8080/으로 접속하면, Vue에서 만든 화면이 잘 나오는 것을 확인할 수 있다. Vue.js에서 View에 필요한 템플릿을 구성하고, 스프링 부트에 번들링하는 과정을 통해 연동하는 과정을 완료했다!"
AI,데이터,로그인 구현에 대해 설명해 주세요,"src/components에 Login.vue를 만들자 vue template div class=""login"" h3 Login /h3 input type=""text"" placeholder=""email"" input type=""password"" placeholder=""password"" button 로그인 /button p 만약 계정이 없다면, 회원가입을 먼저 진행해주세요! /p /div /template script export default { name: 'login', data() { return { } }, methods: {} } /script style scoped .login { margin top: 40px; } input { margin: 10px 0; width: 20%; padding: 15px; } button { margin top: 20px; width: 10%; cursor: pointer; } p { margin top: 40px; font size: 15px; } p a { text decoration: underline; cursor: pointer; } /style 이제 로그인을 router/index.js에 라우터를 추가해주자. javascript import Vue from 'vue' import Router from 'vue router' import HelloWorld from '@/components/HelloWorld' import Login from '@/components/Login' Vue.use(Router) export default new Router({ mode: 'history', routes: [ { path: '/', name: 'HelloWorld', component: HelloWorld }, { path: '/login', name: 'Login', component: Login } ] }) url 중간에 "" ""을 지우기 위해서는 라우터에서 mode: 'history'를 위와 같이 추가해주면 된다. 이제 로 접속하면 아래와 같은 로그인 화면이 나온다."
AI,데이터,src/components/SignUp.vue에 대해 설명해 주세요,"vue template div class=""sign up"" p 회원가입 /p input type=""text"" placeholder=""email"" input type=""password"" placeholder=""password"" button 가입하기 /button span 또는 로그인으로 돌아가기 /span /div /template script export default { name: 'signUp', data() { return { } }, methods: {} } /script style scoped .signUp { margin top: 40px; } input { margin: 10px 0; width: 20%; padding: 15px; } button { margin top: 20px; width: 10%; cursor: pointer; } p { margin top: 40px; font size: 20px; } span { display: block; margin top: 20px; font size: 15px; } /style"
공통,JAVA,router/index.js에 대해 설명해 주세요,"javascript import Vue from 'vue' import Router from 'vue router' import HelloWorld from '@/components/HelloWorld' import Login from '@/components/Login' import SignUp from '@/components/SignUp' Vue.use(Router) export default new Router({ mode: 'history', routes: [ { path: '/', name: 'HelloWorld', component: HelloWorld }, { path: '/login', name: 'Login', component: Login }, { path: '/signup', name: 'SignUp', component: SignUp } ] }) 이제 경로로 들어가면 아래와 같이 회원가입 창이 잘 나오는 것을 확인할 수 있다."
AI,데이터,Login.vue에 대해 설명해 주세요,"vue template div class=""login"" h3 Login /h3 input type=""text"" placeholder=""email"" input type=""password"" placeholder=""password"" button 로그인 /button p 만약 계정이 없다면, router link to=""/signup"" 회원가입 /router link 을 먼저 진행해주세요! /p /div /template / vue template div class=""login"" h3 Login /h3 input type=""email"" placeholder=""email"" input type=""password"" placeholder=""password"" button v on:click=""login"" 로그인 /button p 만약 계정이 없다면, router link to=""/signup"" 회원가입 /router link 을 먼저 진행해주세요! /p /div /template script export default { name: 'login', data() { return { } }, methods: { login() { this.$router.replace('hello') } } } /script style scoped ... /style 로그인 button에 v on:click 을 통해 버튼을 눌렀을 때 login() 메소드가 실행되도록 해둔 상태다. methods에서 구현한 login 메소드가 실행되며, hello라는 경로를 가진 페이지로 이동하는 메소드다. 현재 hello라는 경로가 없기 때문에, 기존의 root 경로를 hello로 변경해주자 javascript import Vue from 'vue' import Router from 'vue router' import HelloWorld from '@/components/HelloWorld' import Login from '@/components/Login' import SignUp from '@/components/SignUp' Vue.use(Router) export default new Router({ mode: 'history', routes: [ { path: '/hello', name: 'HelloWorld', component: HelloWorld }, { path: '/login', name: 'Login', component: Login }, { path: '/signup', name: 'SignUp', component: SignUp } ] }) root 경로의 path를 / 에서 /hello 로 변경했다. 이제 로그인 창에서 이메일과 패스워드를 입력 후 로그인을 누르면 HelloWorld.vue로 이동하는 것을 확인할 수 있을 것이다."
AI,데이터,프로젝트 추가에 대해 설명해 주세요,"이제 파이어베이스 프로젝트 생성이 완료되었다. 해당 프로젝트에 들어가면 코드 스니펫 모양이 있는데, 웹 앱을 추가하는 곳이다. 클릭해서 웹 앱에 파이어베이스를 추가하자 javascript var firebaseConfig = { apiKey: ""개인 API KEY"", authDomain: ""개인 프로젝트 ID.firebaseapp.com"", databaseURL: "" projectId: ""vue firebase tutorial da26f"", storageBucket: """", messagingSenderId: ""173286603007"", appId: ""1:173286603007:web:2258c081f9102650"" }; // Initialize Firebase firebase.initializeApp(firebaseConfig); 코드 중에서 이 부분만 가져와서 활용할 것이다. 적용시키기 전에 터미널에서 firebase를 설치하자 $ npm install save firebase 설치가 끝나면, main.js 파일에다 Firebase를 아래와 같이 적용시키자 javascript import Vue from 'vue' import App from './App' import router from './router' import firebase from 'firebase' Vue.config.productionTip = false var firebaseConfig = { apiKey: ""개인 API KEY"", authDomain: ""개인 프로젝트 ID.firebaseapp.com"", databaseURL: "" projectId: ""vue firebase tutorial da26f"", storageBucket: """", messagingSenderId: ""173286603007"", appId: ""1:173286603007:web:2258c081f9102650"" }; // Initialize Firebase firebase.initializeApp(firebaseConfig); / eslint disable no new / new Vue({ el: ' app', router, render: h = h(App) })"
AI,데이터,회원가입 컴포넌트에서 파이어베이스 사용자 생성하기에 대해 설명해 주세요,"이제 회원가입을 통해 가입한 사용자 데이터를 파이어베이스에게 전송해줘야 한다. 회원가입 시 필요한 email과 password를 받아서 전송해야 하는데, 양방향 데이터 바인딩을 지원하는 v model을 활용 하자 vue input type=""text"" v model=""email"" placeholder=""email"" input type=""password"" v model=""password"" placeholder=""password"" button v on:click=""signUp"" 가입하기 /button 이처럼 회원가입의 template에서 v model과 메소드를 실행할 v on을 추가한다."
AI,데이터,signUp() 메소드 구현에 대해 설명해 주세요,"vue script import firebase from 'firebase' export default { name: 'signUp', data() { return { email: '', password: '' } }, methods: { signUp() { firebase.auth().createUserWithEmailAndPassword(this.email, this.password).then( function(user) { alert('회원가입 완료!') }, function(err) { alert('에러 : ' + err.message) } ); } } } /script createUserWithEmailAndPassword 메소드는 onResolve, onReject 콜백과 파이어베이스의 프로미스를 반환해준다."
BACKEND,네트워크,"파이어베이스 로그인 공급자 활성화시키기에 대해 설명해 주세요
","다시 파이어베이스 콘솔로 돌아가자 왼쪽 사이드바를 열고, DEVELOP의 Authentication으로 들어간다. 회원가입 view로 가서 이메일과 비밀번호를 입력하고 가입해보자"
AI,데이터,사용자 로그인에 대해 설명해 주세요,"회원가입 시 진행했던 것처럼 v model 설정과 로그인 버튼 클릭 시 진행되는 메소드를 파이어베이스의 signInWithEmailAndPassword로 수정하자 vue template div class=""login"" h3 Login /h3 input type=""text"" v model=""email"" placeholder=""email"" input type=""password"" v model=""password"" placeholder=""password"" button v on:click=""login"" 로그인 /button p 만약 계정이 없다면, router link to=""/signup"" 회원가입 /router link 을 먼저 진행해주세요! /p /div /template script import firebase from 'firebase' export default { name: 'login', data() { return { email: '', password: '' } }, methods: { login() { firebase.auth().signInWithEmailAndPassword(this.email, this.password).then( function(user) { alert('로그인 완료!') }, function(err) { alert('에러 : ' + err.message) } ); } } } /script 이제 다 끝났다. 로그인을 진행해보자! 우선 비밀번호를 제대로 입력하지 않고 로그인해본다 다시 제대로 비밀번호를 치면?! 이제 로그인이 되었을 때 보여줘야 하는 화면으로 이동을 하거나 로그인한 사람이 관리자면 따로 페이지를 구성하거나를 구현하고 싶은 계획에 따라 만들어가면 된다."
AI,데이터,페이스북 로그인 연동 script에 대해 설명해 주세요,"vue script import firebase from 'firebase' var provider = new firebase.auth.FacebookAuthProvider() provider.addScope('public profile') provider.setCustomParameters({ 'display': 'popup' }) export default { name: 'login', data() { return { email: '', password: '' } }, methods: { login() { ... }, facebookLogin() { firebase.auth().signInWithPopup(provider).then((result) = { var token = result.credential.accessToken var user = result.user console.log(""token : "" + token) console.log(""user : "" + user) this.$router.replace('welcome') }).catch((err) = { alert('에러 : ' + err.message) }) } } } /script 파이어베이스에서 facebookauth를 불러오고, provider 변수로 작업한다. setCustomParameters의 display를 popup으로 줘서, 버튼을 클릭했을 때 팝업창으로 페이스북 로그인이 진행되도록 한 것이다. 버튼에 작성한 facebookLogin 메소드를 firebase.auth().signInWithPopup로 가져와서 페이스북 로그인을 진행할 수 있다."
AI,데이터,Login.vue의 전체 소스코드에 대해 설명해 주세요,"vue template div class=""login"" h3 로그인 /h3 input type=""text"" v model=""email"" placeholder=""email"" input type=""password"" v model=""password"" placeholder=""password"" button v on:click=""login"" 로그인 /button p 또는 페이스북 로그인 button class=""social button"" v on:click=""facebookLogin"" /button /p p 만약 계정이 없다면, router link to=""/signup"" 회원가입 /router link 을 먼저 진행해주세요! /p /div /template script import firebase from 'firebase' var provider = new firebase.auth.FacebookAuthProvider() provider.addScope('public profile') provider.setCustomParameters({ 'display': 'popup' }) export default { name: 'login', data() { return { email: '', password: '' } }, methods: { login() { firebase.auth().signInWithEmailAndPassword(this.email, this.password).then( (user) = { this.$router.replace('welcome') }, (err) = { alert('에러 : ' + err.message) } ); }, facebookLogin() { firebase.auth().signInWithPopup(provider).then((result) = { var token = result.credential.accessToken var user = result.user console.log(""token : "" + token) console.log(""user : "" + user) this.$router.replace('welcome') }).catch((err) = { alert('에러 : ' + err.message) }) } } } /script style scoped .login { margin top: 40px; } input { margin: 10px 0; width: 20%; padding: 15px; } button { margin top: 20px; width: 10%; cursor: pointer; } p { margin top: 40px; font size: 15px; } p a { text decoration: underline; cursor: pointer; } .social button { width: 75px; background: white; padding: 10px; border radius: 100%; box shadow: 0 2px 4px 0 rgba(0, 0, 0, 0.2); outline: 0; border: 0; } .social button:active { box shadow: 0 2px 4px 0 rgba(0, 0, 0, 0.1); } .social button img { width: 100%; } /style style을 통해 페이스북 로그인 화면도 꾸민 상태다. 이제 서버를 실행하고 로그인 화면을 보자 페이스북 로고 사진을 누르면? 마지막으로 파이어베이스에 사용자 정보가 저장된 데이터를 확인해보자 페이스북으로 로그인한 사람의 정보도 저장되어있는 모습을 확인할 수 있다. 페이스북으로 로그인한 사람의 이메일이 등록되면 로컬에서 해당 이메일로 회원가입이 불가능하다. 위처럼 간단하게 웹페이지에서 페이스북 로그인 연동을 구현시킬 수 있고, 다른 소셜 네트워크 서비스들도 유사한 방법으로 가능하다."
공통,JAVA,"객체지향, 절차지향, 함수형 프로그래밍 차이점에 대해 설명하세요.",JAVA의 함수형 프로그래밍 예시를 설명하세요.
공통,JAVA,Primitive Type과 Reference Type의 차이점에 대해 설명하세요.,Wrapper Class에 대해 설명하세요.
공통,JAVA,Java의 Exception에 대해 설명해 주세요.,프로그래밍의 오류 종류는 무엇이 있을까요?
공통,JAVA,Error와 Exception의 차이점에 대해 설명해주세요.,JAVA에서의 오류는 프로그램 실행 중 어떤 원인에 의해 오작동 혹은 비정상 종료되는 경우를 프로그램 오류라고 합니다.
공통,JAVA,"CheckedException, UncheckedException 의 차이에 대해 설명해 주세요.","CheckedException (컴파일 에외 클래스들) 예외 처리하지 않을 시, 컴파일되지 않기 때문에, 예외 처리가 필수입니다."
공통,JAVA,예외 처리(Exception Handling)를 하는 방법에 대해 설명해 주세요.,"try catch 문으로 감싸서 복구 및 전환하거나, Throws로 던져서 회피하여 처리할 수 있습니다."
공통,JAVA,try with resource에 대해 설명하세요.,"try with resource는 try 블록이 끝날 때, 자동으로 자원을 해제해주는 기능입니다."
공통,JAVA,"AutoCloseable, Closeable 차이점에 대해 설명하세요.","이 둘은 거의 똑같은데, Closeable은 IOException으로 범위가 더 좁습니다."
공통,JAVA,static에 대해 설명해주세요.,공유되는 변수나 메서드를 정의할 때 사용되는 키워드입니다.
공통,JAVA,static 사용을 왜 지양해야 할까요?,메모리가 낭비 됩니다.
공통,JAVA,"그렇다면, static은 어떤 시점에 사용해야 하고, 사용 시, 어떤 이점을 얻을 수 있나요?",자주 사용되는 상수를 정의할 때 사용할 수 있습니다.
공통,JAVA,static이 저장되는 위치는 어디인가요?,static으로 선언된 변수는 Class Variables 영역에 저장됩니다.
공통,JAVA,Java 8이후로 Heap의 Permanent(PermGen) 영역이 Native Memory 영역의 Metaspace로 대체된 이유는?,"결론부터 말씀드리면, OOM(OutOfMemory) 에러의 발생 가능성을 줄이기 위해서입니다."
공통,JAVA,컴파일 과정에서 static 이 어떻게 처리되는지 설명해주세요.,static 키워드가 붙은 멤버는 클래스 로딩 시점(런타임 시점)에 메모리에 할당됩니다.
공통,JAVA,main 메서드가 static인 이유를 아시나요?,프로그램 실행 순간에 메모리에 할당되어야 하고 GC의 정리 대상이 되어서는 안되기 때문입니다.
공통,JAVA,final에 대해 설명해주세요.,JAVA에서 불변성을 확보할 수 있도록 제공하는 키워드입니다.
공통,JAVA,Effective Final 키워드에 대해 아시나요?,"변수에 final 키워드를 사용하지 않아도 초기화 후 변경되지 않는 변수라면, 컴파일러가 final 변수로 인식하는 것을 말합니다."
공통,JAVA,"익명 클래스나 람다 표현식에서 외부 지역변수를 참조할 때, final 혹은 effective final이어야 하는 이유가 있나요?",멀티 스레드에서는 지역 변수를 사용하는 스레드와 람다식을 사용하는 스레드가 다를 수 있습니다.
공통,JAVA,"그렇다면, 어떻게 불변성을 보장할까요?",객체의 경우에는 생성자를 통해 값을 주입받도록 합니다.
공통,JAVA,"컴파일 과정에서, final 키워드는 다르게 취급되나요?",final 키워드가 붙은 변수는 컴파일러에 의해 한 번만 초기화될 수 있음을 표시하는 것입니다.
공통,JAVA,finally와 finalize 용어도 간단하게 설명해주세요.,"finally는 try catch 블록이 종료될 때, 실행될 코드 블록을 정의하기 위해 사용합니다."
공통,JAVA,generic에 대해 설명해주세요.,타입을 클래스 내부에서 지정하는 것이 아닌 외부에서 사용자에 의해 지정하는 기능입니다.
공통,JAVA,Java Stream에 대해 설명해 주세요.,"Java 8에 추가된 것으로 데이터를 쉽게 필터링, 변환, 집계할 수 있는 기능입니다."
공통,JAVA,스트림의 연산과 흐름에 대해 설명하세요.,중간 연산 스트림을 연결할 수 있는 연산을 말합니다.
공통,JAVA,Stream과 foreach 기능에 대해 설명해주세요.,이는 모두 순회하는 기능으로 강제 종료가 불가능합니다.
공통,JAVA,Java Lambda에 대해 설명해 주세요.,함수를 하나의 식으로 표현하는 기능을 말합니다.
공통,JAVA,일급 객체란 무엇인가요?,다른 객체들이 적용 가능한 연산을 모두 지원하는 객체를 의미합니다.
공통,JAVA,함수형 인터페이스에 대해 설명해 주세요.,함수를 일급 객체처럼 이용할 수 있도록 해주는 어노테이션입니다.
공통,JAVA,"익명 클래스나 람다 표현식에서, 주의해야할 점을 말해주세요.",final이거나 effective final인 경우에만 참조할 수 있습니다.
공통,JAVA,Reflection에 대해 설명해 주세요.,클래스의 구체적인 타입을 알지 못해도 해당 클래스에 접근할 수 있도록 해주는 JAVA API 기능입니다.
공통,JAVA,리플렉션의 장/단점에 대해 설명하세요.,"장점 런타임 시점에 클래스 인스턴스를 생성하고 접근 제어자와 관계없이, 필드와 메서드에 접근해 필요한 작업을 수행할 수 있는 유연성을 가집니다."
공통,JAVA,실제로 어디서 리플렉션이 활용되고 있을까요?,"스프링 컨테이너인 BeanFactory 빈은 애플리케이션 실행 후 런타임에 객체가 호출될 때, 동적으로 객체의 인스턴스를 생성합니다."
공통,JAVA,Dynamic Proxy에 대해 설명해 주세요.,동적으로 프록시 인스턴스를 만들어 등록하는 방법을 말합니다.
공통,JAVA,equals()와 hashcode()에 대해 설명해 주세요.,equals() Object의 equals()의 경우 객체의 참조값이 동일한 지 비교합니다.
공통,JAVA,"hashcode() 를 정의해야 한다면, 어떤 점을 염두에 두고 구현할 것 같으세요?",equals 비교에 사용되는 핵심 필드들을 이용해 hashcode()를 반환하도록 구현할 것 같습니다.
공통,JAVA,Synchronized 키워드에 대해 설명해 주세요.,"JAVA에서 제공하는 것으로 특정 코드 블록 및 메서드 영역에 하나의 스레드만 접근할 수 있도록 하여, 스레드 간에 동기화를 제공하는 기능입니다."
공통,JAVA,Thread Safe란 무엇인가요?,멀티 쓰레드 프로그래밍에서 여러 스레드로부터 동시에 접근이 이뤄져도 프로그램 실행에 문제가 없는 것을 의미합니다.
공통,JAVA,Thread Local에 대해 설명해 주세요.,스레드 영역에 변수를 설정해 특정 스레드가 실행하는 모든 코드에서 설정된 변수값을 사용할 수 있게 하는 기능입니다.
공통,JAVA,Volatile에 대해 설명해주세요.,"원자성은 보장할 수 없지만, 가시성을 보장하는 기능입니다."
공통,JAVA,가시성이란 무엇인가요?,가시성 한 쓰레드에서 공유 자원을 변경한 결과가 다른 쓰레드에서 확인할 수 있는 것을 의미합니다.
공통,JAVA,Atomic에 대해 설명해주세요.,synchronized 키워드의 성능 저하 문제를 해결하기 위해 고안된 방법입니다.
공통,JAVA,String에 대해 설명해 주세요.,String은 문자열을 저장하는 자료형으로 불변합니다.
공통,JAVA,"String, StringBuffer, StringBuilder 차이점을 설명해주세요.",String String 클래스는 Immutable Object입니다.
공통,JAVA,Immutable Object에 대해 설명해주세요.,"객체 생성 이후 내부 상태가 변하지 않는, 변경할 수 없는 객체를 의미합니다."
공통,JAVA,Immutable Object의 장점을 말해주세요.,Thread safe하여 동기화를 고려하지 않아도 됩니다.
공통,JAVA,"String a = """" 과 String a = new String("""") 의 차이점을 설명해주세요.","리터럴 방식 : String a = """" 이 방식으로 생성할 경우 Method Area 안의 Constant Pool에 저장되며, 동일한 문자열 리터럴이 여러 곳에 사용되어도 하나의 인스턴스만 존재합니다."
공통,JAVA,"Java에서 제공되는 List, Set, Map에 대해서 설명해주세요.",Array와 ArrayList 차이에 대해 설명해주세요.
공통,JAVA,ArrayList와 LinkedList의 차이에 대해 설명해주세요.,"ArrayList 중복을 허용하고 입력되는 순서를 유지하며, 배열을 사용해 원소들을 관리합니다."
공통,JAVA,LinkedList가 ArrayList 중 선택하는 기준이 있나요?,보통 삽입/삭제가 빈번하면 LinkedList를 사용하고 특정 요소 조회가 빈번하면 ArrayList를 사용한다고 말합니다.
공통,JAVA,"HashMap, HashTable, ConcurrentHashMap, LinkedHashMap, TreeMap 각 차이를 설명해주세요.",HashMap Key와 Value에 Null을 허용합니다.
공통,JAVA,fail fast 속성이란 무엇인가요?,"오류를 가능한 빨리 감지하고 오류 발생 시, 즉시 작업을 중단해 더 큰 시스템 장애로 이어지는 것을 방지하는 것을 말합니다."
공통,JAVA,HashMap과 HashTable이 내부적으로 어떻게 구현되어 있는 지와 동작 방법에 대해서 설명해주세요.,내부적으로 배열과 해시 함수를 통해 구현되어 있습니다.
공통,JAVA,"Hash Collision에 대해서 설명해주시고, 극복할 수 있는 방법에 대해서 설명해주세요.",동일한 해시 값이 나오는 경우를 해시 충돌이라고 합니다.
공통,JAVA,Java 에서 Annotation 은 어떤 기능을 하나요?,어노테이션은 JAVA 소스 코드에 메타데이터를 제공하는 방법입니다.
공통,JAVA,서블릿(Servlet)에 대해 설명하세요.,"클라이언트의 요청을 처리하고, 그 결과를 반환하는 Servlet 클래스의 구현 규칙을 지킨 JAVA 웹 프로그래밍 기술입니다."
BACKEND,네트워크,Spring 환경에서 tomcat 에 request 가 들어왔을 때 RequestMapping 에 도달하기까지 과정을 설명해주세요.,1) 톰캣이 HttpServletRequest와 HttpServletResponse 객체를 생성합니다.
BACKEND,네트워크,필터에서 사용되는 요청과 서블릿에서 사용되는 요청의 차이를 설명하세요.,필터는 ServletRequest 사용되고 서블릿은 HttpServletRequest가 사용됩니다.
공통,디자인패턴,"Spring MVC1, Spring MVC2 패턴 차이에 대해 설명해주세요.",Spring MVC1: View와 Controller를 JSP가 모두 담당하는 형태를 의미합니다.
BACKEND,네트워크,DispatcherServlet 이란?,Http 프로토콜로 들어오는 모든 클라이언트 요청을 최초로 받아 적합한 컨트롤러에 위임해주는 프론트 컨트롤러입니다.
AI,데이터,"DTO, VO, DAO, ENTITY의 각 정의를 말해주세요.",DAO Database에 접근하는 역할을 가진 객체입니다.
공통,JAVA,AspectJ 란 무엇인가요?,AspectJ는 AOP를 구현하기 위한 JAVA 프레임워크입니다.
공통,JAVA,동적 프록시(JDK Dynamic Proxy)에 대해 설명해주세요.,"이 방식은 JAVA에서 제공하는 동적 프록시 기능으로, 인터페이스를 구현하는 프록시 객체를 런타임에 동적으로 생성합니다."
AI,데이터,JDBC(Java Database Connectivity)란 무엇인가요?,JAVA와 데이터베이스를 연결하기 위한 Java 표준 인터페이스입니다.
AI,데이터,Spring JDBC에 대해 설명해주세요.,Spring JDBC는 스프링 프레임워크에서 제공하는 JDBC 기반의 데이터 액세스 기술입니다.
AI,데이터,Spring JDBC 장단점을 설명하세요.,"장점 1) Spring JDBC는 자동으로 데이터베이스 연결, SQL 쿼리, ResultSet을 관리하고 닫아주기 때문에 코드를 간소화하고 메모리 누수를 방지합니다."
AI,데이터,SQL Mapper에 대해 설명해주세요.,객체와 SQL의 필드를 매핑해 데이터를 객체화하는 기술입니다.
AI,데이터,ORM(Object Relational Mapping)이란 무엇인가요?,객체와 Database 테이블을 매핑하여 데이터를 객체화하는 기술입니다.
AI,데이터,Spring Data JPA란 무엇인가요?,Spring에서 제공하는 모듈 중 하나로 개발자가 JPA를 더 쉽고 편하게 사용할 수 있도록 도와줍니다.
AI,데이터,Spring Data JPA 장/단점을 설명하세요.,"장점 1차캐시, 쓰기지연, 변경감지, 지연로딩을 제공하여 성능상 이점을 얻을 수 있습니다."
BACKEND,운영체제,조회용 메서드에 @Transactional 어노테이션을 안 붙여도 되지 않을까요?,조회용 메서드에 대해 @Transactional 어노테이션 유무의 차이는 OSIV가 꺼져있을 때 알 수 있습니다.
공통,JAVA,JPQL(Java Persistence Query Language)이란 무엇인가요?,"JPQL은 SQL과 비슷한 문법을 가지고 있지만, JPQL은 엔티티 객체를 조회하는 객체지향 쿼리입니다."
AI,데이터,"JPQL 사용 시, 기존 영속성 컨텍스트의 데이터가 갱신될까요?","JPQL 호출 시, flush가 발생하기 때문에 갱신됩니다."
AI,데이터,영속성 컨텍스트란 무엇인가요?,Server와 Database 사이에 엔티티를 저장하는 논리적인 영역이라고 할 수 있습니다.
BACKEND,운영체제,OSIV(Open Session In View)에 대해 설명해주세요.,View Layer에서도 Entity의 지연 로딩이 가능합니다.
AI,데이터,플러시란 무엇인가요?,플러시는 영속성 컨텍스트의 내용을 데이터베이스에 반영하는 것을 말합니다.
BACKEND,네트워크,좋은 네트워크란 어떤 네트워크인가요?,"많은 처리량, 짧은 지연시간, 낮은 장애 빈도, 좋은 보안 등을 갖춘 네트워크가 좋은 네트워크라 생각합니다."
BACKEND,네트워크,처리량이란?,성공적으로 전달되는 데이터의 양을 말하는 것으로 보통 트래픽 처리량을 뜻합니다.
BACKEND,네트워크,트래픽과 처리량의 차이는?,트래픽이 많아졌다는 것 = 흐르는 데이터가 많아졌다는 것 처리량이 많아졌다는 것 = 처리되는 트래픽이 많아졌다는 것
BACKEND,네트워크,대역폭이란?,주어진 시간동안 네트워크 연결을 통해 흐를 수 있는 최대 비트 수를 말합니다.
BACKEND,네트워크,RTT(Round Trip Time; 왕복 지연 시간)란?,신호를 전송하고 해당 신호의 수신 확인에 걸린 시간을 더한 값입니다.
BACKEND,네트워크,병목 현상이란 무엇인가요?,일반적으로 전체 시스템의 성능이나 용량이 하나의 구성요소로 인해 제한을 받는 현상을 말합니다.
BACKEND,네트워크,네트워크 성능 분석 명령어에 대해 아시는 게 있나요?,"ping 네트워크 상태를 확인하려는 대상 노드를 향해 일정 크기의 패킷을 전송하는 명령어 이를 통해 해당 노드의 패킷 수신 상태와 도달하기까지 시간, 네트워크 연결 상태 등을 확인할 수 있다."
BACKEND,네트워크,"유니캐스트, 멀티캐스트, 브로드캐스트에 대해 설명해주세요.",유니캐스트 1 : 1 통신이다.
BACKEND,네트워크,"LAN, MAN, WAN에 대해 설명해주세요.","LAN MAN, WAN보다 높은 안정성, 전송 속도를 가진다."
BACKEND,네트워크,OSI 7계층에 대해 설명해 주세요.,네트워크 통신이 일어나는 과정을 7단계로 나눈 네트워크 표준 모델입니다.
BACKEND,네트워크,TCP/IP 4계층에 대해 설명해주세요.,OSI 7 계층 모델은 실무적으로 이용하기에 다소 복잡하여 TCP/IP 프로토콜 통신 과정에 초점을 맞추어 더 단순화한 계층이다.
BACKEND,운영체제,운영체제란?,사용자에게 편리한 인터페이스 환경을 제공하고 컴퓨터 시스템의 자원을 효율적으로 관리하는 일종의 소프트웨어입니다.
BACKEND,운영체제,운영체제의 역할이 무엇인가요?,자원 관리 : 효율성 여러 응용 프로그램이 자원을 요청하면 적절한 순서로 배분하고 회수하여 자원을 효율적으로 관리합니다.
BACKEND,운영체제,운영체제 종류는 무엇이 있을까요?,"운영체제는 앞단에 어떤 인터페이스를 두냐에 따라 GUI, CUI로 나뉠 수 있습니다."
BACKEND,운영체제,커널이란 무엇인가요?,운영체제의 핵심 부분이자 시스템 콜 인터페이스를 제공합니다.
BACKEND,운영체제,운영체제와 커널의 차이점은 무엇인가요?,운영체제는 시스템 전체를 관리하고 사용자와 응용 프로그램에 다양한 서비스를 제공합니다.
BACKEND,운영체제,커널 함수란?,커널 내부에 있는 여러 함수들을 뜻하는 것으로 네이티브 함수를 말합니다.
BACKEND,운영체제,커널 유형은 무엇이 있을까요?,단일형 구조 커널(모놀리식) 초창기 OS 구조로 기능들이 단일의 모듈로 구성되어 있습니다.
BACKEND,운영체제,시스템 호출(System Call)이 무엇인지 설명해 주세요.,시스템 콜은 OS가 커널에 접근하기 위한 인터페이스로 소프트웨어 인터럽트인 Trap의 한 종류입니다.
BACKEND,운영체제,시스템 콜의 장점은 ?,"유저 프로그램이 복잡한 파일 시스템, 프로세스 관리 등의 내부 동작을 몰라도 됩니다."
BACKEND,운영체제,운영체제의 Dual Mode에 대해 설명해 주세요.,운영체제를 보호하기 위한 기법입니다.
BACKEND,운영체제,왜 유저모드와 커널모드를 구분해는 이유가 무엇일까요?,시스템을 보호하기 위해 구분합니다.
BACKEND,운영체제,서로 다른 시스템 콜을 어떻게 구분할 수 있을까요?,"커널은 내부적으로 각각의 시스템 콜을 구분하기 위해 고유한 이름, 매개변수, 시스템 콜 번호, 시스템 콜 번호에 해당하는 서비스 루틴 등을 가집니다."
BACKEND,운영체제,우리가 사용하는 Java에서 시스템 콜을 어떻게 사용하는지 자유롭게 설명해주세요.,Java는 시스템 콜을 사용하기 위해 JNI를 통하여 네이티브 메서드를 활용하는 것으로 알고 있습니다.
BACKEND,운영체제,인터럽트가 무엇인지 설명해 주세요.,즉각적인 주의가 필요한 이벤트를 나타내는 외부 장치 혹은 SW 내부에서 CPU로 전송하는 신호를 말합니다.
BACKEND,운영체제,트랩(Trap)이란?,"트랩은 SW 인터럽트(=내부 인터럽트, 동기적 인터럽트)를 말합니다."
BACKEND,운영체제,인터럽트 핸들러 함수(ISR; Interrupt Service Routine)란?,"인터럽트 발생 시, 이를 핸들링하기 위함 함수를 말합니다."
BACKEND,운영체제,Polling 방식에 대해 설명해 주세요.,폴링은 특정 주기를 갖고 해당 주기마다 처리를 위한 시그널이 들어왔는지 체크합니다.
BACKEND,운영체제,HW/SW 인터럽트 혹은 외부/내부 혹은 비동기적/동기적 인터럽트에 대해 설명해 주세요.,인터럽트에는 HW 인터럽트와 SW 인터럽트가 있고 SW 인터럽트는 비자발적인 예외와 자발적인 System Call로 나뉩니다.
BACKEND,운영체제,"동시에 두 개 이상의 인터럽트가 발생하면, 어떻게 처리해야 하나요?",운영체제에서 사용되는 인터럽트 처리 메커니즘에 따라 정확한 동작이 달라질 수 있지만 주로 아래와 같은 동작으로 처리합니다.
BACKEND,운영체제,HW 인터럽트와 SW 인터럽트 중 어떤 것이 우선순위가 높나요?,보통 HW 인터럽트가 높은 것으로 알고 있습니다.
공통,자료구조,PCB(Process Control Block)가 무엇인가요?,CPU가 프로세스를 실행할 때 필요한 중요 정보들을 보관하는 자료구조입니다.
AI,데이터,전역 변수 중 초기화 하지 않은 변수들은 어디에 저장될까요?,컴파일 시점에 데이터 영역의 BSS(Block Started by Symbol) 영역에 저장됩니다.
AI,데이터,Stack과 Heap의 크기는 정해져 있나요?,클래스 등과 같은 참조형 데이터들은 Stack이 아닌 Heap에서 관리됩니다.
공통,C,스택과 힙 영역을 개발자가 아닌 사용자가 크기를 수정할 수 있나요?,스택과 힙 영역의 크기는 런타임에 결정됩니다.
공통,C,"""스택""영역과 ""힙""영역은 정말 자료구조의 스택/힙과 연관이 있을까요?",결론부터 말씀드리면 관련이 있다고 생각합니다.
AI,데이터,다음과 같이 공간을 분할하는 이유가 있을까요?,결론 : 각 역할을 분배하고 필요에 따라 데이터를 공유하여 메모리 사용량을 줄이기 위함이라 생각합니다.
AI,데이터,"IPC(Inter Process Communication)가 무엇이고, 어떤 종류가 있는지 설명해 주세요.",서로 다른 프로세스가 데이터를 주고 받고 관리하는 메커니즘입니다.
