"""
Multi-Agent RAG ì‹œìŠ¤í…œ
ì˜ì•½í’ˆ ì •ë³´ ê²€ìƒ‰ì˜ ì •í™•ë„ í–¥ìƒì„ ìœ„í•œ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ êµ¬ì¡°
"""
from typing import List, Dict, Any, Optional
from abc import ABC, abstractmethod
from dataclasses import dataclass
import json
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.database import VectorDB
from src.embeddings import EmbeddingGenerator

@dataclass
class AgentResponse:
    """ì—ì´ì „íŠ¸ ì‘ë‹µ ë°ì´í„° í´ë˜ìŠ¤"""
    agent_name: str
    response: str
    confidence: float
    reasoning: str
    sources: List[str]
    metadata: Dict[str, Any]

@dataclass
class QueryContext:
    """ì¿¼ë¦¬ ì»¨í…ìŠ¤íŠ¸ ì •ë³´"""
    original_query: str
    processed_query: str
    query_type: str  # "symptom", "drug_name", "interaction", "dosage" etc.
    user_context: Dict[str, Any]  # age, conditions, etc.

class BaseAgent(ABC):
    """ê¸°ë³¸ ì—ì´ì „íŠ¸ ì¶”ìƒ í´ë˜ìŠ¤"""
    
    def __init__(self, name: str, description: str):
        self.name = name
        self.description = description
        self.db = VectorDB()
        self.embedding_generator = EmbeddingGenerator()
    
    @abstractmethod
    def can_handle(self, query_context: QueryContext) -> bool:
        """ì´ ì—ì´ì „íŠ¸ê°€ í•´ë‹¹ ì¿¼ë¦¬ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ”ì§€ íŒë‹¨"""
        pass
    
    @abstractmethod
    def process_query(self, query_context: QueryContext) -> AgentResponse:
        """ì¿¼ë¦¬ ì²˜ë¦¬ ë° ì‘ë‹µ ìƒì„±"""
        pass
    
    def get_relevant_documents(self, query: str, top_k: int = 5) -> List[tuple]:
        """ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰"""
        query_embedding = self.embedding_generator.generate_embedding(query, is_query=True)
        return self.db.similarity_search(query_embedding, limit=top_k)

class SymptomAnalysisAgent(BaseAgent):
    """ì¦ìƒ ë¶„ì„ ì „ë¬¸ ì—ì´ì „íŠ¸"""
    
    def __init__(self):
        super().__init__(
            name="SymptomAnalysisAgent",
            description="ì¦ìƒì„ ë¶„ì„í•˜ê³  ê´€ë ¨ ì˜ì•½í’ˆì„ ì¶”ì²œí•˜ëŠ” ì—ì´ì „íŠ¸"
        )
    
    def can_handle(self, query_context: QueryContext) -> bool:
        """ì¦ìƒ ê´€ë ¨ ì¿¼ë¦¬ì¸ì§€ íŒë‹¨"""
        # TODO: ì¦ìƒ í‚¤ì›Œë“œ ë¶„ì„ ë¡œì§ êµ¬í˜„
        symptom_keywords = ["ì•„íŒŒ", "í†µì¦", "ì—´", "ê¸°ì¹¨", "ì†Œí™”ë¶ˆëŸ‰", "ë‘í†µ", "ë³µí†µ"]
        return any(keyword in query_context.processed_query for keyword in symptom_keywords)
    
    def process_query(self, query_context: QueryContext) -> AgentResponse:
        """ì¦ìƒ ê¸°ë°˜ ì˜ì•½í’ˆ ì¶”ì²œ"""
        query = query_context.processed_query
        
        # ì¦ìƒë³„ í‚¤ì›Œë“œ ë§¤í•‘
        symptom_mapping = {
            "ë‘í†µ": ["ë‘í†µ", "ë¨¸ë¦¬", "ì•„íŒŒ", "í¸ë‘í†µ"],
            "ê°ê¸°": ["ê°ê¸°", "ê¸°ì¹¨", "ì½§ë¬¼", "ëª©ì•„í””", "ì¸í›„í†µ"],
            "ì†Œí™”ë¶ˆëŸ‰": ["ì†Œí™”", "ìœ„", "ì†ì“°ë¦¼", "ë³µí†µ", "ë°°ì•„í””"],
            "í•´ì—´": ["ì—´", "ë°œì—´", "ì²´ì˜¨", "í•´ì—´"],
            "ì§„í†µ": ["ì•„í””", "í†µì¦", "ì§„í†µ", "ì•„í”„"]
        }
        
        # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        relevant_docs = self.get_relevant_documents(query, top_k=5)
        
        if not relevant_docs:
            return AgentResponse(
                agent_name=self.name,
                response="í•´ë‹¹ ì¦ìƒê³¼ ê´€ë ¨ëœ ì˜ì•½í’ˆ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                confidence=0.1,
                reasoning="ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í•¨",
                sources=[],
                metadata={"query_type": "symptom_analysis"}
            )
        
        # ì¦ìƒ ë¶„ì„ ë° ì¶”ì²œ
        detected_symptoms = []
        for symptom, keywords in symptom_mapping.items():
            if any(keyword in query for keyword in keywords):
                detected_symptoms.append(symptom)
        
        # ì‘ë‹µ ìƒì„±
        if detected_symptoms:
            symptom_text = ", ".join(detected_symptoms)
            response = f"{symptom_text} ì¦ìƒì— ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ì˜ì•½í’ˆì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n\n"
        else:
            response = "ì¦ìƒ ë¶„ì„ ê²°ê³¼ ë‹¤ìŒ ì˜ì•½í’ˆë“¤ì´ ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n"
        
        # ìƒìœ„ 3ê°œ ì œí’ˆ ì •ë³´ í¬í•¨
        for i, (doc_id, content, product_name, distance) in enumerate(relevant_docs[:3], 1):
            confidence_score = 1 - distance
            response += f"{i}. {product_name} (ê´€ë ¨ë„: {confidence_score:.2f})\n"
            # ë‚´ìš© ìš”ì•½ (ì²« 100ì)
            summary = content[:100] + "..." if len(content) > 100 else content
            response += f"   {summary}\n\n"
        
        avg_confidence = sum(1 - doc[3] for doc in relevant_docs[:3]) / min(3, len(relevant_docs))
        
        return AgentResponse(
            agent_name=self.name,
            response=response.strip(),
            confidence=avg_confidence,
            reasoning=f"ì¦ìƒ í‚¤ì›Œë“œ ë¶„ì„ ë° ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ (ê²€ìƒ‰ëœ ë¬¸ì„œ: {len(relevant_docs)}ê°œ)",
            sources=[doc[2] for doc in relevant_docs[:3]],
            metadata={"query_type": "symptom_analysis", "detected_symptoms": detected_symptoms}
        )

class DrugInteractionAgent(BaseAgent):
    """ì•½ë¬¼ ìƒí˜¸ì‘ìš© ë¶„ì„ ì—ì´ì „íŠ¸"""
    
    def __init__(self):
        super().__init__(
            name="DrugInteractionAgent", 
            description="ì•½ë¬¼ ê°„ ìƒí˜¸ì‘ìš©ì„ ë¶„ì„í•˜ëŠ” ì—ì´ì „íŠ¸"
        )
    
    def can_handle(self, query_context: QueryContext) -> bool:
        """ì•½ë¬¼ ìƒí˜¸ì‘ìš© ê´€ë ¨ ì¿¼ë¦¬ì¸ì§€ íŒë‹¨"""
        # TODO: ìƒí˜¸ì‘ìš© í‚¤ì›Œë“œ ë¶„ì„ ë¡œì§ êµ¬í˜„
        interaction_keywords = ["í•¨ê»˜", "ê°™ì´", "ë³‘ìš©", "ìƒí˜¸ì‘ìš©", "ê¸ˆê¸°"]
        return any(keyword in query_context.processed_query for keyword in interaction_keywords)
    
    def process_query(self, query_context: QueryContext) -> AgentResponse:
        """ì•½ë¬¼ ìƒí˜¸ì‘ìš© ë¶„ì„"""
        query = query_context.processed_query
        
        # ì•½ë¬¼ëª… ì¶”ì¶œ ì‹œë„
        common_drugs = [
            "ì•„ìŠ¤í”¼ë¦°", "íƒ€ì´ë ˆë†€", "ê²Œë³´ë¦°", "ë‚™ì„¼", "ë¶€ë£¨íœ", "ì• ë“œë¹Œ",
            "íœì˜", "ë‚™ì„¼", "ì´ë¶€í”„ë¡œíœ", "ì•„ì„¸íŠ¸ì•„ë¯¸ë…¸íœ", "ë””í´ë¡œí˜ë‚™"
        ]
        
        mentioned_drugs = [drug for drug in common_drugs if drug in query]
        
        # ìƒí˜¸ì‘ìš© ê´€ë ¨ í‚¤ì›Œë“œ ê°•í™” ê²€ìƒ‰
        interaction_query = f"ìƒí˜¸ì‘ìš© ë³‘ìš© í•¨ê»˜ ê¸ˆê¸° {query}"
        relevant_docs = self.get_relevant_documents(interaction_query, top_k=5)
        
        if not relevant_docs:
            return AgentResponse(
                agent_name=self.name,
                response="ì•½ë¬¼ ìƒí˜¸ì‘ìš© ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                confidence=0.1,
                reasoning="ìƒí˜¸ì‘ìš© ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í•¨",
                sources=[],
                metadata={"query_type": "drug_interaction"}
            )
        
        # ìƒí˜¸ì‘ìš© ì •ë³´ ì¶”ì¶œ
        interaction_info = []
        warning_info = []
        
        for doc_id, content, product_name, distance in relevant_docs[:3]:
            confidence_score = 1 - distance
            
            sentences = content.split('.')
            for sentence in sentences:
                sentence_lower = sentence.lower()
                if any(keyword in sentence_lower for keyword in ['ìƒí˜¸ì‘ìš©', 'ë³‘ìš©', 'í•¨ê»˜', 'ë™ì‹œ']):
                    interaction_info.append({
                        'product': product_name,
                        'info': sentence.strip(),
                        'confidence': confidence_score
                    })
                elif any(keyword in sentence_lower for keyword in ['ê¸ˆê¸°', 'í”¼í•´ì•¼', 'ì£¼ì˜']):
                    warning_info.append({
                        'product': product_name,
                        'info': sentence.strip(),
                        'confidence': confidence_score
                    })
        
        # ì‘ë‹µ ìƒì„±
        response = "ì•½ë¬¼ ìƒí˜¸ì‘ìš© ë¶„ì„ ê²°ê³¼:\n\n"
        
        if mentioned_drugs:
            response += f"ğŸ” ì–¸ê¸‰ëœ ì•½ë¬¼: {', '.join(mentioned_drugs)}\n\n"
        
        if interaction_info:
            response += "ğŸ”¸ ìƒí˜¸ì‘ìš© ì •ë³´:\n"
            for info in interaction_info[:3]:  # ìµœëŒ€ 3ê°œ
                response += f"   â€¢ {info['product']}: {info['info']}\n"
            response += "\n"
        
        if warning_info:
            response += "âš ï¸ ì£¼ì˜ì‚¬í•­:\n"
            for info in warning_info[:3]:  # ìµœëŒ€ 3ê°œ
                response += f"   â€¢ {info['product']}: {info['info']}\n"
            response += "\n"
        
        if not interaction_info and not warning_info:
            response += "êµ¬ì²´ì ì¸ ìƒí˜¸ì‘ìš© ì •ë³´:\n\n"
            for i, (doc_id, content, product_name, distance) in enumerate(relevant_docs[:2], 1):
                confidence_score = 1 - distance
                summary = content[:150] + "..." if len(content) > 150 else content
                response += f"{i}. {product_name} (ê´€ë ¨ë„: {confidence_score:.2f})\n"
                response += f"   {summary}\n\n"
        
        response += "ğŸš¨ ì¤‘ìš”: ì—¬ëŸ¬ ì•½ë¬¼ì„ í•¨ê»˜ ë³µìš©í•˜ê¸° ì „ì— ë°˜ë“œì‹œ ì˜ì‚¬ë‚˜ ì•½ì‚¬ì™€ ìƒë‹´í•˜ì„¸ìš”."
        
        avg_confidence = sum(1 - doc[3] for doc in relevant_docs[:3]) / min(3, len(relevant_docs))
        
        return AgentResponse(
            agent_name=self.name,
            response=response.strip(),
            confidence=avg_confidence,
            reasoning="ìƒí˜¸ì‘ìš© í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ ë° ì•½ë¬¼ëª… ë¶„ì„",
            sources=[doc[2] for doc in relevant_docs[:3]],
            metadata={
                "query_type": "drug_interaction", 
                "mentioned_drugs": mentioned_drugs,
                "interaction_found": len(interaction_info),
                "warnings_found": len(warning_info)
            }
        )

class DosageAgent(BaseAgent):
    """ìš©ë²•/ìš©ëŸ‰ ì „ë¬¸ ì—ì´ì „íŠ¸"""
    
    def __init__(self):
        super().__init__(
            name="DosageAgent",
            description="ì•½ë¬¼ì˜ ìš©ë²•ê³¼ ìš©ëŸ‰ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ì—ì´ì „íŠ¸"
        )
    
    def can_handle(self, query_context: QueryContext) -> bool:
        """ìš©ë²•/ìš©ëŸ‰ ê´€ë ¨ ì¿¼ë¦¬ì¸ì§€ íŒë‹¨"""
        # TODO: ìš©ë²•/ìš©ëŸ‰ í‚¤ì›Œë“œ ë¶„ì„ ë¡œì§ êµ¬í˜„
        dosage_keywords = ["ìš©ë²•", "ìš©ëŸ‰", "ë³µìš©ë²•", "ë¨¹ëŠ”ë²•", "í•˜ë£¨", "ëª‡ë²ˆ", "ì–¼ë§ˆë‚˜"]
        return any(keyword in query_context.processed_query for keyword in dosage_keywords)
    
    def process_query(self, query_context: QueryContext) -> AgentResponse:
        """ìš©ë²•/ìš©ëŸ‰ ì •ë³´ ì œê³µ"""
        query = query_context.processed_query
        
        # ìš©ë²•/ìš©ëŸ‰ ê´€ë ¨ í‚¤ì›Œë“œ ê°•í™” ê²€ìƒ‰
        dosage_query = f"ìš©ë²• ìš©ëŸ‰ ë³µìš©ë²• {query}"
        relevant_docs = self.get_relevant_documents(dosage_query, top_k=5)
        
        if not relevant_docs:
            return AgentResponse(
                agent_name=self.name,
                response="í•´ë‹¹ ì˜ì•½í’ˆì˜ ìš©ë²•/ìš©ëŸ‰ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                confidence=0.1,
                reasoning="ìš©ë²•/ìš©ëŸ‰ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í•¨",
                sources=[],
                metadata={"query_type": "dosage_info"}
            )
        
        # ìš©ë²•/ìš©ëŸ‰ ì •ë³´ ì¶”ì¶œ
        dosage_info = []
        for doc_id, content, product_name, distance in relevant_docs[:3]:
            confidence_score = 1 - distance
            
            # ìš©ë²•/ìš©ëŸ‰ ê´€ë ¨ ë¬¸ì¥ ì¶”ì¶œ
            sentences = content.split('.')
            dosage_sentences = []
            
            for sentence in sentences:
                if any(keyword in sentence for keyword in ['ìš©ë²•', 'ìš©ëŸ‰', 'ë³µìš©', 'íˆ¬ì—¬', 'í•˜ë£¨', 'íšŒ', 'ì •', 'ìº¡ìŠ', 'mg']):
                    dosage_sentences.append(sentence.strip())
            
            if dosage_sentences:
                dosage_text = '. '.join(dosage_sentences[:2])  # ìµœëŒ€ 2ë¬¸ì¥
                dosage_info.append({
                    'product': product_name,
                    'dosage': dosage_text,
                    'confidence': confidence_score
                })
        
        # ì‘ë‹µ ìƒì„±
        if dosage_info:
            response = "ìš©ë²•/ìš©ëŸ‰ ì •ë³´:\n\n"
            for i, info in enumerate(dosage_info, 1):
                response += f"{i}. {info['product']} (ì‹ ë¢°ë„: {info['confidence']:.2f})\n"
                response += f"   {info['dosage']}\n\n"
        else:
            # ì¼ë°˜ì ì¸ ì •ë³´ ì œê³µ
            response = "ìš©ë²•/ìš©ëŸ‰ ê´€ë ¨ ì •ë³´:\n\n"
            for i, (doc_id, content, product_name, distance) in enumerate(relevant_docs[:2], 1):
                confidence_score = 1 - distance
                summary = content[:150] + "..." if len(content) > 150 else content
                response += f"{i}. {product_name} (ê´€ë ¨ë„: {confidence_score:.2f})\n"
                response += f"   {summary}\n\n"
        
        response += "âš ï¸ ì •í™•í•œ ìš©ë²•/ìš©ëŸ‰ì€ ì˜ì‚¬ë‚˜ ì•½ì‚¬ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
        
        avg_confidence = sum(1 - doc[3] for doc in relevant_docs[:3]) / min(3, len(relevant_docs))
        
        return AgentResponse(
            agent_name=self.name,
            response=response.strip(),
            confidence=avg_confidence,
            reasoning="ìš©ë²•/ìš©ëŸ‰ í‚¤ì›Œë“œ ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰ ë° ì •ë³´ ì¶”ì¶œ",
            sources=[doc[2] for doc in relevant_docs[:3]],
            metadata={"query_type": "dosage_info", "found_dosage_info": len(dosage_info)}
        )

class SafetyAgent(BaseAgent):
    """ì•ˆì „ì„±/ì£¼ì˜ì‚¬í•­ ì „ë¬¸ ì—ì´ì „íŠ¸"""
    
    def __init__(self):
        super().__init__(
            name="SafetyAgent",
            description="ì•½ë¬¼ ì•ˆì „ì„± ë° ì£¼ì˜ì‚¬í•­ì„ ë¶„ì„í•˜ëŠ” ì—ì´ì „íŠ¸"
        )
    
    def can_handle(self, query_context: QueryContext) -> bool:
        """ì•ˆì „ì„± ê´€ë ¨ ì¿¼ë¦¬ì¸ì§€ íŒë‹¨"""
        # TODO: ì•ˆì „ì„± í‚¤ì›Œë“œ ë¶„ì„ ë¡œì§ êµ¬í˜„
        safety_keywords = ["ì£¼ì˜", "ë¶€ì‘ìš©", "ê¸ˆê¸°", "ì„ì‹ ", "ìˆ˜ìœ ", "ì–´ë¦°ì´", "ë…¸ì¸"]
        return any(keyword in query_context.processed_query for keyword in safety_keywords)
    
    def process_query(self, query_context: QueryContext) -> AgentResponse:
        """ì•ˆì „ì„± ì •ë³´ ë¶„ì„"""
        query = query_context.processed_query
        
        # ì•ˆì „ì„± ê´€ë ¨ í‚¤ì›Œë“œ ê°•í™” ê²€ìƒ‰
        safety_query = f"ì£¼ì˜ì‚¬í•­ ë¶€ì‘ìš© ê¸ˆê¸° ì•ˆì „ì„± {query}"
        relevant_docs = self.get_relevant_documents(safety_query, top_k=5)
        
        if not relevant_docs:
            return AgentResponse(
                agent_name=self.name,
                response="í•´ë‹¹ ì˜ì•½í’ˆì˜ ì•ˆì „ì„± ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                confidence=0.1,
                reasoning="ì•ˆì „ì„± ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í•¨",
                sources=[],
                metadata={"query_type": "safety_info"}
            )
        
        # ì•ˆì „ì„± ì •ë³´ ë¶„ë¥˜
        safety_categories = {
            "ë¶€ì‘ìš©": ["ë¶€ì‘ìš©", "ì´ìƒë°˜ì‘", "ë¶€ì‘ìš©", "side effect"],
            "ê¸ˆê¸°ì‚¬í•­": ["ê¸ˆê¸°", "ê¸ˆì§€", "í”¼í•´ì•¼", "í•˜ì§€ë§ˆ", "contraindication"],
            "ì£¼ì˜ì‚¬í•­": ["ì£¼ì˜", "ì¡°ì‹¬", "warning", "caution"],
            "íŠ¹ìˆ˜ì§‘ë‹¨": ["ì„ì‹ ", "ìˆ˜ìœ ", "ì–´ë¦°ì´", "ë…¸ì¸", "ê°„ì¥ì• ", "ì‹ ì¥ì• "]
        }
        
        # ì•ˆì „ì„± ì •ë³´ ì¶”ì¶œ
        safety_info = {}
        for doc_id, content, product_name, distance in relevant_docs[:3]:
            confidence_score = 1 - distance
            
            sentences = content.split('.')
            for category, keywords in safety_categories.items():
                category_sentences = []
                for sentence in sentences:
                    if any(keyword in sentence for keyword in keywords):
                        category_sentences.append(sentence.strip())
                
                if category_sentences:
                    if category not in safety_info:
                        safety_info[category] = []
                    safety_info[category].append({
                        'product': product_name,
                        'info': '. '.join(category_sentences[:2]),  # ìµœëŒ€ 2ë¬¸ì¥
                        'confidence': confidence_score
                    })
        
        # ì‘ë‹µ ìƒì„±
        response = "ì•ˆì „ì„± ë° ì£¼ì˜ì‚¬í•­ ì •ë³´:\n\n"
        
        if safety_info:
            for category, items in safety_info.items():
                response += f"ğŸ”¸ {category}:\n"
                for item in items[:2]:  # ì¹´í…Œê³ ë¦¬ë‹¹ ìµœëŒ€ 2ê°œ
                    response += f"   â€¢ {item['product']}: {item['info']}\n"
                response += "\n"
        else:
            # ì¼ë°˜ì ì¸ ì•ˆì „ì„± ì •ë³´ ì œê³µ
            response += "ê´€ë ¨ ì•ˆì „ì„± ì •ë³´:\n\n"
            for i, (doc_id, content, product_name, distance) in enumerate(relevant_docs[:2], 1):
                confidence_score = 1 - distance
                summary = content[:150] + "..." if len(content) > 150 else content
                response += f"{i}. {product_name} (ê´€ë ¨ë„: {confidence_score:.2f})\n"
                response += f"   {summary}\n\n"
        
        response += "âš ï¸ ì¤‘ìš”: ì˜ì•½í’ˆ ì‚¬ìš© ì „ ë°˜ë“œì‹œ ì˜ì‚¬ë‚˜ ì•½ì‚¬ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
        
        avg_confidence = sum(1 - doc[3] for doc in relevant_docs[:3]) / min(3, len(relevant_docs))
        
        return AgentResponse(
            agent_name=self.name,
            response=response.strip(),
            confidence=avg_confidence,
            reasoning="ì•ˆì „ì„± í‚¤ì›Œë“œ ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰ ë° ì¹´í…Œê³ ë¦¬ë³„ ì •ë³´ ë¶„ë¥˜",
            sources=[doc[2] for doc in relevant_docs[:3]],
            metadata={"query_type": "safety_info", "safety_categories": list(safety_info.keys())}
        )

class MultiAgentCoordinator:
    """ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì¡°ì •ì"""
    
    def __init__(self):
        self.agents: List[BaseAgent] = [
            SymptomAnalysisAgent(),
            DrugInteractionAgent(), 
            DosageAgent(),
            SafetyAgent()
        ]
        self.llm_client = None  # TODO: LLM í´ë¼ì´ì–¸íŠ¸ ì—°ê²°
    
    def analyze_query(self, query: str, user_context: Dict[str, Any] = None) -> QueryContext:
        """ì¿¼ë¦¬ ë¶„ì„ ë° ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
        # TODO: ì¿¼ë¦¬ ë¶„ì„ ë¡œì§ êµ¬í˜„
        return QueryContext(
            original_query=query,
            processed_query=query.lower(),
            query_type="general",
            user_context=user_context or {}
        )
    
    def select_agents(self, query_context: QueryContext) -> List[BaseAgent]:
        """ì ì ˆí•œ ì—ì´ì „íŠ¸ë“¤ ì„ íƒ"""
        selected_agents = []
        for agent in self.agents:
            if agent.can_handle(query_context):
                selected_agents.append(agent)
        
        # ê¸°ë³¸ì ìœ¼ë¡œ ìµœì†Œ 1ê°œ ì—ì´ì „íŠ¸ëŠ” ì„ íƒ
        if not selected_agents:
            selected_agents = [self.agents[0]]  # SymptomAnalysisAgentë¥¼ ê¸°ë³¸ìœ¼ë¡œ
        
        return selected_agents
    
    def aggregate_responses(self, responses: List[AgentResponse]) -> Dict[str, Any]:
        """ì—ì´ì „íŠ¸ ì‘ë‹µë“¤ì„ ì¢…í•©"""
        # TODO: ì‘ë‹µ ì¢…í•© ë¡œì§ êµ¬í˜„
        if not responses:
            return {"error": "No agent responses"}
        
        # ì‹ ë¢°ë„ ê¸°ë°˜ ê°€ì¤‘ í‰ê·  ë˜ëŠ” íˆ¬í‘œ ì‹œìŠ¤í…œ
        best_response = max(responses, key=lambda r: r.confidence)
        
        return {
            "primary_response": best_response.response,
            "confidence": best_response.confidence,
            "contributing_agents": [r.agent_name for r in responses],
            "all_sources": list(set(sum([r.sources for r in responses], []))),
            "detailed_responses": [
                {
                    "agent": r.agent_name,
                    "response": r.response,
                    "confidence": r.confidence,
                    "reasoning": r.reasoning
                } for r in responses
            ]
        }
    
    def process_query(self, query: str, user_context: Dict[str, Any] = None) -> Dict[str, Any]:
        """ë©”ì¸ ì¿¼ë¦¬ ì²˜ë¦¬ í•¨ìˆ˜"""
        try:
            # 1. ì¿¼ë¦¬ ë¶„ì„
            query_context = self.analyze_query(query, user_context)
            
            # 2. ì ì ˆí•œ ì—ì´ì „íŠ¸ ì„ íƒ
            selected_agents = self.select_agents(query_context)
            
            # 3. ê° ì—ì´ì „íŠ¸ì—ì„œ ì‘ë‹µ ìƒì„±
            responses = []
            for agent in selected_agents:
                try:
                    response = agent.process_query(query_context)
                    responses.append(response)
                except Exception as e:
                    print(f"Agent {agent.name} error: {e}")
            
            # 4. ì‘ë‹µ ì¢…í•©
            final_result = self.aggregate_responses(responses)
            
            return final_result
            
        except Exception as e:
            return {"error": f"Multi-agent processing failed: {e}"}

# ì‚¬ìš© ì˜ˆì‹œ ë° í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_multi_agent_system():
    """Multi-agent ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    coordinator = MultiAgentCoordinator()
    
    test_queries = [
        "ë‘í†µì— ì¢‹ì€ ì•½ì´ ìˆë‚˜ìš”?",
        "ê²Œë³´ë¦°ì •ê³¼ íƒ€ì´ë ˆë†€ì„ í•¨ê»˜ ë¨¹ì–´ë„ ë˜ë‚˜ìš”?", 
        "ì•„ìŠ¤í”¼ë¦°ì€ í•˜ë£¨ì— ëª‡ ë²ˆ ë¨¹ì–´ì•¼ í•˜ë‚˜ìš”?",
        "ì„ì‹  ì¤‘ì— ë¨¹ìœ¼ë©´ ì•ˆ ë˜ëŠ” ì•½ì€ ë¬´ì—‡ì¸ê°€ìš”?"
    ]
    
    print("ğŸ¤– Multi-Agent RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    for i, query in enumerate(test_queries, 1):
        print(f"\n[í…ŒìŠ¤íŠ¸ {i}] {query}")
        result = coordinator.process_query(query)
        print(f"ì‘ë‹µ: {result.get('primary_response', 'No response')}")
        print(f"ì°¸ì—¬ ì—ì´ì „íŠ¸: {result.get('contributing_agents', [])}")
        print(f"ì‹ ë¢°ë„: {result.get('confidence', 0):.2f}")
        print("-" * 30)

if __name__ == "__main__":
    test_multi_agent_system()